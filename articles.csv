0
"Python is an interpreted, high-level, general-purpose programming language. Created by Guido van Rossum and first released in 1991, Python's design philosophy emphasizes code readability with its notable use of significant whitespace. Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects.Python is dynamically typed and garbage-collected. It supports multiple programming paradigms, including structured (particularly, procedural), object-oriented, and functional programming. Python is often described as a ""batteries included"" language due to its comprehensive standard library.Python was conceived in the late 1980s as a successor to the ABC language. Python 2.0, released in 2000, introduced features like list comprehensions and a garbage collection system with reference counting.
Python 3.0, released in 2008, was a major revision of the language that is not completely backward-compatible, and much Python 2 code does not run unmodified on Python 3.
The Python 2 language was officially discontinued in 2020 (first planned for 2015), and ""Python 2.7.18 is the last Python 2.7 release and therefore the last Python 2 release."" No more security patches or other improvements will be released for it. With Python 2's end-of-life, only  Python 3.5.x and later are supported.
Python interpreters are available for many operating systems. A global community of programmers develops and maintains CPython, a free and open-source reference implementation. A non-profit organization, the Python Software Foundation, manages and directs resources for Python and CPython development.


== History ==

Python was conceived in the late 1980s by Guido van Rossum at Centrum Wiskunde & Informatica (CWI) in the Netherlands as a successor to the ABC language (itself inspired by SETL), capable of exception handling and interfacing with the Amoeba operating system. Its implementation began in December 1989. Van Rossum shouldered sole responsibility for the project, as the lead developer, until 12 July 2018, when he announced his ""permanent vacation"" from his responsibilities as Python's Benevolent Dictator For Life, a title the Python community bestowed upon him to reflect his long-term commitment as the project's chief decision-maker. He now shares his leadership as a member of a five-person steering council. In January 2019, active Python core developers elected Brett Cannon, Nick Coghlan, Barry Warsaw, Carol Willing and Van Rossum to a five-member ""Steering Council"" to lead the project.Python 2.0 was released on 16 October 2000 with many major new features, including a cycle-detecting garbage collector and support for Unicode.Python 3.0 was released on 3 December 2008. It was a major revision of the language that is not completely backward-compatible. Many of its major features were backported to Python 2.6.x and 2.7.x version series.  Releases of Python 3 include the 2to3 utility, which automates (at least partially) the translation of Python 2 code to Python 3.Python 2.7's end-of-life date was initially set at 2015 then postponed to 2020 out of concern that a large body of existing code could not easily be forward-ported to Python 3.


== Features and philosophy ==
Python is a multi-paradigm programming language. Object-oriented programming and structured programming are fully supported, and many of its features support functional programming and aspect-oriented programming (including by metaprogramming and metaobjects (magic methods)). Many other paradigms are supported via extensions, including design by contract and logic programming.Python uses dynamic typing and a combination of reference counting and a cycle-detecting garbage collector for memory management. It also features dynamic name resolution (late binding), which binds method and variable names during program execution.
Python's design offers some support for functional programming in the Lisp tradition. It has filter, map, and reduce functions; list comprehensions, dictionaries, sets, and generator expressions. The standard library has two modules (itertools and functools) that implement functional tools borrowed from Haskell and Standard ML.The language's core philosophy is summarized in the document The Zen of Python (PEP 20), which includes aphorisms such as:
Beautiful is better than ugly.
Explicit is better than implicit.
Simple is better than complex.
Complex is better than complicated.
Readability counts.Rather than having all of its functionality built into its core, Python was designed to be highly extensible. This compact modularity has made it particularly popular as a means of adding programmable interfaces to existing applications. Van Rossum's vision of a small core language with a large standard library and easily extensible interpreter stemmed from his frustrations with ABC, which espoused the opposite approach.Python strives for a simpler, less-cluttered syntax and grammar while giving developers a choice in their coding methodology. In contrast to Perl's ""there is more than one way to do it"" motto, Python embraces a ""there should be one—and preferably only one—obvious way to do it"" design philosophy. Alex Martelli, a Fellow at the Python Software Foundation and Python book author, writes that ""To describe something as 'clever' is not considered a compliment in the Python culture.""Python's developers strive to avoid premature optimization, and reject patches to non-critical parts of the CPython reference implementation that would offer marginal increases in speed at the cost of clarity. When speed is important, a Python programmer can move time-critical functions to extension modules written in languages such as C, or use PyPy, a just-in-time compiler. Cython is also available, which translates a Python script into C and makes direct C-level API calls into the Python interpreter.
An important goal of Python's developers is keeping it fun to use. This is reflected in the language's name—a tribute to the British comedy group Monty Python—and in occasionally playful approaches to tutorials and reference materials, such as examples that refer to spam and eggs (from a famous Monty Python sketch) instead of the standard foo and bar.A common neologism in the Python community is pythonic, which can have a wide range of meanings related to program style. To say that code is pythonic is to say that it uses Python idioms well, that it is natural or shows fluency in the language, that it conforms with Python's minimalist philosophy and emphasis on readability. In contrast, code that is difficult to understand or reads like a rough transcription from another programming language is called unpythonic.
Users and admirers of Python, especially those considered knowledgeable or experienced, are often referred to as Pythonistas.


== Syntax and semantics ==

Python is meant to be an easily readable language. Its formatting is visually uncluttered, and it often uses English keywords where other languages use punctuation. Unlike many other languages, it does not use curly brackets to delimit blocks, and semicolons after statements are optional. It has fewer syntactic exceptions and special cases than C or Pascal.


=== Indentation ===

Python uses whitespace indentation, rather than curly brackets or keywords, to delimit blocks. An increase in indentation comes after certain statements; a decrease in indentation signifies the end of the current block. Thus, the program's visual structure accurately represents the program's semantic structure. This feature is sometimes termed the off-side rule, which some other languages share, but in most languages indentation doesn't have any semantic meaning.


=== Statements and control flow ===
Python's statements include (among others):

The assignment statement (token '=', the equals sign). This operates differently than in traditional imperative programming languages, and this fundamental mechanism (including the nature of Python's version of variables) illuminates many other features of the language. Assignment in C, e.g., x = 2, translates to ""typed variable name x receives a copy of numeric value 2"". The (right-hand) value is copied into an allocated storage location for which the (left-hand) variable name is the symbolic address. The memory allocated to the variable is large enough (potentially quite large) for the declared type. In the simplest case of Python assignment, using the same example, x = 2, translates to ""(generic) name x receives a reference to a separate, dynamically allocated object of numeric (int) type of value 2."" This is termed binding the name to the object. Since the name's storage location doesn't contain the indicated value, it is improper to call it a variable. Names may be subsequently rebound at any time to objects of greatly varying types, including strings, procedures, complex objects with data and methods, etc. Successive assignments of a common value to multiple names, e.g., x = 2; y = 2; z = 2 result in allocating storage to (at most) three names and one numeric object, to which all three names are bound. Since a name is a generic reference holder it is unreasonable to associate a fixed data type with it. However at a given time a name will be bound to some object, which will have a type; thus there is dynamic typing.
The if statement, which conditionally executes a block of code, along with else and elif (a contraction of else-if).
The for statement, which iterates over an iterable object, capturing each element to a local variable for use by the attached block.
The while statement, which executes a block of code as long as its condition is true.
The try statement, which allows exceptions raised in its attached code block to be caught and handled by except clauses; it also ensures that clean-up code in a finally block will always be run regardless of how the block exits.
The raise statement, used to raise a specified exception or re-raise a caught exception.
The class statement, which executes a block of code and attaches its local namespace to a class, for use in object-oriented programming.
The def statement, which defines a function or method.
The with statement, from Python 2.5 released in September 2006, which encloses a code block within a context manager (for example, acquiring a lock before the block of code is run and releasing the lock afterwards, or opening a file and then closing it), allowing Resource Acquisition Is Initialization (RAII)-like behavior and replaces a common try/finally idiom.
The break statement, exits from the loop.
The continue statement, skips this iteration and continues with the next item.
The pass statement, which serves as a NOP. It is syntactically needed to create an empty code block.
The assert statement, used during debugging to check for conditions that ought to apply.
The yield statement, which returns a value from a generator function. From Python 2.5, yield is also an operator. This form is used to implement coroutines.
The import statement, which is used to import modules whose functions or variables can be used in the current program. There are three ways of using import: import <module name> [as <alias>] or from <module name> import * or from <module name> import <definition 1> [as <alias 1>], <definition 2> [as <alias 2>], ....
The print statement was changed to the print() function in Python 3.Python does not support tail call optimization or first-class continuations, and, according to Guido van Rossum, it never will. However, better support for coroutine-like functionality is provided in 2.5, by extending Python's generators. Before 2.5, generators were lazy iterators; information was passed unidirectionally out of the generator. From Python 2.5, it is possible to pass information back into a generator function, and from Python 3.3, the information can be passed through multiple stack levels.


=== Expressions ===
Some Python expressions are similar to languages such as C and Java, while some are not:

Addition, subtraction, and multiplication are the same, but the behavior of division differs. There are two types of divisions in Python. They are floor division (or integer division) // and floating point/division. Python also added the ** operator for exponentiation.
From Python 3.5, the new @ infix operator was introduced. It is intended to be used by libraries such as NumPy for matrix multiplication.
From Python 3.8, the syntax :=, called the 'walrus operator' was introduced. It assigns values to variables as part of a larger expression.
In Python, == compares by value, versus Java, which compares numerics by value and objects by reference. (Value comparisons in Java on objects can be performed with the equals() method.) Python's is operator may be used to compare object identities (comparison by reference). In Python, comparisons may be chained, for example a <= b <= c.
Python uses the words and, or, not for its boolean operators rather than the symbolic &&, ||, ! used in Java and C.
Python has a type of expression termed a list comprehension. Python 2.4 extended list comprehensions into a more general expression termed a generator expression.
Anonymous functions are implemented using lambda expressions; however, these are limited in that the body can only be one expression.
Conditional expressions in Python are written as x if c else y (different in order of operands from the c ? x : y operator common to many other languages).
Python makes a distinction between lists and tuples. Lists are written as [1, 2, 3], are mutable, and cannot be used as the keys of dictionaries (dictionary keys must be immutable in Python). Tuples are written as (1, 2, 3), are immutable and thus can be used as the keys of dictionaries, provided all elements of the tuple are immutable. The + operator can be used to concatenate two tuples, which does not directly modify their contents, but rather produces a new tuple containing the elements of both provided tuples. Thus, given the variable t initially equal to (1, 2, 3), executing t = t + (4, 5) first evaluates t + (4, 5), which yields (1, 2, 3, 4, 5), which is then assigned back to t, thereby effectively ""modifying the contents"" of t, while conforming to the immutable nature of tuple objects. Parentheses are optional for tuples in unambiguous contexts.
Python features sequence unpacking wherein multiple expressions, each evaluating to anything that can be assigned to (a variable, a writable property, etc.), are associated in the identical manner to that forming tuple literals and, as a whole, are put on the left hand side of the equal sign in an assignment statement. The statement expects an iterable object on the right hand side of the equal sign that produces the same number of values as the provided writable expressions when iterated through, and will iterate through it, assigning each of the produced values to the corresponding expression on the left.
Python has a ""string format"" operator %. This functions analogously to printf format strings in C, e.g. ""spam=%s eggs=%d"" % (""blah"", 2) evaluates to ""spam=blah eggs=2"". In Python 3 and 2.6+, this was supplemented by the format() method of the str class, e.g. ""spam={0} eggs={1}"".format(""blah"", 2). Python 3.6 added ""f-strings"": blah = ""blah""; eggs = 2; f'spam={blah} eggs={eggs}'.
Python has various kinds of string literals:
Strings delimited by single or double quote marks. Unlike in Unix shells, Perl and Perl-influenced languages, single quote marks and double quote marks function identically. Both kinds of string use the backslash (\) as an escape character. String interpolation became available in Python 3.6 as ""formatted string literals"".
Triple-quoted strings, which begin and end with a series of three single or double quote marks. They may span multiple lines and function like here documents in shells, Perl and Ruby.
Raw string varieties, denoted by prefixing the string literal with an r. Escape sequences are not interpreted; hence raw strings are useful where literal backslashes are common, such as regular expressions and Windows-style paths. Compare ""@-quoting"" in C#.
Python has array index and array slicing expressions on lists, denoted as a[key], a[start:stop] or a[start:stop:step]. Indexes are zero-based, and negative indexes are relative to the end. Slices take elements from the start index up to, but not including, the stop index. The third slice parameter, called step or stride, allows elements to be skipped and reversed. Slice indexes may be omitted, for example a[:] returns a copy of the entire list. Each element of a slice is a shallow copy.In Python, a distinction between expressions and statements is rigidly enforced, in contrast to languages such as Common Lisp, Scheme, or Ruby. This leads to duplicating some functionality. For example:

List comprehensions vs. for-loops
Conditional expressions vs. if blocks
The eval() vs. exec() built-in functions (in Python 2, exec is a statement); the former is for expressions, the latter is for statements.Statements cannot be a part of an expression, so list and other comprehensions or lambda expressions, all being expressions, cannot contain statements. A particular case of this is that an assignment statement such as a = 1 cannot form part of the conditional expression of a conditional statement. This has the advantage of avoiding a classic C error of mistaking an assignment operator = for an equality operator == in conditions: if (c = 1) { ... } is syntactically valid (but probably unintended) C code but if c = 1: ... causes a syntax error in Python.


=== Methods ===
Methods on objects are functions attached to the object's class; the syntax instance.method(argument) is, for normal methods and functions, syntactic sugar for Class.method(instance, argument). Python methods have an explicit self parameter to access instance data, in contrast to the implicit self (or this) in some other object-oriented programming languages (e.g., C++, Java, Objective-C, or Ruby).


=== Typing ===

Python uses duck typing and has typed objects but untyped variable names. Type constraints are not checked at compile time; rather, operations on an object may fail, signifying that the given object is not of a suitable type. Despite being dynamically typed, Python is strongly typed, forbidding operations that are not well-defined (for example, adding a number to a string) rather than silently attempting to make sense of them.
Python allows programmers to define their own types using classes, which are most often used for object-oriented programming. New instances of classes are constructed by calling the class (for example, SpamClass() or EggsClass()), and the classes are instances of the metaclass type (itself an instance of itself), allowing metaprogramming and reflection.
Before version 3.0, Python had two kinds of classes: old-style and new-style. The syntax of both styles is the same, the difference being whether the class object is inherited from, directly or indirectly (all new-style classes inherit from object and are instances of type). In versions of Python 2 from Python 2.2 onwards, both kinds of classes can be used. Old-style classes were eliminated in Python 3.0.
The long-term plan is to support gradual typing and from Python 3.5, the syntax of the language allows specifying static types but they are not checked in the default implementation, CPython. An experimental optional static type checker named mypy supports compile-time type checking.
^a Not directly accessible by name 


=== Mathematics ===
Python has the usual symbols for arithmetic operators (+, -, *, /), the floor division operator // and the modulo operation % (where the remainder can be negative,  e.g. 4 % -3 == -2). It also has ** for exponentiation, e.g. 5**3 == 125 and 9**0.5 == 3.0, and a matrix multiply operator @ . These operators work like in traditional math; with the same precedence rules, the operators infix ( + and - can also be unary to represent positive and negative numbers respectively).
Division between integers produces floating point results. The behavior of division has changed significantly over time:
Python 2.1 and earlier used C's division behavior. The / operator is integer division if both operands are integers, and floating-point division otherwise. Integer division rounds towards 0, e.g. 7/3 == 2 and -7/3 == -2.
Python 2.2 changed integer division to round towards negative infinity, e.g. 7/3 == 2 and -7/3 == -3. The floor division // operator was introduced. So 7//3 == 2, -7//3 == -3, 7.5//3 == 2.0 and -7.5//3 == -3.0. Adding from __future__ import division causes a module to use Python 3.0 rules for division (see next).
Python 3.0 changed / to always be floating-point division, e.g. 5/2 == 2.5.In Python terms, / is true division (or simply division), and // is floor division. / before version 3.0 is classic division.Rounding towards negative infinity, though different from most languages, adds consistency. For instance, it means that the equation (a + b)//b == a//b + 1 is always true. It also means that the equation b*(a//b) + a%b == a is valid for both positive and negative values of a. However, maintaining the validity of this equation means that while the result of a%b is, as expected, in the half-open interval [0, b), where b is a positive integer, it has to lie in the interval (b, 0] when b is negative.Python provides a round function for rounding a float to the nearest integer. For tie-breaking, Python 3 uses round to even: round(1.5) and round(2.5) both produce 2. Versions before 3 used round-away-from-zero: round(0.5) is 1.0, round(-0.5) is −1.0.Python allows boolean expressions with multiple equality relations in a manner that is consistent with general use in mathematics. For example, the expression a < b < c tests whether a is less than b and b is less than c. C-derived languages interpret this expression differently: in C, the expression would first evaluate a < b, resulting in 0 or 1, and that result would then be compared with c.Python uses arbitrary-precision arithmetic for all integer operations. The Decimal type/class in the decimal module provides decimal floating point numbers to a pre-defined arbitrary precision and several rounding modes. The Fraction class in the fractions module provides arbitrary precision for rational numbers.Due to Python's extensive mathematics library, and the third-party library NumPy that further extends the native capabilities, it is frequently used as a scientific scripting language to aid in problems such as numerical data processing and manipulation.


== Python programming examples ==
Hello world program:

Program to calculate the factorial of a positive integer:


== Libraries ==
Python's large standard library, commonly cited as one of its greatest strengths, provides tools suited to many tasks. For Internet-facing applications, many standard formats and protocols such as MIME and HTTP are supported. It includes modules for creating graphical user interfaces, connecting to relational databases, generating pseudorandom numbers, arithmetic with arbitrary-precision decimals, manipulating regular expressions, and unit testing.
Some parts of the standard library are covered by specifications (for example, the Web Server Gateway Interface (WSGI) implementation wsgiref follows PEP 333), but most modules are not. They are specified by their code, internal documentation, and test suites. However, because most of the standard library is cross-platform Python code, only a few modules need altering or rewriting for variant implementations.
As of November 2019, the Python Package Index (PyPI), the official repository for third-party Python software, contains over 200,000 packages with a wide range of functionality, including:

Automation
Data analytics
Databases
Documentation
Graphical user interfaces
Image processing
Machine learning
Mobile App
Multimedia
Networking
Scientific computing
System administration
Test frameworks
Text processing
Web frameworks
Web scraping


== Development environments ==

Most Python implementations (including CPython) include a read–eval–print loop (REPL), permitting them to function as a command line interpreter for which the user enters statements sequentially and receives results immediately.
Other shells, including IDLE and IPython, add further abilities such as improved auto-completion, session state retention and syntax highlighting.
As well as standard desktop integrated development environments, there are Web browser-based IDEs; SageMath (intended for developing science and math-related Python programs); PythonAnywhere, a browser-based IDE and hosting environment; and Canopy IDE, a commercial Python IDE emphasizing scientific computing.


== Implementations ==


=== Reference implementation ===
CPython is the reference implementation of Python. It is written in C, meeting the C89 standard with several select C99 features. It compiles Python programs into an intermediate bytecode which is then executed by its virtual machine. CPython is distributed with a large standard library written in a mixture of C and native Python. It is available for many platforms, including Windows (Vista and later; supported Windows XP and older, with by now unsupported Python 2.7) and most modern Unix-like systems. Platform portability was one of its earliest priorities, in Python 1 and 2 time-frame, even supporting VMS and OS/2; support has since been dropped for a lot of platforms.


=== Other implementations ===
PyPy is a fast, compliant interpreter of Python 2.7 and 3.6. Its just-in-time compiler brings a significant speed improvement over CPython but several libraries written in C cannot be used with it.Stackless Python is a significant fork of CPython that implements microthreads; it does not use the C memory stack, thus allowing massively concurrent programs. PyPy also has a stackless version.MicroPython and CircuitPython are Python 3 variants optimized for microcontrollers. This includes Lego Mindstorms EV3.


=== Unsupported implementations ===
Other just-in-time Python compilers have been developed, but are now unsupported:

Google began a project named Unladen Swallow in 2009, with the aim of speeding up the Python interpreter five-fold by using the LLVM, and of improving its multithreading ability to scale to thousands of cores, while ordinary implementations suffer from the global interpreter lock.
Psyco was a just-in-time specializing compiler that integrates with CPython and transforms bytecode to machine code at runtime. The emitted code is specialized for certain data types and is faster than standard Python code.In 2005, Nokia released a Python interpreter for the Series 60 mobile phones named PyS60. It includes many of the modules from the CPython implementations and some additional modules to integrate with the Symbian operating system. The project has been kept up-to-date to run on all variants of the S60 platform, and several third-party modules are available. The Nokia N900 also supports Python with GTK widget libraries, enabling programs to be written and run on the target device.


=== Cross-compilers to other languages ===
There are several compilers to high-level object languages, with either unrestricted Python, a restricted subset of Python, or a language similar to Python as the source language:

Cython compiles Python to C and C++.
Google's Grumpy (latest release in 2017) compiles Python 2 to Go.
IronPython follows a similar approach in order to run Python programs on the .NET Common Language Runtime.
Jython enables the use of the Java class library from a Python program.
MyHDL compiles Python to VHDL.
Nuitka compiles Python into C++.
Numba uses LLVM to compile Python to machine code.
Pyjs (latest release in 2012) compiles Python to JavaScript.
Pyrex (latest release in 2010) and Shed Skin (latest release in 2013) compile to C and C++ respectively.
Pythran compiles Python to C++.
RPython can be compiled to C, and is used to build the PyPy interpreter of Python.


=== Performance ===
A performance comparison of various Python implementations on a non-numerical (combinatorial) workload was presented at EuroSciPy '13. Python's performance compared to other programming languages has also been benchmarked by The Computer Language Benchmarks Game.


== Development ==
Python's development is conducted largely through the Python Enhancement Proposal (PEP) process, the primary mechanism for proposing major new features, collecting community input on issues and documenting Python design decisions. Python coding style is covered in PEP 8. Outstanding PEPs are reviewed and commented on by the Python community and the steering council.Enhancement of the language corresponds with development of the CPython reference implementation. The mailing list python-dev is the primary forum for the language's development. Specific issues are discussed in the Roundup bug tracker hosted at bugs.python.org. Development originally took place on a self-hosted source-code repository running Mercurial, until Python moved to GitHub in January 2017.CPython's public releases come in three types, distinguished by which part of the version number is incremented:

Backward-incompatible versions, where code is expected to break and need to be manually ported. The first part of the version number is incremented. These releases happen infrequently—for example, version 3.0 was released 8 years after 2.0.
Major or ""feature"" releases, about every 18 months, are largely compatible but introduce new features. The second part of the version number is incremented. Each major version is supported by bugfixes for several years after its release.
Bugfix releases, which introduce no new features, occur about every 3 months and are made when a sufficient number of bugs have been fixed upstream since the last release. Security vulnerabilities are also patched in these releases. The third and final part of the version number is incremented.Python 3.9 alpha1 was announced in November 2019 and with the adoption of a new yearly release cadence, the first release of 3.9 is slated for November 2020.Many alpha, beta, and release-candidates are also released as previews and for testing before final releases. Although there is a rough schedule for each release, they are often delayed if the code is not ready. Python's development team monitors the state of the code by running the large unit test suite during development, and using the BuildBot continuous integration system.The major academic conference on Python is PyCon. There are also special Python mentoring programmes, such as Pyladies.


== API documentation generators ==
Python API documentation generators include:

pydoc
Sphinx


== Naming ==
Python's name is derived from the British comedy group Monty Python, whom Python creator Guido van Rossum enjoyed while developing the language. Monty Python references appear frequently in Python code and culture; for example, the metasyntactic variables often used in Python literature are spam and eggs instead of the traditional foo and bar. The official Python documentation also contains various references to Monty Python routines.The prefix Py- is used to show that something is related to Python. Examples of the use of this prefix in names of Python applications or libraries include Pygame, a binding of SDL to Python (commonly used to create games); PyQt and PyGTK, which bind Qt and GTK to Python respectively; and PyPy, a Python implementation originally written in Python.


== Uses ==

Since 2003, Python has consistently ranked in the top ten most popular programming languages in the TIOBE Programming Community Index where, as of February 2020, it is the third most popular language (behind Java, and C). It was selected Programming Language of the Year in 2007, 2010, and 2018.An empirical study found that scripting languages, such as Python, are more productive than conventional languages, such as C and Java, for programming problems involving string manipulation and search in a dictionary, and determined that memory consumption was often ""better than Java and not much worse than C or C++"".Large organizations that use Python include Wikipedia, Google, Yahoo!, CERN, NASA, Facebook, Amazon, Instagram, Spotify and some smaller entities like ILM and ITA. The social news networking site Reddit is written entirely in Python.Python can serve as a scripting language for web applications, e.g., via mod_wsgi for the Apache web server. With Web Server Gateway Interface, a standard API has evolved to facilitate these applications. Web frameworks like Django, Pylons, Pyramid, TurboGears, web2py, Tornado, Flask, Bottle and Zope support developers in the design and maintenance of complex applications. Pyjs and IronPython can be used to develop the client-side of Ajax-based applications. SQLAlchemy can be used as a data mapper to a relational database. Twisted is a framework to program communications between computers, and is used (for example) by Dropbox.
Libraries such as NumPy, SciPy and Matplotlib allow the effective use of Python in scientific computing, with specialized libraries such as Biopython and Astropy providing domain-specific functionality. SageMath is a mathematical software with a notebook interface programmable in Python: its library covers many aspects of mathematics, including algebra, combinatorics, numerical mathematics, number theory, and calculus.Python has been successfully embedded in many software products as a scripting language, including in finite element method software such as Abaqus, 3D parametric modeler like FreeCAD, 3D animation packages such as 3ds Max, Blender, Cinema 4D, Lightwave, Houdini, Maya, modo, MotionBuilder, Softimage, the visual effects compositor Nuke, 2D imaging programs like GIMP, Inkscape, Scribus and Paint Shop Pro, and musical notation programs like scorewriter and capella. GNU Debugger uses Python as a pretty printer to show complex structures such as C++ containers. Esri promotes Python as the best choice for writing scripts in ArcGIS. It has also been used in several video games, and has been adopted as first of the three available programming languages in Google App Engine, the other two being Java and Go.Python is commonly used in artificial intelligence projects and machine learning projects with the help of libraries like TensorFlow, Keras, Pytorch and Scikit-learn. As a scripting language with modular architecture, simple syntax and rich text processing tools, Python is often used for natural language processing.Many operating systems include Python as a standard component. It ships with most Linux distributions, AmigaOS 4 (using Python 2.7), FreeBSD (as a package), NetBSD, OpenBSD (as a package) and macOS and can be used from the command line (terminal). Many Linux distributions use installers written in Python: Ubuntu uses the Ubiquity installer, while Red Hat Linux and Fedora use the Anaconda installer. Gentoo Linux uses Python in its package management system, Portage.
Python is used extensively in the information security industry, including in exploit development.Most of the Sugar software for the One Laptop per Child XO, now developed at Sugar Labs, is written in Python. The Raspberry Pi single-board computer project has adopted Python as its main user-programming language.
LibreOffice includes Python, and intends to replace Java with Python. Its Python Scripting Provider is a core feature since Version 4.0 from 7 February 2013.


== Languages influenced by Python ==
Python's design and philosophy have influenced many other programming languages:

Boo uses indentation, a similar syntax, and a similar object model.
Cobra uses indentation and a similar syntax, and its Acknowledgements document lists Python first among languages that influenced it.
CoffeeScript, a programming language that cross-compiles to JavaScript, has Python-inspired syntax.
ECMAScript/JavaScript borrowed iterators and generators from Python.
GDScript, a scripting language very similar to Python, built-in to the Godot game engine.
Go is designed for the ""speed of working in a dynamic language like Python"" and shares the same syntax for slicing arrays.
Groovy was motivated by the desire to bring the Python design philosophy to Java.
Julia was designed to be ""as usable for general programming as Python"".
Nim uses indentation and a similar syntax.
Ruby's creator, Yukihiro Matsumoto, has said: ""I wanted a scripting language that was more powerful than Perl, and more object-oriented than Python. That's why I decided to design my own language.""
Swift, a programming language developed by Apple, has some Python-inspired syntax.Python's development practices have also been emulated by other languages. For example, the practice of requiring a document describing the rationale for, and issues surrounding, a change to the language (in Python, a PEP) is also used in Tcl, Erlang, and Swift.


== See also ==

Python syntax and semantics
pip (package manager)


== References ==


=== Sources ===
""Python for Artificial Intelligence"". Wiki.python.org. 19 July 2012. Archived from the original on 1 November 2012. Retrieved 3 December 2012.
Paine, Jocelyn, ed. (August 2005). ""AI in Python"". AI Expert Newsletter. Amzi!. Archived from the original on 26 March 2012. Retrieved 11 February 2012.
""PyAIML 0.8.5 : Python Package Index"". Pypi.python.org. Retrieved 17 July 2013.
Russell, Stuart J. & Norvig, Peter (2009). Artificial Intelligence: A Modern Approach (3rd ed.). Upper Saddle River, NJ: Prentice Hall. ISBN 978-0-13-604259-4.


== Further reading ==
Downey, Allen B. (May 2012). Think Python: How to Think Like a Computer Scientist (Version 1.6.6 ed.). ISBN 978-0-521-72596-5.
Hamilton, Naomi (5 August 2008). ""The A-Z of Programming Languages: Python"". Computerworld. Archived from the original on 29 December 2008. Retrieved 31 March 2010.
Lutz, Mark (2013). Learning Python (5th ed.). O'Reilly Media. ISBN 978-0-596-15806-4.
Pilgrim, Mark (2004). Dive into Python. Apress. ISBN 978-1-59059-356-1.
Pilgrim, Mark (2009). Dive into Python 3. Apress. ISBN 978-1-4302-2415-0.
Summerfield, Mark (2009). Programming in Python 3 (2nd ed.). Addison-Wesley Professional. ISBN 978-0-321-68056-3.


== External links ==

Official website 
Python at Curlie"
"The programming language Python was conceived in the late 1980s, and its implementation was started in December 1989 by Guido van Rossum at CWI in the Netherlands as a successor to ABC capable of exception handling and interfacing with the Amoeba operating system. Van Rossum is Python's principal author, and his continuing central role in deciding the direction of Python is reflected in the title given to him by the Python community, Benevolent Dictator for Life (BDFL). (However, van Rossum stepped down as leader on July 12, 2018.) Python was named for the BBC TV show Monty Python's Flying Circus.Python 2.0 was released on October 16, 2000, with many major new features, including a cycle-detecting garbage collector (in addition to reference counting) for memory management and support for Unicode. However, the most important change was to the development process itself, with a shift to a more transparent and community-backed process.Python 3.0, a major, backwards-incompatible release, was released on December 3, 2008 after a long period of testing. Many of its major features have also been backported to the backwards-compatible, while by now unsupported, Python 2.6 and 2.7.


== Early history ==
In February 1991, Van Rossum published the code (labeled version 0.9.0) to alt.sources. Already present at this stage in development were classes with inheritance, exception handling, functions, and the core datatypes of list, dict, str and so on. Also in this initial release was a module system borrowed from Modula-3; Van Rossum describes the module as ""one of Python's major programming units"". Python's exception model also resembles Modula-3's, with the addition of an else clause. In 1994 comp.lang.python, the primary discussion forum for Python, was formed, marking a milestone in the growth of Python's userbase.


== Version 1 ==
Python reached version 1.0 in January 1994. The major new features included in this release were the functional programming tools lambda, map, filter and reduce. Van Rossum stated that ""Python acquired lambda, reduce(), filter() and map(), courtesy of a Lisp hacker who missed them and submitted working patches"".The last version released while Van Rossum was at CWI was Python 1.2.  In 1995, Van Rossum continued his work on Python at the Corporation for National Research Initiatives (CNRI) in Reston, Virginia from where he released several versions.
By version 1.4, Python had acquired several new features. Notable among these are the Modula-3 inspired keyword arguments (which are also similar to Common Lisp's keyword arguments) and built-in support for complex numbers. Also included is a basic form of data hiding by name mangling, though this is easily bypassed.During Van Rossum's stay at CNRI, he launched the Computer Programming for Everybody (CP4E) initiative, intending to make programming more accessible to more people, with a basic ""literacy"" in programming languages, similar to the basic English literacy and mathematics skills required by most employers. Python served a central role in this: because of its focus on clean syntax, it was already suitable, and CP4E's goals bore similarities to its predecessor, ABC. The project was funded by DARPA. As of 2007, the CP4E project is inactive, and while Python attempts to be easily learnable and not too arcane in its syntax and semantics, emailing non-programmers is not an active concern.


=== BeOpen ===
In 2000, the Python core development team moved to BeOpen.com to form the BeOpen PythonLabs team, under the direction of early Google alum Domenic Merenda. CNRI requested that a version 1.6 be released, summarizing Python's development up to the point at which the development team left CNRI. Consequently, the release schedules for 1.6 and 2.0 had a significant amount of overlap. Python 2.0 was the only release from BeOpen.com. After Python 2.0 was released by BeOpen.com, Guido van Rossum and the other PythonLabs developers joined Digital Creations.
The Python 1.6 release included a new CNRI license that was substantially longer than the CWI license that had been used for earlier releases.  The new license included a clause stating that the license was governed by the laws of the State of Virginia.  The Free Software Foundation argued that the choice-of-law clause was incompatible with the GNU General Public License.  BeOpen, CNRI and the FSF negotiated a change to Python's free software license that would make it GPL-compatible.  Python 1.6.1 is essentially the same as Python 1.6, with a few minor bug fixes, and with the new GPL-compatible license.


== Version 2 ==
Python 2.0, released October 2000, introduced list comprehensions, a feature borrowed from the functional programming languages SETL and Haskell. Python's syntax for this construct is very similar to Haskell's, apart from Haskell's preference for punctuation characters and Python's preference for alphabetic keywords. Python 2.0 also introduced a garbage collection system capable of collecting reference cycles.Python 2.1 was close to Python 1.6.1, as well as Python 2.0. Its license was renamed Python Software Foundation License. All code, documentation and specifications added, from the time of Python 2.1's alpha release on, is owned by the Python Software Foundation (PSF), a non-profit organization formed in 2001, modeled after the Apache Software Foundation. The release included a change to the language specification to support nested scopes, like other statically scoped languages. (The feature was turned off by default, and not required, until Python 2.2.)
Python 2.2 was released in December 2001; a major innovation was the unification of Python's types (types written in C) and classes (types written in Python) into one hierarchy. This single unification made Python's object model purely and consistently object oriented. Also added were generators which were inspired by Icon.Python 2.5 was released in September 2006  and introduced the with statement, which encloses a code block within a context manager (for example, acquiring a lock before the block of code is run and releasing the lock afterwards, or opening a file and then closing it), allowing Resource Acquisition Is Initialization (RAII)-like behavior and replacing a common try/finally idiom. Python 2.6 was released to coincide with Python 3.0, and included some features from that release, as well as a ""warnings"" mode that highlighted the use of features that were removed in Python 3.0. Similarly, Python 2.7 coincided with and included features from Python 3.1, which was released on June 26, 2009.
Parallel 2.x and 3.x releases then ceased, and Python 2.7 was the last release in the 2.x series. In November 2014, it was announced that Python 2.7 would be supported until 2020, but users were encouraged to move to Python 3 as soon as possible. Python 2.7 support ended on January 1, 2020, along with code freeze of 2.7 development branch. A final release, 2.7.18, occurred on April 20, 2020, and included fixes for critical bugs and release blockers. This marks the end-of-life of Python 2.


== Version 3 ==
Python 3.0 (also called ""Python 3000"" or ""Py3K"") was released on December 3, 2008. It was designed to rectify fundamental design flaws in the language—the changes required could not be implemented while retaining full backwards compatibility with the 2.x series, which necessitated a new major version number.  The guiding principle of Python 3 was: ""reduce feature duplication by removing old ways of doing things"".
Python 3.0 was developed with the same philosophy as in prior versions.  However, as Python had accumulated new and redundant ways to program the same task, Python 3.0 had an emphasis on removing duplicative constructs and modules, in keeping with ""There should be one— and preferably only one —obvious way to do it"".
Nonetheless, Python 3.0 remained a multi-paradigm language.  Coders could still follow object-oriented, structured, and functional programming paradigms, among others, but within such broad choices, the details were intended to be more obvious in Python 3.0 than they were in Python 2.x.


=== Compatibility ===
Python 3.0 broke backward compatibility, and much Python 2 code does not run unmodified on Python 3. Python's dynamic typing combined with the plans to change the semantics of certain methods of dictionaries, for example, made perfect mechanical translation from Python 2.x to Python 3.0 very difficult. A tool called ""2to3"" does the parts of translation that can be done automatically.  At this, 2to3 appeared to be fairly successful, though an early review noted that there were aspects of translation that such a tool would never be able to handle. Prior to the roll-out of Python 3, projects requiring compatibility with both the 2.x and 3.x series were recommended to have one source (for the 2.x series), and produce releases for the Python 3.x platform using 2to3. Edits to the Python 3.x code were discouraged for so long as the code needed to run on Python 2.x.  This is no longer recommended; as of 2012 the preferred approach was to create a single code base that can run under both Python 2 and 3 using compatibility modules.


=== Features ===
Some of the major changes included for Python 3.0 were:

Changing print so that it is a built-in function, not a statement.  This made it easier to change a module to use a different print function, as well as making the syntax more regular.  In Python 2.6 and 2.7 print() is available as a builtin but is masked by the print statement syntax, which can be disabled by entering from __future__ import print_function at the top of the file
Removal of the Python 2 input function, and the renaming of the raw_input function to input. Python 3's input function behaves like Python 2's raw_input function, in that the input is always returned as a string rather than being evaluated as an expression
Moving reduce (but not map or filter) out of the built-in namespace and into functools (the rationale being code that uses reduce is less readable than code that uses a for loop and accumulator variable)
Adding support for optional function annotations that can be used for informal type declarations or other purposes
Unifying the str/unicode types, representing text, and introducing a separate immutable bytes type; and a mostly corresponding mutable bytearray type, both of which represent arrays of bytes
Removing backward-compatibility features, including old-style classes, string exceptions, and implicit relative imports
A change in integer division functionality: in Python 2, 5 / 2 is 2; in Python 3, 5 / 2 is 2.5. (In both Python 2 (2.2 onwards) and Python 3, a separate operator exists to provide the old behavior: 5 // 2 is 2)Subsequent releases in the Python 3.x series have included additional, substantial new features; all ongoing development of the language is done in the 3.x series.


== Table of versions ==
Releases before numbered versions:

Implementation started - December, 1989
Internal releases at Centrum Wiskunde & Informatica - 1990Table notes:


=== Support ===


== See also ==
History of software engineering


== References ==


== External links ==
Guido Van Rossum blog on Python's History"
"The Rafael Python is a family of air-to-air missiles (AAMs) built by the Israeli weapons manufacturer Rafael Advanced Defense Systems, formerly RAFAEL Armament Development Authority. Originally starting with the Shafrir (Hebrew: שפריר‎, loosely translated as Dragonfly, a male form of inflection for Damselfly (שפרירית)) series, the Shafrir-1 missile was developed in 1959, followed by the Shafrir-2 in early 1970s. Subsequently, the missiles were given the western name of ""Python"" by the parent company for export purposes, starting with the Python-3 in 1978. Since then, it has been further developed and evolved into the Python-4, Python-5, Derby and also, the SPYDER, an advanced ground-based air-defence system. Currently, the missiles are in service with the armed forces of over fifteen countries from around the world.


== Design and development ==

In the 1950s, the Israeli Air Force (IAF) submitted requirements for a domestically-made air-to-air missile, to promote domestic defense industry and reduce reliance on imports. Rafael Armament Development Authority was contracted to develop the Shafrir (Hebrew: שפריר‎, loosely translated as Dragonfly, a male form of inflection for Damselfly (שפרירית)) in 1959. The missile entered operational status with Israeli Mirage jets in 1963, but the IAF was unhappy with its performance and no air combat kills were achieved with it during the Six-Day War, kills being made with guns instead. The improved Shafrir-2 was soon introduced in 1971, and it proved to be one of the most successful air-to-air missiles ever made. During the 1973 Yom Kippur War, the IAF launched 176 Shafrir-2 missiles, destroying 89 enemy aircraft. The Shafrir-2 was exported along with Israeli-made aircraft to South American countries.
After the Shafrir-2, the new missiles made by Rafael were given the western name of Python. This is why the next missile built by Rafael in early 1970s was named Python-3, but there is no Python-1 or Python-2 (they were Shafrir-1, Shafrir-2). The Python-3 has improved range and all-aspect attack ability, it proved itself before and during the 1982 Lebanon War, destroying 35 enemy aircraft. The People's Republic of China was impressed with its performance and license-built the Python-3 as the PiLi-8 (PL-8) AAM.Further improvements to the Python-3 led to the development of Python-4 in mid-1980s, which had limited ""fire-and-forget"" ability but added the option for helmet-sight guidance. In the 1990s Rafael started development on the Python-5 AAM, which was equipped with an advanced electro-optical imaging seeker with lock-on after-launch ability. The new missile was show-cased in 2003 Paris Air Show, and intended for service with IAF the F-15I Ra'am (""Thunder"") and the F-16I Sufa (""Storm"").
The Python-5 is said to have full sphere launch ability or is an all-aspect missile, meaning it can be launched at a target regardless of the target's location relative to the direction of the launching aircraft. It can lock onto targets after launch, even when they are up to 100 degrees off the boresight of the launching aircraft.


== Variants ==


=== Shafrir-1 ===
The Shafrir-1 was developed in 1959–1964 to fulfill IAF's requirement for a domestic air-to-air missile. It was intended to build the domestic defense industry's abilities, and reduce reliance on foreign imports. The fear of foreign dependence was later proven when France banned arms export to Israel.
The Shafrir-1 was intended for use on French-built Mirage jets. The first testing took place in France in 1963. However the missile's performance was so poor that they immediately started on the next improved version, the Shafrir-2.
Length: 250 cm (2.5 m)
Span: 55 cm
Diameter: 14 cm
Weight: 65 kg
Guidance: IR
Warhead: 11 kg blast explosive, later 30 kg
Range: 5 km
Speed: ??


=== Shafrir-2 ===
The Shafrir-2 was credited with 89 kills in the 1973 Yom Kippur War. During its whole service life, it is credited with a total of 106 kills.

Length: 250 cm (2.5 m)
Span: 55 cm
Diameter: 15 cm
Weight: 93 kg
Guidance: IR
Warhead: 11 kg
Range: 5 km
Speed: ??


=== Python-3 ===

The Python-3 is a much-improved AAM with all-aspect attack ability, higher speed, range, and performance. It performed well before and during the 1982 Lebanon War, scoring 35 (other sources claim 50) kills.China's PLAAF was quite impressed with this missile, and paid for licensed production as the PL-8 AAM in the 1980s. The program code named ""Number 8 Project"" (八号工程) and formally started on September 15, 1983. From March 1988 to April 1989, technology transfer to China was complete while license assembly and license built parts continued, and by the spring of 1989, the complete domestic Chinese built missile received state certification. The major supplier of the missile was Xi'an Eastern Machinery Factory (西安东方机械厂) located at Xi'an, and China is also reported to have developed a helmet-mounted sight (HMS) system for the PL-8.
Length: 295 cm
Span: 80 cm
Diameter: 16 cm
Weight: 120 kg
Guidance: IR
Warhead: 11 kg, active proximity fuse
Range: 15 km
Speed: Mach 3.5


=== Python-4 ===

The Python-4 is a 4th generation AAM with all-aspect attack ability, and integration with a helmet-mounted sight (HMS) system. It entered service in the 1990s, and like its predecessor Python-3, it is integrated with the Elbit Systems DASH (Display And Sight Helmet) HMS system for Israeli F-15s and F-16s, Chilean F-16s (MLU and C/D block 50/52 plus), F-5E/F Tiger III, South American Kfirs and the SAAB JAS 39 Gripen. The missile's seeker is reported to use dual band technology array similar to that of US FIM-92 Stinger (infrared homing and ultraviolet), with IRCCM (IR ECCM) ability to reduce background IR radiation to reduce the effectiveness of enemy flares.
Length: 300 cm
Span: 50 cm
Diameter: 16 cm
Weight: 120 kg
Guidance: IR
Warhead: 11 kg, active laser proximity fuse with back-up impact fuse
Range: 15 km
Speed: Mach 3.5 or more


=== Python-5 ===

The Python-5 is currently the most capable air-to-air missile in Israel's inventory and one of the most advanced AAMs in the world. As a beyond-visual-range missile, it is capable of ""lock-on after launch"" (LOAL), and has full-sphere/all-direction (including rearward) attack ability. The missile features an advanced electro-optical infrared homing seeker which scans the target area for hostile aircraft, then locks-on for terminal chase. With a total of eighteen control surfaces and careful design, the resulting missile is supposed to be as maneuverable as any other air-to-air missiles with thrust vectoring nozzles. The Python-5 was first used in combat during the 2006 Lebanon War, when it was used by F-16 Fighting Falcons to destroy two Iranian-made Ababil UAVs used by the Hezbollah.
Length: 310 cm
Span: 64 cm
Diameter: 16 cm
Weight: 105 kg
Guidance: IR + electro-optical imaging
Warhead: 11 kg
Range: >20 km
Speed: Mach 4


== Other Python developments ==


=== Derby ===

Also known as the Alto, the Derby missile is a BVR, medium-range (~50 km) active radar homing missile. Though technically not part of the ""Python"" family, the missile is an enlarged version of the Python-4 with an active-radar seeker.
Length: 362 cm
Span: 64 cm
Diameter: 16 cm
Weight: 118 kg
Guidance: Active Radar
Warhead: 23 kg
Range: 50 km
Speed: Mach 4


==== I-Derby ER ====
In June 2015, Rafael confirmed the existence of the I-Derby-ER, an extended range version of the Derby that increases range to 54 nmi (62 mi; 100 km), after a ""Python 6"" version based on an air-launched Stunner missile was abandoned.  To achieve greater range, a dual-pulse solid rocket motor is added, where the secondary pulse of energy as the missile nears the target extends flight time.  It also combines the seeker and fuse into an integrated sensor and fusing system to make room for the new motor.In May 2019, it was reported that India was planning to arm its Su-30MKI fighters with I-Derby ER missiles to replace its R-77 missiles. Previously, in 2018, it had already been selected for Indian Air Force's HAL Tejas fighter.


=== SPYDER ===

The SPYDER (Surface-to-air PYthon and DERby) is an advanced ground based anti-aircraft missile system developed by Rafael that uses surface-to-air versions of the Python-5 and Derby missiles.


== Operators ==


=== Current operators ===
 Argentina – Shafrir-2 (350 missiles, delivered 1981) and Python-4.
 Bolivia – Python-3.
 Brazil – Python-3 (400 missiles, delivered 2001), Python-4 and Derby (200 missiles each, all delivered 2011).
 Chile – Shafrir-2 (50 missiles, delivered 1978), Python-3 (120 missiles, delivered 1997), Python-4 (280 missiles, delivered 2011) and Derby (60 missiles, delivered 2003).
 People's Republic of China – Python-3 (3000 missiles, delivered 1991–2000, local designation PiLi-8 (PL-8)).
 Colombia – Shafrir-2 (80 missiles, delivered 1989), Python-3/4 (75 missiles each, all delivered 2005), Python-5 (100 missiles, delivered 2011) and Derby (40 missiles, delivered 2010).
 Ecuador – Shafrir-2 (75 missiles, delivered 1984), Python-3/Python-4 (60 missiles, delivered 1996), Python-5 (50 missiles, delivered 2001) and Derby (60 missiles, delivered 2003).
 El Salvador – Shafrir.
 Georgia - Python-5 and Derby missiles delivered as part of SPYDER system.
 Honduras – Shafrir-2 (100 missiles, delivered 1978).
 India – Python-4 and Python-5 (100 missiles, delivered 2007) and Derby.
 Israel – Shafrir-1/2, Python-4 and Python-5, (primary user, local designation Zephyr).
 Philippines - Python-5 and Derby with solid rocket booster (part of SPYDER air defense system). 
 Romania – Python-3.
 Singapore – Python-4 (600 missiles, delivered 2004).
 South Africa – Python-3 (local designation V3S Snake, delivered 1989 and retired in April 2008), Derby (Local designation as R-Darter or V4).
 Republic of China (Taiwan) – Shafrir-2 (450 missiles, delivered 1977).
 Thailand – Python-4 (400–500 missiles, delivered 1990).
 Venezuela – Python-4 (54 missiles, delivered 2004).


== See also ==
List of munitions used by the Israeli Air Force
AIM-9 Sidewinder
IRIS-T
ASRAAM
R-73 (missile)
Astra (missile)


== References ==


== External links ==
Python-5 brochure at Rafael's official site
Derby brochure at Rafael's official site
Shafrir-1/2 on GlobalSecurity.org
Python-3/4/5 on GlobalSecurity.org
Derby on GlobalSecurity.org
Federation of American Scientists' website on Python-3
Federation of American Scientists' website on Python-4
Federation of American Scientists' website on Derby
Fourth Generation AAMs – The Rafael Python 4"
"In computing, a shebang is the character sequence consisting of the characters number sign and exclamation mark (#!) at the beginning of a script. It is also called sha-bang, hashbang, pound-bang, or hash-pling.When a text file with a shebang is used as if it is an executable in a Unix-like operating system, the program loader mechanism parses the rest of the file's initial line as an interpreter directive. The loader executes the specified interpreter program, passing to it as an argument the path that was initially used when attempting to run the script, so that the program may use the file as input data. For example, if a script is named with the path path/to/script, and it starts with the following line, #!/bin/sh, then the program loader is instructed to run the program /bin/sh, passing path/to/script as the first argument.
In Linux, this behavior is the result of both kernel and user-space code.The shebang line is usually ignored by the interpreter, because the ""#"" character is a comment marker in many scripting languages; some language interpreters that do not use the hash mark to begin comments still may ignore the shebang line in recognition of its purpose.


== Syntax ==
The form of a shebang interpreter directive is as follows:
#!interpreter [optional-arg]

in which interpreter is an absolute path to an executable program.
The optional argument is a string representing a single argument. White space after #! is optional.
In Linux, the file specified by interpreter can be executed if it has the execute right and contains code which the kernel can execute directly, if it has a wrapper defined for it via sysctl (such as for executing Microsoft .exe binaries using wine), or if it contains a shebang. On Linux and Minix, an interpreter can also be a script. A chain of shebangs and wrappers yields a directly executable file that gets the encountered scripts as parameters in reverse order. For example, if file /bin/A is an executable file in ELF format, file /bin/B contains the shebang #!/bin/A optparam, and file /bin/C contains the shebang #!/bin/B, then executing file /bin/C resolves to /bin/B /bin/C, which finally resolves to /bin/A optparam /bin/B /bin/C.
In Solaris and Darwin derived operating systems (such as macOS) the file specified by interpreter must be an executable binary and cannot itself be a script.


== Examples ==
Some typical shebang lines:

#!/bin/sh – Execute the file using the Bourne shell, or a compatible shell, assumed to be in the /bin directory
#!/bin/bash – Execute the file using the Bash shell
#!/usr/bin/env python3 – Execute with a Python interpreter, using the program search path to find it
#!/bin/false – Do nothing, but return a non-zero exit status, indicating failure. Used to prevent stand-alone execution of a script file intended for execution in a specific context, such as by the . command from sh/bash, source from csh/tcsh, or as a .profile, .cshrc, or .login file.Shebang lines may include specific options that are passed to the interpreter. However, implementations vary in the parsing behavior of options; for portability, only one option should be specified without any embedded whitespace. Further portability guidelines are found below.


== Purpose ==
Interpreter directives allow scripts and data files to be used as commands, hiding the details of their implementation from users and other programs, by removing the need to prefix scripts with their interpreter on the command line.
A Bourne shell script that is identified by the path some/path/to/foo, has the initial line,

#!/bin/sh -x

and is executed with parameters bar and baz as

some/path/to/foo bar baz

provides a similar result as having actually executed the following command line instead:

/bin/sh -x some/path/to/foo bar baz

If /bin/sh specifies the Bourne shell, then the end result is that all of the shell commands in the file some/path/to/foo are executed with the positional variables $1 and $2 having the values bar and baz, respectively. Also, because the initial number sign is the character used to introduce comments in the Bourne shell language (and in the languages understood by many other interpreters), the whole shebang line is ignored by the interpreter.
However, it is up to the interpreter to ignore the shebang line; thus, a script consisting of the following two lines simply echos both lines to standard output when run:

#!/bin/cat
Hello world!


=== Strengths ===
When compared to the use of global association lists between file extensions and the interpreting applications, the interpreter directive method allows users to use interpreters not known at a global system level, and without administrator rights. It also allows specific selection of interpreter, without overloading the filename extension namespace (where one file extension refers to more than one file type), and allows the implementation language of a script to be changed without changing its invocation syntax by other programs. Invokers of the script need not know what the implementation language is as the script itself is responsible for specifying the interpreter to use.


== Portability ==


=== Program location ===
Shebangs must specify absolute paths (or paths relative to current working directory) to system executables; this can cause problems on systems that have a non-standard file system layout. Even when systems have fairly standard paths, it is quite possible for variants of the same operating system to have different locations for the desired interpreter. Python, for example, might be in /usr/bin/python3, /usr/local/bin/python3, or even something like /home/username/bin/python3 if installed by an ordinary user.
A similar problem exists for the POSIX shell, since POSIX only required its name to be sh, but did not mandate a path. A common value is /bin/sh, but some systems such as Solaris have the POSIX-compatible shell at /usr/xpg4/bin/sh. In many Linux systems, /bin/sh is a hard or symbolic link to /bin/bash, the Bourne Again shell (BASH). Using bash-specific syntax while maintaining a shebang pointing to sh is also not portable.Because of this it is sometimes required to edit the shebang line after copying a script from one computer to another because the path that was coded into the script may not apply on a new machine, depending on the consistency in past convention of placement of the interpreter. For this reason and because POSIX does not standardize path names, POSIX does not standardize the feature.
Often, the program /usr/bin/env can be used to circumvent this limitation by introducing a level of indirection. #! is followed by /usr/bin/env, followed by the desired command without full path, as in this example:

#!/usr/bin/env sh

This mostly works because the path /usr/bin/env is commonly used for the env utility,
and it invokes the first sh found in the user's $PATH, typically /bin/sh.
On a system with setuid script support this will reintroduce the race eliminated by the /dev/fd workaround described below. There are still some portability issues with OpenServer 5.0.6 and Unicos 9.0.2 which have only /bin/env and no /usr/bin/env.


=== Character interpretation ===
Another portability problem is the interpretation of the command arguments.
Some systems, including Linux, do not split up the arguments; for example, when running the script with the first line like,

#!/usr/bin/env python3 -c

That is, python3 -c will be passed as one argument to /usr/bin/env, rather than two arguments. Cygwin also behaves this way.
Complex interpreter invocations are possible through the use of an additional wrapper. FreeBSD 6.0 (2005) introduced a -S option to its env as it changed the shebang-reading behavior to non-splitting. This option tells env to split the string itself. The GNU env utility since coreutil 8.30 (2018) also includes this feature. Although using this option mitigates the portability issue on the kernel end with splitting, it adds the requirement that env supports this particular extension.
Another problem is scripts containing a carriage return character immediately after the shebang line, perhaps as a result of being edited on a system that uses DOS line breaks, such as Microsoft Windows. Some systems interpret the carriage return character as part of the interpreter command, resulting in an error message.


=== Magic number ===
The shebang is actually a human-readable instance of a magic number in the executable file, the magic byte string being 0x23 0x21, the two-character encoding in ASCII of #!. This magic number is detected by the ""exec"" family of functions, which determine whether a file is a script or an executable binary. The presence of the shebang will result in the execution of the specified executable, usually an interpreter for the script's language. It has been claimed that some old versions of Unix expect the normal shebang to be followed by a space and a slash (#! /), but this appears to be untrue; rather, blanks after the shebang have traditionally been allowed, and sometimes documented with a space (see the 1980 email in history section below).
The shebang characters are represented by the same two bytes in extended ASCII encodings, including UTF-8, which is commonly used for scripts and other text files on current Unix-like systems. However, UTF-8 files may begin with the optional byte order mark (BOM); if the ""exec"" function specifically detects the bytes 0x23 and 0x21, then the presence of the BOM (0xEF 0xBB 0xBF) before the shebang will prevent the script interpreter from being executed. Some authorities recommend against using the byte order mark in POSIX (Unix-like) scripts, for this reason and for wider interoperability and philosophical concerns. Additionally, a byte order mark is not necessary in UTF-8, as that encoding does not have endianness issues; it serves only to identify the encoding as UTF-8.


== Etymology ==
An executable file starting with an interpreter directive is simply called a script, often prefaced with the name or general classification of the intended interpreter. The name shebang for the distinctive two characters may have come from an inexact contraction of SHArp bang or haSH bang, referring to the two typical Unix names for them. Another theory on the sh in shebang is that it is from the default shell sh, usually invoked with shebang. This usage was current by December 1989, and probably earlier.


== History ==
The shebang was introduced by Dennis Ritchie between Edition 7 and 8 at Bell Laboratories. It was also added to the BSD releases from Berkeley's Computer Science Research (present at 2.8BSD and activated by default by 4.2BSD). As AT&T Bell Laboratories Edition 8 Unix, and later editions, were not released to the public, the first widely known appearance of this feature was on BSD.
The lack of an interpreter directive, but support for shell scripts, is apparent in the documentation from Version 7 Unix in 1979, which describes instead a facility of the Bourne shell where files with execute permission would be handled specially by the shell, which would (sometimes depending on initial characters in the script, such as "":"" or ""#"") spawn a subshell which would interpret and run the commands contained in the file. In this model, scripts would only behave as other commands if called from within a Bourne shell. An attempt to directly execute such a file via the operating system's own exec() system trap would fail, preventing scripts from behaving uniformly as normal system commands.
In later versions of Unix-like systems, this inconsistency was removed. Dennis Ritchie introduced kernel support for interpreter directives in January 1980, for Version 8 Unix, with the following description:

From uucp Thu Jan 10 01:37:58 1980
>From dmr Thu Jan 10 04:25:49 1980 remote from research
The system has been changed so that if a file being executed
begins with the magic characters #! , the rest of the line is understood
to be the name of an interpreter for the executed file.
Previously (and in fact still) the shell did much of this job;
it automatically executed itself on a text file with executable mode
when the text file's name was typed as a command.
Putting the facility into the system gives the following
benefits.
1) It makes shell scripts more like real executable files,
because they can be the subject of 'exec.'
2) If you do a 'ps' while such a command is running, its real
name appears instead of 'sh'.
Likewise, accounting is done on the basis of the real name.
3) Shell scripts can be set-user-ID.
4) It is simpler to have alternate shells available;
e.g. if you like the Berkeley csh there is no question about
which shell is to interpret a file.
5) It will allow other interpreters to fit in more smoothly.
To take advantage of this wonderful opportunity,
put

  #! /bin/sh
at the left margin of the first line of your shell scripts.
Blanks after ! are OK.  Use a complete pathname (no search is done).
At the moment the whole line is restricted to 16 characters but
this limit will be raised.

Kernel support for interpreter directives spread to other versions of Unix, and one modern implementation can be seen in the Linux kernel source in fs/binfmt_script.c.This mechanism allows scripts to be used in virtually any context normal compiled programs can be, including as full system programs, and even as interpreters of other scripts. As a caveat, though, some early versions of kernel support limited the length of the interpreter directive to roughly 32 characters (just 16 in its first implementation), would fail to split the interpreter name from any parameters in the directive, or had other quirks.  Additionally, some modern systems allow the entire mechanism to be constrained or disabled for security purposes (for example, set-user-id support has been disabled for scripts on many systems).
Note that, even in systems with full kernel support for the #! magic number, some scripts lacking interpreter directives (although usually still requiring execute permission) are still runnable by virtue of the legacy script handling of the Bourne shell, still present in many of its modern descendants. Scripts are then interpreted by the user's default shell.


== See also ==
binfmt_misc
CrunchBang Linux
File association
URI fragment


== References ==


== External links ==
Details about the shebang mechanism on various Unix flavours
#! - the Unix truth as far as I know it (a more generic approach)
FOLDOC shebang article"
"Setuptools is a package development process library designed to facilitate packaging Python projects by enhancing the Python standard library distutils (distribution utilities). It includes:

Python package and module definitions
Distribution package metadata
Test hooks
Project installation
Platform-specific details
Python 3 support


== History ==
In 2013, Distribute, a fork of Setuptools, was merged back into Setuptools 0.7.


== Package format ==

Python wheels have replaced eggs.Python eggs are a way of bundling additional information with a Python project, that allows the project's dependencies to be checked and satisfied at runtime, as well as allowing projects to provide plugins for other projects.

""Eggs are to Pythons as Jars are to Java...""


== Package manager ==
Python pip has replaced EasyInstall.EasyInstall is a package manager for Python that provides a standard format for distributing Python programs and libraries (based on the Python Eggs format). EasyInstall is a module bundled with Setuptools. It is analogous to RubyGems for Ruby.
EasyInstall is not a fully fledged package manager. It cannot list local packages nor update them all. Pip and Python Package Manager (PyPM) are Python applications designed to fulfill a similar role as EasyInstall. The Distribute fork was created specifically due to the lack of progress in EasyInstall development.By default, EasyInstall looks in the Python Package Index (PyPI) for the desired packages and uses the metadata there to download and install the package and its dependencies.


== See also ==

Buildout - software build tool designed to handle Python package dependencies
Software repository


== References ==


== External links ==
Official website 
PyPI project page
setuptools on GitHub"
"RabbitMQ is an open-source message-broker software (sometimes called message-oriented middleware) that originally implemented the Advanced Message Queuing Protocol (AMQP) and has since been extended with a plug-in architecture to support Streaming Text Oriented Messaging Protocol (STOMP), MQ Telemetry Transport (MQTT), and other protocols.The RabbitMQ server program is written in the Erlang programming language and is built on the Open Telecom Platform framework for clustering and failover. Client libraries to interface with the broker are available for all major programming languages.


== History ==
Rabbit Technologies Ltd. originally developed RabbitMQ.
Rabbit Technologies started as a joint venture between LShift and CohesiveFT in 2007, and was acquired in April 2010 by SpringSource, a division of VMware. 
The project became part of Pivotal Software in May 2013.The source code is released under the Mozilla Public License.
The project consists of:

The RabbitMQ exchange server itself
Gateways for AMQP, HTTP, STOMP, and MQTT protocols
AMQP client libraries for Java, .NET Framework, and Erlang. (AMQP clients for other languages are available from other vendors.)
A plug-in platform for custom additions, with a pre-defined collection of supported plug-ins, including:
A ""Shovel"" plug-in that takes care of moving or copying (replicating) messages from one broker to another.
A ""Federation"" plug-in that enables efficient sharing of messages between brokers (at the exchange level).
A ""Management"" plug-in that enables monitoring and control of brokers and clusters of brokers.


== Examples ==
This section gives sample programs written in Python (using the pika package) for sending and receiving messages using a queue.


=== Sending ===
The following code fragment establishes a connection, makes sure the recipient queue exists, then sends a message and finally closes the connection.


=== Receiving ===
Similarly, the following program receives messages from the queue and prints them on the screen:
(Note: This example does not acknowledge receipt of the message.)


== See also ==


== References ==


== Further reading ==
Joern Barthel (2009-09-13). ""Getting started with AMQP and RabbitMQ"". InfoQ.
Peter Cooper (2009-04-09). ""RabbitMQ - A Fast, Reliable Queuing Option for Rubyists"". RubyInside.
RabbitMQ: An Open Source Messaging Broker That Just Works. Google Tech Talks. 2008-09-25.


== External links ==
Official website"
"Beautiful Soup is a Python package for parsing HTML and XML documents (including having malformed markup, i.e. non-closed tags, so named after tag soup). It creates a parse tree for parsed pages that can be used to extract data from HTML, which is useful for web scraping.It is available for Python 2.7 and Python 3.


== Code example ==


== Advantages and Disadvantages ==
This table summarizes the advantages and disadvantages of each parser library


== Release ==
Beautiful Soup 3 was the official release line of Beautiful Soup from May 2006 to March 2012. The current release is Beautiful Soup 4.9.1 (May 17, 2020). You can install Beautiful Soup 4 with pip install beautifulsoup4.


== See also ==
Comparison of HTML parsers


== References =="
"Datagram Transport Layer Security (DTLS) is a communications protocol that provides security for datagram-based applications by allowing them to communicate in a way that is designed to prevent eavesdropping, tampering, or message forgery. The DTLS protocol is based on the stream-oriented Transport Layer Security (TLS) protocol and is intended to provide similar security guarantees. The DTLS protocol datagram preserves the semantics of the underlying transport—the application does not suffer from the delays associated with stream protocols, but because it uses UDP, the application has to deal with packet reordering, loss of datagram and data larger than the size of a datagram network packet. Because DTLS uses UDP rather than TCP, it avoids the ""TCP meltdown problem"", when being used to create a VPN tunnel.


== Definition ==
The following documents define DTLS:

RFC 6347 for use with User Datagram Protocol (UDP),
RFC 5238 for use with Datagram Congestion Control Protocol (DCCP),
RFC 5415 for use with Control And Provisioning of Wireless Access Points (CAPWAP),
RFC 6083 for use with Stream Control Transmission Protocol (SCTP) encapsulation,
RFC 5764 for use with Secure Real-time Transport Protocol (SRTP) subsequently called DTLS-SRTP in a draft with Secure Real-Time Transport Control Protocol (SRTCP).DTLS 1.0 is based on TLS 1.1, and DTLS 1.2 is based on TLS 1.2. There is no DTLS 1.1; that version number was skipped in order to harmonize version numbers with TLS.


== Implementations ==


=== Libraries ===


=== Applications ===
Cisco AnyConnect VPN Client uses TLS and invented DTLS based VPN.
OpenConnect is an open source AnyConnect-compatible client and ocserv server that supports (D)TLS. 
Cisco InterCloud Fabric uses DTLS to form a tunnel between private and public/provider compute environments
ZScaler 2.0 (a popular ZTN solution) uses DTLS for tunneling 
F5 Networks Edge VPN Client uses TLS and DTLS
Citrix Systems NetScaler uses DTLS to secure UDP
Web browsers: Google Chrome, Opera and Firefox support DTLS-SRTP for WebRTC


== Vulnerabilities ==
In February 2013 two researchers from Royal Holloway, University of London discovered an attack which allowed them to recover plaintext from a DTLS connection using the OpenSSL implementation of DTLS when Cipher Block Chaining mode encryption was used.


== See also ==

ZRTP
Reliable User Datagram Protocol
QUIC


== References ==


== External links ==
""Transport Layer Security (tls) - Charter"". IETF.
Modadugu, Nagendra; Rescorla, Eric (2003-11-21). ""The Design and Implementation of Datagram TLS"" (PDF). Stanford Crypto Group. Retrieved 2013-03-17.
AlFardan, Nadhem J.; Paterson, Kenneth G. ""Plaintext-Recovery Attacks Against Datagram TLS"" (PDF). Retrieved 2013-11-25.
Gibson, Steve; Laporte, Leo (2012-11-28). ""Datagram Transport Layer Security"". Security Now 380. Retrieved 2013-03-17. Skip to 1:07:14.
Robin Seggelmann's Sample Code: echo, character generator, and discard client/servers.

This article is based on material taken from  the Free On-line Dictionary of Computing  prior to 1 November 2008 and incorporated under the ""relicensing"" terms of the GFDL, version 1.3 or later."
"pip is a de facto standard package-management system used to install and manage software packages written in Python. Many packages can be found in the default source for packages and their dependencies — Python Package Index (PyPI).Most distributions of Python come with pip preinstalled. Python 2.7.9 and later (on the python2 series), and Python 3.4 and later include pip (pip3 for Python 3) by default.First introduced as pyinstall in 2008 by Ian Bicking (the creator of the virtualenv package) as an alternative to easy_install, pip was chosen as the new name from one of several suggestions that the creator received on his blog post. According to Bicking himself, the name is an acronym for ""Pip Installs Packages"". In 2011, the Python Packaging Authority (PyPA) was created to take over the maintenance of pip and virtualenv from Bicking, led by Carl Meyer, Brian Rosner, and Jannis Leidel.


== Command-line interface ==

One major advantage of pip is the ease of its command-line interface, which makes installing Python software packages as easy as issuing a command:

Users can also easily remove the package:

Most importantly pip has a feature to manage full lists of packages and corresponding version numbers, possible through a ""requirements"" file. This permits the efficient re-creation of an entire group of packages in a separate environment (e.g. another computer) or virtual environment. This can be achieved with a properly formatted file and the following command, where requirements.txt is the name of the file:

Install some package for a specific version python, where ${version} is replaced for 2, 3, 3.4, etc.:


== See also ==
Anaconda
Python Package Manager
RubyGems
Setuptools


== References ==


== External links ==
Official website"
"CPython is the reference implementation of the Python programming language. Written in C and Python, CPython is the default and most widely used implementation of the language.
CPython can be defined as both an interpreter and a compiler as it compiles Python code into bytecode before interpreting it. It has a foreign function interface with several languages including C, in which one must explicitly write bindings in a language other than Python.


== Design ==
A particular feature of CPython is that it makes use of a global interpreter lock (GIL) on each CPython interpreter process, which means that within a single process only one thread may be processing Python bytecode at any one time. This does not mean that there is no point in multithreading; the most common multi-threading scenario is where threads are mostly waiting on external processes to complete.
For example, imagine when three threads are servicing separate clients. One thread may be waiting for a client to reply, another may be waiting for a database query to execute, while the third thread is actually processing Python code.
However the GIL does mean that CPython is not suitable for processes that implement CPU intensive algorithms in Python code that could potentially be distributed across multiple cores.
In real world applications, situations where the GIL is a significant bottleneck are quite rare. This is because Python is an inherently slow language and is generally not used for CPU-intensive or time-sensitive operations. Python is typically used at the top level and calls functions in libraries to perform specialized tasks. These libraries are generally not written in Python and Python code in another thread can be executed while a call to one of these underlying processes takes place. The non-Python library being called to perform the CPU-intensive task is not subject to the GIL and may concurrently execute many threads on multiple processors without restriction.
Concurrency of Python code can only be achieved with separate CPython interpreter processes managed by a multitasking operating system. This complicates communication between concurrent Python processes, though the multiprocessing module mitigates this somewhat; it means that applications that really can benefit from concurrent Python-code execution can be implemented with a limited amount of overhead.
The presence of the GIL simplifies the implementation of CPython, and makes it easier to implement multi-threaded applications that do not benefit from concurrent Python code execution. However, without a GIL multiprocessing apps must make sure all common code is thread safe.
Although many proposals have been made to eliminate the GIL, the general consensus has been that in most cases the advantages of the GIL outweigh the disadvantages; in the few cases were the GIL is a bottleneck, the application should be built around the multiprocessing structure.


== History ==


=== Unladen Swallow ===
Unladen Swallow was an optimization branch of CPython, intended to be fully compatible and significantly faster. It aimed to achieve its goals by supplementing CPython's custom virtual machine with a just-in-time compiler built using LLVM.
The project had stated a goal of a speed improvement by a factor of five over CPython; this goal was not met.The project was sponsored by Google, and the project owners, Thomas Wouters, Jeffrey Yasskin, and Collin Winter, are full-time Google employees, however most project contributors were not Google employees. Unladen Swallow was hosted on Google Code.Like many things regarding the Python language, the name Unladen Swallow is a Monty Python reference, specifically to the joke about the airspeed velocity of unladen swallows in Monty Python and the Holy Grail.
Although it fell short of all published goals, Unladen Swallow did produce some code which got added to the main Python implementation, such as improvements to the cPickle module.In July 2010, some observers speculated on whether the project was dead or dying, since the 2009 Q4 milestone had not yet been released. The traffic on Unladen's mailing list had decreased from 500 messages in January 2010, to fewer than 10 in September 2010. It has also been reported that Unladen lost Google's funding. In November 2010, one of the main developers announced that ""Jeffrey and I have been pulled on to other projects of higher importance to Google"".The 2009 Q4 development branch was created on 26 January 2010, but no advertising was made on the website. Further, regarding the long-term plans, and as the project missed the Python 2.7 release, a Python Enhancement Proposal (PEP) was accepted, which proposed a merge of Unladen Swallow into a special py3k-jit branch of Python's official repository. As of July 2010, this work was ongoing. This merging would have taken some time, since Unladen Swallow was originally based on Python 2.6 with which Python 3 broke compatibility (see Python 3000 for more details).  However, the PEP was subsequently withdrawn.
In early 2011, it became clear that the project was stopped.


==== Unladen Swallow release history ====
2009 Q1
2009 Q2
2009 Q3: reduce memory use, improve speed


== Distribution ==
Supported platforms include:
Unix-like

Special and embedded

Other

PEP 11 lists platforms which are not supported in CPython by the Python Software Foundation. These platforms can still be supported by external ports. These ports include:

External ports not integrated to Python Software Foundation's official version of CPython, with links to its main development site, often include additional modules for platform-specific functionalities, like graphics and sound API for PSP and SMS and camera API for S60. These ports include:


=== Enterprise Linux ===
These Python versions are distributed with currently-supported enterprise Linux distributions. The support status of Python in the table refers to support from the Python core team, and not from the distribution maintainer.


== Alternatives ==
CPython is one of several ""production-quality"" Python implementations including: Jython, written in Java for the Java virtual machine (JVM), PyPy, written in RPython and translated into C, and IronPython, which is written in C# for the Common Language Infrastructure. There are also several experimental implementations.


== References ==


== External links ==
CPython on GitHub"
"Monty Python (also collectively known as the Pythons) were a British surreal comedy troupe who created the sketch comedy television show Monty Python's Flying Circus, which first aired on the BBC in 1969. Forty-five episodes were made over four series. The Python phenomenon developed from the television series into something larger in scope and impact, including touring stage shows, films, albums, books and musicals. The Pythons' influence on comedy has been compared to the Beatles' influence on music. Regarded as an enduring icon of 1970s pop culture, their sketch show has been referred to as being ""an important moment in the evolution of television comedy"".Broadcast by the BBC between 1969 and 1974, Monty Python's Flying Circus was conceived, written and performed by its members Graham Chapman, John Cleese, Terry Gilliam, Eric Idle, Terry Jones, and Michael Palin. Loosely structured as a sketch show, but with an innovative stream-of-consciousness approach aided by Gilliam's animation, it pushed the boundaries of what was acceptable in style and content. A self-contained comedy team responsible for both writing and performing their work, the Pythons had creative control which allowed them to experiment with form and content, discarding rules of television comedy. Following their television work, they began making films, including Monty Python and the Holy Grail (1975), Life of Brian (1979) and The Meaning of Life (1983). Their influence on British comedy has been apparent for years, while in North America, it has coloured the work of cult performers from the early editions of Saturday Night Live through to more recent absurdist trends in television comedy. ""Pythonesque"" has entered the English lexicon as a result.
At the 41st British Academy Film Awards in 1988, Monty Python received the BAFTA Award for Outstanding British Contribution To Cinema. In 1998 they were awarded the AFI Star Award by the American Film Institute. Many sketches from their TV show and films are well-known and widely quoted. Both Holy Grail and Life of Brian are frequently ranked in lists of greatest comedy films. In a 2005 poll of over 300 comics, comedy writers, producers and directors throughout the English-speaking world to find ""The Comedian's Comedian"", three of the six Pythons members were voted to be among the top 50 greatest comedians ever: Cleese at No. 2, Idle at No. 21, and Palin at No. 30.


== Before Flying Circus ==
Jones and Palin met at Oxford University, where they performed together with the Oxford Revue. Chapman and Cleese met at Cambridge University. Idle was also at Cambridge, but started a year after Chapman and Cleese. Cleese met Gilliam in New York City while on tour with the Cambridge University Footlights revue Cambridge Circus (originally entitled A Clump of Plinths). Chapman, Cleese, and Idle were members of the Footlights, which at that time also included the future Goodies (Tim Brooke-Taylor, Bill Oddie, and Graeme Garden), and Jonathan Lynn (co-writer of Yes Minister and Yes, Prime Minister). During Idle's presidency of the club, feminist writer Germaine Greer and broadcaster Clive James were members. Recordings of Footlights' revues (called ""Smokers"") at Pembroke College include sketches and performances by Cleese and Idle, which, along with tapes of Idle's performances in some of the drama society's theatrical productions, are kept in the archives of the Pembroke Players.The six Python members appeared in or wrote these shows before Flying Circus:

I'm Sorry, I'll Read That Again (radio) (1964–1973): Cleese (cast member and writer), Idle and Chapman (writers)
The Frost Report (1966–1967): Cleese (cast member and writer), Idle (writer of Frost's monologues), Chapman, Palin and Jones (writers)
At Last the 1948 Show (1967): Chapman and Cleese (writers and cast members), Idle (guest star and writer)
Twice a Fortnight (1967): Palin and Jones (cast members and writers)
Do Not Adjust Your Set (1967–1969): Idle, Jones, and Palin (cast members and writers), Gilliam (animation) + Bonzo Dog Band (musical interludes)
We Have Ways of Making You Laugh (1968): Idle (cast member and writer), Gilliam (animation)
How to Irritate People (1968): Cleese and Chapman (cast members and writers), Palin (cast member)
The Complete and Utter History of Britain (1969): Palin and Jones (cast members and writers)
Doctor in the House (1969), Cleese and Chapman (writers)The BBC's satirical television show The Frost Report, broadcast from March 1966 to December 1967, is credited as first uniting the British Pythons and providing an environment in which they could develop their particular styles.

Following the success of Do Not Adjust Your Set, broadcast on ITV from December 1967 to May 1969, Thames Television offered Gilliam, Idle, Jones, and Palin their own late-night adult comedy series together. At the same time, Chapman and Cleese were offered a show by the BBC, which had been impressed by their work on The Frost Report and At Last the 1948 Show. Cleese was reluctant to do a two-man show for various reasons, including Chapman's supposedly difficult and erratic personality. Cleese had fond memories of working with Palin on How to Irritate People and invited him to join the team. With no studio available at Thames until summer 1970 for the late-night show, Palin agreed to join Cleese and Chapman, and suggested the involvement of his writing partner Jones and colleague Idle—who in turn wanted Gilliam to provide animations for the projected series. Much has been made of the fact that the Monty Python troupe is the result of Cleese's desire to work with Palin and the chance circumstances that brought the other four members into the fold.By contrast, according to John Cleese's autobiography, the origins of Monty Python lay in the admiration that writing partners Cleese and Chapman had for the new type of comedy being done on Do Not Adjust Your Set; as a result, a meeting was initiated by Cleese between Chapman, Idle, Jones, Palin, and himself at which it was agreed to pool their writing and performing efforts and jointly seek production sponsorship. According to their official website, the group was born from a Kashmir tandoori restaurant in Hampstead on 11 May 1969, following a taping of Do Not Adjust Your Set which Cleese and Chapman attended. It was the first time all six got together, reportedly going back to Cleese's apartment on nearby Basil Street afterwards to continue discussions.


== Monty Python's Flying Circus ==


=== Development of the series ===
The Pythons had a definite idea about what they wanted to do with the series. They were admirers of the work of Peter Cook, Alan Bennett, Jonathan Miller, and Dudley Moore on Beyond the Fringe—seminal to the British ""satire boom""—and had worked on Frost, which was similar in style. They enjoyed Cook and Moore's sketch show Not Only... But Also. One problem the Pythons perceived with these programmes was that though the body of the sketch would be strong, the writers would often struggle to then find a punchline funny enough to end on, and this would detract from the overall sketch quality. They decided that they would simply not bother to ""cap"" their sketches in the traditional manner, and early episodes of the Flying Circus series make great play of this abandonment of the punchline (one scene has Cleese turn to Idle, as the sketch descends into chaos, and remark that ""This is the silliest sketch I've ever been in""—they all resolve not to carry on and simply walk off the set). However, as they began assembling material for the show, the Pythons watched one of their collective heroes, Spike Milligan, whom they had admired on The Goon Show (a show the Pythons regard as their biggest influence, which also featured Peter Sellers, whom Cleese called ""the greatest voice man of all time"") recording his groundbreaking BBC series Q... (1969). Not only was Q... more irreverent and anarchic than any previous television comedy, but Milligan also would often ""give up"" on sketches halfway through and wander off set (often muttering ""Did I write this?""). It was clear that their new series would now seem less original, and Jones in particular became determined the Pythons should innovate. Michael Palin recalls ""Terry Jones and I adored the Q... shows...[Milligan] was the first writer to play with the conventions of television.""

After much debate, Jones remembered an animation Gilliam had created for Do Not Adjust Your Set called ""Beware of the Elephants"", which had intrigued him with its stream-of-consciousness style. Jones felt it would be a good concept to apply to the series: allowing sketches to blend into one another. Palin had been equally fascinated by another of Gilliam's efforts, entitled ""Christmas Cards"", and agreed that it represented ""a way of doing things differently"". Since Cleese, Chapman, and Idle were less concerned with the overall flow of the programme, Jones, Palin, and Gilliam became largely responsible for the presentation style of the Flying Circus series, in which disparate sketches are linked to give each episode the appearance of a single stream-of-consciousness (often using a Gilliam animation to move from the closing image of one sketch to the opening scene of another). The BBC states, ""Gilliam's unique animation style became crucial, segueing seamlessly between any two completely unrelated ideas and making the stream-of-consciousness work.""Writing started at 9 am and finished at 5 pm. Typically, Cleese and Chapman worked as one pair isolated from the others, as did Jones and Palin, while Idle wrote alone. After a few days, they would join together with Gilliam, critique their scripts, and exchange ideas. Their approach to writing was democratic. If the majority found an idea humorous, it was included in the show. The casting of roles for the sketches was a similarly unselfish process, since each member viewed himself primarily as a ""writer"", rather than an actor eager for screen time. When the themes for sketches were chosen, Gilliam had a free hand in bridging them with animations, using a camera, scissors, and airbrush.

While the show was a collaborative process, different factions within Python were responsible for elements of the team's humour. In general, the work of the Oxford-educated members (Jones and Palin) was more visual, and more fanciful conceptually (e.g., the arrival of the Spanish Inquisition in a suburban front room), while the Cambridge graduates' sketches tended to be more verbal and more aggressive (for example, Cleese and Chapman's many ""confrontation"" sketches, where one character intimidates or hurls abuse, or Idle's characters with bizarre verbal quirks, such as ""The Man Who Speaks In Anagrams""). Cleese confirmed that ""most of the sketches with heavy abuse were Graham's and mine, anything that started with a slow pan across countryside and impressive music was Mike and Terry's, and anything that got utterly involved with words and disappeared up any personal orifice was Eric's"". Gilliam's animations ranged from the whimsical to the savage (the cartoon format allowing him to create some astonishingly violent scenes without fear of censorship).Several names for the show were considered before Monty Python's Flying Circus was settled upon. Some were Owl Stretching Time, The Toad Elevating Moment, A Horse, a Spoon and a Bucket, Vaseline Review, and Bun, Wackett, Buzzard, Stubble and Boot. Flying Circus stuck when the BBC explained it had printed that name in its schedules and was not prepared to amend it. Many variations on the name in front of this title then came and went (popular legend holds that the BBC considered Monty Python's Flying Circus to be a ridiculous name, at which point the group threatened to change their name every week until the BBC relented). Gwen Dibley's Flying Circus was named after a woman Palin had read about in the newspaper, thinking it would be amusing if she were to discover she had her own TV show. Baron Von Took's Flying Circus was considered as an affectionate tribute to Barry Took, the man who had brought them together. Arthur Megapode's Flying Circus was suggested, then discarded. The name Baron Von Took's Flying Circus had the form of Baron Manfred von Richthofen's Flying Circus of WWI fame, and the new group was forming in a time when the Royal Guardsmen's 1966 song ""Snoopy vs. the Red Baron"" had peaked. The term 'flying circus' was also another name for the popular entertainment of the 1920s known as barnstorming, where multiple performers collaborated with their stunts to perform a combined set of acts.Differing, somewhat confusing accounts are given of the origins of the Python name, although the members agree that its only ""significance"" was that they thought it sounded funny. In the 1998 documentary Live at Aspen during the US Comedy Arts Festival, where the troupe was awarded the AFI Star Award by the American Film Institute, the group implied that ""Monty"" was selected (Eric Idle's idea) as a gently mocking tribute to Field Marshal Lord Montgomery, a British general of World War II; requiring a ""slippery-sounding"" surname, they settled on ""Python"". On other occasions, Idle has claimed that the name ""Monty"" was that of a popular and rotund fellow who drank in his local pub; people would often walk in and ask the barman, ""Has Monty been in yet?"", forcing the name to become stuck in his mind. The name Monty Python was later described by the BBC as being ""envisaged by the team as the perfect name for a sleazy entertainment agent"".


=== Style of the show ===
Flying Circus popularised innovative formal techniques, such as the cold open, in which an episode began without the traditional opening titles or announcements. An example of this is the ""It's"" man: Palin, outfitted in Robinson Crusoe garb, making a tortuous journey across various terrains, before finally approaching the camera to state, ""It's ..."", only to be then cut off by the title sequence and theme music. On several occasions, the cold open lasted until mid-show, after which the regular opening titles ran. Occasionally, the Pythons tricked viewers by rolling the closing credits halfway through the show, usually continuing the joke by fading to the familiar globe logo used for BBC continuity, over which Cleese would parody the clipped tones of a BBC announcer. On one occasion, the credits ran directly after the opening titles. On the subversive nature of the show (and their subsequent films), Cleese states ""anti-authoritarianism was deeply ingrained in Python"".

Because of their dislike of finishing with punchlines, they experimented with ending the sketches by cutting abruptly to another scene or animation, walking offstage, addressing the camera (breaking the fourth wall), or introducing a totally unrelated event or character. A classic example of this approach was the use of Chapman's ""anti-silliness"" character of ""the Colonel"", who walked into several sketches and ordered them to be stopped because things were becoming ""far too silly"".

Another favourite way of ending sketches was to drop a cartoonish ""16-ton weight"" prop on one of the characters when the sketch seemed to be losing momentum, or a knight in full armour (played by Terry Gilliam) would wander on-set and hit characters over the head with a rubber chicken, before cutting to the next scene. Yet another way of changing scenes was when John Cleese, usually outfitted in a dinner suit, would come in as a radio commentator and, in a rather pompous manner, make the formal and determined announcement ""And now for something completely different."", which later became the title of the first Monty Python film.The Python theme music is the Band of the Grenadier Guards' rendition of John Philip Sousa's ""The Liberty Bell"" which was first published in 1893. Under the Berne Convention's ""country of origin"" concept, the composition was subject to United States copyright law which states that any work first published prior to 1924 was in the public domain, owing to copyright expiration. This enabled Gilliam to co-opt the march for the series without having to make any royalty payments.

The use of Gilliam's surreal, collage stop motion animations was another innovative intertextual element of the Python style. Many of the images Gilliam used were lifted from famous works of art, and from Victorian illustrations and engravings. The giant foot which crushes the show's title at the end of the opening credits is in fact the foot of Cupid, cut from a reproduction of the Renaissance masterpiece Venus, Cupid, Folly and Time by Bronzino. This foot, and Gilliam's style in general, are visual trademarks of the programme.The Pythons used the British tradition of cross-dressing comedy by donning frocks and makeup and playing female roles themselves while speaking in falsetto. Jones specialised in playing the working-class housewife, or ""ratbag old women"" as termed by the BBC. Palin and Idle generally played the role more posh, with Idle playing more feminine women. Cleese played female roles more sparsely, while Chapman was frequently paired with Jones as a ratbag woman or with Idle portraying middle-class women commenting upon TV. Generally speaking, female roles were played by women only when the scene specifically required that the character be sexually attractive (although sometimes they used Idle for this). The troupe later turned to Carol Cleveland, who co-starred in numerous episodes after 1970. In some episodes, and later in Monty Python's Life of Brian, they took the idea one step further by playing women who impersonated men (in the stoning scene).Many sketches are well-known and widely quoted. ""Dead Parrot sketch"", ""The Lumberjack Song"", ""Spam"" (which led to the coining of the term email spam), ""Nudge Nudge"", ""The Spanish Inquisition"", ""Upper Class Twit of the Year"", ""Cheese Shop"", ""The Ministry of Silly Walks"", ""Argument Clinic"", ""The Funniest Joke in the World"" (a sketch referenced in Google Translate), and Four Yorkshiremen sketch"" are just a few examples. Most of the show’s sketches satirise areas of public life, such as, Dead Parrot (poor customer service), Silly Walks (bureaucratic inefficiency), Spam (ubiquity of Spam post World War II), Four Yorkshiremen (nostalgic conversations). Featuring regularly in skits, Gumbys (characters of limited intelligence and vocabulary) were part of the Pythons' satirical view of television of the 1970s which condescendingly encouraged more involvement from the ""man on the street"".


=== Introduction to North America and the world ===
The Canadian Broadcasting Corporation (CBC) added Monty Python's Flying Circus to its national September 1970 fall line-up. They aired the 13 episodes of series 1, which had first run on the BBC the previous autumn (October 1969 to January 1970), as well as the first six episodes of series 2 only a few weeks after they first appeared on the BBC (September to November 1970). The CBC dropped the show when it returned to regular programming after the Christmas 1970 break, choosing to not place the remaining seven episodes of series 2 on the January 1971 CBC schedule. Within a week, the CBC received hundreds of calls complaining of the cancellation, and more than 100 people staged a demonstration at the CBC's Montreal studios. The show eventually returned, becoming a fixture on the network during the first half of the 1970s.

Sketches from Monty Python's Flying Circus were introduced to American audiences in August 1972, with the release of the Python film And Now for Something Completely Different, featuring sketches from series 1 and 2 of the television show.  This 1972 release met with limited box office success.
The ability to show Monty Python's Flying Circus under the American NTSC standard had been made possible by the commercial actions of American television producer Greg Garrison.  Garrison produced the NBC series The Dean Martin Comedy World, which ran during the summer of 1974.  The concept was to show clips from comedy shows produced in other countries, including tape of the Python sketches ""Bicycle Repairman"" and ""The Dull Life of a Stockbroker"". Payment for use of these two sketches was enough to allow Time-Life Films to convert the entire Python library to NTSC standard, allowing for the sale to the PBS network stations which then brought the entire show to US audiences.
Through the efforts of Python's American manager Nancy Lewis, during the summer of 1974, Ron Devillier, the programme director for nonprofit PBS television station KERA in Dallas, Texas, started airing episodes of Monty Python's Flying Circus. Ratings shot through the roof, providing an encouraging sign to the other 100 PBS stations that had signed up to begin airing the show in October 1974—exactly five years after their BBC debut. There was also cross-promotion from FM radio stations across the US, whose airing of tracks from the Python LPs had already introduced American audiences to this bizarre brand of comedy. The popularity on PBS resulted in the 1974 re-release of the 1972 ...Completely Different film, with much greater box office success. The success of the show was captured by a March 1975 article headline in The New York Times, ""Monty Python's Flying Circus Is Barnstorming Here"". Asked what challenges were left, now that they had made TV shows, films, written books, and produced records, Chapman responded, ""Well, actually world supremacy would be very nice"", before Idle cautioned, ""Yes, but that sort of thing has got to be done properly"".In 1975 ABC broadcast two 90-minute Monty Python specials, each with three shows, but cut out a total of 24 minutes from each, in part to make time for commercials, and in part to avoid upsetting their audience.  As the judge observed in Gilliam v. American Broadcasting Companies, Inc., where Monty Python sued for damages caused by broadcast of the mutilated version, ""According to the network, appellants should have anticipated that most of the excised material contained scatological references inappropriate for American television and that these scenes would be replaced with commercials, which presumably are more palatable to the American public.""  Monty Python won the case.With the popularity of Python throughout the rest of the 1970s and through most of the 1980s, PBS stations looked at other British comedies, leading to UK shows such as Are You Being Served? gaining a US audience, and leading, over time, to many PBS stations having a ""British Comedy Night"" which airs many popular UK comedies.In 1976 Monty Python became the top rated show in Japan. The literal translation of the Japanese title was The Gay Dragon Boys Show. The popularity of the show in the Netherlands saw the town of Spijkenisse near Rotterdam open a 'silly walks' road crossing in 2018. Believed to be a world first, the official sign asks pedestrians to cross the road in a comical manner.


=== Cleese departs; the circus closes ===
Having considered the possibility at the end of the second season, Cleese left the Flying Circus at the end of the third. He later explained that he felt he no longer had anything fresh to offer the show, and claimed that only two Cleese- and Chapman-penned sketches in the third series (""Dennis Moore"" and the ""Cheese Shop"") were truly original, and that the others were bits and pieces from previous work cobbled together in slightly different contexts. He was also finding Chapman, who was at that point in the full throes of alcoholism, difficult to work with. According to an interview with Idle, ""It was on an Air Canada flight on the way to Toronto, when John (Cleese) turned to all of us and said 'I want out.' Why? I don't know. He gets bored more easily than the rest of us. He's a difficult man, not easy to be friendly with. He's so funny because he never wanted to be liked. That gives him a certain fascinating, arrogant freedom."" Jones noted his reticence in 2012, ""He was good at it, when he did it he was professional, but he’d rather not have done it. The others all loved it, but he got more and more pissed off about having to come out and do filming, and the one that really swung it, in my view, was when we had to do the day on the Newhaven lifeboat.""The rest of the group carried on for one more ""half"" season before calling a halt to the programme in 1974. While the first three seasons contained 13 episodes each, the fourth ended after just six. The name Monty Python's Flying Circus appears in the opening animation for season four, but in the end credits, the show is listed as simply Monty Python. Although Cleese left the show, he was credited as a writer for three of the six episodes, largely concentrated in the ""Michael Ellis"" episode, which had begun life as one of the many drafts of the ""Holy Grail"" motion picture.  When a new direction for ""Grail"" was decided upon, the subplot of Arthur and his knights wandering around a strange department store in modern times was lifted out and recycled as the aforementioned TV episode. Songwriter Neil Innes contributed to some sketches, including ""Appeal on Behalf of Very Rich People"".


== Life beyond the Flying Circus ==


=== Filmography ===


==== And Now for Something Completely Different (1971) ====

The Pythons' first feature film was directed by Ian MacNaughton, reprising his role from the television series. It consisted of sketches from the first two seasons of the Flying Circus, reshot on a low budget (and often slightly edited) for cinema release. Material selected for the film includes: ""Dead Parrot"", ""The Lumberjack Song"", ""Upper Class Twit of the Year"", ""Hell's Grannies"", ""Self-Defence Class"", ""How Not to Be Seen"", and ""Nudge Nudge"". Financed by Playboy's UK executive Victor Lownes, it was intended as a way of breaking Monty Python into America, and although it was ultimately unsuccessful in this, the film did good business in the UK, and later in the US on the ""Midnight movie"" circuit after their breakthrough television and film success, this being in the era before home video would make the original material much more accessible. The group did not consider the film a success.


==== Monty Python and the Holy Grail (1975) ====

In 1974, between production on the third and fourth seasons, the group decided to embark on their first ""proper"" feature film, containing entirely new material. Monty Python and the Holy Grail was based on Arthurian legend and was directed by Jones and Gilliam. Again, the latter also contributed linking animations (and put together the opening credits). Along with the rest of the Pythons, Jones and Gilliam performed several roles in the film, but Chapman took the lead as King Arthur. Cleese returned to the group for the film, feeling that they were once again breaking new ground. Holy Grail was filmed on location, in picturesque rural areas of Scotland, with a budget of only £229,000; the money was raised in part with investments from rock groups such as Pink Floyd, Jethro Tull, and Led Zeppelin, as well as UK music industry entrepreneur Tony Stratton-Smith (founder and owner of the Charisma Records label, for which the Pythons recorded their comedy albums).The backers of the film wanted to cut the famous Black Knight scene (a Sam Peckinpah send-up in which the Black Knight loses his limbs in a duel), but it was eventually kept in the movie. ""Tis but a scratch"" and ""It's just a flesh wound…"" are often quoted. Holy Grail was selected as the second-best comedy of all time in the ABC special Best in Film: The Greatest Movies of Our Time. and viewers in a Channel 4 poll placed it sixth.


==== Monty Python's Life of Brian (1979) ====

Following the success of Holy Grail, reporters asked for the title of the next Python film, though the team had not even begun to consider a third one. Eventually, Idle flippantly replied ""Jesus Christ – Lust for Glory"", which became the group's stock answer to such questions. However, they soon began to seriously consider a film lampooning the New Testament era in the same way Holy Grail had lampooned Arthurian legend. Despite sharing a distrust of organised religion, they agreed not to mock Jesus or his teachings directly. They also mentioned that they could not think of anything legitimate to make fun of about him. Instead, they decided to write a satire on credulity and hypocrisy among the followers of someone [Brian] who had been mistaken for the ""Messiah"", but who had no desire to be followed as such. Terry Jones adds it was a satire on those who for the next 2,000 years ""couldn't agree on what Jesus was saying about peace and love"".

The focus therefore shifted to a separate individual, Brian Cohen, born at the same time, and in a neighbouring stable, to Jesus. When Jesus appears in the film (first, as a baby in the stable, and then later on the Mount, speaking the Beatitudes), he is played straight (by actor Kenneth Colley) and portrayed with respect. The comedy begins when members of the crowd mishear his statements of peace, love, and tolerance (""I think he said, 'Blessed are the cheesemakers'"").Directing duties were handled solely by Jones, having amicably agreed with Gilliam that Jones' approach to film-making was better suited for Python's general performing style. Holy Grail's production had often been stilted by their differences behind the camera. Gilliam again contributed two animated sequences (one being the opening credits) and took charge of set design. The film was shot on location in Tunisia, the finances being provided this time by The Beatles' George Harrison, who together with Denis O'Brien formed the production company Hand-Made Films for the movie. Harrison had a cameo role as the ""owner of the Mount"".Despite its subject matter attracting controversy, particularly upon its initial release, it has (together with its predecessor) been ranked among the greatest comedy films. In 2006 it was ranked first on a Channel 4 list of the 50 Greatest Comedy Films. In 2013, Richard Burridge, a theologian decorated by Pope Francis, called Life of Brian an ""extraordinary tribute to the life and work and teaching of Jesus—that they couldn't actually blaspheme or make a joke out of it. They did a great satire on closed minds and people who follow blindly. Then you have them splitting into factions...it is a wonderful satire on the way that Jesus's own teaching has been used to persecute others. They were satirising fundamentalism and persecution of others and at the same time saying the one person who rises above all this was Jesus"".


==== Monty Python Live at the Hollywood Bowl (1982) ====

Filmed at the Hollywood Bowl in Los Angeles during preparations for The Meaning of Life, this was a concert film (directed by Terry Hughes) in which the Pythons performed sketches from the television series in front of an audience. The released film also incorporated footage from the German television specials (the inclusion of which gives Ian MacNaughton his first on-screen credit for Python since the end of Flying Circus) and live performances of several songs from the troupe's then-current Monty Python's Contractual Obligation Album.


==== Monty Python's The Meaning of Life (1983) ====

The Pythons' final film returned to something structurally closer to the style of Flying Circus. A series of sketches loosely follows the ages of man from birth to death. Directed again by Jones solo, The Meaning of Life is embellished with some of the group's most bizarre and disturbing moments, as well as various elaborate musical numbers, which include ""Galaxy Song"" (performed by Idle) and ""Every Sperm Is Sacred"" (performed by Palin and Jones). The film is by far their darkest work, containing a great deal of black humour, garnished by some spectacular violence (including an operation to remove a liver from a living patient without anaesthetic and the morbidly obese Mr. Creosote exploding over several restaurant patrons after finally giving in to the smooth maître d' telling him to eat a mint – ""It's only a wafer-thin mint...""). At the time of its release, the Pythons confessed their aim was to offend ""absolutely everyone"", adding ""It is guaranteed to offend"".The Liver Donor scene (which sees someone come to a man's door to take his liver, to which he says: ""No, no, I'm not dead"", before being told: ""Oooh, it doesn't say that on the form""), is a satire on bureaucracy, a common Python trope. Besides the opening credits and the fish sequence, Gilliam, by now an established live-action director, no longer wanted to produce any linking cartoons, offering instead to direct one sketch, ""The Crimson Permanent Assurance"". Under his helm, though, the segment grew so ambitious and tangential that it was cut from the movie and used as a supporting feature in its own right. (Television screenings also use it as a prologue.) This was the last project on which all six Pythons collaborated, except for the 1989 compilation Parrot Sketch Not Included, where they are all seen sitting in a closet for four seconds. This was the last time Chapman appeared on screen with the Pythons.


=== Secret Policeman's Ball benefit shows ===
Members of Python contributed their services to charitable endeavours and causes—sometimes as an ensemble, at other times as individuals. The cause that has been the most frequent and consistent beneficiary has been the human rights work of Amnesty International. Between 1976 and 1981, the troupe or its members appeared in four major fund-raisers for Amnesty—known collectively as the Secret Policeman's Ball shows—which were turned into multiple films, TV shows, videos, record albums, and books. The brainchild of John Cleese, these benefit shows in London and their many spin-offs raised considerable sums of money for Amnesty, raised public and media awareness of the human rights cause, and influenced many other members of the entertainment community (especially rock musicians) to become involved in political and social issues. Among the many musicians who have publicly attributed their activism—and the organisation of their own benefit events—to the inspiration of the work in this field of Monty Python are Bob Geldof (organiser of Live Aid), U2, Pete Townshend, and Sting. Bono told Rolling Stone in 1986, ""I saw The Secret Policeman’s Ball and it became a part of me. It sowed a seed..."" Sting states, “before [the Ball] I did not know about Amnesty, I did not know about its work, I did not know about torture in the world."" On the impact of the Ball on Geldof, Sting states, ""he took the ‘Ball’ and ran with it.""Ball co-founder Cleese and Jones had an involvement (as performer, writer or director) in all four Amnesty benefit shows, Palin in three, Chapman in two, and Gilliam in one. Idle did not participate in the Amnesty shows. Notwithstanding Idle's lack of participation, the other five members (together with ""Associate Pythons"" Carol Cleveland and Neil Innes) all appeared together in the first Secret Policeman's Ball benefit—the 1976 A Poke in the Eye held at Her Majesty's Theatre in London's West End—where they performed several Python sketches. In this first show, they were collectively billed as Monty Python. Peter Cook deputised for the absent Idle in a courtroom sketch. In the next three shows, the participating Python members performed many Python sketches, but were billed under their individual names rather than under the collective Python banner. The second show featured newcomer Rowan Atkinson and Scottish comedian Billy Connolly. The Secret Policeman's Ball were the first stage shows in the UK to present comedic performers (such as Monty Python and Rowan Atkinson) in the same setting and shows as their contemporaries in rock music (which included Eric Clapton, Sting and Phil Collins). After a six-year break, Amnesty resumed producing Secret Policeman's Ball benefit shows which were held at the London Palladium in 1987 (sometimes with, and sometimes without, variants of the title) and by 2006 had presented a total of twelve shows. Since 1987 the Balls featured newer generations of British comedic performers, such as Stephen Fry, Hugh Laurie, and puppets from the satirical TV show Spitting Image, with many attributing their participation in the show to their desire to emulate the Python's pioneering work for Amnesty. Cleese and Palin made a brief cameo appearance in the 1989 Amnesty show; apart from that, the Pythons have not appeared in shows after the first four.


=== Going solo ===

Each member has pursued various film, television, and stage projects since the break-up of the group, but often continued to work with one another. Many of these collaborations were very successful, most notably A Fish Called Wanda (1988), written by Cleese, in which he starred along with Palin. The pair also appeared in Time Bandits (1981), a film directed by Gilliam, who wrote it together with Palin. Gilliam directed Jabberwocky (1977), and also directed and co-wrote Brazil (1985), which featured Palin, and The Adventures of Baron Munchausen (1988), which featured Idle. Yellowbeard (1983) was co-written by Chapman and featured Chapman, Idle, and Cleese, as well as many other English comedians including Peter Cook, Spike Milligan, and Marty Feldman.Palin and Jones wrote the comedic TV series Ripping Yarns (1976–79), starring Palin. Jones also appeared in the pilot episode and Cleese appeared in a nonspeaking part in the episode ""Golden Gordon"". Jones' film Erik the Viking also has Cleese playing a small part. In 1996 Terry Jones wrote and directed an adaptation of Kenneth Grahame's novel The Wind in the Willows. It featured four members of Monty Python: Jones as Mr. Toad, Idle as Ratty, Cleese as Mr. Toad's lawyer, and Palin as the Sun. Gilliam was considered for the voice of the river. The film included Steve Coogan who played Mole.Cleese has the most prolific solo career, appearing in dozens of films, several TV shows or series (including Cheers, 3rd Rock from the Sun, Q's assistant in the James Bond movies, and Will & Grace), many direct-to-video productions, some video games and a number of commercials. His BBC sitcom Fawlty Towers (written by and starring Cleese together with his wife Connie Booth) is the only comedy series to rank higher than the Flying Circus on the BFI TV 100's list, topping the whole poll. Cleese's character, Basil Fawlty, was ranked second (to Homer Simpson) on Channel 4's 2001 list of the 100 Greatest TV Characters.Idle enjoyed critical success with Rutland Weekend Television in the mid-1970s, out of which came the Beatles parody the Rutles (responsible for the cult mockumentary All You Need Is Cash), and as an actor in Nuns on the Run (1990) with Robbie Coltrane. In 1976 Idle directed music videos for George Harrison songs ""This Song"" and ""Crackerbox Palace"", the latter of which also featured cameo appearances from Neil Innes and John Cleese. Idle has had success with Python songs: ""Always Look on the Bright Side of Life"" went to no. 3 in the UK singles chart in 1991. The song had been revived by Simon Mayo on BBC Radio 1, and was consequently released as a single that year. The theatrical phenomenon of the Python musical Spamalot has made Idle the most financially successful of the troupe after Python. Written by Idle (and featuring a pre-recorded cameo of Cleese as the voice of God), it has proved to be an enormous hit on Broadway, London's West End and Las Vegas. This was followed by Not the Messiah, which revises The Life of Brian as an oratorio. For the work's 2007 premiere at the Luminato festival in Toronto (which commissioned the work), Idle himself sang the ""baritone-ish"" part.


=== After Python reunions ===

Since The Meaning of Life, their last project as a team, the Pythons have often been the subject of reunion rumours. In 1988 Monty Python won the BAFTA Award for Outstanding British Contribution To Cinema, with four of the six Pythons (Jones, Palin, Gilliam and Chapman) collecting the award. The final appearance of all six together occurred during the 1989 Parrot Sketch Not Included – 20 Years of Monty Python TV special. The death of Chapman in October 1989 put an end to the speculation of any further reunions. Several occasions since 1989 have occurred when the surviving five members have gathered together for appearances—albeit not formal reunions. In 1996 Jones, Idle, Cleese, and Palin were featured in a film adaptation of The Wind in the Willows, which was later renamed Mr. Toad's Wild Ride. In 1997 Palin and Cleese rolled out a new version of the ""Dead Parrot sketch"" for Saturday Night Live.Monty Python were the inaugural recipients of the Empire Inspiration Award in 1997. Palin, Jones and Gilliam received the award on stage in London from Elton John while Cleese and Idle appeared via satellite from Los Angeles. In 1998 during the US Comedy Arts Festival, where the troupe were awarded the AFI Star Award by the American Film Institute, the five remaining members, along with what was purported to be Chapman's ashes, were reunited on stage for the first time in 18 years. The occasion was in the form of an interview called Monty Python Live at Aspen, (hosted by Robert Klein, with an appearance by Eddie Izzard) in which the team looked back at some of their work and performed a few new sketches. On 9 October 1999, to commemorate 30 years since the first Flying Circus television broadcast, BBC2 devoted an evening to Python programmes, including a documentary charting the history of the team, interspersed with new sketches by the Monty Python team filmed especially for the event.The surviving Pythons had agreed in principle to perform a live tour of America in 1999. Several shows were to be linked with Q&A meetings in various cities. Although all had said yes, Palin later changed his mind, much to the annoyance of Idle, who had begun work organising the tour. This led to Idle refusing to take part in the new material shot for the BBC anniversary evening. In 2002 four of the surviving members, bar Cleese, performed ""The Lumberjack Song"" and ""Sit on My Face"" for George Harrison's memorial concert. The reunion also included regular supporting contributors Neil Innes and Carol Cleveland, with a special appearance from Tom Hanks.

In an interview to publicise the DVD release of The Meaning of Life, Cleese said a further reunion was unlikely. ""It is absolutely impossible to get even a majority of us together in a room, and I'm not joking,"" Cleese said. He said that the problem was one of busyness rather than one of bad feelings. A sketch appears on the same DVD spoofing the impossibility of a full reunion, bringing the members ""together"" in a deliberately unconvincing fashion with modern bluescreen/greenscreen techniques.
Idle responded to queries about a Python reunion by adapting a line used by George Harrison in response to queries about a possible Beatles reunion. When asked in November 1989 about such a possibility, Harrison responded: ""As far as I'm concerned, there won't be a Beatles reunion as long as John Lennon remains dead."" Idle's version of this was that he expected to see a proper Python reunion, ""just as soon as Graham Chapman comes back from the dead"", but added, ""we're talking to his agent about terms.""The Pythons Autobiography by The Pythons (2003), compiled from interviews with the surviving members, reveals that a series of disputes in 1998, over a possible sequel to Holy Grail that had been conceived by Idle, may have resulted in the group's split. Cleese's feeling was that The Meaning of Life had been personally difficult and ultimately mediocre, and did not wish to be involved in another Python project for a variety of reasons (not least amongst them was the absence of Chapman, whose straight man-like central roles in the Grail and Brian films had been considered to be an essential anchoring performance). The book also reveals that Cleese saw Chapman as his ""greatest sounding board. If Graham thought something was funny, then it almost certainly was funny. You cannot believe how invaluable that is.' Ultimately it was Cleese who ended the possibility of another Python movie.A full, if nonperforming, reunion of the surviving Python members appeared at the March 2005 premiere of Idle's musical Spamalot, based on Monty Python and the Holy Grail. It opened in Chicago and has since played in New York on Broadway, London, and numerous other major cities across the world. In 2004 it was nominated for 14 Tony Awards and won three: Best Musical, Best Direction of a Musical for Mike Nichols, and Best Performance by a Featured Actress in a Musical for Sara Ramirez, who played the Lady of the Lake, a character specially added for the musical.  The original Broadway cast included Tim Curry as King Arthur, Michael McGrath as Patsy, David Hyde Pierce as Sir Robin, Hank Azaria as Sir Lancelot and other roles (e.g., the French Taunter, Knight of Ni, and Tim the Enchanter), Christopher Sieber as Sir Galahad and other roles (e.g., the Black Knight and Prince Herbert's Father). Cleese played the voice of God, a role played in the film by Chapman.Owing in part to the success of Spamalot, PBS announced on 13 July 2005 that it would begin to re-air the entire run of Monty Python's Flying Circus and new one-hour specials focusing on each member of the group, called Monty Python's Personal Best. Each episode was written and produced by the individual being honoured, with the five remaining Pythons collaborating on Chapman's programme, the only one of the editions to take on a serious tone with its new material.

In 2009, to commemorate the 40th anniversary of the first episode of Monty Python's Flying Circus, a six-part documentary entitled Monty Python: Almost the Truth (Lawyers Cut) was released, featuring interviews with the surviving members of the team, as well as archive interviews with Graham Chapman and numerous excerpts from the television series and films. Each episode opens with a different re-recording of the theme song from Life of Brian, with Iron Maiden vocalist and Python fan Bruce Dickinson performing the sixth.Also in commemoration of the 40th anniversary, Idle, Palin, Jones, and Gilliam appeared in a production of Not the Messiah at the Royal Albert Hall. The European premiere was held on 23 October 2009. An official 40th anniversary Monty Python reunion event took place in New York City on 15 October 2009, where the team received a Special Award from the British Academy of Film and Television Arts.In June 2011, it was announced that A Liar's Autobiography: The Untrue Story of Monty Python's Graham Chapman, an animated 3D movie based on the memoir of Graham Chapman, was in the making. The memoir A Liar's Autobiography was published in 1980 and details Chapman's journey through medical school, alcoholism, acknowledgement of his gay identity, and the tolls of surreal comedy. Asked what was true in a deliberately fanciful account by Chapman of his life, Terry Jones joked: ""Nothing ... it's all a downright, absolute, blackguardly lie."" The film uses Chapman's own voice—from a reading of his autobiography shortly before he died of cancer—and entertainment channel Epix announced the film's release in early 2012 in both 2D and 3D formats. Produced and directed by London-based Bill Jones, Ben Timlett, and Jeff Simpson, the new film has 15 animation companies working on chapters that will range from three to 12 minutes in length, each in a different style. John Cleese recorded dialogue which was matched with Chapman's voice. Michael Palin voiced Chapman's father and Terry Jones voiced his mother. Terry Gilliam voiced Graham's psychiatrist.  They all play various other roles. Among the original Python group, only Eric Idle was not involved.On 26 January 2012, Terry Jones announced that the five surviving Pythons would reunite in a sci-fi comedy film called Absolutely Anything. The film would combine computer-generated imagery and live action. It would be directed by Jones based on a script by Jones and Gavin Scott, and in addition to the Python members it would also star Simon Pegg, Kate Beckinsale and Robin Williams (in his final film role). The plot revolves around a teacher who discovers aliens (voiced by the Pythons) have given him magical powers to do ""absolutely anything"". Eric Idle responded via Twitter that he would not, in fact, be participating, although he was later added to the cast.


=== Monty Python Live (Mostly): One Down, Five to Go ===

In 2013 the Pythons lost a legal case to Mark Forstater, the film producer of Monty Python and the Holy Grail, over royalties for the derivative work Spamalot. They owed a combined £800,000 in legal fees and back royalties to Forstater. They proposed a reunion show to pay their legal bill.On 19 November 2013, a new reunion was reported, following months of ""secret talks"". The original plan was for a live, one-off stage show at the O2 Arena in London on 1 July 2014, with ""some of Monty Python's greatest hits, with modern, topical, Pythonesque twists"" according to a press release. The tickets for this show went on sale in November 2013 and sold out in just 43 seconds. Nine additional shows were added, all of them at the O2, the last on 20 July.  They have said that their reunion was inspired by South Park creators Trey Parker and Matt Stone, who are massive Monty Python fans.Mick Jagger featured in a promotional video for the shows: ""Who wants to see that again, really? It's a bunch of wrinkly old men trying to relive their youth and make a load of money—the best one died years ago!"" Michael Palin stated that the final reunion show on 20 July 2014 would be the last time that the troupe would perform together. It was screened to 2,000 cinemas around the world. Prior to the final night, Idle stated, ""It is a world event and that’s really quite exciting. It means we’re actually going to say goodbye publicly on one show. Nobody ever has the chance to do that. The Beatles didn’t get a last good night."" The last show was broadcast in the UK on Gold TV and internationally in cinemas by Fathom Events through a Dish Network satellite link.


== Python members ==
Graham Chapman was originally a medical student, joining the Footlights at Cambridge. He completed his medical training and was legally entitled to practise as a doctor. Chapman is best remembered for the lead roles in Holy Grail, as King Arthur, and Life of Brian, as Brian Cohen. He died of metastatic throat cancer on 4 October 1989. At Chapman's memorial service, Cleese delivered an irreverent eulogy that included all the euphemisms for being dead from the ""Dead Parrot"" sketch, which they had written. Chapman's comedic fictional memoir, A Liar's Autobiography, was adapted into an animated 3D movie in 2012.John Cleese is the oldest Python. He met his future Python writing partner, Chapman, in Cambridge. Outside of Python, he is best known for setting up the Video Arts group and for the sitcom Fawlty Towers (co-written with Connie Booth, whom Cleese met during work on Python and to whom he was married for a decade). Cleese has also co-authored several books on psychology and wrote the screenplay for the award-winning A Fish Called Wanda, in which he starred with Michael Palin.Terry Gilliam, an American by birth, is the only member of the troupe of non-British origin. He started off as an animator and strip cartoonist for Harvey Kurtzman's Help! magazine, one issue of which featured Cleese. Moving from the US to England, he animated features for Do Not Adjust Your Set and was then asked by its makers to join them on their next project: Monty Python's Flying Circus. He co-directed Monty Python and the Holy Grail and directed short segments of other Python films (for instance ""The Crimson Permanent Assurance"", the short film that appears before The Meaning of Life).

When Monty Python was first formed, two writing partnerships were already in place: Cleese and Chapman, Jones and Palin. That left two in their own corners: Gilliam, operating solo due to the nature of his work, and Eric Idle. Regular themes in Idle's contributions were elaborate wordplay and musical numbers. After Flying Circus, he hosted Saturday Night Live four times in the first five seasons. Idle's initially successful solo career faltered in the 1990s with the failures of his 1993 film Splitting Heirs (written, produced by, and starring him) and 1998's An Alan Smithee Film: Burn Hollywood Burn (in which he starred). He revived his career by returning to the source of his worldwide fame, adapting Monty Python material for other media. Idle wrote the Tony Award-winning musical Spamalot, based on Holy Grail. Following the success of the musical he wrote Not the Messiah, an oratorio derived from the Life of Brian. Representing Monty Python, Idle featured in a one-hour symphony of British Music when he performed at the London 2012 Olympic Games closing ceremony.Terry Jones has been described by other members of the team as the ""heart"" of the operation. Jones had a lead role in maintaining the group's unity and creative independence. Python biographer George Perry has commented that should ""[you] speak to him on subjects as diverse as fossil fuels, or Rupert Bear, or mercenaries in the Middle Ages or Modern China ... in a moment you will find yourself hopelessly out of your depth, floored by his knowledge."" Many others agree that Jones is characterised by his irrepressible, good-natured enthusiasm. However, Jones' passion often led to prolonged arguments with other group members—in particular Cleese—with Jones often unwilling to back down. Since his major contributions were largely behind the scenes (direction, writing), and he often deferred to the other members of the group as an actor, Jones' importance to Python was often under-rated. However, he does have the legacy of delivering possibly the most famous line in all of Python, as Brian's mother Mandy in Life of Brian, ""He's not the Messiah, he's a very naughty boy!"", a line voted the funniest in film history on two occasions. Jones died on 21 January 2020 from complications of dementia.Sir Michael Palin attended Oxford, where he met his Python writing partner Jones. The two also wrote the series Ripping Yarns together. Palin and Jones originally wrote face-to-face, but soon found it was more productive to write apart and then come together to review what the other had written. Therefore, Jones and Palin's sketches tended to be more focused than that of the others, taking one bizarre situation, sticking to it, and building on it. After Flying Circus, Palin hosted Saturday Night Live four times in the first 10 seasons. His comedy output began to decrease in amount following the increasing success of his travel documentaries for the BBC. Palin released a book of diaries from the Python years entitled Michael Palin Diaries 1969–1979, published in 2007. Palin was awarded a knighthood in the 2019 New Year Honours, which was announced by Buckingham Palace in December 2018.


=== Associate Pythons ===
Several people have been accorded unofficial ""associate Python"" status over the years. Occasionally such people have been referred to as the 'seventh Python', in a style reminiscent of George Martin (or other associates of the Beatles) being dubbed ""the Fifth Beatle"".  The two collaborators with the most meaningful and plentiful contributions have been Neil Innes and Carol Cleveland. Both were present and presented as Associate Pythons at the official Monty Python 25th-anniversary celebrations held in Los Angeles in July 1994.

Neil Innes is the only non-Python besides Douglas Adams to be credited with writing material for Flying Circus. He appeared in sketches and the Python films, as well as performing some of his songs in Monty Python Live at the Hollywood Bowl. He was also a regular stand-in for absent team members on the rare occasions when they recreated sketches. For example, he took the place of Cleese at the Concert for George. Gilliam once noted that if anyone qualified for the title of the seventh Python, it would be Innes. He was one of the creative talents in the off-beat Bonzo Dog Band. He would later portray Ron Nasty of the Rutles and write all of the Rutles' compositions for All You Need Is Cash (1978), a mockumentary film co-directed by Idle. By 2005, a falling out had occurred between Idle and Innes over additional Rutles projects, the results being Innes' critically acclaimed Rutles ""reunion"" album The Rutles: Archaeology and Idle's straight-to-DVD The Rutles 2: Can't Buy Me Lunch, each undertaken without the other's participation. According to an interview with Idle in the Chicago Tribune in May 2005, his attitude is that Innes and he go back ""too far. And no further."" Innes died of a heart attack on 29 December 2019 near Toulouse, where he had lived for several years.Carol Cleveland was the most important female performer in the Monty Python ensemble, commonly referred to as ""the female Python"". She was originally hired by producer/director John Howard Davies for just the first five episodes of the Flying Circus. The Pythons then pushed to make Cleveland a permanent recurring performer after producer/director Ian MacNaughton brought in several other actresses who were not as good as she was. Cleveland went on to appear in about two-thirds of the episodes, as well as in all of the Python films, and in most of their stage shows, as well. According to Time, her most recognisable film roles are playing Zoot and Dingo, two maidens in the Castle Anthrax in Holy Grail.


=== Other contributors ===
Cleese's first wife, Connie Booth, appeared as various characters in all four series of Flying Circus. Her most significant role was the ""best girl"" of the eponymous Lumberjack in ""The Lumberjack Song"", though this role was sometimes played by Carol Cleveland. Booth appeared in a total of six sketches and also played one-off characters in Python feature films And Now for Something Completely Different and Monty Python and the Holy Grail.Douglas Adams was ""discovered"" by Chapman when a version of Footlights Revue (a 1974 BBC2 television show featuring some of Adams' early work) was performed live in London's West End. In Cleese's absence from the final TV series, the two formed a brief writing partnership, with Adams earning a writing credit in one episode for a sketch called ""Patient Abuse"". In the sketch—a satire on mind-boggling bureaucracy—a man who had been stabbed by a nurse arrives at his doctor's office bleeding profusely from the stomach, when the doctor makes him fill in numerous senseless forms before he can administer treatment. He also had two cameo appearances in this season. Firstly, in the episode ""The Light Entertainment War"", Adams shows up in a surgeon's mask (as Dr. Emile Koning, according to the on-screen captions), pulling on gloves, while Palin narrates a sketch that introduces one person after another, and never actually gets started. Secondly, at the beginning of ""Mr. Neutron"", Adams is dressed in a ""pepperpot"" outfit and loads a missile onto a cart being driven by Terry Jones, who is calling out for scrap metal (""Any old iron ...""). Adams and Chapman also subsequently attempted a few non-Python projects, including Out of the Trees. He also contributed to a sketch on the soundtrack album for Monty Python and the Holy Grail.
Other than Carol Cleveland, the only other non-Python to make a significant number of appearances in the Flying Circus was Ian Davidson. He appeared in the first two series of the show, and played over 10 roles. While Davidson is primarily known as a scriptwriter, it is not known if he had any contribution toward the writing of the sketches, as he is only credited as a performer. In total, Davidson is credited as appearing in eight episodes of the show, which is more than any other male actor who was not a Python. Despite this, Davidson did not appear in any Python-related media subsequent to series 2, though footage of him was shown on the documentary Python Night – 30 Years of Monty Python.Stand-up comedian Eddie Izzard, a devoted fan of the group, has occasionally stood in for absent members. When the BBC held a ""Python Night"" in 1999 to celebrate 30 years of the first broadcast of Flying Circus, the Pythons recorded some new material with Izzard standing in for Idle, who had declined to partake in person (he taped a solo contribution from the US). Izzard hosted The Life of Python (1999), a history of the group that was part of Python Night and appeared with them at a festival/tribute in Aspen, Colorado, in 1998 (released on DVD as Live at Aspen). Izzard has said that Monty Python was a significant influence on his style of comedy and Cleese has referred to him as ""the lost Python"".Series director of Flying Circus, Ian MacNaughton, is also regularly associated with the group and made a few on-screen appearances in the show and in the film And Now for Something Completely Different. Apart from Neil Innes, others to contribute musically included Fred Tomlinson and the Fred Tomlinson Singers. They made appearances in songs such as ""The Lumberjack Song"" as a backup choir. Other contributors and performers for the Pythons included John Howard Davies, John Hughman, Lyn Ashley, Bob Raymond, John Young, Rita Davies, Stanley Mason, Maureen Flanagan, and David Ballantyne.


=== Timeline ===

Monty Python in films

1971 – And Now for Something Completely Different
1975 – Monty Python and the Holy Grail
1979 – Life of Brian
1983 – The Meaning of Life
2012 – A Liar's Autobiography: The Untrue Story of Monty Python's Graham ChapmanMonty Python live

1970 – Oh Hampstead (Benefit show at St Pancras Town Hall, London, UK)
1971 – Lanchester Arts Festival '71 (Coventry, UK)
1972 – Then Great Western Express Festival (Four day event at Tupholme Hall, Lincolnshire, UK)
1973 – 1st UK Tours (UK)
1973 – 1st Farewell Tours (Canada)
1974 – Live Drury Lane (London, UK)
1976 – Monty Python Live! (New York, USA)
1980 – Monty Python Live at the Hollywood Bowl (Los Angeles, US)
2014 – Monty Python Live (Mostly): One Down, Five to Go (London, UK)Monty Python reunions

1989 – Parrot Sketch Not Included – 20 Years of Monty Python
1998 – Monty Python Live at Aspen (Aspen, US)
1999 – Python Night – 30 Years of Monty Python
2002 – Concert for George (Royal Albert Hall, UK)
2009 – Not the Messiah (He's a Very Naughty Boy) (Royal Albert Hall, UK)
2014 – Monty Python Live (Mostly): One Down, Five to Go (London, UK)


== Cultural influence and legacy ==

By the time of Monty Python's 25th anniversary, in 1994, the point was already being made that ""the five surviving members had with the passing years begun to occupy an institutional position in the edifice of British social culture that they had once had so much fun trying to demolish"". A similar point is made in a 2006 book on the relationship between Python and philosophy: ""It is remarkable, after all, not only that the utterly bizarre Monty Python's Flying Circus was sponsored by the BBC in the first place, but that Monty Python itself grew into an institution of enormous cultural influence.""A self-contained comedy unit responsible for both writing and performing their work, Monty Python's influence on comedy has been compared to the Beatles' influence on music. Author Neil Gaiman writes, ""A strange combination of individuals gave us Python. And you needed those people, just in the same way that with the Beatles you had four talented people, but together you had the Beatles. And I think that's so incredibly true when it comes to Python.""


=== Comedy stylists ===

Monty Python have been named as being influential to the comedy stylings of a great many people including: Sacha Baron Cohen, David Cross, Rowan Atkinson, Seth MacFarlane, Seth Meyers, Trey Parker, Matt Stone, Vic and Bob, Mike Myers, and ""Weird Al"" Yankovic. Matt Groening, creator of The Simpsons, was influenced by Python's ""high velocity sense of the absurd and not stopping to explain yourself"", and pays tribute through a couch gag used in seasons five and six. Appearing on Monty Python's Best Bits (Mostly), Jim Carrey—who refers to Monty Python as the ""Super Justice League of comedy""—recalled the effect on him of Ernest Scribbler (played by Palin) laughing himself to death in ""The Funniest Joke in the World"" sketch.Comedian John Oliver states, ""Writing about the importance of Monty Python is basically pointless. Citing them as an influence is almost redundant. It's assumed. This strange group of wildly talented, appropriately disrespectful, hugely imaginative and massively inspirational idiots changed what comedy could be for their generation and for those that followed."" On how Python's freeform style influenced sketch comedy, Tina Fey of the US television show Saturday Night Live states, ""Sketch endings are overrated. Their key was to do something as long as it was funny and then just stop and do something else.""


=== Places ===
In spaceSeven asteroids are named after Monty Python or its members: 9617 Grahamchapman, 9618 Johncleese, 9619 Terrygilliam, 9620 Ericidle, 9621 Michaelpalin, 9622 Terryjones, and 13681 Monty Python.
In 2010 the commercial space company SpaceX launched a wheel of cheese into low earth orbit and returned it safely to Earth on COTS Demo Flight 1. Elon Musk, CEO and CTO of SpaceX, said this was done as a tribute to Monty Python.TerrestrialAfter John Cleese spoke negatively about the town of Palmerston North in New Zealand, recommending it as a good place to commit suicide, the town renamed a compost heap ""Mt. Cleese"".


=== ""Pythonesque"" ===
Among the more visible cultural influences of Monty Python is the inclusion of terms either directly from, or derived from, Monty Python, into the lexicon of the English language.

The most obvious of these is the term ""Pythonesque"", which has become a byword in surreal humour, and is included in standard dictionaries. Terry Jones commented on his disappointment at the existence of such a term, claiming the initial aim of Monty Python was to create something new and impossible to categorise, and  ""the fact that Pythonesque is now a word in the Oxford English Dictionary shows the extent to which we failed"".
The term has been applied to animations similar to those constructed by Gilliam (e.g., the cut-out style of South Park, whose creators have often acknowledged a debt to Python, including contributing material to the aforementioned 30th-anniversary theme night).
Good Eats creator Alton Brown cited Python as one of the influences that shaped how he created the series, as well as how he authors the script for each episode. Later episodes included Gilliam-style animations to illustrate key points.
Film critic Robbie Collin writes, ""You can find the Pythonesque everywhere in cinema. Most successful Hollywood comedies bear some kind of Python-print. The Austin Powers series chugs along on Pythonisms. Then there are Christopher Guest's mockumentaries, such as Waiting for Guffman and Best in Show, which revel in the quiet absurdity of the everyday—well-staked-out Python territory. And there's a tensile weirdness in the films of Will Ferrell that's also deeply Pythonesque.""


=== TV ===
The Japanese anime series, Girls und Panzer, featured the special episode, ""Survival War!"", which referenced the 'Spam' sketch.


=== Things named after Monty Python ===
Beyond a dictionary definition, Python terms have entered the lexicon in other ways.

The term ""spam"" in reference to bulk, unsolicited email is derived from the show's 1970 ""Spam"" sketch. As the waitress recites the Spam-filled menu, a chorus of Viking patrons drown out all conversations with a song, repeating ""Spam, Spam, Spam, Spam… Spammity Spam! Wonderful Spam!"".
The Python programming language by Guido van Rossum is named after the troupe, and Monty Python references are often found in sample code created for that language. The default integrated development environment of the programming language is named IDLE, an alternative one is named eric, both in honour of Eric Idle.  Additionally, a 2001 April Fool's Day joke by van Rossum and Larry Wall involving the merger of Python with Perl was dubbed ""Parrot"" after the Dead Parrot sketch. The name ""Parrot"" was later used for a project to develop a virtual machine for running bytecode for interpreted languages such as Perl and Python. Its package index is also known as the ""Cheese Shop"" after the sketch of the same name. There is also a python refactoring tool called bicyclerepair named after Bicycle Repair Man sketch.
In 1985 a fossil of a previously unknown species of gigantic prehistoric snake from the Miocene was discovered in Riversleigh, Queensland, Australia. The Australian palaeontologist who discovered the fossil snake was a Monty Python fan, and he gave the snake the taxonomic name of Montypythonoides riversleighensis in honour of the Monty Python team.
In 2006, Ben & Jerry's, known for their ""celebrity flavours"", introduced to the line-up ""Vermonty Python"", a coffee liqueur ice cream with a chocolate cookie crumb swirl and fudge cows. The name ""Minty Python"" had been suggested before in 1996 in a contest to select the quintessential British ice cream flavour.
In 1999, in connection with the group's 30th anniversary, a beer named ""Holy Grail Ale"" was released by the Black Sheep Brewery in North Yorkshire.
The endangered Bemaraha woolly lemur (Avahi cleesei) is named after John Cleese.
Geneticists discovered a mutant gene which caused mutant flies to live twice as long as normal ones.  They dubbed the gene ""Indy,"" which is an acronym for the line of dialogue: ""I'm not dead yet!"", from the film Monty Python and the Holy Grail.
The band Toad the Wet Sprocket took its name from the Rock Notes sketch on the comedy album, Monty Python's Contractual Obligation Album.


=== World records ===

On St George's Day, 23 April 2007, the cast and creators of Spamalot gathered in Trafalgar Square under the tutelage of the two Terrys (Jones and Gilliam) to set a new record for the world's largest coconut orchestra. They led 5,567 people ""clip-clopping"" in time to the Python classic, ""Always Look on the Bright Side of Life"", for the Guinness World Records attempt.On 5 October 2019, to mark the 50th anniversary of Monty Python's first show, the ""first official Monty Python Guinness world record attempt"" tried to break the record for ""the largest gathering of people dressed as Gumbys."" A recurring character on the show, a Gumby wears a handkerchief on their head, has spectacles, braces, a knitted tank top, and wellington boots. The shirt sleeves and trouser legs are always rolled up, exposing their socks and knees. Dimwitted, their most famous catchphrases are ""My brain hurts!"" and repeated shouts of ""Hello!"" and ""Sorry!"".


== Media ==


=== Television ===
Monty Python's Flying Circus (1969–74)
The show that started the Python phenomenon, see also List of Monty Python's Flying Circus episodes.
Monty Python's Fliegender Zirkus (1972)
Two 45-minute specials were made by WDR for West German television.  The first was recorded in German, while the second was in English with German dubbing.
Monty Python's Personal Best (2006)
Six one-hour specials, each episode presenting the best of one member's work.


=== Films ===
Five Monty Python productions were released as theatrical films:

And Now for Something Completely Different (1971)
A collection of sketches from the first and second TV series of Monty Python's Flying Circus re-enacted and shot for film.
Monty Python and the Holy Grail (1975)
King Arthur and his knights embark on a low-budget search for the Holy Grail, encountering humorous obstacles along the way. Some of these turned into stand-alone sketches.
Monty Python's Life of Brian (1979)
Brian is born on the first Christmas, in the stable next to Jesus'. He spends his life being mistaken for a messiah.
Monty Python Live at the Hollywood Bowl (1982)
A videotape recording directed by Terry Hughes of a live performance of sketches, it was originally intended for a TV/video special. It was transferred to 35 mm and given a limited theatrical release in the US.
Monty Python's The Meaning of Life (1983)
An examination of the meaning of life in a series of sketches from conception to death and beyond.


=== Albums ===
Monty Python's Flying Circus (1970)
Another Monty Python Record (1971)
Monty Python's Previous Record (1972)
The Monty Python Matching Tie and Handkerchief (1973)
Monty Python Live at Drury Lane (1974)
The Album of the Soundtrack of the Trailer of the Film of Monty Python and the Holy Grail (1975)
Monty Python Live at City Center (1976)
The Monty Python Instant Record Collection (1977)
Monty Python's Life of Brian (1979)
Monty Python Examines The Life of Brian (promo) (1979)
Monty Python's Contractual Obligation Album (1980)
The Monty Python Instant Record Collection (US version) (1981)
Monty Python's The Meaning of Life (1983)
Monty Python's The Meaning of Life: Audio Press Kit (promo) (1983)
The Final Rip Off (1987)
Monty Python Sings (1989)
The Ultimate Monty Python Rip Off (1994)
Monty Python Sings Again (2014)
The Hastily Cobbled Together for a Fast Buck Album (unreleased)


=== Theatre ===
Monty Python's Flying Circus
Between 1974 and 1980 (Live at the Hollywood Bowl was released in 1982, but was performed in 1980), the Pythons made three sketch-based stage shows, comprising mainly material from the original television series.
Monty Python's Spamalot
Written by Idle and directed by Mike Nichols, with music and lyrics by John Du Prez and Idle, it starred Hank Azaria, Tim Curry, and David Hyde Pierce; Spamalot is a musical adaptation of the film Monty Python and the Holy Grail. It ran in Chicago from 21 December 2004 to 23 January 2005, and began performances on Broadway on 17 March 2005. It won three Tony Awards. It was one of eight UK musicals commemorated on Royal Mail stamps, issued in February 2011.
Not the Messiah
the Toronto Symphony Orchestra commissioned Idle and John Du Prez to write the music and lyrics of an oratorio based on Monty Python's Life of Brian. Entitled Not the Messiah, it had its world premiere as part of Luminato, a ""festival of arts and creativity"" taking place 1–10 June 2007 in Toronto, Ontario, Canada. Not the Messiah was conducted by Peter Oundjian, Music Director of the Toronto Symphony Orchestra, who is Idle's cousin. It was performed by a narrator, the Toronto Symphony Orchestra, with guest soloists and choir. According to Idle, ""I promise it will be funnier than Handel, though probably not as good"".
Monty Python Live
One Down, Five to Go : (1–5, 15–16, 18–20 July 2014). The Pythons have stated this is the last live reunion of the remaining members of Monty Python. Held at London's O2 Arena, tickets for the first night's show sold out in 43 seconds. The set list included a mix of live performances of their most popular sketches, clips from their shows, and elaborate dance numbers. Each night featured a different celebrity ""victim"" of the ""Blackmail"" sketch. The final show was screened to 2,000 cinemas around the world.


=== Books ===
Monty Python's Big Red Book (1971) ISBN 0-416-66890-9.
The Brand New Monty Python Bok (1973) ISBN 0-413-30130-3.
Monty Python and the Holy Grail (1977) ISBN 0-413-38520-5.
Monty Python's The Life of Brian/MONTYPYTHONSCRAPBOOK (1979, plus script-only reprint) ISBN 0-413-46550-0.
The Complete Works of Shakespeare and Monty Python. Volume One – Monty Python (1981)  ISBN 978-0-413-49450-4.
Monty Python: The Case Against (by Robert Hewison) (1981)
Monty Python's The Meaning of Life (1983) ISBN 0-413-53380-8.
The Monty Python Gift Boks (1986)
Monty Python's Flying Circus – Just The Words Volume 1 (1989) ISBN 0-413-62540-0.
Monty Python's Flying Circus – Just The Words Volume 2 (1989) ISBN 0-413-62550-8.
The Fairly Incomplete & Rather Badly Illustrated Monty Python Song Book (1994) ISBN 0-413-69000-8
Monty Python's Fliegender Zirkus (edited by Alfred Biolek) (1998)
Monty Python Speaks! (edited by David Morgan) (1999)
A Pocketful of Python Volume 1 (edited by Terry Jones) (1999)
A Pocketful of Python Volume 2 (edited by John Cleese) (1999)
A Pocketful of Python Volume 3 (edited by Terry Gilliam) (2000)
A Pocketful of Python Volume 4 (edited by Michael Palin) (2000)
A Pocketful of Python Volume 5 (edited by Eric Idle) (2002)
The Pythons Autobiography by The Pythons (edited by Bob McCabe) (2003, plus various reformatted editions)
Monty Python Live! (2009)
Monty Python at Work (by Michael Palin, compilation of republished diary entries) (2014)
So, Anyway ... (by John Cleese, Autobiography to age 30) (2014)
Always Look on the Bright Side of Life (by Eric Idle, Autobiography) (2018) ISBN 978-1-9848-2258-1.


=== Games ===
Monty Python's Flying Circus (1990) a computer game released by Virgin Games for 8-bit systems such as the Commodore 64, Amstrad CPC and the Sinclair ZX Spectrum, and for the 32-bit Amiga
Monty Python's Complete Waste of Time (1994) released by 7th Level for PC / Mac / DOS
Monty Python & the Quest for the Holy Grail (1996), official game released by 7th Level
Monty Python's The Meaning of Life (1997), also released by 7th Level.
Python-opoly (2007), a Monty Python-themed property game released by Toy Vault Inc.
Monty Python Fluxx (2008), a card game released by Looney Labs
Monty Python's Cow Tossing (2011), a smartphone game.
The Ministry of Silly Walks (2014), a smartphone game


== See also ==

List of recurring characters in Monty Python's Flying Circus
Python (Monty) Pictures
The Firesign Theatre


== References ==


== Further reading ==
Graham Chapman; Jim Yoakum (1997). Graham Crackers: Fuzzy Memories, Silly Bits, and Outright Lies. Career Press. ISBN 978-1-56414-334-1. Retrieved 1 October 2010.
Jim Yoakum (2011). Monty Python Vs The World. CreateSpace. ISBN 978-1-4700-0820-8.
Landy, Marcia (2005). Monty Python's flying circus. Wayne State University Press. ISBN 978-0-8143-3103-3. Retrieved 1 October 2010.
Larsen, Darl (2003). Monty Python, Shakespeare, and English Renaissance drama. McFarland. ISBN 978-0-7864-1504-5. Retrieved 1 October 2010.
Morgan, David (1999). Monty Python speaks!. Fourth Estate. ISBN 978-1-84115-168-7. Retrieved 1 October 2010.
Alan Parker; Mick O'Shea (2006). And Now For Something Completely Digital: The Complete Illustrated Guide to Monty Python CDs and DVDs. The Disinformation Company. ISBN 978-1-932857-31-3. Retrieved 1 October 2010.
Perry, George (2007). The Life of Python. Pavilion. ISBN 978-1-86205-762-3. Retrieved 1 October 2010.
Wilmut, Roger (1980). From fringe to flying circus: celebrating a unique generation of comedy, 1960–1980. Eyre Methuen. ISBN 978-0-413-46950-2. Retrieved 1 October 2010.
The Secret Policeman's Balls, 3-DVD set (2009)
""The Secret Policeman's Balls DVD Release"". Music For Human Rights. 27 January 2009. Archived from the original on 14 May 2009. Retrieved 19 August 2009.
Monty Python: 40 Years of Insanity
""Monty Python: 40 Years of Insanity"". Life. 5 October 2009. Archived from the original on 7 October 2009. Retrieved 6 October 2009.
The Life of Python – 20 Greatest Monty Python Sketches (40th Anniversary)
""The Life of Python – 20 Greatest Monty Python Sketches"". Gnews.com. 5 October 2009. Archived from the original on 7 October 2009. Retrieved 6 October 2009.


== External links ==

Official website
Monty Python at Curlie
Monty Python – Official YouTube page
40 Years of Monty Python – photo essay by TIME magazine
2014 interview on return to live shows
Monty Python on youtube"
"Tkinter is a Python binding to the Tk GUI toolkit. It is the standard Python interface to the Tk GUI toolkit, and is Python's de facto standard GUI. Tkinter is included with standard Linux, Microsoft Windows and Mac OS X installs of Python.
The name Tkinter comes from Tk interface. Tkinter was written by Fredrik Lundh.Tkinter is free software released under a Python license.


== Description ==
As with most other modern Tk bindings, Tkinter is implemented as a Python wrapper around a complete Tcl interpreter embedded in the Python interpreter. Tkinter calls are translated into Tcl commands which are fed to this embedded interpreter, thus making it possible to mix Python and Tcl in a single application.
There are several popular GUI library alternatives available, such as wxPython, PyQt, PySide, Pygame, Pyglet, and PyGTK.


=== Some definitions ===


=== Window ===
This term has different meanings in different contexts, but in general it refers to a rectangular area somewhere on the user's display screen.


=== Top Level Window ===
A window that exists independently on the screen. It will be decorated with the standard frame and controls for the desktop manager. It can be moved around the desktop, and can usually be resized.


=== Widget ===
The generic term for any of the building blocks that make up an application in a graphical user interface.

Core widgets: The containers: frame, labelframe, toplevel, paned window. The buttons: button, radiobutton, checkbutton (checkbox), and menubutton. The text widgets: label, message, text.  The entry widgets: scale, scrollbar, listbox, slider, spinbox, entry (singleline), optionmenu, text (multiline), and canvas (vector and pixel graphics).
Tkinter provides three modules that allow pop-up dialogs to be displayed: tk.messagebox (confirmation, information, warning and error dialogs), tk.filedialog (single file, multiple file and directory selection dialogs) and tk.colorchooser (colour picker).
Python 2.7 and Python 3.1 incorporate the ""themed Tk"" (""ttk"") functionality of Tk 8.5. This allows Tk widgets to be easily themed to look like the native desktop environment in which the application is running, thereby addressing a long-standing criticism of Tk (and hence of Tkinter). Some widgets are exclusive to ttk, such as the combobox, progressbar and treeview widgets


=== Frame ===
In Tkinter, the Frame widget is the basic unit of organization for complex layouts. A frame is a rectangular area that can contain other widgets.


=== Child and parent ===
When any widget is created, a parent-child relationship is created. For example, if you place a text label inside a frame, the frame is the parent of the label.


== A minimal application ==
Here is a minimal Python 3 Tkinter application with one widget: (For Python 2, the only difference is the word ""tkinter"" in the import command will be capitalized to ""Tkinter."")


=== Process ===
There are four stages to creating a widget

Create
create it within a frame
Configure
change the widgets attributes
Pack
pack it into position so it becomes visible
Bind
bind it to a function or event. These are often compressed and the order can vary.


=== Simple application ===
Using the object orientated paradigm in Python, a simple program would be (requires Tcl version 8.6, which is not used by Python on MacOS by default):

line 1:	Hashbang directive to the program launcher, allowing the selection of an appropriate interpreter executable, when self-executing.
line 2:	This line imports the tkinter module into your program's namespace, but renames it as tk.
line 4:	The application class inherits from Tkinter's Frame class.
line 6:	Defines the function that sets up the Frame
line 7:	Calls the constructor for the parent class, Frame.
line 11:	Defining the widgets
line 12:   Creates a label, named MondialLabel with the text ""Hello World""
line 13:   Sets the MondialLabel background colour to cyan
line 14:   Places the label on the application so it is visible using the grid geometry manager method
line 15:    Creates a button labeled “Quit”.
line 16:	Places the button on the application. Grid, place and pack are all methods of making the widget visible
line 18:	The main program starts here by instantiating the Application class.
line 19:	This method call sets the title of the window to “Sample application”.
line 20:	Starts the application's main loop, waiting for mouse and keyboard events.


== References ==


== External links ==
TkInter, Python Wiki
Tkinter GUI Tutorial, covers each widget individually.
Lundh, Fredrik (1999), An Introduction to Tkinter
TkDocs: includes language-neutral and Python-specific information and a tutorial
Ferg, Stephen, Thinking in Tkinter"
"Zed A. Shaw is a software developer most commonly known for creating the Mongrel web server for Ruby web applications, as well as his articles on technology, business, and technical communities. His most famous and well-covered piece was his article called ""Rails is a Ghetto"" which has since been removed from his site. Shaw is also behind an initiative entitled ""Programming, Motherfucker"", whose manifesto claims that programmers are ""tired of being told we're socially awkward idiots who need to be manipulated to work in a Forced Pair Programming chain gang.""


== Software ==
Shaw authored the Mongrel web server for Ruby web applications. Mongrel was the first web server used by Twitter, and inspired Node.js, according to its creator Ryan Dahl. Mongrel2 is the language-agnostic successor to Mongrel.
He has also written a Python mail server called Lamson, on which the mailing list site LibreList is built.


== Learn Code the Hard Way ==
Shaw is the author of learncodethehardway.org, which offers to teach users Python, Ruby, C, Regex, and SQL.


== Positions ==


=== Opposition to Python 3 ===
""There is a high probability that Python 3 is such a failure it will kill Python.""  - Zed Shaw
Shaw has a long-standing rant opposing Python 3, where he finds the new string type difficult to use, and as a result believes it should not be adopted.  Nonetheless, in February 2017 he published a first draft of Learn Python 3 The Hard Way.He stated in November 2016 that ""Python 3 is not Turing complete"" due to claims from Python project developers that Python 2 code cannot be made to run in the Python 3 VM.  This statement has drawn a lot of criticism.


=== Criticism of certain behaviours within startup culture ===
Shaw has spoken about the amounts of vague and misleading information that is pervasive on the startup and entrepreneur culture, particularly concerning self-proclaimed startup advisors or entrepreneurship ""gurus"", having demonstrated publicly how some notable figures in the industry appear to speak and provide advice from a background of success that they never actually attained.


== Books ==
Mongrel (Digital Shortcut): Serving, Deploying, and Extending Your Ruby Applications. Addison-Wesley Professional, 2006. ISBN 9780132701778
Professional Ruby Collection: Mongrel, Rails Plugins, Rails Routing, Refactoring to REST, and Rubyisms CD1 (Ruby Series). Addison-Wesley Professional, 2007. ISBN 0132417995
Learn Python the Hard Way. Self-published (1st and 2nd Editions), 2010 and 2011. ISBN 978-0321884916 and ISBN 978-1257853212
The Command Line Crash Course. Self-published, 2011.
Learn Regex the Hard Way. Self-published, 2011.
Learn SQL the Hard Way. Self-published, 2011.
Learn Python the Hard Way: A Very Simple Introduction to the Terrifyingly Beautiful World of Computers and Code 3rd edition. Republished under Addison-Wesley Professional, 2013. ISBN 978-0321884916
Learn Ruby the Hard Way: A Simple and Idiomatic Introduction to the Imaginative World Of Computational Thinking with Code. Addison-Wesley Professional, 2014 ISBN 978-0321884992
Learn C the Hard Way: Practical Exercises on the Computational Subjects You Keep Avoiding (Like C) (Zed Shaw's Hard Way Series). Addison-Wesley Professional, 2015. ISBN 978-0321884923
Mongrel: Learn to Build the Greatest Ruby Web Server Ever. Addison-Wesley Professional, 2015. ISBN 978-0321503091
Learn Python 3 the Hard Way: A Very Simple Introduction to the Terrifyingly Beautiful World of Computers and Code (Zed Shaw's Hard Way Series). Addison-Wesley Professional, 2017. ISBN 978-0134692883


== References ==


== External links ==
Zed Shaw's homepage
Zed's Web Framework, Tir Web Framework
LibreList, mailing list site built on Lamson
Zed Shaw's GitHub page
Learn Code the Hard Way Home Page"
"Python is an interpreted, high-level, general-purpose programming language. Created by Guido van Rossum and first released in 1991, Python's design philosophy emphasizes code readability with its notable use of significant whitespace. Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects.Python is dynamically typed and garbage-collected. It supports multiple programming paradigms, including structured (particularly, procedural), object-oriented, and functional programming. Python is often described as a ""batteries included"" language due to its comprehensive standard library.Python was conceived in the late 1980s as a successor to the ABC language. Python 2.0, released in 2000, introduced features like list comprehensions and a garbage collection system with reference counting.
Python 3.0, released in 2008, was a major revision of the language that is not completely backward-compatible, and much Python 2 code does not run unmodified on Python 3.
The Python 2 language was officially discontinued in 2020 (first planned for 2015), and ""Python 2.7.18 is the last Python 2.7 release and therefore the last Python 2 release."" No more security patches or other improvements will be released for it. With Python 2's end-of-life, only  Python 3.5.x and later are supported.
Python interpreters are available for many operating systems. A global community of programmers develops and maintains CPython, a free and open-source reference implementation. A non-profit organization, the Python Software Foundation, manages and directs resources for Python and CPython development.


== History ==

Python was conceived in the late 1980s by Guido van Rossum at Centrum Wiskunde & Informatica (CWI) in the Netherlands as a successor to the ABC language (itself inspired by SETL), capable of exception handling and interfacing with the Amoeba operating system. Its implementation began in December 1989. Van Rossum shouldered sole responsibility for the project, as the lead developer, until 12 July 2018, when he announced his ""permanent vacation"" from his responsibilities as Python's Benevolent Dictator For Life, a title the Python community bestowed upon him to reflect his long-term commitment as the project's chief decision-maker. He now shares his leadership as a member of a five-person steering council. In January 2019, active Python core developers elected Brett Cannon, Nick Coghlan, Barry Warsaw, Carol Willing and Van Rossum to a five-member ""Steering Council"" to lead the project.Python 2.0 was released on 16 October 2000 with many major new features, including a cycle-detecting garbage collector and support for Unicode.Python 3.0 was released on 3 December 2008. It was a major revision of the language that is not completely backward-compatible. Many of its major features were backported to Python 2.6.x and 2.7.x version series.  Releases of Python 3 include the 2to3 utility, which automates (at least partially) the translation of Python 2 code to Python 3.Python 2.7's end-of-life date was initially set at 2015 then postponed to 2020 out of concern that a large body of existing code could not easily be forward-ported to Python 3.


== Features and philosophy ==
Python is a multi-paradigm programming language. Object-oriented programming and structured programming are fully supported, and many of its features support functional programming and aspect-oriented programming (including by metaprogramming and metaobjects (magic methods)). Many other paradigms are supported via extensions, including design by contract and logic programming.Python uses dynamic typing and a combination of reference counting and a cycle-detecting garbage collector for memory management. It also features dynamic name resolution (late binding), which binds method and variable names during program execution.
Python's design offers some support for functional programming in the Lisp tradition. It has filter, map, and reduce functions; list comprehensions, dictionaries, sets, and generator expressions. The standard library has two modules (itertools and functools) that implement functional tools borrowed from Haskell and Standard ML.The language's core philosophy is summarized in the document The Zen of Python (PEP 20), which includes aphorisms such as:
Beautiful is better than ugly.
Explicit is better than implicit.
Simple is better than complex.
Complex is better than complicated.
Readability counts.Rather than having all of its functionality built into its core, Python was designed to be highly extensible. This compact modularity has made it particularly popular as a means of adding programmable interfaces to existing applications. Van Rossum's vision of a small core language with a large standard library and easily extensible interpreter stemmed from his frustrations with ABC, which espoused the opposite approach.Python strives for a simpler, less-cluttered syntax and grammar while giving developers a choice in their coding methodology. In contrast to Perl's ""there is more than one way to do it"" motto, Python embraces a ""there should be one—and preferably only one—obvious way to do it"" design philosophy. Alex Martelli, a Fellow at the Python Software Foundation and Python book author, writes that ""To describe something as 'clever' is not considered a compliment in the Python culture.""Python's developers strive to avoid premature optimization, and reject patches to non-critical parts of the CPython reference implementation that would offer marginal increases in speed at the cost of clarity. When speed is important, a Python programmer can move time-critical functions to extension modules written in languages such as C, or use PyPy, a just-in-time compiler. Cython is also available, which translates a Python script into C and makes direct C-level API calls into the Python interpreter.
An important goal of Python's developers is keeping it fun to use. This is reflected in the language's name—a tribute to the British comedy group Monty Python—and in occasionally playful approaches to tutorials and reference materials, such as examples that refer to spam and eggs (from a famous Monty Python sketch) instead of the standard foo and bar.A common neologism in the Python community is pythonic, which can have a wide range of meanings related to program style. To say that code is pythonic is to say that it uses Python idioms well, that it is natural or shows fluency in the language, that it conforms with Python's minimalist philosophy and emphasis on readability. In contrast, code that is difficult to understand or reads like a rough transcription from another programming language is called unpythonic.
Users and admirers of Python, especially those considered knowledgeable or experienced, are often referred to as Pythonistas.


== Syntax and semantics ==

Python is meant to be an easily readable language. Its formatting is visually uncluttered, and it often uses English keywords where other languages use punctuation. Unlike many other languages, it does not use curly brackets to delimit blocks, and semicolons after statements are optional. It has fewer syntactic exceptions and special cases than C or Pascal.


=== Indentation ===

Python uses whitespace indentation, rather than curly brackets or keywords, to delimit blocks. An increase in indentation comes after certain statements; a decrease in indentation signifies the end of the current block. Thus, the program's visual structure accurately represents the program's semantic structure. This feature is sometimes termed the off-side rule, which some other languages share, but in most languages indentation doesn't have any semantic meaning.


=== Statements and control flow ===
Python's statements include (among others):

The assignment statement (token '=', the equals sign). This operates differently than in traditional imperative programming languages, and this fundamental mechanism (including the nature of Python's version of variables) illuminates many other features of the language. Assignment in C, e.g., x = 2, translates to ""typed variable name x receives a copy of numeric value 2"". The (right-hand) value is copied into an allocated storage location for which the (left-hand) variable name is the symbolic address. The memory allocated to the variable is large enough (potentially quite large) for the declared type. In the simplest case of Python assignment, using the same example, x = 2, translates to ""(generic) name x receives a reference to a separate, dynamically allocated object of numeric (int) type of value 2."" This is termed binding the name to the object. Since the name's storage location doesn't contain the indicated value, it is improper to call it a variable. Names may be subsequently rebound at any time to objects of greatly varying types, including strings, procedures, complex objects with data and methods, etc. Successive assignments of a common value to multiple names, e.g., x = 2; y = 2; z = 2 result in allocating storage to (at most) three names and one numeric object, to which all three names are bound. Since a name is a generic reference holder it is unreasonable to associate a fixed data type with it. However at a given time a name will be bound to some object, which will have a type; thus there is dynamic typing.
The if statement, which conditionally executes a block of code, along with else and elif (a contraction of else-if).
The for statement, which iterates over an iterable object, capturing each element to a local variable for use by the attached block.
The while statement, which executes a block of code as long as its condition is true.
The try statement, which allows exceptions raised in its attached code block to be caught and handled by except clauses; it also ensures that clean-up code in a finally block will always be run regardless of how the block exits.
The raise statement, used to raise a specified exception or re-raise a caught exception.
The class statement, which executes a block of code and attaches its local namespace to a class, for use in object-oriented programming.
The def statement, which defines a function or method.
The with statement, from Python 2.5 released in September 2006, which encloses a code block within a context manager (for example, acquiring a lock before the block of code is run and releasing the lock afterwards, or opening a file and then closing it), allowing Resource Acquisition Is Initialization (RAII)-like behavior and replaces a common try/finally idiom.
The break statement, exits from the loop.
The continue statement, skips this iteration and continues with the next item.
The pass statement, which serves as a NOP. It is syntactically needed to create an empty code block.
The assert statement, used during debugging to check for conditions that ought to apply.
The yield statement, which returns a value from a generator function. From Python 2.5, yield is also an operator. This form is used to implement coroutines.
The import statement, which is used to import modules whose functions or variables can be used in the current program. There are three ways of using import: import <module name> [as <alias>] or from <module name> import * or from <module name> import <definition 1> [as <alias 1>], <definition 2> [as <alias 2>], ....
The print statement was changed to the print() function in Python 3.Python does not support tail call optimization or first-class continuations, and, according to Guido van Rossum, it never will. However, better support for coroutine-like functionality is provided in 2.5, by extending Python's generators. Before 2.5, generators were lazy iterators; information was passed unidirectionally out of the generator. From Python 2.5, it is possible to pass information back into a generator function, and from Python 3.3, the information can be passed through multiple stack levels.


=== Expressions ===
Some Python expressions are similar to languages such as C and Java, while some are not:

Addition, subtraction, and multiplication are the same, but the behavior of division differs. There are two types of divisions in Python. They are floor division (or integer division) // and floating point/division. Python also added the ** operator for exponentiation.
From Python 3.5, the new @ infix operator was introduced. It is intended to be used by libraries such as NumPy for matrix multiplication.
From Python 3.8, the syntax :=, called the 'walrus operator' was introduced. It assigns values to variables as part of a larger expression.
In Python, == compares by value, versus Java, which compares numerics by value and objects by reference. (Value comparisons in Java on objects can be performed with the equals() method.) Python's is operator may be used to compare object identities (comparison by reference). In Python, comparisons may be chained, for example a <= b <= c.
Python uses the words and, or, not for its boolean operators rather than the symbolic &&, ||, ! used in Java and C.
Python has a type of expression termed a list comprehension. Python 2.4 extended list comprehensions into a more general expression termed a generator expression.
Anonymous functions are implemented using lambda expressions; however, these are limited in that the body can only be one expression.
Conditional expressions in Python are written as x if c else y (different in order of operands from the c ? x : y operator common to many other languages).
Python makes a distinction between lists and tuples. Lists are written as [1, 2, 3], are mutable, and cannot be used as the keys of dictionaries (dictionary keys must be immutable in Python). Tuples are written as (1, 2, 3), are immutable and thus can be used as the keys of dictionaries, provided all elements of the tuple are immutable. The + operator can be used to concatenate two tuples, which does not directly modify their contents, but rather produces a new tuple containing the elements of both provided tuples. Thus, given the variable t initially equal to (1, 2, 3), executing t = t + (4, 5) first evaluates t + (4, 5), which yields (1, 2, 3, 4, 5), which is then assigned back to t, thereby effectively ""modifying the contents"" of t, while conforming to the immutable nature of tuple objects. Parentheses are optional for tuples in unambiguous contexts.
Python features sequence unpacking wherein multiple expressions, each evaluating to anything that can be assigned to (a variable, a writable property, etc.), are associated in the identical manner to that forming tuple literals and, as a whole, are put on the left hand side of the equal sign in an assignment statement. The statement expects an iterable object on the right hand side of the equal sign that produces the same number of values as the provided writable expressions when iterated through, and will iterate through it, assigning each of the produced values to the corresponding expression on the left.
Python has a ""string format"" operator %. This functions analogously to printf format strings in C, e.g. ""spam=%s eggs=%d"" % (""blah"", 2) evaluates to ""spam=blah eggs=2"". In Python 3 and 2.6+, this was supplemented by the format() method of the str class, e.g. ""spam={0} eggs={1}"".format(""blah"", 2). Python 3.6 added ""f-strings"": blah = ""blah""; eggs = 2; f'spam={blah} eggs={eggs}'.
Python has various kinds of string literals:
Strings delimited by single or double quote marks. Unlike in Unix shells, Perl and Perl-influenced languages, single quote marks and double quote marks function identically. Both kinds of string use the backslash (\) as an escape character. String interpolation became available in Python 3.6 as ""formatted string literals"".
Triple-quoted strings, which begin and end with a series of three single or double quote marks. They may span multiple lines and function like here documents in shells, Perl and Ruby.
Raw string varieties, denoted by prefixing the string literal with an r. Escape sequences are not interpreted; hence raw strings are useful where literal backslashes are common, such as regular expressions and Windows-style paths. Compare ""@-quoting"" in C#.
Python has array index and array slicing expressions on lists, denoted as a[key], a[start:stop] or a[start:stop:step]. Indexes are zero-based, and negative indexes are relative to the end. Slices take elements from the start index up to, but not including, the stop index. The third slice parameter, called step or stride, allows elements to be skipped and reversed. Slice indexes may be omitted, for example a[:] returns a copy of the entire list. Each element of a slice is a shallow copy.In Python, a distinction between expressions and statements is rigidly enforced, in contrast to languages such as Common Lisp, Scheme, or Ruby. This leads to duplicating some functionality. For example:

List comprehensions vs. for-loops
Conditional expressions vs. if blocks
The eval() vs. exec() built-in functions (in Python 2, exec is a statement); the former is for expressions, the latter is for statements.Statements cannot be a part of an expression, so list and other comprehensions or lambda expressions, all being expressions, cannot contain statements. A particular case of this is that an assignment statement such as a = 1 cannot form part of the conditional expression of a conditional statement. This has the advantage of avoiding a classic C error of mistaking an assignment operator = for an equality operator == in conditions: if (c = 1) { ... } is syntactically valid (but probably unintended) C code but if c = 1: ... causes a syntax error in Python.


=== Methods ===
Methods on objects are functions attached to the object's class; the syntax instance.method(argument) is, for normal methods and functions, syntactic sugar for Class.method(instance, argument). Python methods have an explicit self parameter to access instance data, in contrast to the implicit self (or this) in some other object-oriented programming languages (e.g., C++, Java, Objective-C, or Ruby).


=== Typing ===

Python uses duck typing and has typed objects but untyped variable names. Type constraints are not checked at compile time; rather, operations on an object may fail, signifying that the given object is not of a suitable type. Despite being dynamically typed, Python is strongly typed, forbidding operations that are not well-defined (for example, adding a number to a string) rather than silently attempting to make sense of them.
Python allows programmers to define their own types using classes, which are most often used for object-oriented programming. New instances of classes are constructed by calling the class (for example, SpamClass() or EggsClass()), and the classes are instances of the metaclass type (itself an instance of itself), allowing metaprogramming and reflection.
Before version 3.0, Python had two kinds of classes: old-style and new-style. The syntax of both styles is the same, the difference being whether the class object is inherited from, directly or indirectly (all new-style classes inherit from object and are instances of type). In versions of Python 2 from Python 2.2 onwards, both kinds of classes can be used. Old-style classes were eliminated in Python 3.0.
The long-term plan is to support gradual typing and from Python 3.5, the syntax of the language allows specifying static types but they are not checked in the default implementation, CPython. An experimental optional static type checker named mypy supports compile-time type checking.
^a Not directly accessible by name 


=== Mathematics ===
Python has the usual symbols for arithmetic operators (+, -, *, /), the floor division operator // and the modulo operation % (where the remainder can be negative,  e.g. 4 % -3 == -2). It also has ** for exponentiation, e.g. 5**3 == 125 and 9**0.5 == 3.0, and a matrix multiply operator @ . These operators work like in traditional math; with the same precedence rules, the operators infix ( + and - can also be unary to represent positive and negative numbers respectively).
Division between integers produces floating point results. The behavior of division has changed significantly over time:
Python 2.1 and earlier used C's division behavior. The / operator is integer division if both operands are integers, and floating-point division otherwise. Integer division rounds towards 0, e.g. 7/3 == 2 and -7/3 == -2.
Python 2.2 changed integer division to round towards negative infinity, e.g. 7/3 == 2 and -7/3 == -3. The floor division // operator was introduced. So 7//3 == 2, -7//3 == -3, 7.5//3 == 2.0 and -7.5//3 == -3.0. Adding from __future__ import division causes a module to use Python 3.0 rules for division (see next).
Python 3.0 changed / to always be floating-point division, e.g. 5/2 == 2.5.In Python terms, / is true division (or simply division), and // is floor division. / before version 3.0 is classic division.Rounding towards negative infinity, though different from most languages, adds consistency. For instance, it means that the equation (a + b)//b == a//b + 1 is always true. It also means that the equation b*(a//b) + a%b == a is valid for both positive and negative values of a. However, maintaining the validity of this equation means that while the result of a%b is, as expected, in the half-open interval [0, b), where b is a positive integer, it has to lie in the interval (b, 0] when b is negative.Python provides a round function for rounding a float to the nearest integer. For tie-breaking, Python 3 uses round to even: round(1.5) and round(2.5) both produce 2. Versions before 3 used round-away-from-zero: round(0.5) is 1.0, round(-0.5) is −1.0.Python allows boolean expressions with multiple equality relations in a manner that is consistent with general use in mathematics. For example, the expression a < b < c tests whether a is less than b and b is less than c. C-derived languages interpret this expression differently: in C, the expression would first evaluate a < b, resulting in 0 or 1, and that result would then be compared with c.Python uses arbitrary-precision arithmetic for all integer operations. The Decimal type/class in the decimal module provides decimal floating point numbers to a pre-defined arbitrary precision and several rounding modes. The Fraction class in the fractions module provides arbitrary precision for rational numbers.Due to Python's extensive mathematics library, and the third-party library NumPy that further extends the native capabilities, it is frequently used as a scientific scripting language to aid in problems such as numerical data processing and manipulation.


== Python programming examples ==
Hello world program:

Program to calculate the factorial of a positive integer:


== Libraries ==
Python's large standard library, commonly cited as one of its greatest strengths, provides tools suited to many tasks. For Internet-facing applications, many standard formats and protocols such as MIME and HTTP are supported. It includes modules for creating graphical user interfaces, connecting to relational databases, generating pseudorandom numbers, arithmetic with arbitrary-precision decimals, manipulating regular expressions, and unit testing.
Some parts of the standard library are covered by specifications (for example, the Web Server Gateway Interface (WSGI) implementation wsgiref follows PEP 333), but most modules are not. They are specified by their code, internal documentation, and test suites. However, because most of the standard library is cross-platform Python code, only a few modules need altering or rewriting for variant implementations.
As of November 2019, the Python Package Index (PyPI), the official repository for third-party Python software, contains over 200,000 packages with a wide range of functionality, including:

Automation
Data analytics
Databases
Documentation
Graphical user interfaces
Image processing
Machine learning
Mobile App
Multimedia
Networking
Scientific computing
System administration
Test frameworks
Text processing
Web frameworks
Web scraping


== Development environments ==

Most Python implementations (including CPython) include a read–eval–print loop (REPL), permitting them to function as a command line interpreter for which the user enters statements sequentially and receives results immediately.
Other shells, including IDLE and IPython, add further abilities such as improved auto-completion, session state retention and syntax highlighting.
As well as standard desktop integrated development environments, there are Web browser-based IDEs; SageMath (intended for developing science and math-related Python programs); PythonAnywhere, a browser-based IDE and hosting environment; and Canopy IDE, a commercial Python IDE emphasizing scientific computing.


== Implementations ==


=== Reference implementation ===
CPython is the reference implementation of Python. It is written in C, meeting the C89 standard with several select C99 features. It compiles Python programs into an intermediate bytecode which is then executed by its virtual machine. CPython is distributed with a large standard library written in a mixture of C and native Python. It is available for many platforms, including Windows (Vista and later; supported Windows XP and older, with by now unsupported Python 2.7) and most modern Unix-like systems. Platform portability was one of its earliest priorities, in Python 1 and 2 time-frame, even supporting VMS and OS/2; support has since been dropped for a lot of platforms.


=== Other implementations ===
PyPy is a fast, compliant interpreter of Python 2.7 and 3.6. Its just-in-time compiler brings a significant speed improvement over CPython but several libraries written in C cannot be used with it.Stackless Python is a significant fork of CPython that implements microthreads; it does not use the C memory stack, thus allowing massively concurrent programs. PyPy also has a stackless version.MicroPython and CircuitPython are Python 3 variants optimized for microcontrollers. This includes Lego Mindstorms EV3.


=== Unsupported implementations ===
Other just-in-time Python compilers have been developed, but are now unsupported:

Google began a project named Unladen Swallow in 2009, with the aim of speeding up the Python interpreter five-fold by using the LLVM, and of improving its multithreading ability to scale to thousands of cores, while ordinary implementations suffer from the global interpreter lock.
Psyco was a just-in-time specializing compiler that integrates with CPython and transforms bytecode to machine code at runtime. The emitted code is specialized for certain data types and is faster than standard Python code.In 2005, Nokia released a Python interpreter for the Series 60 mobile phones named PyS60. It includes many of the modules from the CPython implementations and some additional modules to integrate with the Symbian operating system. The project has been kept up-to-date to run on all variants of the S60 platform, and several third-party modules are available. The Nokia N900 also supports Python with GTK widget libraries, enabling programs to be written and run on the target device.


=== Cross-compilers to other languages ===
There are several compilers to high-level object languages, with either unrestricted Python, a restricted subset of Python, or a language similar to Python as the source language:

Cython compiles Python to C and C++.
Google's Grumpy (latest release in 2017) compiles Python 2 to Go.
IronPython follows a similar approach in order to run Python programs on the .NET Common Language Runtime.
Jython enables the use of the Java class library from a Python program.
MyHDL compiles Python to VHDL.
Nuitka compiles Python into C++.
Numba uses LLVM to compile Python to machine code.
Pyjs (latest release in 2012) compiles Python to JavaScript.
Pyrex (latest release in 2010) and Shed Skin (latest release in 2013) compile to C and C++ respectively.
Pythran compiles Python to C++.
RPython can be compiled to C, and is used to build the PyPy interpreter of Python.


=== Performance ===
A performance comparison of various Python implementations on a non-numerical (combinatorial) workload was presented at EuroSciPy '13. Python's performance compared to other programming languages has also been benchmarked by The Computer Language Benchmarks Game.


== Development ==
Python's development is conducted largely through the Python Enhancement Proposal (PEP) process, the primary mechanism for proposing major new features, collecting community input on issues and documenting Python design decisions. Python coding style is covered in PEP 8. Outstanding PEPs are reviewed and commented on by the Python community and the steering council.Enhancement of the language corresponds with development of the CPython reference implementation. The mailing list python-dev is the primary forum for the language's development. Specific issues are discussed in the Roundup bug tracker hosted at bugs.python.org. Development originally took place on a self-hosted source-code repository running Mercurial, until Python moved to GitHub in January 2017.CPython's public releases come in three types, distinguished by which part of the version number is incremented:

Backward-incompatible versions, where code is expected to break and need to be manually ported. The first part of the version number is incremented. These releases happen infrequently—for example, version 3.0 was released 8 years after 2.0.
Major or ""feature"" releases, about every 18 months, are largely compatible but introduce new features. The second part of the version number is incremented. Each major version is supported by bugfixes for several years after its release.
Bugfix releases, which introduce no new features, occur about every 3 months and are made when a sufficient number of bugs have been fixed upstream since the last release. Security vulnerabilities are also patched in these releases. The third and final part of the version number is incremented.Python 3.9 alpha1 was announced in November 2019 and with the adoption of a new yearly release cadence, the first release of 3.9 is slated for November 2020.Many alpha, beta, and release-candidates are also released as previews and for testing before final releases. Although there is a rough schedule for each release, they are often delayed if the code is not ready. Python's development team monitors the state of the code by running the large unit test suite during development, and using the BuildBot continuous integration system.The major academic conference on Python is PyCon. There are also special Python mentoring programmes, such as Pyladies.


== API documentation generators ==
Python API documentation generators include:

pydoc
Sphinx


== Naming ==
Python's name is derived from the British comedy group Monty Python, whom Python creator Guido van Rossum enjoyed while developing the language. Monty Python references appear frequently in Python code and culture; for example, the metasyntactic variables often used in Python literature are spam and eggs instead of the traditional foo and bar. The official Python documentation also contains various references to Monty Python routines.The prefix Py- is used to show that something is related to Python. Examples of the use of this prefix in names of Python applications or libraries include Pygame, a binding of SDL to Python (commonly used to create games); PyQt and PyGTK, which bind Qt and GTK to Python respectively; and PyPy, a Python implementation originally written in Python.


== Uses ==

Since 2003, Python has consistently ranked in the top ten most popular programming languages in the TIOBE Programming Community Index where, as of February 2020, it is the third most popular language (behind Java, and C). It was selected Programming Language of the Year in 2007, 2010, and 2018.An empirical study found that scripting languages, such as Python, are more productive than conventional languages, such as C and Java, for programming problems involving string manipulation and search in a dictionary, and determined that memory consumption was often ""better than Java and not much worse than C or C++"".Large organizations that use Python include Wikipedia, Google, Yahoo!, CERN, NASA, Facebook, Amazon, Instagram, Spotify and some smaller entities like ILM and ITA. The social news networking site Reddit is written entirely in Python.Python can serve as a scripting language for web applications, e.g., via mod_wsgi for the Apache web server. With Web Server Gateway Interface, a standard API has evolved to facilitate these applications. Web frameworks like Django, Pylons, Pyramid, TurboGears, web2py, Tornado, Flask, Bottle and Zope support developers in the design and maintenance of complex applications. Pyjs and IronPython can be used to develop the client-side of Ajax-based applications. SQLAlchemy can be used as a data mapper to a relational database. Twisted is a framework to program communications between computers, and is used (for example) by Dropbox.
Libraries such as NumPy, SciPy and Matplotlib allow the effective use of Python in scientific computing, with specialized libraries such as Biopython and Astropy providing domain-specific functionality. SageMath is a mathematical software with a notebook interface programmable in Python: its library covers many aspects of mathematics, including algebra, combinatorics, numerical mathematics, number theory, and calculus.Python has been successfully embedded in many software products as a scripting language, including in finite element method software such as Abaqus, 3D parametric modeler like FreeCAD, 3D animation packages such as 3ds Max, Blender, Cinema 4D, Lightwave, Houdini, Maya, modo, MotionBuilder, Softimage, the visual effects compositor Nuke, 2D imaging programs like GIMP, Inkscape, Scribus and Paint Shop Pro, and musical notation programs like scorewriter and capella. GNU Debugger uses Python as a pretty printer to show complex structures such as C++ containers. Esri promotes Python as the best choice for writing scripts in ArcGIS. It has also been used in several video games, and has been adopted as first of the three available programming languages in Google App Engine, the other two being Java and Go.Python is commonly used in artificial intelligence projects and machine learning projects with the help of libraries like TensorFlow, Keras, Pytorch and Scikit-learn. As a scripting language with modular architecture, simple syntax and rich text processing tools, Python is often used for natural language processing.Many operating systems include Python as a standard component. It ships with most Linux distributions, AmigaOS 4 (using Python 2.7), FreeBSD (as a package), NetBSD, OpenBSD (as a package) and macOS and can be used from the command line (terminal). Many Linux distributions use installers written in Python: Ubuntu uses the Ubiquity installer, while Red Hat Linux and Fedora use the Anaconda installer. Gentoo Linux uses Python in its package management system, Portage.
Python is used extensively in the information security industry, including in exploit development.Most of the Sugar software for the One Laptop per Child XO, now developed at Sugar Labs, is written in Python. The Raspberry Pi single-board computer project has adopted Python as its main user-programming language.
LibreOffice includes Python, and intends to replace Java with Python. Its Python Scripting Provider is a core feature since Version 4.0 from 7 February 2013.


== Languages influenced by Python ==
Python's design and philosophy have influenced many other programming languages:

Boo uses indentation, a similar syntax, and a similar object model.
Cobra uses indentation and a similar syntax, and its Acknowledgements document lists Python first among languages that influenced it.
CoffeeScript, a programming language that cross-compiles to JavaScript, has Python-inspired syntax.
ECMAScript/JavaScript borrowed iterators and generators from Python.
GDScript, a scripting language very similar to Python, built-in to the Godot game engine.
Go is designed for the ""speed of working in a dynamic language like Python"" and shares the same syntax for slicing arrays.
Groovy was motivated by the desire to bring the Python design philosophy to Java.
Julia was designed to be ""as usable for general programming as Python"".
Nim uses indentation and a similar syntax.
Ruby's creator, Yukihiro Matsumoto, has said: ""I wanted a scripting language that was more powerful than Perl, and more object-oriented than Python. That's why I decided to design my own language.""
Swift, a programming language developed by Apple, has some Python-inspired syntax.Python's development practices have also been emulated by other languages. For example, the practice of requiring a document describing the rationale for, and issues surrounding, a change to the language (in Python, a PEP) is also used in Tcl, Erlang, and Swift.


== See also ==

Python syntax and semantics
pip (package manager)


== References ==


=== Sources ===
""Python for Artificial Intelligence"". Wiki.python.org. 19 July 2012. Archived from the original on 1 November 2012. Retrieved 3 December 2012.
Paine, Jocelyn, ed. (August 2005). ""AI in Python"". AI Expert Newsletter. Amzi!. Archived from the original on 26 March 2012. Retrieved 11 February 2012.
""PyAIML 0.8.5 : Python Package Index"". Pypi.python.org. Retrieved 17 July 2013.
Russell, Stuart J. & Norvig, Peter (2009). Artificial Intelligence: A Modern Approach (3rd ed.). Upper Saddle River, NJ: Prentice Hall. ISBN 978-0-13-604259-4.


== Further reading ==
Downey, Allen B. (May 2012). Think Python: How to Think Like a Computer Scientist (Version 1.6.6 ed.). ISBN 978-0-521-72596-5.
Hamilton, Naomi (5 August 2008). ""The A-Z of Programming Languages: Python"". Computerworld. Archived from the original on 29 December 2008. Retrieved 31 March 2010.
Lutz, Mark (2013). Learning Python (5th ed.). O'Reilly Media. ISBN 978-0-596-15806-4.
Pilgrim, Mark (2004). Dive into Python. Apress. ISBN 978-1-59059-356-1.
Pilgrim, Mark (2009). Dive into Python 3. Apress. ISBN 978-1-4302-2415-0.
Summerfield, Mark (2009). Programming in Python 3 (2nd ed.). Addison-Wesley Professional. ISBN 978-0-321-68056-3.


== External links ==

Official website 
Python at Curlie"
"MoinMoin is a wiki engine implemented in Python, initially based on the PikiPiki wiki engine. Its name is a play on the North German greeting Moin, repeated as in WikiWiki. The MoinMoin code is licensed under the GNU General Public License v2, or (at the user's option) any later version (except some 3rd party modules that are licensed under other Free Software licenses compatible with the GPL).Dozens of organizations use MoinMoin to run public wikis, including free software projects Ubuntu, Apache, Debian, and FreeBSD.MoinMoin faces a supportability gap in 2020, based on the January 2020 deprecation of Python 2.7.  The current release of Moinmoin, 1.9.10, is written in Python 2.7 and is not slated to be ported to Python 3.  Moinmoin 2.0, based on Python 3.5, is not yet released (as of Aug. 2019), and ""development is very slow going,"" according to their Python3 support page.  Installation of Moinmoin 1.9.10 now yields multiple warnings of this deprecation.


== Technical details ==
MoinMoin's storage mechanism is based on flat files and folders, rather than a database. This makes it easy to manipulate the content in a text editor on the server if necessary, including managing revisions if the wiki gets attacked by spammers.
MoinMoin supports plug-ins and can be extended via Macros and Actions. It also uses the idea of separate parsers, e.g., for parsing the wiki syntax, and formatters, e.g., for outputting HTML code, with a SAX-like interface between the two. Therefore, to output DocBook instead of HTML, one would only need to write a docbook-formatter that implements the formatter interface, and all parsers that use the interface will automatically be supported.MoinMoin supports CamelCase linking as well as free links (non-CamelCase linking). The CamelCase is activated by default and MoinMoin does not allow disabling CamelCase links except on a one-off basis. The workaround to do this is to use a different parser but this option does not work with the WYSIWYG editor.MoinMoin also has extensive support for access-control lists (ACL) that greatly increase its usability in a content management system (CMS). It also has GUI editing capabilities.MoinMoin is able to either use a built-in search engine (rather slow, but no dependencies) or a Xapian-based indexed search engine (faster, and can also search old revisions and attached files).MoinMoin also allows synchronization of contents from instance to instance via XML-RPC, and therefore allows distributed offline editing.
The original MoinMoin ""DesktopEdition"" is significantly easier to use, because it uses a built-in Web server to display pages, requiring only Python to be installed on the host machine. Since version  1.6.0, the ""DesktopEdition"" has been integrated into the standard release. Also, in this release a different markup syntax was introduced, which had not been changed much since the early releases.


== See also ==

Comparison of wiki software
List of content management systems
List of wiki software


== References ==


== External links ==
Official website
MoinMoin Wiki GitHub organisation"
"Django ( JANG-goh; stylised as django) is a Python-based free and open-source web framework that follows the model-view-controller (MVC) architectural pattern. It is maintained by the Django Software Foundation (DSF), an American independent organization established as a 501(c)(3) non-profit.
Django's primary goal is to ease the creation of complex, database-driven websites. The framework emphasizes reusability and ""pluggability"" of components, less code, low coupling, rapid development, and the principle of don't repeat yourself. Python is used throughout, even for settings files and data models. Django also provides an optional administrative create, read, update and delete interface that is generated dynamically through introspection and configured via admin models.
Some well known sites that use Django include PBS, Instagram, Mozilla, The Washington Times, Disqus, Bitbucket, and Nextdoor.


== History ==
Django was created in the fall of 2003, when the web programmers at the Lawrence Journal-World newspaper, Adrian Holovaty and Simon Willison, began using Python to build applications. Jacob Kaplan-Moss was hired early in Django's development shortly before Simon Willison's internship ended. It was released publicly under a BSD license in July 2005. The framework was named after guitarist Django Reinhardt.In June 2008, it was announced that a newly formed Django Software Foundation (DSF) would maintain Django in the future.


== Features ==


=== Components ===

Despite having its own nomenclature, such as naming the callable objects generating the HTTP responses ""views"", the core Django framework can be seen as an MVC architecture. It consists of an object-relational mapper (ORM) that mediates between data models (defined as Python classes) and a relational database (""Model""), a system for processing HTTP requests with a web templating system (""View""), and a regular-expression-based URL dispatcher (""Controller"").
Also included in the core framework are:

a lightweight and standalone web server for development and testing
a form serialization and validation system that can translate between HTML forms and values suitable for storage in the database
a template system that utilizes the concept of inheritance borrowed from object-oriented programming
a caching framework that can use any of several cache methods
support for middleware classes that can intervene at various stages of request processing and carry out custom functions
an internal dispatcher system that allows components of an application to communicate events to each other via pre-defined signals
an internationalization system, including translations of Django's own components into a variety of languages
a serialization system that can produce and read XML and/or JSON representations of Django model instances
a system for extending the capabilities of the template engine
an interface to Python's built-in unit test framework
We can also create web apis with Django Rest Framework.


=== Bundled applications ===
The main Django distribution also bundles a number of applications in its ""contrib"" package, including:

an extensible authentication system
the dynamic administrative interface
tools for generating RSS and Atom syndication feeds
a ""Sites"" framework that allows one Django installation to run multiple websites, each with their own content and applications
tools for generating Google Sitemaps
built-in mitigation for cross-site request forgery, cross-site scripting, SQL injection, password cracking and other typical web attacks, most of them turned on by default
a framework for creating GIS applications


=== Extensibility ===
Django's configuration system allows third party code to be plugged into a regular project, provided that it follows the reusable app conventions. More than 2500 packages are available to extend the framework's original behavior, providing solutions to issues the original tool didn't tackle: registration, search, API provision and consumption, CMS, etc.
This extensibility is, however, mitigated by internal components' dependencies. While the Django philosophy implies loose coupling, the template filters and tags assume one engine implementation, and both the auth and admin bundled applications require the use of the internal ORM. None of these filters or bundled apps are mandatory to run a Django project, but reusable apps tend to depend on them, encouraging developers to keep using the official stack in order to benefit fully from the apps ecosystem.


=== Server arrangements ===
Django can be run in conjunction with Apache, Nginx using WSGI, Gunicorn, or Cherokee using flup (a Python module). Django also includes the ability to launch a FastCGI server, enabling use behind any web server which supports FastCGI, such as Lighttpd or Hiawatha. It is also possible to use other WSGI-compliant web servers. Django officially supports four database backends: PostgreSQL, MySQL, SQLite, and Oracle. Microsoft SQL Server can be used with django-mssql on Microsoft operating systems, while similarly external backends exist for IBM Db2, SQL Anywhere and Firebird. There is a fork named django-nonrel, which supports NoSQL databases, such as MongoDB and Google App Engine's Datastore.Django may also be run in conjunction with Jython on any Java EE application server such as GlassFish or JBoss. In this case django-jython must be installed in order to provide JDBC drivers for database connectivity, which also can provide functionality to compile Django in to a .war suitable for deployment.Google App Engine includes support for Django version 1.x.x as one of the bundled frameworks.


== Version history ==
The Django team will occasionally designate certain releases to be “long-term support” (LTS) releases. LTS releases will get security and data loss fixes applied for a guaranteed period of time, typically 3+ years, regardless of the pace of releases afterwards.


== Development tools with Django support ==
For developing a Django project, no special tools are necessary, since the source code can be edited with any conventional text editor.
Nevertheless, editors specialized on computer programming can help increase the productivity of development, e.g., with features such as syntax highlighting. Since Django is written in Python, text editors which are aware of Python syntax are beneficial in this regard.
Integrated development environments (IDE) add further functionality, such as debugging, refactoring, and unit testing. As with plain editors, IDEs with support for Python can be beneficial. Some IDEs that are specialized on Python additionally have integrated support for Django projects, so that using such an IDE when developing a Django project can help further increase productivity. For comparison of such Python IDEs, see the main article:


== Community ==
There is a semiannual conference for Django developers and users, named ""DjangoCon"", that has been held since September 2008. DjangoCon is held annually in Europe, in May or June; while another is held in the United States in August or September, in various cities. The 2012 DjangoCon took place in Washington, D.C., from 3 to 8 September. 2013 DjangoCon was held in Chicago at the Hyatt Regency Hotel and the post-conference Sprints were hosted at Digital Bootcamp, computer training center. The 2014 DjangoCon US returned to Portland, OR from 30 August to 6 September. The 2015 DjangoCon US was held in Austin, TX from 6 to 11 September at the AT&T Executive Center. The 2016 DjangoCon US was held in Philadelphia, PA at The Wharton School of the University of Pennsylvania from 17 to 22 July.The 2017 DjangoCon US was held in Spokane, WA; in 2018 DjangoCon US was held in San Diego, CA. DjangoCon US 2019 was held again in San Diego, CA from Sept 22–27.
Django mini-conferences are usually held every year as part of the Australian Python Conference 'PyCon AU'. Previously, these mini-conferences have been held in:

Hobart, Australia, in July 2013,
Brisbane, Australia, in August 2014 and 2015,
Melbourne, Australia in August 2016 and 2017, and
Sydney, Australia, in August 2018 and 2019.Django has spawned user groups and meetups around the world, the most notable group is the Django Girls organization, which began in Poland but now has had events in 91 countries.


== Ports to other languages ==
Programmers have ported Django's template design from Python to other languages, providing decent cross-platform support. Some of these options are more direct ports; others, though inspired by Django and retaining its concepts, take the liberty to deviate from Django's design:

Liquid for Ruby
Template::Swig for Perl
Twig for PHP and JavaScript
Jinja for Python
ErlyDTL for Erlang


== See also ==

Flask (web framework)
Pylons project
Comparison of web frameworks
Web2py
Ruby on Rails


== References ==


== Bibliography ==

This list is an extraction from Current Django Books


== External links ==
Official website"
"Matplotlib is a plotting library for the Python programming language and its numerical mathematics extension NumPy. It provides an object-oriented API for embedding plots into applications using general-purpose GUI toolkits like Tkinter, wxPython, Qt, or GTK+. There is also a procedural ""pylab"" interface based on a state machine (like OpenGL), designed to closely resemble that of MATLAB, though its use is discouraged. SciPy makes use of Matplotlib.
Matplotlib was originally written by John D. Hunter, since then it has an active development community, and is distributed under a BSD-style license. Michael Droettboom was nominated as matplotlib's lead developer shortly before John Hunter's death in August 2012, and further joined by Thomas Caswell.Matplotlib 2.0.x supports Python versions 2.7 through 3.6. Python 3 support started with Matplotlib 1.2. Matplotlib 1.4 is the last version to support Python 2.6. Matplotlib has pledged to not support Python 2 past 2020 by signing the Python 3 Statement.


== Comparison with MATLAB ==
Pyplot is a Matplotlib module which provides a MATLAB-like interface. Matplotlib is designed to be as usable as MATLAB, with the ability to use Python, and the advantage of being free and open-source.


== Examples ==

		
		
		
		
		
		
		
		
		
		


== Toolkits ==
Several toolkits are available which extend Matplotlib functionality. Some are separate downloads, others ship with the Matplotlib source code but have external dependencies.
Basemap: map plotting with various map projections, coastlines, and political boundaries
Cartopy: a mapping library featuring object-oriented map projection definitions, and arbitrary point, line, polygon and image transformation capabilities. (Matplotlib v1.2 and above)
Excel tools: utilities for exchanging data with Microsoft Excel
GTK tools: interface to the GTK+ library
Qt interface
Mplot3d: 3-D plots
Natgrid: interface to the natgrid library for gridding irregularly spaced data.
matplotlib2tikz: export to Pgfplots for smooth integration into LaTeX documents


== Related projects ==
Biggles
Chaco
DISLIN
GNU Octave
Gnuplot-py
PLplot – Python bindings available
PyCha – libcairo implementation
PyPlotter – compatible with Jython
SageMath – uses Matplotlib to draw plots
SciPy (modules plt and gplt)
wxPython (module wx.lib.plot.py)
Plotly – for interactive, online Matplotlib and Python graphs
Bokeh – Python interactive visualization library that targets modern web browsers for presentation


== References ==


== External links ==
Official website"
"wxPython is a wrapper for the cross-platform GUI API (often referred to as a ""toolkit"") wxWidgets (which is written in C++) for the Python programming language. It is one of the alternatives to Tkinter. It is implemented as a Python extension module (native code).


== License ==
Being a wrapper, wxPython uses the same free software licence used by wxWidgets (wxWindows License)—which is approved by Free Software Foundation and Open Source Initiative.


== History ==
wxPython was created when Robin Dunn needed a GUI to be deployed on HP-UX systems and also on Windows 3.1 within a few weeks.  While evaluating commercial solutions, he ran across Python bindings for the wxWidgets toolkit. Thus, he learned Python and, in a short time, together with Harri Pasanen, became one of the main developers of wxPython, which grew from those initial bindings.
The first versions of the wrapper were created by hand. However, soon the code base became very difficult to maintain and keep synchronized with wxWidgets releases. Later versions were created with SWIG, greatly decreasing the amount of work to update the wrapper. The first ""modern"" version was announced in 1998.


== Example ==
This is a simple ""Hello world"" module, depicting the creation of the two main objects in wxPython (the main window object and the application object), followed by passing the control to the event-driven system (by calling MainLoop()) which manages the user-interactive part of the program.

This is another example of wxpython Close Button with wxpython GUI display show in windows 10 operation system.


== Project Phoenix ==
Project Phoenix, which began in 2010, is an effort to clean up the wxPython implementation and in the process make it compatible with Python 3. This project is a new implementation of wxPython, focused on improving speed, maintainability and extensibility. Just like ""Classic"" wxPython, it wraps the wxWidgets C++ toolkit and provides access to the user interface portions of the wx API, enabling Python applications to have a graphical user interface on Windows, Mac or Unix systems with a native look and feel and requiring very little, if any, platform-specific code.


== Applications developed with wxPython ==
BitTorrent, a peer-to-peer BitTorrent application
Chandler, a personal information manager
Editra, a multi-platform text editor
Google Drive, desktop client for the Google cloud-based storage system
GRASS GIS, a free, open source geographical information system
Métamorphose, a batch renamer
Phatch, a photo batch processor
PlayOnLinux and PlayOnMac, Wine front-ends
PsychoPy, experiment creation tool for neuroscience and psychology research


== References ==


=== Citations ===


=== Sources ===


== Further reading ==
Precord, Cody (December 2010). wxPython 2.8 Application Development Cookbook. Greenwich: Packt Publishing. p. 308. ISBN 978-1-84951-178-0.


== External links ==

Official website
Project Phoenix main page
List of applications developed with wxPython
Tutorial screencasts for starting wxPython programming at showmedo"
"Python molurus is a large, nonvenomous python species native to tropical and subtropical regions of the Indian subcontinent and Southeast Asia. It is known by the common names Indian python, black-tailed python, Indian rock python, and Asian rock python.  It is generally lighter colored than the Burmese python and reaches usually 3 m (9.8 ft).


== Description ==

The rock python's color pattern is whitish or yellowish with the blotched patterns varying from tan to dark brown shades. This varies with terrain and habitat. Specimens from the hill forests of Western Ghats and Assam are darker, while those from the Deccan Plateau and Eastern Ghats are usually lighter.The nominate subspecies occurring in India typically grows to 3 m (9.8 ft). This value is supported by a 1990 study in Keoladeo National Park, where 25% of the python population was 2.7–3.3 m (8.9–10.8 ft) long. Two individuals even measured nearly 3.6 m (12 ft).Because of confusion with the Burmese python, exaggerations, and stretched skins in the past, the maximum length of this subspecies is difficult to tell. The longest scientifically recorded specimen, collected in Pakistan, was 4.6 m (15 ft) long and weighed 52 kg (110 lb). In Pakistan, Indian pythons commonly reach a length of 2.4–3.0 m (7.9–9.8 ft).


== Distribution and habitat ==

P. molurus occurs in India, southern Nepal, Pakistan, Sri Lanka, Bhutan, Bangladesh, and probably in the north of Myanmar. It lives in a wide range of habitats, including grasslands, swamps, marshes, rocky foothills, woodlands, open forest, and river valleys. It needs a permanent source of water. It hides in abandoned mammal burrows, hollow trees, dense water reeds, and mangrove thickets.


== Behavior ==

Lethargic and slow moving even in their native habitat, they exhibit timidity and rarely try to attack even when attacked. Locomotion is usually with the body moving in a straight line, by ""walking on its ribs"". They are excellent swimmers and are quite at home in water. They can be wholly submerged in water for many minutes if necessary, but usually prefer to remain near the bank.


=== Feeding ===

Like all snakes, Indian pythons are strict carnivores and feed on mammals, birds, and reptiles indiscriminately, but seem to prefer mammals. Roused to activity on sighting prey, the snake advances with a quivering tail and lunges with an open mouth. Live prey is constricted and killed. One or two coils are used to hold it in a tight grip. The prey, unable to breathe, succumbs and is subsequently swallowed head first. After a heavy meal, they are disinclined to move. If forced to, hard parts of the meal may tear through the body. Therefore, if disturbed, some specimens  disgorge their meal to escape from potential predators. After a heavy meal, an individual may fast for weeks, the longest recorded duration being 2 years. The python can swallow prey bigger than its diameter because the jaw bones are not connected. Moreover, prey cannot escape from its mouth because of the arrangement of the teeth (which are reverse saw-like).


=== Reproduction ===

Oviparous, up to 100 eggs are laid by a female, which she protects and incubates. Towards this end, they are capable of raising their body temperature above the ambient level through muscular contractions. The hatchlings are 45–60 cm (18–24 in) in length and grow quickly. An artificial incubation method using climate-controlled environmental chambers was developed in India for successfully raising hatchlings from abandoned or unattended eggs.


== Conservation status ==
The Indian python is classified as lower risk/near threatened on the  IUCN Red List of Threatened Species (v2.3, 1996). This listing indicates that it may become threatened with extinction and is in need of frequent reassessment.


== Taxonomy ==
In the literature, one other subspecies may be encountered: P. m. pimbura Deraniyagala, 1945, which is found in Sri Lanka.
The Burmese python (Python bivittatus) was referred to as a subspecies of the Indian python until 2009, when it was elevated to full species status. The name Python molurus bivittatus is found in older literature.


== In popular culture ==
Kaa, a large and young Indian python, is featured in The Jungle Book.


== References ==


== Further reading ==


== External links ==
Python molurus at the Reptarium.cz Reptile Database. Accessed 13 September 2007.
Indian Python at Ecology Asia. Accessed 13 September 2007.
Indian python at Animal Pictures Archive. Accessed 13 September 2007.
Watch Indian rock python (Python molurus) video clips from the BBC archive on Wildlife Finder"
"The proc filesystem (procfs) is a special filesystem in Unix-like operating systems that presents information about processes and other system information in a hierarchical file-like structure, providing a more convenient and standardized method for dynamically accessing process data held in the kernel than traditional tracing methods or direct access to kernel memory. Typically, it is mapped to a mount point named /proc at boot time. The proc  file  system acts as an interface to internal data structures in the
kernel. It  can  be  used to obtain information about the system and to change
certain kernel parameters at runtime (sysctl).
Many Unix-like operating systems support the proc filesystem, including Solaris, IRIX, Tru64 UNIX, BSD, Linux, IBM AIX, QNX, and Plan 9 from Bell Labs. OpenBSD dropped support in version 5.7, released in May 2015.
The Linux kernel extends it to non–process-related data.
The proc filesystem provides a method of communication between kernel space and user space. For example, the GNU version of the process reporting utility ps uses the proc file system to obtain its data, without using any specialized system calls.


== History ==


=== UNIX 8th Edition ===
Tom J. Killian implemented the UNIX 8th Edition (V8) version of /proc: he presented a paper titled ""Processes as Files"" at USENIX in June 1984. The design of procfs aimed to replace the ptrace system call used for process tracing.  Detailed documentation can be found in the proc(4) manual page.


=== SVR4 ===
Roger Faulkner and Ron Gomes ported V8 /proc to SVR4, and published a paper called ""The Process File System and Process Model in UNIX System V"" at USENIX in January 1991. This kind of procfs supported the creation of ps, but the files could only be accessed with functions read(), write(), and ioctl(). Between 1995 and 1996, Roger Faulkner created the procfs-2 interface for Solaris-2.6 that offers a structured /proc filesystem with sub-directories.


=== Plan 9 ===
Plan 9 implemented a process file system, but went further than V8.  V8's process file system implemented a single file per process. Plan 9 created a hierarchy of separate files to provide those functions, and made /proc a real part of the file system.


=== 4.4BSD ===
4.4BSD cloned its implementation of /proc from Plan 9. As of February 2011, procfs is gradually becoming phased out in FreeBSD. It was removed from OpenBSD in version 5.7, which was released in May 2015, because it ""always suffered from race conditions and is now unused"".


=== Solaris ===
/proc in Solaris was available from the beginning. Solaris 2.6 in 1996 introduced procfs2 from Roger Faulkner.


=== Linux ===
Linux implementation includes a directory for each running process, including kernel processes, in directories named /proc/PID, where PID is the process number. Each directory contains information about one process, including:

/proc/PID/cmdline, the command that originally started the process.
/proc/PID/cwd, a symlink to the current working directory of the process.
/proc/PID/environ contains the names and values of the environment variables that affect the process.
/proc/PID/exe, a symlink to the original executable file, if it still exists (a process may continue running after its original executable has been deleted or replaced).
/proc/PID/fd, a directory containing a symbolic link for each open file descriptor.
/proc/PID/fdinfo, a directory containing entries which describe the position and flags for each open file descriptor.
/proc/PID/maps, a text file containing information about mapped files and blocks (like heap and stack).
/proc/PID/mem, a binary image representing the process's virtual memory, can only be accessed by a ptrace'ing process.
/proc/PID/root, a symlink to the root path as seen by the process.  For most processes this will be a link to / unless the process is running in a chroot jail.
/proc/PID/status contains basic information about a process including its run state and memory usage.
/proc/PID/task, a directory containing hard links to any tasks that have been started by this (i.e.: the parent) process.(Users may obtain the PID with a utility such as pgrep, pidof or ps:

)
/proc also includes non-process-related system information, although in the 2.6 kernel much of that information moved to a separate pseudo-file system, sysfs, mounted under /sys:

depending on the mode of power management (if at all), either directory, /proc/acpi or /proc/apm, which predate sysfs and contain various bits of information about the state of power management.
/proc/buddyinfo, information about the buddy algorithm that handles memory fragmentation.
/proc/bus, containing directories representing various buses on the computer, such as input/PCI/USB.  This has been largely superseded by sysfs under /sys/bus which is far more informative.
/proc/fb, a list of the available framebuffers
/proc/cmdline, giving the boot options passed to the kernel
 /proc/cpuinfo, containing information about the CPU, such as its vendor (and CPU family, model and model names which should allow users to identify the CPU) and its speed (CPU clockspeed), cache size, number of siblings, cores, and CPU flags.  /proc/cpuinfo includes a value for ""bogomips"", frequently misconstrued as a measure of CPU speed, like a benchmark, but it does not actually measure any sensible (for end-users) value at all. It occurs as a side-effect of kernel timer calibration and yields highly varying values depending on CPU type, even at equal clock speeds.
On multi-core CPUs, /proc/cpuinfo contains the fields for ""siblings"" and ""cpu cores"" which represent the following calculation is applied:
""siblings"" = (HT per CPU package) * (# of cores per CPU package)
""cpu cores"" = (# of cores per CPU package)
A CPU package means physical CPU which can have multiple cores (single core for one, dual core for two, quad core for four).
This allows a distinction between hyper-threading and dual-core, i.e. the number of hyper-threads per CPU package can be calculated by siblings / CPU cores. If both values for a CPU package are the same, then hyper-threading is not supported.  For instance, a CPU package with siblings=2 and ""cpu cores""=2 is a dual-core CPU but does not support hyper-threading.

/proc/crypto, a list of available cryptographic modules
/proc/devices,  a list of character and block devices sorted by device ID but giving the major part of the /dev name too
/proc/diskstats, giving some information (including device numbers) for each of the logical disk devices
/proc/filesystems, a list of the file systems supported by the kernel at the time of listing
/proc/interrupts, /proc/iomem, /proc/ioports and the directory /proc/irq, giving some self-explanatory details about the devices (physical or logical) using the various system resources
/proc/kmsg, holding messages output by the kernel
/proc/meminfo, containing a summary of how the kernel is managing its memory.
/proc/modules, one of the most important files in /proc, containing a list of the kernel modules currently loaded . It gives some indication (not always entirely correct) of dependencies.
/proc/mounts, a symlink to self/mounts which contains a list of the currently mounted devices and their mount points (and which file system is in use and what mount options are in use).
/proc/net/, a directory containing useful information about the network stack, in particular /proc/net/nf_conntrack, which lists existing network connections (particularly useful for tracking routing when iptables FORWARD is used to redirect network connections)
/proc/partitions, a list of the device-numbers, their size and /dev names which the kernel has identified as existing partitions
/proc/scsi, giving information about any devices connected via a SCSI or RAID controller
a symbolic link to the current (traversing) process at /proc/self (i.e. /proc/PID/ where PID is that of the current process).
/proc/slabinfo, listing statistics on the caches for frequently-used objects in the Linux kernel
/proc/swaps, a list of the active swap partitions, their various sizes and priorities
Access to dynamically-configurable kernel options under /proc/sys.  Under /proc/sys appear directories representing the areas of kernel, containing readable and writable virtual files. For example, a commonly referenced virtual file is  /proc/sys/net/ipv4/ip_forward, because it is necessary for routing firewalls or tunnels. The file contains either a '1' or a '0': if it is 1, the IPv4 stack forwards packets not meant for the local host, if it is 0 then it does not.
/proc/sysvipc, containing memory-sharing and inter-process communication (IPC) information.
/proc/tty, containing information about the current terminals; /proc/tty/driver looks to be a list of the different types of tty available - each of which is a list of those of each type
/proc/uptime, the length of time the kernel has been running since boot and spent in idle mode (both in seconds)
/proc/version, containing the Linux kernel version, distribution number, gcc version number (used to build the kernel) and any other pertinent information relating to the version of the kernel currently running
other files depending on various hardware, module configurations, and changes to the kernel.The basic utilities that use /proc under Linux come in the procps (/proc processes) package, and only function in conjunction with a mounted /proc.


=== Proprietary Expansions ===
Several companies and projects added additional functions to /proc for their systems, e.g. /proc/lcd, might be a file containing the contents of the front-panel LCD screen.  Text written to this file would be displayed on the screen.


== References ==

Unix 8th Edition proc(2) manual page - Description of the original procfs.
Plan 9 procfs manual page - Plan 9 greatly expanded the procfs concept, providing a much expanded interface to control and manipulate processes.
Linux Manual Pages Proc(5) Linux manual documentation for procfs
Documentation/filesystems/proc.txt Linux kernel documentation for procfs


== External links ==
A brief history of /proc Eric Schrock's Weblog
Access the Linux kernel using the Procfs An IBM developerWorks article by M. Tim Jones
Linux-Filesystem-Hierarchy Linux Documentation Project
Discover the possibilities of the /proc directory by Federico Kereki"
"PyQt is a Python binding of the cross-platform GUI toolkit Qt, implemented as a Python plug-in. PyQt is free software developed by the British firm Riverbank Computing. It is available under similar terms to Qt versions older than 4.5; this means a variety of licenses including GNU General Public License (GPL) and commercial license, but not the GNU Lesser General Public License (LGPL). PyQt supports Microsoft Windows as well as various flavours of UNIX, including Linux and MacOS (or Darwin).PyQt implements around 440 classes and over 6,000 functions and methods including:

a substantial set of GUI widgets
classes for accessing SQL databases (ODBC, MySQL, PostgreSQL, Oracle, SQLite)
QScintilla, Scintilla-based rich text editor widget
data aware widgets that are automatically populated from a database
an XML parser
SVG support
classes for embedding ActiveX controls on Windows (only in commercial version)To automatically generate these bindings, Phil Thompson developed the tool SIP, which is also used in other projects.
In August 2009, Nokia, the then owners of the Qt toolkit, released PySide, providing similar functionality, but under the LGPL, after failing to reach an agreement with Riverbank Computing  to change its licensing terms to include LGPL as an alternative license.


== PyQt main components ==
PyQt4 contains the following Python modules.

The QtCore module contains the core non-GUI classes, including the event loop and Qt's signal and slot mechanism. It also includes platform independent abstractions for Unicode, threads, mapped files, shared memory, regular expressions, and user and application settings.
The QtGui module contains the majority of the GUI classes. These include a number of table, tree and list classes based on the model–view–controller design pattern. Also provided is a sophisticated 2D canvas widget capable of storing thousands of items including ordinary widgets.
The QtNetwork module contains classes for writing UDP and TCP clients and servers. It includes classes that implement FTP and HTTP clients and support DNS lookups. Network events are integrated with the event loop making it very easy to develop networked applications.
The QtOpenGL module contains classes that enable the use of OpenGL in rendering 3D graphics in PyQt applications.
The QtSql module contains classes that integrate with open-source and proprietary SQL databases. It includes editable data models for database tables that can be used with GUI classes. It also includes an implementation of SQLite.
The QtSvg module contains classes for displaying the contents of SVG files. It supports the static features of SVG 1.2 Tiny.
The QtXml module implements SAX and DOM interfaces to Qt's XML parser.
The QtMultimedia module implements low-level multimedia functionality. Application developers would normally use the phonon module.
The QtDesigner module contains classes that allow Qt Designer to be extended using PyQt.
The Qt module consolidates the classes contained in all of the modules described above into a single module. This has the advantage that you don't have to worry about which underlying module contains a particular class. It has the disadvantage that it loads the whole of the Qt framework, thereby increasing the memory footprint of an application. Whether you use this consolidated module, or the individual component modules is down to personal taste.
The uic module implements support for handling the XML files created by Qt Designer that describe the whole or part of a graphical user interface. It includes classes that load an XML file and render it directly, and classes that generate Python code from an XML file for later execution.PyQt5 contains the following Python modules:

QtQml Module
QtQtuick Module
QtCore Module
QtGui Module
QtPrintSupport Module
QtWidgets Module
QGLContext Module
QGLFormat Module
QGLWidget Module
QtWebKit Module
QtWebKitWidgets Module


== Versions ==
PyQt version 4 works with both Qt 4 and Qt 5. PyQt version 5 only supports Qt version 5, and drops support for features that are deprecated in Qt 5.


== Hello World example ==
The below code shows a small window on the screen.


=== PyQt4 ===


=== PyQt5 ===


== Notable applications that use PyQt ==
Anki, a spaced repetition flashcard program
Calibre, an E-book management application
Dropbox, a file hosting service
Eric Python IDE
fman, cross-platform file manager
Kodos, Python Regular Expression Debugger
Leo, an outliner and literate programming editor
Ninja-IDE, an extensible open-source Python IDE
OpenLP, an open-source lyrics projection program
OpenShot, a video editing program
Orange, a data mining and visualization framework
Puddletag, an open-source, cross-platform ID3 tag editor
QGIS, a free software desktop Geographic Information Systems (GIS) application
qt-recordMyDesktop, Qt4 frontend for recordMyDesktop
Spyder, a Python data science IDE
TortoiseHg, a graphical interface for the Mercurial source management program (Hg)
Veusz, a scientific plotting application


== See also ==
PyQt is one of Python's options for GUI programming. Popular alternatives are PySide (the Qt binding with official support and a more liberal license), PyGTK, wxPython, Kivy and Tkinter (which is bundled with Python).


== References ==


== Further reading ==
Willman, Joshua (2020), Beginning PyQt - A Hands-on Approach to GUI Programming (1st ed.), Apress, p. 440, ISBN 978-1-4842-5856-9
Summerfield, Mark (October 28, 2007), Rapid GUI Programming with Python and Qt (Covers PyQt4) (1st ed.), Prentice Hall, p. 648, ISBN 978-0-13-235418-9
Rempt, Boudewijn (2002), GUI Programming with Python: QT Edition (Covers PyQt3), OpenDocs, archived from the original on 2010-04-09


== External links ==
Official website
PyQt and PyKDE community Wiki
PyQt5 Tutorial Series
PyQT4 tutorial series
Tutorials
Tutorial"
"The syntax of the Python programming language is the set of rules that defines how a Python program will be written and interpreted (by both the runtime system and by human readers). The Python language has many similarities to Perl, C, and Java. However, there are some definite differences between the languages.


== Design philosophy ==
Python was designed to be a highly readable language. It has a relatively uncluttered visual layout and uses English keywords frequently where other languages use punctuation.  Python aims to be simple and consistent in the design of its syntax, encapsulated in the mantra ""There should be one—and preferably only one—obvious way to do it"", from ""The Zen of Python"".This mantra is deliberately opposed to the Perl and Ruby mantra, ""there's more than one way to do it"".


== Keywords ==
Python has these 35 keywords or reserved words; they cannot be used as identifiers.

Notes


== Indentation ==
Python uses whitespace to delimit control flow blocks (following the off-side rule). Python borrows this feature from its predecessor ABC: instead of punctuation or keywords, it uses indentation to indicate the run of a block.
In so-called ""free-format"" languages — that use the block structure derived from ALGOL — blocks of code are set off with braces ({ }) or keywords. In most coding conventions for these languages, programmers conventionally indent the code within a block, to visually set it apart from the surrounding code (prettyprinting).
Consider a function, foo, which is passed a single parameter, x, and if the parameter is 0 will call bar and baz, otherwise it will call qux, passing x, and also call itself recursively, passing x-1 as the parameter. Here are implementations of this function in both C and Python:
foo function in C with K&R indent style:

foo function in Python:

Python mandates a convention that programmers in ALGOL-style languages often follow. Incorrectly indented code can be understood by human reader differently than does a compiler or interpreter.
This example illustrates an error introduced by incorrect indentation:

Here, in contrast to the above Python foo example, the function call foo(x - 1) always gets executed, resulting in an endless recursion. Such an indentation error (like the accidental removal of the indentation in the last line) is only possible in programming languages that do not mark blocks with distinct markers, like curly brackets in C. In this particular case, not even an editor with automatic indentation could prevent the erroneous behaviour of this Python code. This unintended error can easily pass into the code base without prior noticing by the programmer. In most other programming languages, this would not be possible (deleting a block-end marker in C would lead to a compiler error), and this makes the Python syntax less robust than most other languages.
Both space characters and tab characters are currently accepted as forms of indentation in Python. Since many tools do not visually distinguish them, mixing spaces and tabs can create bugs that take specific efforts to find (a perennial suggestion among Python users has been removing tabs as block markers; other Python users propound removing spaces instead). Moreover, formatting routines which remove whitespace—for instance, many Internet forums—can destroy the syntax of a Python program, whereas a program in a bracketed language would merely become more difficult to read.
Many popular code editors handle Python's indentation conventions seamlessly, sometimes after a configuration option is enabled.


== Data structures ==
Since Python is a dynamically typed language, Python values, not variables, carry type.  This has implications for many aspects of the way the language functions.
All variables in Python hold references to objects, and these references are passed to functions; a function cannot change the value of variable references in its calling function (but see below for exceptions). Some people (including Guido van Rossum himself) have called this parameter-passing scheme ""Call by object reference."" An object reference means a name, and the passed reference is an ""alias"", i.e. a copy of the reference to the same object, just as in C/C++. The object's value may be changed in the called function with the ""alias"", for example:

Function my_func changed the value of alist with the formal argument al, which is an alias of alist. However, any attempt to operate on the alias itself will have no effect on the original object. In Python, non-innermost-local and not-declared-global accessible names are all aliases.
Among dynamically typed languages, Python is moderately type-checked. Implicit conversion is defined for numeric types (as well as booleans), so one may validly multiply a complex number by an integer (for instance) without explicit casting. However, there is no implicit conversion between, for example, numbers and strings; a string is an invalid argument to a mathematical function expecting a number.


=== Base types ===
Python has a broad range of basic data types. Alongside conventional integer and floating-point arithmetic, it transparently supports arbitrary-precision arithmetic, complex numbers, and decimal floating point numbers.
Python supports a wide variety of string operations.  Strings in Python are immutable, so a string operation such as a substitution of characters, that in other programming languages might alter a string in place, returns a new string in Python.  Performance considerations sometimes push for using special techniques in programs that modify strings intensively, such as joining character arrays into strings only as needed.


=== Collection types ===
One of the very useful aspects of Python is the concept of collection (or container) types. In general a collection is an object that contains other objects in a way that is easily referenced or indexed. Collections come in two basic forms: sequences and mappings.
The ordered sequential types are lists (dynamic arrays), tuples, and strings. All sequences are indexed positionally (0 through length − 1) and all but strings can contain any type of object, including multiple types in the same sequence. Both strings and tuples are immutable, making them perfect candidates for dictionary keys (see below). Lists, on the other hand, are mutable; elements can be inserted, deleted, modified, appended, or sorted in-place.
Mappings, on the other hand, are unordered types implemented in the form of dictionaries which ""map"" a set of immutable keys to corresponding elements (much like a mathematical function).  For example, one could define a dictionary having a string ""toast"" mapped to the integer 42 or vice versa.  The keys in a dictionary must be of an immutable Python type, such as an integer or a string, because under the hood they are implemented via a hash function. This makes for much faster lookup times, but requires keys not change (and also results in a dictionary's lack of order).
Dictionaries are also central to the internals of the language as they reside at the core of all Python objects and classes: the mappings between variable names (strings) and the values which the names reference are stored as dictionaries (see Object system).  Since these dictionaries are directly accessible (via an object's __dict__ attribute), metaprogramming is a straightforward and natural process in Python.
A set collection type was added to the core language in version 2.4. A set is an unindexed, unordered collection that contains no duplicates, and implements set theoretic operations such as union, intersection, difference, symmetric difference, and subset testing.  There are two types of sets: set and frozenset, the only difference being that set is mutable and frozenset is immutable. Elements in a set must be hashable. Thus, for example, a frozenset can be an element of a regular set whereas the opposite is not true.
Python also provides extensive collection manipulating abilities such as built in containment checking and a generic iteration protocol.


=== Object system ===
In Python, everything is an object, even classes.  Classes, as objects, have a class, which is known as their metaclass. Python also supports multiple inheritance and mixins.
The language supports extensive introspection of types and classes. Types can be read and compared—types are instances of type.  The attributes of an object can be extracted as a dictionary.
Operators can be overloaded in Python by defining special member functions - for instance, defining __add__ on a class permits one to use the + operator on members of that class.


== Literals ==


=== Strings ===
Python has various kinds of string literals.


==== Normal string literals ====
Either single or double quotes can be used to quote strings.  Unlike in Unix shell languages, Perl or Perl-influenced languages such as Ruby or Groovy, single quotes and double quotes function identically, i.e. there is no string interpolation of $foo expressions.  However, interpolation can be done in various ways: with ""f-strings"" (since Python 3.6), using the format method or the old % string-format operator.
For instance, the Perl statement:

is equivalent to any of these Python statements:


==== Multi-line string literals ====
There are also multi-line strings, which begin and end with a series of three single or double quotes and function like here documents in Perl and Ruby.
A simple example with variable interpolation (using the format method) is:


==== Raw strings ====
Finally, all of the previously mentioned string types come in ""raw"" varieties (denoted by placing a literal r before the opening quote), which do no backslash-interpolation and hence are very useful for regular expressions; compare ""@-quoting"" in C#. Raw strings were originally included specifically for regular expressions. Due to limitations of the tokenizer, raw strings may not have a trailing backslash. Creating a raw string holding a Windows path ending with a backslash requires some variety of workaround (commonly, using forward slashes instead of backslashes, since Windows accepts both).
Examples include:


==== Concatenation of adjacent string literals ====
String literals (using possibly different quote conventions) appearing contiguously and only separated by whitespace (including new lines), are allowed and are aggregated into a single longer string.
Thus

is equivalent to


=== Numbers ===
Numeric literals in Python are of the normal sort, e.g. 0, -1, 3.4, 3.5e-8.
Python has arbitrary-length integers and automatically increases the storage size as necessary. Prior to Python version 3, there were two kinds of integral numbers: traditional fixed size integers and ""long"" integers of arbitrary range. The conversion to ""long"" integers was performed automatically when required, and thus the programmer usually didn't have to be aware of the two integral types. In newer language versions the fixed-size integers are completely gone.
Python supports normal floating point numbers, which are created when a dot is used in a literal (e.g. 1.1), when an integer and a floating point number are used in an expression, or as a result of some mathematical operations (""true division"" via the / operator, or exponentiation with a negative exponent).
Python also supports complex numbers natively.  Complex numbers are indicated with the J or j suffix, e.g. 3 + 4j.


=== Lists, tuples, sets, dictionaries ===
Python has syntactic support for the creation of container types.
Lists (class list) are mutable sequences of items of arbitrary types, and can be created either with the special syntax

or using normal object creation

Tuples (class tuple) are immutable sequences of items of arbitrary types. There is also a special syntax to create tuples

Although tuples are created by separating items with commas, the whole construct is usually wrapped in parentheses to increase readability. An empty tuple is denoted by ().
Sets (class set) are mutable containers of hashable items of arbitrary types, with no duplicates. The items are not ordered, but sets support iteration over the items. A syntax for set creation appeared in Python 2.7/3.0

In earlier Python versions, sets would be created by initializing the set class with a list argument. Python sets are very much like mathematical sets, and support operations like set intersection and union.
Python also features a frozenset class for immutable sets.
Dictionaries (class dict) are mutable mappings tying keys and corresponding values.
Python has special syntax to create dictionaries ({key: value})

The dictionary syntax is similar to the set syntax, the difference is the presence of colons. The empty literal {} results in an empty dictionary rather than an empty set, which is instead created using the non-literal constructor: set().


== Operators ==


=== Arithmetic ===
Python includes the +, -, *, /, % (modulus), and ** (exponentiation) operators, with their usual mathematical precedence.
Traditionally, x / y performed integer division if both x and y were integers (returning the floor of the quotient), and returned a float if either was a float.  However, because Python is a dynamically typed language, it was not always possible to tell which operation was being performed, which often led to subtle bugs.  For example, with

A call to mean([3.0, 4.0]) would return 3.5, but mean([3, 4]) would return 3.  If this was not the intended behavior, it was necessary to use a workaround such as

To avoid this issue, a proposal was made to change the behavior of the Python division operator.  In Python 2.2, a new operator // was introduced for floor division, both for integer and floating-point arguments.  The / operator was changed so that the quotient of two integers returned a float, but for backwards compatibility, this behavior had to be explicitly requested until Python 3.0.


=== Comparison operators ===
The basic comparison operators such as ==, <, >=, and so forth are used on all manner of values. Numbers, strings, sequences, and mappings can all be compared. Although disparate types (such as a str and an int) are defined to have a consistent relative ordering, this is considered a historical design quirk and will no longer be allowed in Python 3.0.
Chained comparison expressions such as a < b < c have roughly the meaning that they have in mathematics, rather than the unusual meaning found in C and similar languages. The terms are evaluated and compared in order. The operation has short-circuit semantics, meaning that evaluation is guaranteed to stop as soon as a verdict is clear: if a < b is false, c is never evaluated as the expression cannot possibly be true anymore.
For expressions without side effects, a < b < c is equivalent to a < b and b < c. However, there is a substantial difference when the expressions have side effects. a < f(x) < b will evaluate f(x) exactly once, whereas a < f(x) and f(x) < b will evaluate it twice if the value of a is less than f(x) and once otherwise.


=== Logical operators ===
Python 2.2 and earlier does not have an explicit boolean type. In all versions of Python, boolean operators treat zero values or empty values such as """", 0, None, 0.0, [], and {} as false, while in general treating non-empty, non-zero values as true. In Python 2.2.1 the boolean constants True and False were added to the language (subclassed from 1 and 0). The binary comparison operators such as == and > return either True or False.
The boolean operators and and or use minimal evaluation. For example, y == 0 or x/y > 100 will never raise a divide-by-zero exception. These operators return the value of the last operand evaluated, rather than True or False. Thus the expression (4 and 5) evaluates to 5, and (4 or 5) evaluates to 4.


== Functional programming ==
As mentioned above, another strength of Python is the availability of a functional programming style. As may be expected, this makes working with lists and other collections much more straightforward.


=== Comprehensions ===

One such construction is the list comprehension, which can be expressed with the following format:

Using list comprehension to calculate the first five powers of two:

The Quicksort algorithm can be expressed elegantly (albeit inefficiently) using list comprehensions:

Python 2.7+ also supports set comprehensions and dictionary comprehensions.


=== First-class functions ===
In Python, functions are first-class objects that can be created and passed around dynamically.
Python's limited support for anonymous functions is the lambda construct. An example is the anonymous function which squares its input, called with the argument of 5:

Lambdas are limited to containing an expression rather than statements, although control flow can still be implemented less elegantly within lambda by using short-circuiting, and more idiomatically with conditional expressions.


=== Closures ===
Python has had support for lexical closures since version 2.2.  Here's an example:

Python's syntax, though, sometimes leads programmers of other languages to think that closures are not supported. Variable scope in Python is implicitly determined by the scope in which one assigns a value to the variable, unless scope is explicitly declared with global or nonlocal.Note that the closure's binding of a name to some value is not mutable from within the function.  Given:

and you can see that b, as visible from the closure's scope, retains the value it had; the changed binding of b inside the inner function did not propagate out.  The way around this is to use a nonlocal b statement in bar. In Python 2 (which lacks nonlocal), the usual workaround is to use mutable value and change that value, not the binding.  E.g., a list with one element.


=== Generators ===
Introduced in Python 2.2 as an optional feature and finalized in version 2.3, generators are Python's mechanism for lazy evaluation of a function that would otherwise return a space-prohibitive or computationally intensive list.
This is an example to lazily generate the prime numbers:

To use this function simply call, e.g.:

The definition of a generator appears identical to that of a function, except the keyword yield is used in place of return. However, a generator is an object with persistent state, which can repeatedly enter and leave the same scope. A generator call can then be used in place of a list, or other structure whose elements will be iterated over. Whenever the for loop in the example requires the next item, the generator is called, and yields the next item.
Generators don't have to be infinite like the prime-number example above. When a generator terminates, an internal exception is raised which indicates to any calling context that there are no more values. A for loop or other iteration will then terminate.


=== Generator expressions ===

Introduced in Python 2.4, generator expressions are the lazy evaluation equivalent of list comprehensions.  Using the prime number generator provided in the above section, we might define a lazy, but not quite infinite collection.

Most of the memory and time needed to generate this many primes will not be used until the needed element is actually accessed.  Unfortunately, you cannot perform simple indexing and slicing of generators, but must use the itertools modules or ""roll your own"" loops.  In contrast, a list comprehension is functionally equivalent, but is greedy in performing all the work:

The list comprehension will immediately create a large list (with 78498 items, in the example, but transiently creating a list of primes under two million), even if most elements are never accessed.  The generator comprehension is more parsimonious.


=== Dictionary and set comprehensions ===
While lists and generators had comprehensions/expressions, in Python versions older than 2.7 the other Python built-in collection types (dicts and sets) had to be kludged in using lists or generators:

Python 2.7 and 3.0 unify all collection types by introducing dict and set comprehensions, similar to list comprehensions:


== Objects ==
Python supports most object oriented programming techniques. It allows polymorphism, not only within a class hierarchy but also by duck typing. Any object can be used for any type, and it will work so long as it has the proper methods and attributes. And everything in Python is an object, including classes, functions, numbers and modules. Python also has support for metaclasses, an advanced tool for enhancing classes' functionality. Naturally, inheritance, including multiple inheritance, is supported. It has limited support for private variables using name mangling. See the ""Classes"" section of the tutorial for details.
Many Python users don't feel the need for private variables, though.
The slogan ""We're all responsible users here"" is used to describe this attitude.
Some consider information hiding to be unpythonic, in that it suggests that the class in question contains unaesthetic or ill-planned internals. However, the strongest argument for name mangling is prevention of unpredictable breakage of programs: introducing a new public variable in a superclass can break subclasses if they don't use ""private"" variables.
From the tutorial: As is true for modules, classes in Python do not put an absolute barrier between definition and user, but rather rely on the politeness of the user not to ""break into the definition.""
OOP doctrines such as the use of accessor methods to read data members are not enforced in Python. Just as Python offers functional-programming constructs but does not attempt to demand referential transparency, it offers an object system but does not demand OOP behavior. Moreover, it is always possible to redefine the class using properties so that when a certain variable is set or retrieved in calling code, it really invokes a function call, so that spam.eggs = toast might really invoke spam.set_eggs(toast). This nullifies the practical advantage of accessor functions, and it remains OOP because the property eggs becomes a legitimate part of the object's interface: it need not reflect an implementation detail.
In version 2.2 of Python, ""new-style"" classes were introduced. With new-style classes, objects and types were unified, allowing the subclassing of types.
Even entirely new types can be defined, complete with custom behavior for infix operators. This allows for many radical things to be done syntactically within Python. A new method resolution order for multiple inheritance was also adopted with Python 2.3.  It is also possible to run custom code while accessing or setting attributes, though the details of those techniques have evolved between Python versions.


=== With statements ===
The ""with"" statement handles resources. One function is called when entering scope and another when leaving. This prevents forgetting to remove the resource and also handles more complicated situations such as exceptions.


=== Properties ===
Properties allow specially defined methods to be invoked on an object instance by using the same syntax as used for attribute access.  An example of a class defining some properties is:


=== Descriptors ===
A class that defines one or more of the special methods __get__(self, instance, owner), __set__(self, instance, value), __delete__(self, instance) can be used as a descriptor. Creating an instance of a descriptor as a class member of a second class makes the instance a property of the second class.


=== Class and static methods ===
Python allows the creation of class methods and static method via the use of the @classmethod  and @staticmethod decorators.  The first argument to a class method is the class object instead of the self-reference to the instance.  A static method has no special first argument.  Neither the instance, nor the class object is passed to a static method.


== Exceptions ==
Python supports (and extensively uses) exception handling as a means of testing for error conditions and other ""exceptional"" events in a program. Indeed, it is even possible to trap the exception caused by a syntax error.
Python style calls for the use of exceptions whenever an error condition might arise. Rather than testing for access to a file or resource before actually using it, it is conventional in Python to just go ahead and try to use it, catching the exception if access is rejected.
Exceptions can also be used as a more general means of non-local transfer of control, even when an error is not at issue.  For instance, the Mailman mailing list software, written in Python, uses exceptions to jump out of deeply nested message-handling logic when a decision has been made to reject a message or hold it for moderator approval.
Exceptions are often used as an alternative to the if-block, especially in threaded situations. A commonly invoked motto is EAFP, or ""It is Easier to Ask for Forgiveness than Permission,"" which is attributed to Grace Hopper. The alternative, known as LBYL, or ""Look Before You Leap"", explicitly tests for pre-conditions.In this first code sample, following the LBYL approach, there is an explicit check for the attribute before access:

This second sample follows the EAFP paradigm:

These two code samples have the same effect, although there will be performance differences.  When spam has the attribute eggs, the EAFP sample will run faster.  When spam does not have the attribute eggs (the ""exceptional"" case), the EAFP sample will run slower. The Python profiler can be used in specific cases to determine performance characteristics. If exceptional cases are rare, then the EAFP version will have superior average performance than the alternative. In addition, it avoids the whole class of time-of-check-to-time-of-use (TOCTTOU) vulnerabilities, other race conditions, and is compatible with duck typing. A drawback of EAFP is that it can be used only with statements; an exception cannot be caught in a generator expression, list comprehension, or lambda function.


== Comments and docstrings ==
Python has two ways to annotate Python code. One is by using comments to indicate what some part of the code does. Single-line comments begin with the hash character (""#"") and are terminated by the end of line. Comments spanning more than one line are achieved by inserting a multi-line string (with """""" as the delimiter on each end) that is not used in assignment or otherwise evaluated, but sits in between other statements.
Commenting a piece of code:

Commenting a piece of code with multiple lines:

Docstrings (documentation strings), that is, strings that are located alone without assignment as the first indented line within a module, class, method or function, automatically set their contents as an attribute named __doc__, which is intended to store a human-readable description of the object's purpose, behavior, and usage. The built-in help function generates its output based on __doc__ attributes. Such strings can be delimited with "" or ' for single line strings, or may span multiple lines if delimited with either """""" or ''' which is Python's notation for specifying multi-line strings. However, the style guide for the language specifies that triple double quotes ("""""") are preferred for both single and multi-line docstrings.
Single line docstring:

Multi-line docstring:

Docstrings can be as large as the programmer wants and contain line breaks. In contrast with comments, docstrings are themselves Python objects and are part of the interpreted code that Python runs. That means that a running program can retrieve its own docstrings and manipulate that information. But the normal usage is to give other programmers information about how to invoke the object being documented in the docstring.
There are tools available that can extract the docstrings to generate an API documentation from the code. Docstring documentation can also be accessed from the interpreter with the help() function, or from the shell with the pydoc command pydoc.
The doctest standard module uses interactions copied from Python shell sessions into docstrings, to create tests, whereas the docopt module uses them to define command-line options.


== Function annotations ==
Function annotations are defined in PEP 3107. They allow attaching data to the arguments and return of a function. The behaviour of annotations is not defined by the language, and is left to third party frameworks. For example, a library could be written to handle static typing:


== Decorators ==

A decorator is any callable Python object that is used to modify a function, method or class definition.  A decorator is passed the original object being defined and returns a modified object, which is then bound to the name in the definition.  Python decorators were inspired in part by Java annotations, and have a similar syntax; the decorator syntax is pure syntactic sugar, using @ as the keyword:

is equivalent to

Decorators are a form of metaprogramming; they enhance the action of the function or method they decorate. For example, in the sample below, viking_chorus might cause menu_item to be run 8 times (see Spam sketch) for each time it is called:

Canonical uses of function decorators are for creating class methods or static methods, adding function attributes, tracing, setting pre- and postconditions, and synchronization, but can be used for far more besides, including tail recursion elimination, memoization and even improving the writing of decorators.Decorators can be chained by placing several on adjacent lines:

is equivalent to

or, using intermediate variables

In the example above, the favourite_colour decorator factory takes an argument. Decorator factories must return a decorator, which is then called with the object to be decorated as its argument:

This would then decorate the black_knight function such that the colour, ""Blue"", would be printed prior to the black_knight function running. Closure ensures that the colour argument is accessible to the innermost wrapper function even when it is returned and goes out of scope, which is what allows decorators to work.
Despite the name, Python decorators are not an implementation of the decorator pattern.  The decorator pattern is a design pattern used in statically typed object-oriented programming languages to allow functionality to be added to objects at run time; Python decorators add functionality to functions and methods at definition time, and thus are a higher-level construct than decorator-pattern classes.  The decorator pattern itself is trivially implementable in Python, because the language is duck typed, and so is not usually considered as such.


== Easter eggs ==
Users of curly bracket programming languages, such as C or Java, sometimes expect or wish Python to follow a block-delimiter convention.  Brace-delimited block syntax has been repeatedly requested, and consistently rejected by core developers.  The Python interpreter contains an easter egg that summarizes its developers' feelings on this issue.  The code from __future__ import braces raises the exception SyntaxError: not a chance. The __future__ module is normally used to provide features from future versions of Python.
Another hidden message, The Zen of Python (a summary of Python philosophy), is displayed when trying to import this.
The message Hello world! is printed when the import statement import __hello__ is used. In Python 2.7, instead of Hello world! it prints Hello world....
An antigravity module was added to Python 2.7 and 3.0. Importing it opens a web browser to xkcd comic 353 that portrays a humorous fictional use for such a module, intended to demonstrate the ease with which Python modules enable additional functionality. In Python 3.0, this module also contains an implementation of the ""geohash"" algorithm, a reference to xkcd comic 426.


== References ==


== External links ==
Python tutorial written by the author of Python, Guido van Rossum."
"Python Imaging Library (abbreviated as PIL) (in newer versions known as Pillow) is a free and open-source additional library for the Python programming language that adds support for opening, manipulating, and saving many different image file formats. It is available for Windows, Mac OS X and Linux. The latest version of PIL is 1.1.7, was released in September 2009 and supports Python 1.5.2–2.7, with Python 3 support to be released ""later"".Development appears to be discontinued, with the last commit to the PIL repository coming in 2011. Consequently, a successor project called Pillow has forked the PIL repository and added Python 3.x support. This fork has been adopted as a replacement for the original PIL in Linux distributions including Debian and Ubuntu (since 13.04).


== Capabilities ==
Pillow offers several standard procedures for image manipulation. These include:

per-pixel manipulations,
masking and transparency handling,
image filtering, such as blurring, contouring, smoothing, or edge finding,
image enhancing, such as sharpening, adjusting brightness, contrast or color,
adding text to images and much more.


== File formats ==
Some of the file formats supported are PPM, PNG, JPEG, GIF, TIFF, and BMP.
It is also possible to create new file decoders to expand the library of file formats accessible.


== Usage example ==
This example loads an image from the file system, blurs it, and shows both the original and the blurred image on the screen:

This example loads and rotates an image by 180 degrees:

This example loads and crops an image:


== License ==
The Python Imaging Library (PIL) is

 Copyright © 1997-2011 by Secret Labs AB
 Copyright © 1995-2011 by Fredrik Lundh

Based on [1]


== References ==


== External links ==
Official website
PIL Library reference
 Python Imaging Library at Wikibooks
Pillow (Successor project)
PIL Tutorial Examples"
"MicroPython is a software implementation of a programming language largely compatible with Python 3, written in C, that is optimized to run on a microcontroller.MicroPython is a full Python compiler and runtime that runs on the micro-controller hardware. The user is presented with an interactive prompt (the REPL) to execute supported commands immediately. Included are a selection of core Python libraries; MicroPython includes modules which give the programmer access to low-level hardware.The source code for the project is available on GitHub under the MIT License.


== History ==
MicroPython was originally created by the Australian programmer and physicist Damien George, after a successful Kickstarter backed campaign in 2013. While the original Kickstarter campaign released MicroPython with an STM32F4-powered development board ""pyboard"", MicroPython supports a number of ARM based architectures. The ports supported in the mainline are ARM Cortex-M (many STM32 boards, TI CC3200/WiPy, Teensy boards, Nordic nRF series, SAMD21 and SAMD51), ESP8266, ESP32, 16bit PIC, Unix, Windows, Zephyr, and JavaScript. Also, there are many forks for a variety of systems and hardware platforms not supported in the mainline. In 2016, a version of MicroPython for the BBC Micro Bit was created as part of the Python Software Foundation's contribution to the Micro Bit partnership with the BBC.In July 2017, MicroPython was forked to create CircuitPython, a version of MicroPython with emphasis on education and ease of use. MicroPython and CircuitPython support somewhat different sets of hardware (e.g. CircuitPython supports Atmel SAM D21 and D51 boards, but dropped support for ESP8266). As of version 4.0, CircuitPython is based on MicroPython version 1.9.4.In 2017, Microsemi made a MicroPython port for RISC-V (RV32 and RV64) architecture.In April 2019, a version of MicroPython for the Lego Mindstorms EV3 was created.


== Bytecode ==
MicroPython includes a cross compiler which generates MicroPython bytecode (file extension .mpy). The Python code can be compiled into the bytecode either directly on a microcontroller or it can be precompiled elsewhere. 
MicroPython firmware can be built without the compiler, leaving only the virtual machine which can run the precompiled mpy programs.


== References ==


== External links ==
Official website
micropython on GitHub
GOTO 2016 • MicroPython & the Internet of Things • Damien George on YouTube
MicroPython playlist on YouTube • Tutorials by Tony DiCola / Adafruit"
"Anaconda is a free and open-source distribution of the Python and R programming languages for scientific computing (data science, machine learning applications, large-scale data processing, predictive analytics, etc.), that aims to simplify package management and deployment. The distribution includes data-science packages suitable for Windows, Linux, and macOS. It is developed and maintained by Anaconda, Inc., which was founded by Peter Wang and Travis Oliphant in 2012. As an Anaconda, Inc. product, it is also known as Anaconda Distribution or Anaconda Individual Edition, while other products from the company are Anaconda Team Edition and Anaconda Enterprise Edition, which are both not free.Package versions in Anaconda are managed by the package management system conda. This package manager was spun out as a separate open-source package as it ended up being useful on its own and for other things than Python. There is also a small, bootstrap version of Anaconda called Miniconda, which includes only conda, Python, the packages they depend on, and a small number of other  packages.


== Overview ==
Anaconda distribution comes with over 250 packages automatically installed, and over 7,500 additional open-source packages can be installed from PyPI as well as the conda package and virtual environment manager. It also includes a GUI, Anaconda Navigator, as a graphical alternative to the command line interface (CLI). 
The big difference between conda and the pip package manager is in how package dependencies are managed, which is a significant challenge for Python data science and the reason conda exists. 
When pip installs a package, it automatically installs any dependent Python packages without checking if these conflict with previously installed packages. It will install a package and any of its dependencies regardless of the state of the existing installation. Because of this, a user with a working installation of, for example, Google Tensorflow, can find that it stops working having used pip to install a different package that requires a different version of the dependent numpy library than the one used by Tensorflow. In some cases, the package may appear to work but produce different results in detail.
In contrast, conda analyses the current environment including everything currently installed, and, together with any version limitations specified (e.g. the user may wish to have Tensorflow version 2,0 or higher), works out how to install a compatible set of dependencies, and shows a warning if this cannot be done.
Open source packages can be individually installed from the Anaconda repository, Anaconda Cloud (anaconda.org), or the user's own private repository or mirror, using the conda install command. Anaconda, Inc. compiles and builds the packages available in the Anaconda repository itself, and provides binaries for Windows 32/64 bit, Linux 64 bit and MacOS 64-bit. Anything available on PyPI may be installed into a conda environment using pip, and conda will keep track of what it has installed itself and what pip has installed.
Custom packages can be made using the conda build command, and can be shared with others by uploading them to Anaconda Cloud, PyPI or other repositories.
The default installation of Anaconda2 includes Python 2.7 and Anaconda3 includes Python 3.7. However, it is possible to create new environments that include any version of Python packaged with conda. 


=== Anaconda Navigator ===
Anaconda Navigator is a desktop graphical user interface (GUI) included in Anaconda distribution that allows users to launch applications and manage conda packages, environments and channels without using command-line commands. Navigator can search for packages on Anaconda Cloud or in a local Anaconda Repository, install them in an environment, run the packages and update them. It is available for Windows, macOS and Linux.
The following applications are available by default in Navigator:

JupyterLab
Jupyter Notebook
QtConsole
Spyder
Glue
Orange
RStudio
Visual Studio Code


=== Conda ===

Conda is an open source, cross-platform, language-agnostic package manager and environment management system  that installs, runs, and updates packages and their dependencies. It was created for Python programs, but it can package and distribute software for any language (e.g., R), including multi-language projects. 
The conda package and environment manager is included in all versions of Anaconda, Miniconda, and Anaconda Repository.


== Anaconda Cloud ==
Anaconda Cloud is a package management service by Anaconda where users can find, access, store and share public and private notebooks, environments, and conda and PyPI packages. Cloud hosts useful Python packages, notebooks and environments for a wide variety of applications. Users do not need to log in or to have a Cloud account, to search for public packages, download and install them.
Users can build new packages using the Anaconda Client command line interface (CLI), then manually or automatically upload the packages to Cloud.


== See also ==
List of software package management systems
Package manager
Pip (package manager)
Setuptools


== References ==


== External links ==
Official website 
Anaconda Cloud"
"The California Medical Assistance Program (Medi-Cal or MediCal) is California's Medicaid program serving low-income individuals, including families, seniors, persons with disabilities, children in foster care, pregnant women, and childless adults with incomes below 138% of federal poverty level. Benefits include ambulatory patient services, emergency services, hospitalization, maternity and newborn care, mental health and substance use disorder treatment, dental (Denti-Cal), vision, and long term care and supports. Approximately 13.3 million people were enrolled in Medi-Cal as of January 2018, or about one-third of California's population; in Tulare County and Merced County, more than 50% of county residents were enrolled as of September 2015.


== Eligibility ==
Medi-Cal provides health coverage for people with low income and limited ability to pay for health coverage, including the aged, blind, disabled, young adults and children, pregnant women, persons in a skilled nursing or intermediate care home, and persons in the Breast and Cervical Cancer Treatment Program (BCCTP). People receiving federally funded cash assistance programs, such as CalWORKs (a state implementation of the federal Temporary Assistance for Needy Families (TANF) program), the State Supplementation Program (SSP) (a state supplement to the federal Supplemental Security Income (SSI) program), foster care, adoption assistance, certain refugee assistance programs, or In-Home Supportive Services (IHSS) are also eligible.As a means-tested program, Medi-Cal imposes asset limits on certain prospective enrollees. Medi-Cal individuals who receive long-term supportive services or who enroll in Medi-Cal through certain disabilities are subject to asset tests. This limit depends on the number of individuals being considered for coverage; for one enrollee, this limit is $2,000, while for two enrollees, the limit is $3,000. Each additional individual being considered results in an additional $150 of permitted assets, up to a total of ten individuals covered. If applicants possess property whose total value exceeds the allowed amount, they are required to reduce (""sell down"") their assets through activities such as purchasing clothes, purchasing home furnishings, paying medical bills, paying a home mortgage, paying home loans, and paying off other debts.
Beginning in 2014 under the Patient Protection and Affordable Care Act (PPACA), those with family incomes up to 138% of the federal poverty level became eligible for Medi-Cal (pursuant to 42 U.S.C. § 1396a(a)(10)(A)(i)(VIII)), and individuals with higher incomes and some small businesses may choose a plan in Covered California, California's health insurance marketplace, with potential federal subsidies.Medi-Cal has open enrollment year-round and you can apply in a few ways: 

Online at https://www.coveredca.com/apply/apply-online/
In person, use this map to find a convenient office https://storefronts.coveredca.com/
By phone by calling Covered California at [800-300-1506]


=== Immigration status ===
Lawful permanent residents (green card holders) are eligible for full-scope Medi-Cal in California regardless of their date of entry if they meet all other eligibility requirements, even if they have been in the United States for less than 5 years. Nonimmigrants and undocumented immigrants are not eligible for full-scope Medi-Cal, but if they meet all eligibility requirements other than immigration status, they can get restricted-scope Medi-Cal limited to emergency and pregnancy-related services.


== Benefits ==
Medi-Cal health benefits include ambulatory patient services, emergency services, hospitalization, maternity and newborn care, mental health and substance use disorder treatment, dental (Denti-Cal), vision, and long term care and supports.California is one of a few US states that provide Medicaid dental benefits to adults. But given Denti-Cal's bare-bones coverage and the widespread absence of participating dentists in the program, a patchwork of supplemental programs has grown up to fill in some of the gaps, including Federally Qualified Health Centers (FQHC), a designation that refers to hundreds of health clinics and systems that operate in underserved, low-income and uninsured communities that private-practice dentists tend to avoid, and the state's First 5 county commissions, which are funded by tobacco sales taxes, as well as a sprinkling of county-funded dental care.


== Administration ==


=== Medi-Cal fee for service ===
As of January 2018, 2.5 million people were enrolled in Medi-Cal fee-for-service, representing about 19% of all enrollees. In the fee-for-service arrangement, health care providers submit claims to the Medi-Cal program for services rendered.


=== Medi-Cal managed care ===
Most beneficiaries receive Medi-Cal benefits from contracted Medicaid managed care organizations (MCOs). As of January 2018, 10.8 million people were enrolled in a Medi-Cal managed care plan, representing about 81% of all enrollees.California has several models of managed care which are designated at the county level:
a County Organized Health System (COHS) model, with one health plan per county,
a ""two plan model"" with one community health plan and one commercial health plan in the county,
a geographic managed care model with multiple plans per county,
a regional managed care model with 1-2 commercial health plans in many counties,
and unique one-county models in San Benito, Imperial counties and  the bi-county plan ""CenCal Health"" in San Luís Obispo and Santa Barbara.In Denti-Cal, the majority of beneficiaries are covered through fee-for-service arrangements, where the state pays dentists directly for services, instead of the managed care model. However, more than 879,000 Denti-Cal enrollees do receive dental care through managed care plans started as experimental alternatives in the 1990s: in Los Angeles County where managed care plans are optional for beneficiaries, and in Sacramento County where they are mandatory. Eleven counties had no Denti-Cal providers or no providers willing to accept new child patients covered by Denti-Cal: Del Norte, Tehama, Yuba, Sierra, Nevada, Amador, Calaveras, Alpine, Mariposa, Mono and Inyo counties. Delta Dental, operating in the same building as DHCS' Denti-Cal division, enrolls dentists into DentiCal, processes claims by dentists, pays dentists and authorizes treatments, and also handles customer service operations and outreach.


==== Bridge to Reform waiver ====
In 2011, CMS approved a Section 1115 Medicaid waiver called Bridge to Reform. The program included an expansion of the patient-centered medical home primary care approach, an expansion of coverage with the Low Income Health Program (LIHP), and incentive pay-for-performance to hospitals via the Delivery System Reform Incentive Pool (DSRIP). It also made enrollment in managed care plans (as opposed to fee-for-service programs) mandatory for people with disabilities with the intention of improving care coordination and reducing costs. The DSRIP program showed improvements in quality of care and population health, with less improvement in cost of care.Renewal of the waiver in 2015 extended the program to 2020 in an initiative called Medi-Cal 2020, with additional programs including additional alternative payment systems, the Dental Transformation Initiative, and the Whole Person Care program focused on high-risk, high-utilizing recipients. In the negotiation with CMS, several proposals were dropped.


==== Contractual requirements ====
Medi-Cal enforces requirements on MCOs with contracts, with boilerplate versions posted online; these contracts the primary way that the state affects the operations, quality, and coverage of managed care plans. In 2005, the California Health Care Foundation recommend various steps to improve the plans, which resulted in some changes to the contracts.


=== Government agencies ===
Medi-Cal is jointly administered by the Centers for Medicare and Medicaid Services (CMS) and the California Department of Health Care Services (DHCS), while the county welfare department in each of the 58 counties is responsible for local administration of the Medi-Cal program. C4Yourself and CalWIN are statewide online application systems that allows you to apply for benefits.


=== Law ===
Federal law mostly consists of the Social Security Amendments of 1965 which added Title XIX to the Social Security Act (42 U.S.C. § 1396 et seq.), and state law mostly consists of California Welfare and Institutions Code (WIC) Division 9, Part 3, Chapter 7 (WIC § 14000 et seq.). Federal regulations are mostly found in Code of Federal Regulations (CFR) Title 42, Chapter IV, Subchapter C (42 C.F.R. 430 et seq.) and state regulations are contained in California Code of Regulations (CCR) Title 22, Division 3 (22 CCR § 50005).


=== Costs ===
Medi-Cal costs are estimated at $73.9 billion ($16.9 billion in state funds) in 2014-15. For comparison, the entire California state budget in 2014-2015 is $156 billion, of which about $108 billion was general funds (not allocated for special expenditures, such as bonds).


== Related programs ==


=== Partnership for Long-Term Care ===
The Long-Term Care Partnership Program is a public-private partnership between states and private insurance companies, designed to reduce Medicaid expenditures by delaying or eliminating the need for some people to rely on Medicaid to pay for long-term care services. To encourage the purchase of private partnership policies, long-term care insurance policyholders are allowed to protect some or all of their assets from Medicaid spend-down requirements during the eligibility determination process, but they still must meet income requirements. The California Partnership for Long-Term Care Program links Medi-Cal and the In-Home Supportive Services program, i.e., private long-term care insurance and health care service plan contracts that cover long-term care for aged, blind, or disabled persons.


=== Covered California ===

Covered California is the health insurance marketplace in California, the state's implementation of the American Health Benefit Exchange provisions of the Patient Protection and Affordable Care Act.


=== Indigent health programs ===

Since 1933, California law has required counties to provide relief to the poor, including health care services and general assistance. County indigent medical programs can be categorized as California Medical Service Program (CMSP) and Medically Indigent Service Program (MISP) counties. There are 34 CMSP counties and 24 MISP counties. The CMSP county programs are largely managed by the state, whereas MISP counties manage their own programs with their own rules and regulations. Many patients from both the CMSP and MISP county programs transitioned to Medi-Cal when the Patient Protection and Affordable Care Act took effect in 2014.


== Quality of care metrics ==
Medi-Cal reports quality metrics, broadly similar to the HEDIS metrics from the NCQA.
In 2017, it reported on 13 of the 20 frequently reported from the CMS Medicaid/CHIP Child Core Set and 15 of 19 frequently reported from the CMS Medicaid Adult Core Set.


== History ==
Medi-Cal was created in 1965 by the California Medical Assistance Program a few months after the national legislation was passed.


== See also ==

Healthcare in California
Welfare in California
Local government in California
Health care districts in California


== References ==


== External links ==
Official website
BenefitsCal.org (to apply) from the County Welfare Directors Association
C4Yourself system from C-IV
CalWIN system from WCDS
YourBenefitsNow! system for Los Angeles County
California Medical Assistance Program in the California Code of Regulations
Medicaid State Plan information for California
State Waivers for Medicaid program in California"
"A medical speciality is a branch of medical practice that is focused on a defined group of patients, diseases, skills, or philosophy. Examples include children (paediatrics), cancer (oncology), laboratory medicine (pathology), or primary care (family medicine). After completing medical school, physicians or surgeons usually further their medical education in a specific specialty of medicine by completing a multiple-year residency to become a specialist.


== History of medical specialization ==
To a certain extent, medical practitioners have long been specialized. According to Galen, specialization was common among Roman physicians. The particular system of modern medical specialties evolved gradually during the 19th century. Informal social recognition of medical specialization evolved before the formal legal system. The particular subdivision of the practice of medicine into various specialties varies from country to country, and is somewhat arbitrary.


== Classification of medical specialization ==
Medical specialties can be classified along several axes. These are:

Surgical or internal medicine
Age range of patients
Diagnostic or therapeutic
Organ-based or technique-basedThroughout history, the most important has been the division into surgical and internal medicine specialties. The surgical specialties are those in which an important part of diagnosis and treatment is achieved through major surgical techniques. The internal medicine specialties are the specialties in which the main diagnosis and treatment is never major surgery. In some countries, anesthesiology is classified as a surgical discipline, since it is vital in the surgical process, though anesthesiologists never perform major surgery themselves.
Many specialties are organ-based. Many symptoms and diseases come from a particular organ. Others are based mainly around a set of techniques, such as radiology, which was originally based around X-rays.
The age range of patients seen by any given specialist can be quite variable. Paediatricians handle most complaints and diseases in children that do not require surgery, and there are several subspecialties (formally or informally) in paediatrics that mimic the organ-based specialties in adults. Paediatric surgery may or may not be a separate specialty that handles some kinds of surgical complaints in children.
A further subdivision is the diagnostic versus therapeutic specialties. While the diagnostic process is of great importance in all specialties, some specialists perform mainly or only diagnostic examinations, such as pathology, clinical neurophysiology, and radiology. This line is becoming somewhat blurred with interventional radiology, an evolving field that uses image expertise to perform minimally invasive procedures.


== Specialties that are common worldwide ==


== List of specialties recognized in the European Union and European Economic Area ==
The European Union publishes a list of specialties recognized in the European Union, and by extension, the European Economic Area. Note that there is substantial overlap between some of the specialties and it is likely that for example ""Clinical radiology"" and ""Radiology"" refer to a large degree to the same pattern of practice across Europe.


== List of North American medical specialties and others ==
In this table, as in many healthcare arenas, medical specialties are organized into the following groups:

Surgical specialties focus on manually operative and instrumental techniques to treat disease.
Medical specialties that focus on the diagnosis and non-surgical treatment of disease.
Diagnostic specialties focus more purely on diagnosis of disorders.


== Salaries ==
The mean annual salary of a medical specialist in the US in 2006 was $175,011 and $272,000 for surgeons.The table below details the average range of salaries for physicians in the US of selected specialties as of July 2010. Also given in the average number of hours worked per week for full-time physicians (2003 data).


== Specialties by country ==


=== Australia and New Zealand ===
There are 15 recognised specialty medical Colleges in Australia. The majority of these are Australasian Colleges and therefore also oversee New Zealand specialist doctors. These Colleges are:

In addition, the Royal Australasian College of Dental Surgeons supervises training of specialist medical practitioners specializing in Oral and Maxillofacial Surgery in addition to its role in the training of dentists. There are approximately 260 faciomaxillary surgeons in Australia .
The Royal New Zealand College of General Practitioners is a distinct body from the Australian Royal Australian College of General Practitioners. There are approximately 5100 members of the RNZCGP.
Within some of the larger Colleges, there are sub-faculties, such as: Australasian Faculty of Rehabilitation Medicine within the Royal Australasian College of Physicians
There are some collegiate bodies in Australia that are not officially recognised as specialities by the Australian Medical Council but have a College structure for members, such as: Australasian College of Physical Medicine
There are some collegiate bodies in Australia of Allied Health non-medical practitioners with specialisation. They are not recognised as medical specialists, but can be treated as such by private health insurers, such as: Australasian College of Podiatric Surgeons


=== Canada ===
Specialty training in Canada is overseen by the Royal College of Physicians and Surgeons of Canada and the College of Family Physicians of Canada. For specialists working in the province of Quebec, the Collège des médecins du Québec also oversees the process.


=== Germany ===
In Germany these doctors use the term Facharzt.


=== India ===
Specialty training in India is overseen by the Medical Council of India, which is responsible for recognition of post graduate training and by the National Board of Examinations. And education of Ayurveda in overseen by Central Council of Indian Medicine (CCIM), the council conducts u.g and p.g courses all over India, while Central Council of Homoeopathy does the same in the field of Homeopathy.


=== Sweden ===
In Sweden, a medical license is required before commencing specialty training. Those graduating from Swedish medical schools are first required to do a rotational internship of about 1.5 to 2 years in various specialties before attaining a medical license. The specialist training lasts 5 years.


=== United States ===
There are three agencies or organizations in the United States that collectively oversee physician board certification of MD and DO physicians in the United States in the 26 approved medical specialties recognized in the country. These organizations are the American Board of Medical Specialties (ABMS) and the American Medical Association (AMA); the American Osteopathic Association Bureau of Osteopathic Specialists (AOABOS) and the American Osteopathic Association; the American Board of Physician Specialties (ABPS) and the American Association of Physician Specialists (AAPS). Each of these agencies and their associated national medical organization functions as its various specialty academies, colleges and societies.

All boards of certification now require that medical practitioners demonstrate, by examination, continuing mastery of the core knowledge and skills for a chosen specialty. Recertification varies by particular specialty between every seven and every ten years.
In the United States there are hierarchies of medical specialties in the cities of a region. Small towns and cities have primary care, middle sized cities offer secondary care, and metropolitan cities have tertiary care. Income, size of population, population demographics, distance to the doctor, all influence the numbers and kinds of specialists and physicians located in a city.


== Demography ==
A population's income level determines whether sufficient physicians can practice in an area and whether public subsidy is needed to maintain the health of the population. Developing countries and poor areas usually have shortages of physicians and specialties, and those in practice usually locate in larger cities. For some underlying theory regarding physician location, see central place theory.The proportion of men and women in different medical specialties varies greatly. Such sex segregation is largely due to differential application.


== Satisfaction and burnout ==
A survey of physicians in the United States came to the result that dermatologists are most satisfied with their choice of specialty followed by radiologists, oncologists, plastic surgeons, and gastroenterologists. In contrast, primary care physicians were the least satisfied, followed by nephrologists, obstetricians/gynecologists, and pulmonologists. Surveys have also revealed high levels of depression among medical students (25 - 30%) as well as among physicians in training (22 - 43%), which for many specialties, continue into regular practice. A UK survey conducted of cancer-related specialties in 1994 and 2002 found higher job satisfaction in those specialties with more patient contact. Rates of burnout also varied by specialty.


== See also ==
Interdisciplinary sub-specialties of medicine, including
Occupational medicine – branch of clinical medicine that provides health advice to organizations and individuals concerning work-related health and safety issues and standards. See occupational safety and health.
Disaster medicine – branch of medicine that provides healthcare services to disaster survivors; guides medically related disaster preparation, disaster planning, disaster response and disaster recovery throughout the disaster life cycle and serves as a liaison between and partner to the medical contingency planner, the emergency management professional, the incident command system, government and policy makers.
Preventive medicine – part of medicine engaged with preventing disease rather than curing it. It can be contrasted not only with curative medicine, but also with public health methods (which work at the level of population health rather than individual health).
Medical genetics – the application of genetics to medicine. Medical genetics is a broad and varied field. It encompasses many different individual fields, including clinical genetics, biochemical genetics, cytogenetics, molecular genetics, the genetics of common diseases (such as neural tube defects), and genetic counseling.
Specialty Registrar
Federation of National Specialty Societies of Canada
Society of General Internal Medicine
Super Specialty Hospital


== References =="
"A physician (American English), medical practitioner (Commonwealth English), medical doctor, or simply doctor, is a professional who practises medicine, which is concerned with promoting, maintaining, or restoring health through the study, diagnosis, prognosis and treatment of disease, injury, and other physical and mental impairments. Physicians may focus their practice on certain disease categories, types of patients, and methods of treatment—known as specialities—or they may assume responsibility for the provision of continuing and comprehensive medical care to individuals, families, and communities—known as general practice. Medical practice properly requires both a detailed knowledge of the academic disciplines, such as anatomy and physiology, underlying diseases and their treatment—the science of medicine—and also a decent competence in its applied practice—the art or craft of medicine.
Both the role of the physician and the meaning of the word itself vary around the world. Degrees and other qualifications vary widely, but there are some common elements, such as medical ethics requiring that physicians show consideration, compassion, and benevolence for their patients.


== Modern meanings ==


=== Specialist in internal medicine ===

Around the world the term physician refers to a specialist in internal medicine or one of its many sub-specialties (especially as opposed to a specialist in surgery). This meaning of physician conveys a sense of expertise in treatment by drugs or medications, rather than by the procedures of surgeons.This term is at least nine hundred years old in English: physicians and surgeons were once members of separate professions, and traditionally were rivals. The Shorter Oxford English Dictionary, third edition, gives a Middle English quotation making this contrast, from as early as 1400: ""O Lord, whi is it so greet difference betwixe a cirugian and a physician.""Henry VIII granted a charter to the London Royal College of Physicians in 1518. It was not until 1540 that he granted the Company of Barber-Surgeons (ancestor of the Royal College of Surgeons) its separate charter. In the same year, the English monarch established the Regius Professorship of Physic at the University of Cambridge. Newer universities would probably describe such an academic as a professor of internal medicine. Hence, in the 16th century, physic meant roughly what internal medicine does now.
Currently, a specialist physician in the United States may be described as an internist. Another term, hospitalist, was introduced in 1996, to describe US specialists in internal medicine who work largely or exclusively in hospitals. Such 'hospitalists' now make up about 19% of all US general internists, who are often called general physicians in Commonwealth countries.
This original use, as distinct from surgeon, is common in most of the world including the United Kingdom and other Commonwealth countries (such as Australia, Bangladesh, India, New Zealand, Pakistan, South Africa, Sri Lanka, and Zimbabwe), as well as in places as diverse as Brazil, Hong Kong, Indonesia, Japan, Ireland, and Taiwan. In such places, the more general English terms doctor or medical practitioner are prevalent, describing any practitioner of medicine (whom an American would likely call a physician, in the broad sense). In Commonwealth countries, specialist pediatricians and geriatricians are also described as specialist physicians who have sub-specialized by age of patient rather than by organ system.


=== Physician and surgeon ===
Around the world, the combined term ""physician and surgeon"" is used to describe either a general practitioner or any medical practitioner irrespective of specialty. This usage still shows the original meaning of physician and preserves the old difference between a physician, as a practitioner of physic, and a surgeon. The term may be used by state medical boards in the United States, and by equivalent bodies in Canadian provinces, to describe any medical practitioner.


=== North America ===

In modern English, the term physician is used in two main ways, with relatively broad and narrow meanings respectively. This is the result of history and is often confusing. These meanings and variations are explained below.
In the United States and Canada, the term physician describes all medical practitioners holding a professional medical degree. The American Medical Association, established in 1847, as well as the American Osteopathic Association, founded in 1897, both currently use the term physician to describe members. However, the American College of Physicians, established in 1915, does not: its title uses physician in its original sense.


==== American physicians ====
The vast majority of physicians trained in the United States have a Doctor of Medicine degree, and use the initials M.D. A smaller number attend Osteopathic schools and have a Doctor of Osteopathic Medicine degree and use the initials D.O. After completion of medical school, physicians complete a residency in the specialty in which they will practice. Subspecialties require the completion of a fellowship after residency.
All boards of certification now require that physicians demonstrate, by examination, continuing mastery of the core knowledge and skills for a chosen specialty. Recertification varies by particular specialty between every seven and every ten years.


===== Primary care =====
Primary care physicians guide patients in preventing disease and detecting health problems early while they’re still treatable. They are divided into two types: family medicine doctors and internal medicine doctors. Family doctors, or family physicians, are trained to care for patients of any age, while internists are trained to care for adults. Family doctors receive training in a variety of care and are therefore also referred to as general practitioners. Family medicine grew out of the general practitioner movement of the 1960s in response to the growing specialization in medicine that was seen as threatening to the doctor-patient relationship and continuity of care.


==== Podiatric physicians ====
Also in the United States, the American Podiatric Medical Association (APMA) defines podiatrists as physicians and surgeons that fall under the department of surgery in hospitals. They undergo training with the Doctor of Podiatric Medicine (DPM) degree. In the US, podiatrist are required to complete three to four years surgical residency upon graduating from DPM degree. After residency, one to two years of fellowship programs are available in plastic surgery, foot and ankle reconstructive surgery, sports medicine, and wound care. This degree is also available at one Canadian university, namely the Université du Québec à Trois-Rivières. Students are typically required to complete an internship in New York prior to the obtention of their professional degree.


== Shortage ==

Many countries in the developing world have the problem of too few physicians.  In 2015, the Association of American Medical Colleges warned that the US will face a doctor shortage of as many as 90,000 by 2025.


== Social role and world view ==


=== Biomedicine ===
Within Western culture and over recent centuries, medicine has become increasingly based on scientific reductionism and materialism. This style of medicine is now dominant throughout the industrialized world, and is often termed biomedicine by medical anthropologists. Biomedicine ""formulates the human body and disease in a culturally distinctive pattern"", and is a world view learnt by medical students. Within this tradition, the medical model is a term for the complete ""set of procedures in which all doctors are trained"", including mental attitudes. A particularly clear expression of this world view, currently dominant among conventional physicians, is evidence-based medicine. Within conventional medicine, most physicians still pay heed to their ancient traditions:

 The critical sense and sceptical attitude of the citation of medicine from the shackles of priestcraft and of caste; secondly, the conception of medicine as an art based on accurate observation, and as a science, an integral part of the science of man and of nature; thirdly, the high moral ideals, expressed in that most ""memorable of human documents"" (Gomperz), the Hippocratic oath; and fourthly, the conception and realization of medicine as the profession of a cultivated gentleman.— Sir William Osler, Chauvanism in Medicine (1902)

In this Western tradition, physicians are considered to be members of a learned profession, and enjoy high social status, often combined with expectations of a high and stable income and job security. However, medical practitioners often work long and inflexible hours, with shifts at unsociable times. Their high status is partly from their extensive training requirements, and also because of their occupation's special ethical and legal duties. The term traditionally used by physicians to describe a person seeking their help is the word patient (although one who visits a physician for a routine check-up may also be so described). This word patient is an ancient reminder of medical duty, as it originally meant 'one who suffers'. The English noun comes from the Latin word patiens, the present participle of the deponent verb, patior, meaning 'I am suffering', and akin to the Greek verb πάσχειν (romanized: paschein, lit. to suffer) and its cognate noun πάθος (pathos, suffering).Physicians in the original, narrow sense (specialist physicians or internists, see above) are commonly members or fellows of professional organizations, such as the American College of Physicians or the Royal College of Physicians in the United Kingdom, and such hard-won membership is itself a mark of status.


=== Alternative medicine ===
While contemporary biomedicine has distanced itself from its ancient roots in religion and magic, many forms of traditional medicine and alternative medicine continue to espouse vitalism in various guises: ""As long as life had its own secret properties, it was possible to have sciences and medicines based on those properties"". The US National Center for Complementary and Alternative Medicine (NCCAM) classifies complementary and alternative medicine therapies into five categories or domains, including: alternative medical systems, or complete systems of therapy and practice; mind-body interventions, or techniques designed to facilitate the mind's effect on bodily functions and symptoms; biologically based systems including herbalism; and manipulative and body-based methods such as chiropractic and massage therapy.
In considering these alternate traditions that differ from biomedicine (see above), medical anthropologists emphasize that all ways of thinking about health and disease have a significant cultural content, including conventional western medicine.Ayurveda, Unani medicine, and homeopathy are popular types of alternative medicine. They are included in national systems of medicine in countries such as India. In general, the practitioners of this medicine in these countries are referred to as Vaidya, Hakim and homeopathic doctor/homeopath/homeopathic physician, respectively.


=== Physicians' own health ===
Some commentators have argued that physicians have duties to serve as role models for the general public in matters of health, for example by not smoking cigarettes. Indeed, in most western nations relatively few physicians smoke, and their professional knowledge does appear to have a beneficial effect on their health and lifestyle. According to a study of male physicians, life expectancy is slightly higher for physicians (73 years for white and 69 years for black) than lawyers or many other highly educated professionals. Causes of death which are less likely to occur in physicians than the general population include respiratory disease (including pneumonia, pneumoconioses, COPD, but excluding emphysema and other chronic airway obstruction), alcohol-related deaths, rectosigmoid and anal cancers, and bacterial diseases.Physicians do experience exposure to occupational hazards, and there is a well-known aphorism that ""doctors make the worst patients"". Causes of death that are shown to be higher in the physician population include suicide among doctors and self-inflicted injury, drug-related causes, traffic accidents, and cerebrovascular and ischaemic heart disease. Physicians are also prone to occupational burnout. This manifests as a long-term stress reaction characterized by poorer quality of care towards patients, emotional exhaustion, a feeling of decreased personal achievement, and others. A study by the Agency for Healthcare Research and Quality reported that time pressure was the greatest cause of burnout; a survey from the American Medical Association reported that more than half of all respondents chose “too many bureaucratic tasks” as the leading cause of burnout.


== Education and training ==

Medical education and career pathways for doctors vary considerably across the world.


=== All medical practitioners ===
In all developed countries, entry-level medical education programs are tertiary-level courses, undertaken at a medical school attached to a university. Depending on jurisdiction and university, entry may follow directly from secondary school or require pre-requisite undergraduate education. The former commonly takes five or six years to complete. Programs that require previous undergraduate education (typically a three- or four-year degree, often in science) are usually four or five years in length. Hence, gaining a basic medical degree may typically take from five to eight years, depending on jurisdiction and university.
Following the completion of entry-level training, newly graduated medical practitioners are often required to undertake a period of supervised practice before full registration is granted, typically one or two years. This may be referred to as an ""internship"", as the ""foundation"" years in the UK, or as ""conditional registration"". Some jurisdictions, including the United States, require residencies for practice.
Medical practitioners hold a medical degree specific to the university from which they graduated. This degree qualifies the medical practitioner to become licensed or registered under the laws of that particular country, and sometimes of several countries, subject to requirements for an internship or conditional registration.


=== Specialists in internal medicine ===
Specialty training is begun immediately following completion of entry-level training, or even before. In other jurisdictions, junior medical doctors must undertake generalist (un-streamed) training for one or more years before commencing specialization. Hence, depending on the jurisdiction, a specialist physician (internist) often does not achieve recognition as a specialist until twelve or more years after commencing basic medical training—five to eight years at university to obtain a basic medical qualification, and up to another nine years to become a specialist.


== Regulation ==
In most jurisdictions, physicians (in either sense of the word) need government permission to practice. Such permission is intended to promote public safety, and often to protect government spending, as medical care is commonly subsidized by national governments.
In some jurisdictions such as in Singapore, it is common for physicians to inflate their qualifications with the title ""Dr"" in correspondence or namecards, even if their qualifications are limited to a basic (e.g., bachelor level) degree. In other countries such as Germany, only physicians holding an academic doctorate may call themselves doctor – on the other hand, the European Research Council has decided that the German medical doctorate does not meet the international standards of a PhD research degree.


=== All medical practitioners ===
Among the English-speaking countries, this process is known either as licensure as in the United States, or as registration in the United Kingdom, other Commonwealth countries, and Ireland. Synonyms in use elsewhere include colegiación in Spain, ishi menkyo in Japan, autorisasjon in Norway, Approbation in Germany, and άδεια εργασίας in Greece. In France, Italy and Portugal, civilian physicians must be members of the Order of Physicians to practice medicine.
In some countries, including the United Kingdom and Ireland, the profession largely regulates itself, with the government affirming the regulating body's authority. The best-known example of this is probably the General Medical Council of Britain. In all countries, the regulating authorities will revoke permission to practice in cases of malpractice or serious misconduct.
In the large English-speaking federations (United States, Canada, Australia), the licensing or registration of medical practitioners is done at a state or provincial level, or nationally as in New Zealand. Australian states usually have a ""Medical Board,"" which has now been replaced by the Australian Health Practitioner Regulatory Authority (AHPRA) in most states, while Canadian provinces usually have a ""College of Physicians and Surgeons"". All American states have an agency that is usually called the ""Medical Board"", although there are alternate names such as ""Board of Medicine,"" ""Board of Medical Examiners"", ""Board of Medical Licensure"", ""Board of Healing Arts"" or some other variation. After graduating from a first-professional school, physicians who wish to practice in the US usually take standardized exams, such as the USMLE for a Doctor in Medicine.


=== Specialists in internal medicine ===
Most countries have some method of officially recognizing specialist qualifications in all branches of medicine, including internal medicine. Sometimes, this aims to promote public safety by restricting the use of hazardous treatments. Other reasons for regulating specialists may include standardization of recognition for hospital employment and restriction on which practitioners are entitled to receive higher insurance payments for specialist services.


=== Performance and professionalism supervision ===
The issue of medical errors, drug abuse, and other issues in physician professional behavior received significant attention across the world, in particular following a critical 2000 report which ""arguably launched"" the patient-safety movement. In the US, as of 2006 there were few organizations that systematically monitored performance. In the US, only the Department of Veterans Affairs randomly drug tests physicians, in contrast to drug testing practices for other professions that have a major impact on public welfare. Licensing boards at the US state-level depend upon continuing education to maintain competence. Through the utilization of the National Practitioner Data Bank, Federation of State Medical Boards' disciplinary report, and American Medical Association Physician Profile Service, the 67 State Medical Boards continually self-report any adverse/disciplinary actions taken against a licensed physician in order that the other Medical Boards in which the physician holds or is applying for a medical license will be properly notified so that corrective, reciprocal action can be taken against the offending physician. In Europe, as of 2009 the health systems are governed according to various national laws, and can also vary according to regional differences similar to the United States.


== See also ==


== References ==


== External links ==
 Media related to Physicians at Wikimedia Commons
 The dictionary definition of physician at Wiktionary"
"A medical school is a tertiary educational institution, or part of such an institution, that teaches medicine, and awards a professional degree for physicians and surgeons. Such medical degrees include the Bachelor of Medicine, Bachelor of Surgery (MBBS, MBChB, MBBCh, BMBS), Doctor of Medicine (MD), or Doctor of Osteopathic Medicine (DO). Many medical schools offer additional degrees, such as a Doctor of Philosophy (Ph.D), Master's degree (M.Sc), a physician assistant program, or other post-secondary education.
Medical schools can also carry out medical research and operate teaching hospitals. Around the world, criteria, structure, teaching methodology, and nature of medical programs offered at medical schools vary considerably. Medical schools are often highly competitive, using standardized entrance examinations, as well as grade point average and leadership roles, to narrow the selection criteria for candidates.
In most countries, the study of medicine is completed as an undergraduate degree not requiring prerequisite undergraduate coursework. However, an increasing number of places are emerging for graduate entrants who have completed an undergraduate degree including some required courses. In the United States and Canada, almost all medical degrees are second entry degrees, and require several years of previous study at the university level.
Medical degrees are awarded to medical students after the completion of their degree program, which typically lasts five or more years for the undergraduate model and four years for the graduate model. Many modern medical schools integrate clinical education with basic sciences from the beginning of the curriculum (e.g.). More traditional curricula are usually divided into preclinical and clinical blocks. In preclinical sciences, students study subjects such as biochemistry, genetics, pharmacology, pathology, anatomy, physiology and medical microbiology, among others. Subsequent clinical rotations usually include internal medicine, general surgery, pediatrics, psychiatry, and obstetrics and gynecology, among others.
Although medical schools confer upon graduates a medical degree, a physician typically may not legally practice medicine until licensed by the local government authority. Licensing may also require passing a test, undergoing a criminal background check, checking references, paying a fee, and undergoing several years of postgraduate training. Medical schools are regulated by each country and appear in the World Directory of Medical Schools which was formed by the merger of the AVICENNA Directory for Medicine and the FAIMER International Medical Education Directory.


== Africa ==

By 2005 there were more than 100 medical schools across Africa, most of which had been established after 1970.


=== Ghana ===
There are seven medical schools in Ghana: The University of Ghana Medical School in Accra, the KNUST School of Medical Sciences in Kumasi, University for Development Studies School of Medicine in Tamale, University of Cape Coast Medical School and the University of Allied Health Sciences in Ho, Volta Region, the leading private medical school in Ghana -  the Accra College of Medicine, and Family Health Medical School, another private medical school.
Basic Medical education lasts 6 years in all the medical schools. Entry into these medical schools is highly competitive and it is usually based on successful completion of the Senior High School Examinations. The University of Ghana Medical School has, however, introduced a graduate entry medical program to admit students with mainly science-related degrees into a 4-year medical school program.
Students graduating from any of these medical schools get the MBChB degree and the title ""Dr"". For the first 3 years, students are awarded BSc in the field of Medical Sciences for University of Ghana medical school; and Human biology for KNUST and UDS medical schools.
The University of Ghana Medical School and KNUST School of Medical Sciences in Kumasi use a traditional medical education model whiles University for Development Studies School of Medicine uses the problem-based learning model.
Medical graduates are then registered provisionally with the Medical and Dental Council (MDC) of Ghana as House Officers (Interns). Upon completion of the mandatory 2-year housemanship, these medical doctors are permanently registered with the MDC and can practice as medical officers (General Practitioners) anywhere in the country. The housemanship training is done only in hospitals accredited for such purposes by the Medical and Dental Council of Ghana
Following the permanent registration with the medical and dental council, doctors can specialize in any of the various fields that is organized by either the West African college of Physicians and Surgeons or the Ghana College of Physician and Surgeons.
Medical officers are also sometimes hired by the Ghana Health Service to work in the District/Rural areas as Primary Care Physicians.


=== Kenya ===
In Kenya, medical school is a faculty of a university. Medical education lasts for 6 years after which the student graduates with an undergraduate (MBChB) degree. This is followed by a mandatory 12-month full-time internship at an approved hospital after which one applies for registration with the Kenya Medical Practitioners and Dentists Board if they intend to practice medicine in the country. The first two years of medical school cover the basic medical (preclinical) sciences while the last four years are focused on the clinical sciences and internship.
There are no medical school entry examinations or interviews and admission is based on students' performance in the high school exit examination (Kenya Certificate of Secondary Education - KCSE). Students who took the AS Level or the SAT can also apply but there is a very strict quota limiting the number of students that get accepted into public universities. This quota does not apply to private universities.
There are six established public medical schools:

University of Nairobi (oldest, established 1967)
Moi University in Eldoret (established in the 1980s with major support from the Indiana University School of Medicine - USA, and with whom there remain significant ties)
Kenyatta University at Kahawa (established 2004)
Egerton University in Nakuru (established in 2007)
Jomo Kenyatta University of Agriculture and Technology in Juja,Kiambu
Maseno University in Maseno,Kisumu County.
Muliro University of Science and Technology in Kakamega(established in 2019)
South Eastern Kenya University in Kitui(established in 2013)
Nairobi,Moi and Maseno Universities run post graduate medical training programs that run over 2-6 years depending on the speciality and lead to the award of master of medicine, MMed, in the respective specialty.
There are also two private established medical schools;Mount Kenya University and Kenya Methodist University.
There has been progress made by the Aga Khan University in Karachi, Pakistan and the Aga Khan University Hospital (AKUH) in Nairobi towards the establishment of a Health Sciences University in Kenya with an associated medical school. AKUH in Nairobi, already offers post graduate MMed programmes. These are run over 4 years.
Completion of formal specialty training in Kenya is followed by two years of supervised clinical work before one can apply for recognition as a specialist, in their respective field, by the medical board.


=== Nigeria ===
There are several medical schools in Nigeria. Entrance into these schools is highly competitive. Candidates graduating from high school must attain high scores on the West African Examination Council's (WAEC) Senior School Certificate Exam (SSCE/GCE) and high scores in five subjects (Physics, Mathematics, English, Chemistry, and Biology) in the University Matriculation Examination (UME). Students undergo rigorous training for 6 years and culminate with a Bachelor of Medicine and Bachelor of Surgery (MBBS/MBChB). The undergraduate program is six years and one year of work experience in government hospitals. After medical school, graduates are mandated to spend one year of housemanship (internship) and one year of community service before they are eligible to be fully licensed by the Medical and Dental Council.
Candidates are required to score at least 280 in the UME.


=== South Africa ===
See also: List of medical schools in South Africa; Healthcare in South Africa; Category:Teaching hospitals in South Africa
Related: Dental degree#South AfricaThere are eight medical schools in South Africa, each under the auspices of a public university. As the country is a former British colony, most of the institutions follow the British-based undergraduate method of instruction, admitting students directly from high school into a 6 or occasionally five-year program. Some universities such as the University of the Witwatersrand in Johannesburg have started offering post-graduate medical degrees that run concurrently with their undergraduate programs. In this instance, a student having completed an appropriate undergraduate degree with basic sciences can enter into a four-year postgraduate program.
South African medical schools award the MBChB degree, except the University of the Witwatersrand, which styles its degree MBBCh. Some universities allow students to earn an intercalated degree, completing a BSc (Medical) with an additional year of study after the second or third year of the MBChB. The University of Cape Town, in particular, has spearheaded a recent effort to increase the level of medical research training and exposure of medical students through an Intercalated Honours Programme, with the option to extend this to a PhD.Following successful completion of study, all South African medical graduates must complete a two-year internship as well as a further year of community service in order to register with the Health Professions Council and practice as a doctor in the country.
Specialisation is usually a five- to seven-year training process (depending on the specialty) requiring registering as a medical registrar attached to an academic clinical department in a large teaching hospital with appropriate examinations. The specialist qualification may be conferred as a Fellowship by the independent Colleges of Medicine of South Africa (CMSA), following British tradition, or as a Magisterial degree by the university (usually the M Med, Master of Medicine, degree). The Medical schools and the CMSA also offer Higher Diplomas in many fields. Research degrees are the M.Med and Ph.D. or M.D., depending on university.
Medical students from all over the world come to South Africa to gain practical experience in the country's many teaching hospitals and rural clinics. The language of instruction is English but a few indigenous languages are studied briefly. The University of the Free State has a parallel medium policy, meaning all English classes are also presented in Afrikaans, therefore students who choose to study in Afrikaans, do so separately from the English class.


=== Sudan ===
In Sudan, medical school is a faculty of a university. Medical school is usually 5–6 years, and by the end of the 5–6 years the students acquires a bachelor's degree of Medicine and Surgery. Post graduating there is a mandatory one-year full-time internship at one of the university or Government Teaching hospital  in the four major Specialty in 3 months rotation, then a license is issued after a written exam conducted by the Sudan medical council (SMC) .
During the first 3–4 years the curriculum is completed, and throughout the next 2 years it is repeated with clinical training. Students with high grades in high school are accepted for free in Government Universities. Private faculty accept low grades than governmental faculty but their grades still high . Students who take foreign examinations other than the Sudanese High School Examination are also accepted in Universities, students taking IGCSE/SATs and other Arabian countries. 
All medical students who want to be enrolled in  internship program, should undergo registration under the Sudanese Medical Council. Postgraduate training conducted by Sudan medical specialisation board (SMSB) & the degree optain is medical doctor (MD). The duration of training vary from 4–6 years depend on the scientific Council of the specific speciality.


=== Tunisia ===
In Tunisia, education is free for all Tunisian citizens and for foreigners who have scholarships. The oldest Medical school is the Medicine School of Tunis. There are four medicine faculties situated in the major cities of Tunis, Sfax, Sousse and Monastir. Admission is bound to the success and score in the Tunisian Baccalaureate examination. Admission score threshold is very high, based on competition among all applicants throughout the nation. Medical school curriculum consists of seven years; five years as an 'extern' and two years of internship or 'intern trainee' :
Two years are medical theory, containing all basic sciences related to medicine. The curriculum is more focused on theoretical than on practical learning.
Three years during which the student receives both theoretical and practical training with total immersion in the hospital environment, it consists of clinical issues related to all medical specialties. During these three years, the student has to attend at the university hospital every day, rotating around all wards. Every period is followed by a clinical exam regarding the student's knowledge in that particular specialty.
Two years on internship, in which the student is a physician but under the supervision of the chief doctor; the student rotates over the major and most essential specialties during period of four months each. After that, student has the choice of either passing the residency national exam or extending his internship for another year, after which he gains the status of family physician. The residency program consists of four to five years in the specialty he qualifies, depending on his score in the national residency examination under the rule of highest score chooses first. Whether the student chooses to be a family doctor or a specialist, he has to make a doctorate thesis, which he will be defending in front of a jury, after which he gains his degree of Doctor of Medicine (MD).In contrast, studies in dental medicine (general practitioner) and pharmaceutical studies last only 6 years. Courses throughout the university curriculum in both medicine and pharmacy are taught in French.
There are four universities of general medicine: the Faculty of Medicine of Tunis, the Faculty of Medicine Ibn El Jazzar of Sousse, the Faculty of Medicine of Monastir and the Faculty of Medicine of Sfax.
On the other hand, there is only one university of dentistry and pharmacy in Monastir: the faculty of dentistry of Monastir  and the faculty of pharmacy of Monastir.


=== Uganda ===

As of April 2017, there are nine accredited medical schools in Uganda. Training leading to the award of the degree of Bachelor of Medicine and Bachelor of Surgery (MBChB) lasts five years, if there are no re-takes. After graduating, a year of internship in a hospital designated for that purpose, under the supervision of a specialist in that discipline is required before an unrestricted license to practice medicine and surgery is granted by the Uganda Medical and Dental Practitioners Council (UMDPC).
There is Postgraduate training such as the degree of Master of Medicine (MMed) which is a three-year programme, available at Makerere University School of Medicine in several disciplines. Makerere University School of Public Health, offers the degree of Master of Public Health (MPH) following a twenty-two (22)-month period of study, which includes field work.


=== Zimbabwe ===
In Zimbabwe there are three medical schools is offering Medical degrees. For undergrads, these are University of Zimbabwe - College of Health Sciences {MBChB}, National University of Science and Technology (NUST) Medical school {MBBS} and Midlands State University (MSU) {MBChB}. Only UZ is offering postgrad degrees in the Medical faculty.
Training lasts 5 1/2 years. The curriculum is as follows:

Part 1 (1 year) – Biochemistry, Communication Skills for Academic Purposes, Anatomy, Physiology and Behavioral Sciences. Professional exams are written in the first two and failure to attain a pass in Biochemistry warranties a repeat of first year.
Part 2 (1 year) – Communication Skills for Professional Purposes, Anatomy, Physiology, Behavioral Sciences. Professional exams are written at the end of second year and failure to attain a passmark in any of the last three courses on the list warranties a repeat of the year. Communication Skills can be carried to the next year, but the student should pass the course before graduation.
Part 3 (1.5 years) – Pathology (Histopathology), Medical Microbiology, Chemical Pathology, Hematology, Forensic Pathology, Immunology and Toxicology. A professional exam is written at the end of the third year and the student has to pass to proceed. There are also surgery and medicine rotations during the year. Also, the students cover most of the basic Pharmacology during the third stage of the degrees.
Part 4 (1 year) – Community Medicine, Psychiatry and Clinical Pharmacology
Part 5 (1 year) – Medicine, Surgery, Obstetrics and Gynecology, PediatricsInternship is 2 years duration, with the first year spent in medicine and surgery and the second year doing pediatrics, anesthesia/psychiatry and obstetrics and gynecology. Thereafter one can apply for MMED at the university which last 4–5 years depending on specialty. Currently no subspecialist education is available.


== Americas ==


=== Argentina ===

Medical degree programs in Argentina typically are six years long, with some universities opting for 7 year programs. Each one of the 3000 medical students who graduate each year in Argentina are required before graduation to dedicate a minimum of 8 months to community service without pay; although in some provinces (especially round the more developed south) there are government-funded hospitals who pay for this work. Some universities have cultural exchange programmes that allow a medical student in their final year to serve their community time overseas.
Upon graduation, one of the following degrees is obtained, according to the university: Doctor of Medicine, or both Doctor of Medicine and Doctor of Surgery. Public universities usually confer both degrees, and private universities bestow only Doctor of Medicine. In daily practice, however, there is no substantial difference between what a Doctor of Medicine or a Doctor of Medicine and Doctor of Surgery are allowed to do. When the degree is obtained, a record is created for that new doctor in the index of the National Ministry of Education (Ministerio Nacional de Educación) and the physician is given their corresponding medical practitioner's ID, which is a number that identifies him and his academic achievements. In addition, there is a provincial ID, i. e. a number to identify doctors in the province they practice medicine in.
Doctors wishing to pursue a speciality must take entrance exams at the public/private institution of their choice that offers them. It is easier for students in private Medical Schools to obtain a residency in a Private Hospital, especially when the university has its own hospital, as the university holds positions specifically for its graduates. Speciality courses last about two to five years, depending on the branch of medicine the physician has chosen. There is no legal limit for the number of specialities a doctor can learn, although most doctors choose to do one and then they sub-specialise for further job opportunities and less overall competition, along with higher wages.
In Argentina there are public and private medical schools, however the prestige of the public institutions is undeniable and the private institutions do not normally appear in international rankings. A person who can afford to attend a private university, quite expensive for the average Argentinian, will choose that option over public education because of the smaller groups of students in each class and because of the lack of strictness in course evaluation. By law entrance into public institutions is open and tuition-free to all who have a high school diploma, and universities are expressly forbidden from restricting access with difficult entrance exams. Point in case, in 2016 La Universidad Nacional de la Plata was obligated by the governing bodies to stop forcing its students to write an entrance exam. As a result, that university experienced a major increase in the size of its student population. When it comes to educational quality, la Universidad de Buenos Aires, a public university, is widely recognised as the top medical school in the country.


=== Bolivia ===
In Bolivia, all medical schools are Faculties within a University and follow the European model of a six-year curriculum (9 000 ECTS or more) divided into three cycles. The first two years are called biomedical or pre-clinical cycle. During this time students are instructed in the basic sciences (anatomy, anthropology, biochemistry, biophysics, cell biology, embryology, histology, physiology, pharmacology, biostatistics, etc.). The next three years are the clinical cycle and consist of medical specialties instruction at the faculty and hospital practice. The last year consists of an internship from 3 months each of surgery, internal medicine, gynecology and pediatrics. To acquire the license from the government to practice medicine, at the end of internship must be done a Honorary Mandatory Socialist Service (SSSRO) in a rural area of the country during at least three months.
After getting the degree and license as ""Graduate of Medicine and Surgery"" or Médico Cirujano (MC) may take a post-graduate residency from 3 to 6 years in order to acquire a specialty.


=== Brazil ===
The Brazilian medical schools follow the European model of a six-year curriculum, divided into three cycles of two years each. The first two years are called basic cycle (ciclo básico). During this time students are instructed in the basic sciences (anatomy, physiology, pharmacology, immunology etc.) with activities integrated with the medical specialties, allowing the student an overview of the practical application of such content. After its completion, the students advance to the clinical cycle (ciclo clinico). At this stage contacts with patients intensify and work with tests and diagnostics, putting into practice what was learned in the first two years. The last two are called cycle internship (ciclo do internato). In this last step the students focus on clinical practice, through training in teaching hospitals and clinics. The teaching of this last step respecting an axis of increasing complexity, enabling students to make decisions and participate effectively in form and operative care under the direct supervision of faculty and qualified to act as teaching aids physicians. The performance of the internal develops redemption of ethical and humanistic dimensions of care, causing the student to recognize the values and principles that guide the physician-patient relationship.
After six years of training, students graduate and are awarded the title of physician (Médico) allowing them to register with the Regional Council of Medicine (Conselho Regional de Medicina). The recent graduate will be able to exercise the medical profession as a general practitioner and may apply to undertake postgraduate training. In 2012, the Regional Council of Medicine of São Paulo (Conselho Regional de Medicina do Estado de São Paulo) established that physicians who graduate from this year must pass a test to obtain professional registration. Passing the exam, however, is not linked to obtaining registration. It required only the presence of the candidate and the test performance. Already at the national level, pending in the Senate a bill creating the National Proficiency Examination in Medicine (Exame Nacional de Proficiência em Medicina), which would make the race a prerequisite for the exercise of profession.
Physicians who want to join a specialization program must undergo a new selection examination considered as competitive as that required to join a medical school. Works in health institutions under the guidance of medical professionals with high ethical and professional qualification. The specialization programs are divided into two categories: direct access and prerequisite. The specialties with direct access are those in which the doctor can enroll without having any prior expertise. Any physicians can apply to examinations for these specialties, regardless of time of training or prior experience. To apply to proprietary pre-requisite, the doctor should have already completed a specialty prior. The programs may range from 2 to 6. In Brazil are currently recognized by the Federal Council of Medicine, the Brazilian Medical Association and the National Commission of Medical Residency 53 residency programs. Fully complied with, gives the title of resident physician specialist.


=== Canada ===

In 2013, the Association of American Medical Colleges lists 17 accredited MD-granting medical schools in Canada.
In Canada, a medical school is a faculty or school of a university that offers a three- or four-year Doctor of Medicine (M.D. or M.D.C.M.) degree. Generally, medical students begin their studies after receiving a bachelor's degree in another field, often one of the biological sciences. However, admittance can still be granted during third and fourth year. Minimum requirements for admission vary by region from two to four years of post-secondary study. The Association of Faculties of Medicine of Canada publishes a detailed AFMC.ca, guide to admission requirements of Canadian faculties of medicine on a yearly basis.
Admission offers are made by individual medical schools, generally on the basis of a personal statement, undergraduate record (GPA), scores on the Medical College Admission Test (MCAT), and interviews. Volunteer work is often an important criterion considered by admission committees. All four medical schools in Quebec and two Ontario schools (University of Ottawa, Northern Ontario School of Medicine) do not require the MCAT. McMaster requires that the MCAT be written, though they only look for particular scores (6 or better) on the verbal reasoning portion of the test.
The first half of the medical curriculum is dedicated mostly to teaching the basic sciences relevant to medicine. Teaching methods can include traditional lectures, problem-based learning, laboratory sessions, simulated patient sessions, and limited clinical experiences. The remainder of medical school is spent in clerkship. Clinical clerks participate in the day-to-day management of patients. They are supervised and taught during this clinical experience by residents and fully licensed staff physicians.
Students enter into the Canadian Resident Matching Service, commonly abbreviated as CaRMS in the fall of their final year. Students rank their preferences of hospitals and specialties. A computerized matching system determines placement for residency positions. 'Match Day' usually occurs in March, a few months before graduation. The length of post-graduate training varies with choice of specialty.
During the final year of medical school, students complete part 1 of the Medical Council of Canada Qualifying Examination (MCCQE). Upon completion of the final year of medical school, students are awarded the degree of M.D. Students then begin training in the residency program designated to them by CaRMS. Part 2 of the MCCQE, an Objective Structured Clinical Examination, is taken following completion of twelve months of residency training. After both parts of the MCCQE are successfully completed, the resident becomes a Licentiate of the Medical Council of Canada. However, in order to practice independently, the resident must complete the residency program and take a board examination pertinent to his or her intended scope of practice. In the final year of residency training, residents take an exam administered by either the College of Family Physicians of Canada or the Royal College of Physicians and Surgeons of Canada, depending on whether they are seeking certification in family medicine or another specialty.


=== Caribbean ===

In 2011, the International Medical Education Directory listed 59 current medical schools in the Caribbean. 54 grant the MD degree, 3 grant the MBBS degree, and 2 grant either the MD or MBBS degree.
30 of the medical schools in the Caribbean are regional, which train students to practice in the country or region where the school is located. The remaining 29 Caribbean medical schools are known as offshore schools, which primarily train students from the United States and Canada who intend to return home for residency and clinical practice after graduation. At most offshore schools, basic sciences are completed in the Caribbean while clinical clerkships are completed at teaching hospitals in the United States.
Several agencies may also accredit Caribbean medical schools, as listed in the FAIMER Directory of Organizations that Recognize/Accredit Medical Schools (DORA). 25 of the 29 regional medical schools in the Caribbean are accredited, while 14 of the 30 offshore medical schools are accredited.


=== Curaçao ===
Curaçao currently (2015), has 5 medical schools and one other medical university under construction. The majority are located within the city of Willemstad. All six medical schools on the island of Curaçao, only provide education in Basic Medical Science (BMS) which goes towards the degree of Medical Doctor or Doctor of Medicine (2016). 
Presently, none of the medical schools offer other degrees; such as MBBS or PhD (2016). 
All students after completing their medical school's Basic Medical Science program in Curaçao; will then have to apply to either take USMLE Step Exams, The Canadian or UK Board Exams. 
A large percentage of these medical students who attend these medical schools in Curaçao are either from North America, Africa, Europe or Asia.


=== Chile ===
In Chile, there are 21 medical schools. Principal medical schools are Universidad de Chile, Pontificia Universidad Católica de Chile, Universidad de Concepción, Universidad de Valparaíso and Universidad de Santiago de Chile. The pre-grade studies are distributed in 7 years, where the last 2 are the internship, that include at least surgery, internal medicine, gynecology and pediatrics. After getting the degree of Licenciate in Medicine (General Medicine) the M.D. must pass a medicine knowledge exam called the Unique National Exam of Medical Knowledge (EUNACOM ""Examen Único Nacional de Conocimientos de Medicina"" in Spanish) and can take a direct specialty or work before in primary attention in order to gain access to a residency.


=== Colombia ===
In Colombia, there are 50 medical schools listed in the World Directory of Medical Schools, 27 of which have active programs and are currently registered and accredited as high-quality programs by the Colombian Ministry of Education. The main medical programs are offered by the Universidad Nacional de Colombia, Pontificia Universidad Javeriana, Universidad del Rosario, Universidad El Bosque, Universidad de los Andes, Universidad del Valle, Universidad de Antioquia, Universidad de Santander, Universidad del Norte and Universidad de la Sabana.  Most programs require between 6–7 years of study, and all offer a Doctor of Medicine (MD) degree. In some cases the school also allows for a second degree to be studied for at the same time (this is chosen by the student, though most students end up needing to do alternate semesters between their degrees, and mostly in careers like microbiology or biomedical engineering). For example, the Universidad de los Andes has a program whereby the medical student could graduate with both an MD and a Master of Business Administration (MBA) degree, or an MD and a master's degree in public health. Admission to medical school varies with the school, but is usually dependent on a combination of a general application to the university, an entrance exam, a personal statement or interview, and secondary (high) school performance mostly as reflected on the ICFES score (the grade received on the state exam in the final year of secondary/high school).
In most medical programs, the first two years deal with basic scientific courses (cellular and molecular biology, chemistry, organic chemistry, mathematics, and physics), and the core medical sciences (anatomy, embryology, histology, physiology, and biochemistry). The following year may change in how it is organized in different schools, but is usually organ system-based pathophysiology and therapeutics (general and systems pathology, pharmacology, microbiology, parasitology, immunology, and medical genetics are also taught in this block). In the first two years, the programs also usually begin the courses in the epidemiology track (which may or may not include biostatistics), a clinical skills track (semiology and the clinical examination), a social medicine/public health track, and a medical ethics and communication skills track. Modes of training vary, but are usually based on lectures, simulations, standardized-patient sessions, problem-based learning sessions, seminars, and observational clinical experiences. By year three, most schools have begun the non-elective, clinical-rotation block with accompanying academic courses (these include but are not limited to internal medicine, pediatrics, general surgery, anaesthesiology, orthopaedics, gynaecology and obstetrics, emergency medicine, neurology, psychiatry, oncology, urology, physical medicine and rehabilitation, ophthalmology, and otorhinolaryngology). Elective rotations are usually introduced in the fourth or fifth year, though as in the case of the non-elective rotations, the hospitals the medical students may be placed in or apply to for a given rotation depend entirely on the medical schools. This is important in terms of the medical training, given the particular distinction of patients, pathologies, procedures, and skills seen and learned in private vs. public hospitals in Colombia. Most schools, however, have placements in both types of hospitals for many specialties.
The final year of medical school in Colombia is referred to as the internship year (""internado""). The internship year is usually divided into two semesters. The first semester is made up of obligatory rotations that every student does though in different orders, and the medical intern serves in 5-7 different specialties, typically including internal medicine, paediatrics, general surgery, anaesthesiology, orthopaedics, gynaecology and obstetrics, and emergency medicine. The extent of the responsibilities of the intern varies with the hospital, as does the level of supervision and teaching, but generally, medical interns in Colombia extensively take, write, and review clinical histories, answer and discuss referrals with their seniors, do daily progress notes for the patients under their charge, participate in the service rounds, present and discuss patients at rounds, serve shifts, assist in surgical procedures, and assist in general administrative tasks. Sometimes, they are charged with ordering diagnostic testing, but, under Colombian law they cannot prescribe medication as they are not graduate physicians. This, of course, are to be completed in addition to their academic responsibilities. The second semester is made up of elective rotations, which can be at home or abroad, in the form of clerkships or observerships. A final graduation requirement is to sit a standardized exam, the State Exam for Quality in Higher Education (""Examen de Estado de Calidad de la Educación Superior"" or ECAES, also known as SABER PRO) specific to medicine, which tests, for example, knowledge in public health and primary care.
After graduation, the physician is required to register with the Colombian Ministry of Health, in order to complete a year of obligatory social service (""servicio social obligatorio""), after which they qualify for a professional license to practice general medicine and apply for a medical residency within Colombia. If, however, the student wishes to practice general medicine abroad or continue onto their postgraduate studies, for example, they can independently begin the appropriate application/equivalency process, without doing their obligatory social service. In this case they would not be licensed to practise medicine in Colombia and if they wish to do so, will have to register with the Ministry of Health. N.B. If the graduate physician gets accepted immediately into a residency within Colombia in internal medicine, paediatrics, family medicine, gynecology and obstetrics, general surgery or anaesthesiology, they are allowed to complete a 6-month-long social service after their residency.
In contrast with most countries, residencies in Colombia are NOT paid positions, since one applies for the program through the university offering the post, which requires a tuition. However, on 9th May, 2017, legislation was formally introduced in Congress that would seek to regulate payment for medical residents, regulate their tuitions, and advocate for their vacation time and working hours. As in other countries, length of residency training depends upon the specialty chosen, and, following its completion, the physician may choose to apply for a fellowship (subspecialty) at home or abroad depending on the availability of their desired training programs, or practice in their specialty.


=== El Salvador ===
The Universidad de El Salvador (University of El Salvador) has a program of 8 years for students who want to study medicine. The first six years are organized in a two semesters fashion, the seventh year is used for a rotating internship through the mayor specialty areas in a 10-week periods fashion (psychiatry and public health share a period) and the eighth year is designated for Social service in locations approved by the Ministry of Health (usually as attending physician in Community Health Centers or non-profit organizations). The graduates receive the degree of MD and must register in the Public Health Superior Council(CSSP) to get the medical license and a registered national number that allows them to prescribe barbiturates and other controlled drugs. In order to attend further studies (Surgery, Internal medicine, G/OB, Pediatrics, Psychiatry), the students in the year of Social service or graduates of any Salvadorian university must apply independently for the residency to the hospital of choice; the preliminary selection process is based on the results of clinical knowledge tests, followed by psychiatric evaluations and interviews with the hospital medical and administrative staff. The basic residencies mentioned above commonly last 3 years; at the last trimester of the third year, the residents can apply to the position of Chief of residents (1 year) or follow further studies as resident (3 years) of a specialty (for example:orthopedic surgery, urology, neurology, endocrinology...). No further studies are offered to the date; therefore, specialist looking for training or practice in a specific area (For example: a neurosurgeon looking for specialty in endovascular neurosurgery, spine surgery or pediatric neurosurgery) must attend studies in other countries and apply for such positions independently.


=== Guyana ===
In Guyana the medical school is accredited by the National Accreditation Council of Guyana. The medical program ranges from 4 years to 6 years. Students are taught the basic sciences aspect of the program within the first 2 years of medical school. In the clinical sciences program, students are introduced to the hospital setting where they gain hands on training from the qualifying physicians and staff at the various teaching hospitals across Guyana.

Lincoln American University
Texila American University
American International School of Medicine
University of GuyanaStudents graduating from the University of Guyana are not required to sit a board exams before practicing medicine in Guyana. Students graduating from the American International School of Medicine sit the USMLE, PLAB or CAMC exams.


=== Haiti ===
Medical schools in Haiti conduct training in French. The universities offering medical training in Haiti are the Université Notre Dame d'Haïti, Université Quisqueya, Université d'Etat d'Haïti and Université Lumière.
The Université Notre Dame d'Haïti (UNDH) is a private Catholic university established by the Episcopal Conference of Haiti. According to the UNDH website, ""the UNDH is not just about academic degrees, it is mainly the formation of a new type of Haiti, which includes in its culture and moral values of the Gospel, essential for serious and honest people that the country needs today.""
The other two private schools offering medical degrees are Université Quisqueya and Université Lumière. The Université d'Etat d'Haïti is a public school.Attending medical school in Haiti may be less expensive than attending medical universities located in other parts of the world, but the impact of the country's political unrest should be considered, as it affects the safety of both visitors and Haitians.
Duration of basic medical degree course, including practical training: 6 years
Title of degree awarded: Docteur en Médecine (Doctor of Medicine)
Medical registration/license to practice: Registration is obligatory with the Ministère de la Santé publique
et de la Population, Palais des Ministères, Port-au-Prince. The license to practice medicine is granted to
medical graduates who have completed 1 year of social service. Those who have qualified abroad must
have their degree validated by the Faculty of Medicine in Haiti. Foreigners require special
authorization to practice.


=== Panama ===
The system of Medical education in Panama usually takes students from high school directly into Medical School for a 6-year course, typically with a two years internship.


=== United States ===

In 2019, the Association of American Medical Colleges and American Association of Colleges of Osteopathic Medicine listed 154 accredited M.D.-granting and 36 accredited D.O.-granting medical schools in the United States.
The Doctor of Medicine (MD) and Doctor of Osteopathic Medicine (DO) are graded to be equivalent to a Professional Doctorate.Admission to medical school in the United States is based mainly on a GPA, MCAT score, admissions essay, interview, clinical work experience, and volunteering activities, along with research and leadership roles in an applicant's history. While obtaining an undergraduate degree is not an explicit requirement for a few medical schools, virtually all admitted students have earned at least a bachelor's degree. A few medical schools offer pre-admittance to students directly from high school by linking a joint 3-year accelerated undergraduate degree and a standard 4-year medical degree with certain undergraduate universities, sometimes referred to as a ""7-year program"", where the student receives a bachelor's degree after their first year in medical school.
As undergraduates, students must complete a series of prerequisites, consisting of biology, physics, and chemistry (general chemistry and organic). Many medical schools have additional requirements including calculus, genetics, statistics, biochemistry, English, and/or humanities classes. In addition to meeting the pre-medical requirements, medical school applicants must take and report their scores on the MCAT, a standardized test that measures a student's knowledge of the sciences and the English language. Some students apply for medical school following their third year of undergraduate education while others pursue advanced degrees or other careers prior to applying to medical school.
In the nineteenth century, there were over 400 medical schools in the United States. By 1910, the number was reduced to 148 medical schools and by 1930 the number totaled only 76. Many early medical schools were criticized for not sufficiently preparing their students for medical professions, leading to the creation of the American Medical Association in 1847 for the purpose of self-regulation of the profession. Abraham Flexner (who in 1910 released the Flexner report with the Carnegie Foundation), the Rockefeller Foundation, and the AMA are credited with laying the groundwork for what is now known as the modern medical curriculum.The standard U.S. medical school curriculum is four years long. Traditionally, the first two years are composed mainly of classroom basic science education, while the final two years primarily include rotations in clinical settings where students learn patient care firsthand. Today, clinical education is spread across all four years with the final year containing the most clinical rotation time. The Centers for Medicare and Medicaid Services (CMS) of the U.S. Department of Health and Human Services (HHS) has published mandatory rules, obliging on all inpatient and outpatient teaching settings, laying down the guidelines for what medical students in the United States may do, if they have not completed a clerkship or sub-internship. These rules apply to when they are in the clinical setting in school, not when they are, for example, helping staff events or in other non-formal educational settings, even if they are helping provide certain clinical services along with nurses and the supervising physicians- for example, certain basic screening procedures. In the formal clinical setting in school, they can only assist with certain patient evaluation and management tasks, after the vital signs, chief complaint and the history of present illness have been discerned, but prior to the physical examination: reviewing the patient's signs and symptoms in each body system, and then reviewing the patient's personal medical, genetic, family, educational/occupational, and psychosocial history. The student's supervising physician (or another physician with supervisory privileges if the original doctor is no longer available, for some reason) must be in the room during the student's work, and must conduct this same assessment of the patient before performing the actual physical examination, and after finishing and conferring with the student, will review his or her notes and opinion, editing or correcting them if necessary, and will also have his or her own professional notes; both must then sign and date and I.D. the student's notes and the medical record. They may observe, but not perform, physical examinations, surgeries, endoscopic or laparoscopic procedures, radiological or nuclear medicine procedures, oncology sessions, and obstetrics. The patient must give consent for their presence and participation in his or her care, even at a teaching facility. Depending on the time they have completed in school, their familiarity with the area of medicine and the procedure, and the presence of their supervisor, and any others needed, in the room or nearby, they may be allowed to conduct certain very minor tests associated with the physical examination, such as simple venipuncture blood draws, and electrocardiograms and electroencephalograms, for learning and experience purposes, especially when there is no intern or resident available.
Upon successful completion of medical school, students are granted the title of Doctor of Medicine (M.D.) or Doctor of Osteopathic Medicine (D.O.). Residency training, which is a supervised training period of three to seven years (usually incorporating the 1st year internship) typically completed for specific areas of specialty. Physicians who sub-specialize or who desire more supervised experience may complete a fellowship, which is an additional one to four years of supervised training in their area of expertise.
Upon completion of medical school in the United States, students transition into residency programs through the National Resident Match Program (NRMP). Each year, approximately 16,000 US medical school students participate in the residency match. An additional 18,000 independent applicants—former graduates of U.S. medical schools, U.S. osteopathic medical schools, U.S. podiatry students, Canadian students, and graduates of foreign medical schools—compete for the approximately 25,000 available residency positions.Unlike those in many other countries, US medical students typically finance their education with personal debt. In 1992, the average debt of a medical doctor after residency was $25,000. For the class of 2009, the average debt of a medical student is $157,990 and 25.1% of students had debt in excess of $200,000 (prior to residency). For the past decade the cost of attendance has increased 5-6% each year (roughly 1.6 to 2.1 times inflation).Licensing of medical doctors in the United States is coordinated at the state level. Most states require that prospective licensees complete the following requirements:

Graduation from an accredited medical school granting the degree of D.O. or M.D.
United States and Canada schools must be accredited by the American Association of Colleges of Osteopathic Medicine or the Liaison Committee on Medical Education.
Foreign medical school graduates generally must complete some training within the United States.
Satisfactory completion of at least one year of an AOA- or ACGME-approved residency.
Passing the United States Medical Licensing Examination or the Comprehensive Osteopathic Medical Licensing Examination (USMLE, COMLEX, or simply ""the boards""). USMLE and COMLEX both consist of four similar parts:
Step or Level I is taken at the end of the second year of medical school and tests students' mastery of the basic sciences as they apply to clinical medicine.
Step II Clinical Knowledge (CK) or Level II Cognitive Evaluation (CE) is taken during the fourth year of medical school and tests students' mastery of the management of ill patients.
Step II Clinical Skills (CS) or Level II Performance Evaluation (PE) is taken during the fourth year of medical school and tests students' mastery of clinical skills using a series of standardized patient encounters.
Step or Level III is taken after the first year of a residency program and tests physicians' ability to independently manage the care of patients.


=== Uruguay ===
The University of Montevideo in Uruguay is the oldest in Latin America, being public and free, co-governed by students, graduates and teachers.
The progress of medical and biological sciences in the nineteenth century, the impact of the work of Claude Bernard (1813–1878), Rudolf Virchow (1821–1902) Robert Koch (1843–1910), Louis Pasteur (1822–1895) and all the splendor of French medical schools, Vienna, Berlin and Edinburgh, was a stimulus for the creation of a medical school in the country. The basic medical school program lasts seven years. There is also a second medical school in the country, Universidad CLAEH (Centro Latinoamericano de Economía Humana), which is located in Punta del Este, Maldonado.


=== Venezuela ===
These are the universities with a medical school in Venezuela:

Central University of Venezuela.
University of the Andes (Venezuela).
University of Zulia.
University of Carabobo.
Universidad de Oriente.
Universidad Centroccidental Lisandro Alvarado.
Universidad Nacional Experimental Francisco de Miranda.
Universidad Nacional Experimental de Los Llanos Centrales Rómulo Gallegos.
Bolivarian University of Venezuela.


== Asia and Oceania ==


=== Australia ===

Historically, Australian medical schools have followed the British tradition by conferring the degrees of Bachelor of Medicine and Bachelor of Surgery (MBBS) to its graduates whilst reserving the title of Doctor of Medicine (MD) for their research training degree, analogous to the PhD, or for their honorary doctorates. Although the majority of Australian MBBS degrees have been graduate programs since the 1990s, under the previous Australian Qualifications Framework (AQF) they remained categorised as Level 7 Bachelor degrees together with other undergraduate programs.
The latest version of the AQF includes the new category of Level 9 Master's (Extended) degrees which permits the use of the term 'Doctor' in the styling of the degree title of relevant professional programs. As a result, various Australian medical schools have replaced their MBBS degrees with the MD to resolve the previous anomalous nomenclature. With the introduction of the Master's level MD, universities have also renamed their previous medical research doctorates. The University of Melbourne was the first to introduce the MD in 2011 as a basic medical degree, and has renamed its research degree to Doctor of Medical Science (DMedSc).


=== Bangladesh ===

In Bangladesh, admission to medical colleges is organized by the Governing Body of University of Dhaka. A single admission test is held for government and private colleges. Due to the highly competitive nature of these exams, the total number of applicants across the country is around 78 times the number of students accepted. Admission is based on the entrance examination, as well as students' individual academic records.The entrance examination consists carries a time limit of one hour. 100 marks are allocated based on objective questions, in which the mark allocation is distributed between a variety of subjects. Biology questions carry 30 marks, Chemistry carries 25, Physics carries 20, English carries 15, and general knowledge carries 10.
Additionally, students' previous SSC (Secondary School Certificate) and HSC (Higher Secondary School Certificate) scores each carry up to 100 marks towards the overall examination result.
English students prepare themselves for the admission exam ahead of time. This is because as the GCSE and A-Level exams do not cover parts of the Bangladesh syllabus.The undergraduate program consists of five years study, followed by a one-year internship. The degrees granted are Bachelor of Medicine and Bachelor of Surgery (M.B.B.S.). Further postgraduate qualifications may be obtained in the form of Diplomas or Degrees (MS or MD), M.Phil and FCPS (Fellowship of the College of Physicians and Surgeons).
The University of Dhaka launched a new BSc in ""Radiology and Imaging Technology,"" offering 30 students the opportunity to contribute towards their entrance exam grade. For students who have passed the HSC, this course contributes towards 25% of the mark. The course contributes up to 75% for Diploma-holding students. The duration of the course is four years (plus 12 weeks for project submission). The course covers a variety of topics, including behavioural science, radiological ethics, imaging physics and general procedure.


=== Cambodia ===
After 6 years of general medical education (a foundation year + 5 years), all students will graduate with Bachelor of Medical Sciences (BMedSc) បរិញ្ញាប័ត្រ វិទ្យាសាស្រ្តវេជ្ជសាស្ត្រ. This degree does not allow graduates to work independently as Physician, but it is possible for those who wish to continue to master's degrees in other fields relating to medical sciences such as Public Health, Epidemiology, Biomedical Science, Nutrition...
Medical graduates, who wish to be fully qualified as physicians or specialists must follow the rule as below:

General Practitioner's (GP) course is 8 years (BMedSc + 2-year internship). Clinical rotation in the internship is modulated within 4 main disciplines (general medicine, surgery, gynecology, pediatrics). The medical degree awarded is Doctor of Medicine (MD) សញ្ញាប័ត្រ វេជ្ជបណ្ឌិត, equivalent to a master's degree.
After graduating with BMedSc; any students, who wishes to enter Residency Training Programs, are required to sit for a rigorous and Entrance Exam. The duration of residency programs lasts from 3 to 4 years after BMedSc (BMedSc + 3– 4 years of specialization). Once the graduates, after successful defense of their practicum thesis, are officially awarded the Degree of Specialized Doctor (MD-with specialization) សញ្ញាប័ត្រវេជ្ជបណ្ឌិតឯកទេស ""Professional Doctorate"".All Medical graduates must complete Thesis Defense and pass the National Exit Exam ប្រឡងចេញថ្នាក់ជាតិក្នុងវិស័យសុខាភិបាល to become either GPs or Medical or Surgical Specialists.


=== Hong Kong ===

Hong Kong has two comprehensive medical faculties, the Li Ka Shing Faculty of Medicine, University of Hong Kong and the Faculty of Medicine, Chinese University of Hong Kong, and they are also the sole two institutes offering medical and pharmacy programs. Other healthcare discipline programs (like nursing) are dispersed among some other universities which do not host a medical faculty.
Prospective medical students enter either faculty of Medicine available from high schools. The medical program consists of 5 years for those who take the traditional Hong Kong's Advanced Level Examination (HKALE) for admission, or 6 years for those who take the new syllabus Hong Kong's Diploma of Secondary School Education Examination (HKDSE). International students who take examinations other the two mentioned will be assessed by the schools to decide if they will take the 5-year program or the 6-year one.
The competition of entering the medical undergraduate programs is intense as the number of intakes each year is very limited: in 2019, the quota is 265 from each school (530 in total), hence candidates need to attain an excellent examination result and good performance in interviews. The schools put a great emphasis on students' languages (both Chinese and English) and communication skills as they need to communicate with other health care professionals and patients or their families in the future.
During their studies at the medical schools, students need to accumulate enough clinical practicing hours in addition before their graduation.
The education leads to a degree of Bachelor of medicine and Bachelor of surgery (M.B., B.S. by HKU or M.B., Ch.B. by CUHK). After a 5- or 6-year degree, one year of internship follows in order to be eligible to practice in Hong Kong.
Both HKU and CUHK provide a prestigious Bachelor of Pharmacy course that is popular among local and overseas students. Students of most other health care disciplines have a study duration of 4 years, except nursing programs which require 5 years.


=== India ===

In India, admission to medical colleges is organized by the central government by NTA (National Testing Agency) through tests known as NEET entrance examination. Students who have successfully completed their 10+2 (Physics, Chemistry and Biology Marks are considered and PCB is mandatory) education (higher secondary school) can appear for the tests the same year.
The NEET-UG (National Eligibility cum Entrance Test) for filling up of 15% of total MBBS seats in India, conducted by NTA (National Testing Agency) 1 time in a year in the month of May intakes about only 65,000 students out of a total applicants of over 15,00,000. The Supreme Court Of India has mandated the necessity of entrance examination based upon multiple choice questions and negative marking for wrong answers with subsequent merit over 50% for selection into MBBS as well as higher medical education. The entrance exams are highly competitive.
The graduate program consists of three professionals consisting of 9 semesters, followed by one-year internship (rotating housemanship). The degree granted is Bachelor of Medicine and Bachelor of Surgery (M.B.B.S.) of five years and six months.
The graduate degree of MBBS is divided into 3 professionals, with each professional ending with a professional exam conducted by the university (a single university may have up to dozens of medical colleges offering various graduate/post-graduate/post-doctoral degrees). After clearing this the student moves into the next professional. Each professional exam consists of a theory exam and a practical exam conducted not only by the same college but also external examiners. The exams are tough and many students are unable to clear them, thereby prolonging their degree time. The first professional is for 1 year and includes preclinical subjects, anatomy, physiology and biochemistry. The second professional is for 1 and a half year and has subjects pathology, pharmacology, microbiology (including immunology) and forensic medicine. Clinical exposure starts in the second professional. The third professional is divided into two parts. Part 1 consists of ophthalmology, ENT, and PSM (preventive and social medicine) and part 2 consists of general-medicine[including dermatology, psychiatry as short subjects], general surgery [including radiology, anaesthesiology and orthopaedics as short subjects] and pediatrics and gynaecology and obstetrics . This is followed by one-year of internship (house-surgeonship). After internship, the degree of MBBS is awarded by the respective university. Some states have made rural service compulsory for a certain period of time after MBBS.
Selection for higher medical education is through entrance examinations as mandated by the Supreme Court Of India. Further postgraduate qualifications may be obtained as Post-graduate Diploma of two years residency or Doctoral Degree (MS: Master of Surgery, or MD) of three years of residency under the aegis of the Medical Council of India. The MD/MS seats in India are filled up through NEET PG Examination conducted by the National Board of Examinations (NBE) under the supervision of the Directorate General Of Health Services. Theses/Dissertations are mandatory to be submitted and cleared by university along with examinations (written and clinicals) to obtain MD/MS degree. Further sub-speciality post-doctoral qualification (DM - Doctorate of Medicine, or MCh - Magister of Chirurgery) of three years of residency followed by university examinations may also be obtained.PG (post-graduate) qualification is equivalent to M.D./M.S., consisting of two/three-years residency after MBBS. A PG diploma may also be obtained through the National Board of Examinations (NBE), which also offers three-years residency for sub-specialisation. All degrees by NBE are called DNB (Diplomate of National Board). DNB's are awarded only after clearance of theses/dissertations and examinations. DNBs equivalent to DM/MCh have to clear examinations mandatorily.


=== Indonesia ===

In Indonesia, high school graduates who aspires to enroll in public medical schools must have their names enlisted by their high school faculty in the ""SNMPTN Undangan"" program, arranged by Directorate General of Higher Education, Ministry of National Education. Depending on the high school's accreditation, only the class' top 10%-15% will be considered for admissions. Fewer places are available through entrance exam conducted autonomously by each university. These exams are highly competitive for medicine, especially in prestigious institutions such as University of Indonesia in Jakarta, Airlangga University in Surabaya, and Gadjah Mada University in Yogyakarta. For private medical schools, almost all places offer seats through independently run admission tests.
The standard Indonesian medical school curriculum is six years long. The four years long undergraduate program is composed mainly of classroom education, continued with the last two years in professional program which primarily includes rotations in clinical settings where students learn patient care firsthand. If they pass the undergraduate program, they will be granted the title ""S.Ked"" (Bachelor of Medicine) and if they finish the professional program and pass the national examination arranged by IDI (Indonesian Medical Association) they will become general physician and be assigned the prefix, ""dr. (doctor)"".
Upon graduation, a physician planning to become a specialist in a specific field of medicine must complete a residency, which is a supervised training with periods ranging from three to four years. A physician who sub-specializes or who desires more supervised experience may complete a fellowship, which is an additional one to three years of supervised training in his/her area of expertise


=== Iran ===

General medicine education in Iran takes 7 to 7.5 years. Students enter the university after high school. Students study basic medical science (such as anatomy, physiology, biochemistry, histology, biophysics, embryology, etc.) for 2.5 years. At the end of this period they should pass a ""basic science"" exam. Those who passed the exam will move on to study physiopathology of different organs in the next 1.5 years. The organ-based learning approach emphasizes critical thinking and clinical application. In the next period of education students enter clinics and educational hospitals for two years. During this period, they will also learn practical skills such as history taking and physical examination. Students should then pass the ""pre-internship"" exam to enter the last 1.5 years of education in which medical students function as interns. During this period, medical students participate in all aspects of medical care of the patients and they take night calls. At the end of these 7.5 years students are awarded an M.D degree. M.D doctors can continue their educations through residency and fellowship.


=== Israel ===

There are five university medical schools in Israel: the Technion in Haifa, Ben Gurion University in Be'er Sheva, Tel Aviv University, the Hebrew University in Jerusalem and the Medical school of the Bar-Ilan University in Ramat Gan. These all follow the European 6-year model except Bar-Ilan University which has a four-year program similar to the US system.The Technion Medical School, Ben Gurion University, and Tel Aviv University Sackler Faculty of Medicine offer 4-year MD programs for American Bachelor's graduates who have taken the MCAT, interested in completing rigorous medical education in Israel before returning to the US or Canada.
The entrance requirements of the various schools of medicine are very strict. Israeli students require a high school Baccalaureate average above 100 and psychometric examination grade over 700. The demand for medical education is strong and growing and there is a lack of doctors in Israel.
The degree of Doctor of Medicine (MD) is legally considered to be equivalent to a Masters degree within the Israeli Educational System .


=== Japan ===

In Japan, medical schools are faculties of universities and thus they are undergraduate programs that generally last for six years. Admission is based on an exam taken at the end of high school and an entrance exam at the university itself, which is the most competitive.
Medical students study Liberal Arts and Science for the first 1–2 years, which include Physics, Mathematics, Chemistry, and Foreign Languages together with 2 years long Basic Medicine (Anatomy, Physiology, Pharmacology, Immunology), Clinical Medicine, Public health, and Forensics for the next two years.
Medical students train in the University Hospital for the last two years. Clinical training is a part of the curriculum. Upon completion of the graduation examination, students are awarded an M.D. Medical graduates are titled as Doctor, as are Ph.D. holders. The University does have an MD/PhD program that enables Doctors of Medicine to become Ph.D. holders, as well.
At the end, Medical students take the National Medical License examination and, if they pass it, become a Physician and register in the record in the Ministry of Health, Labour and Welfare. The scope of this exam encompasses every aspect of medicine.


=== Jordan ===
The Bachelor of Medicine and Surgery (MBBS) degree is awarded in Jordan after completion of six years comprising three years of medical sciences and three clinical years. Currently, four state supported universities include a medical school and grant the degree, which are:

Jordan University of Science and Technology in Irbid
University of Jordan in Amman
Mutah University in Al Karak
Hashemite University in Zarqa


=== Kyrgyzstan ===
In Kyrgyzstan, the Government university Kyrgyz State Medical Academy offers 6 years duration undergraduate (bachelor's degree) program whereas the other institutions mostly private such as the International School of Medicine at the International University of Kyrgyzstan offers a five-year medical program, with a requisite for English knowledge, that is recognized by the World Health Organization, the General Medical Council, and UNESCO. The medical school is also partnered with the University of South Florida School of Medicine, the University of Heidelberg (Germany), the Novosibirsk Medical University (Russia), and the University of Sharjah (UAE).
Other medical schools located in Kyrgyzstan include the 5 years duration MD/MBBS undergraduate degree program at International University of Science and Business or Mezhdunarodnyy Universitet Nauki i Biznesa, Kyrgyzstan others are the Asian Medical Institute, Kyrgyzstan and the Medical Institute, Osh State University and so on.


=== Lebanon ===
In Lebanon, there are two programs of medical education followed: the American system (4 years) and the European system (6 years). Programs are offered in English and French.
Admission requirements to the American system requires a candidate to complete a bachelor's degree along with specific pre-medical courses during the undergraduate years, and writing the MCAT examination.
European programs usually requires a candidate to complete 1 year of general science followed by a selection exam by the end of the year.
Schools following the American system (M.D. degree) are:

American University of Beirut: located in Beirut and is the oldest medical school in Lebanon. Training will take place at the American University of Beirut Medical center (AUBMC) in Beirut.
Lebanese American University (LAU): LAU Medical school is located in Byblos and has a 10-year affiliation with Partners Harvard Medical International. Training will take place at the University Medical center - Rizk Hospital (UMC-RH) located in Beirut. It is also affiliated with Clemenceau Medical Center and Rafik Hariri University Hospital.
University of Balamand: located in Koura, north Lebanon. Training will take place at the Saint George University Medical center in Beirut.The language of instruction in all three is English.
Schools following the European system (MBBS degree) are:

Lebanese University: languages of instruction are French and English. Training will take place at the Rafik Hariri University Hospital located in Beirut.
Saint Joseph University: language of instruction is French. Training will take place in Hôtel-Dieu de France hospital located in Beirut.
Beirut Arab University: language of instruction is English. Training will take place at Hammoud Hospital UMC located in Sidon and Rafik Hariri University Hospital located in Beirut.
Holy Spirit University of Kaslik: Located in Jounieh, languages of instruction are French and English. Training will take place at the Centre Hospitalier Universitaire Notre Dame des Secours located in Byblos.


=== Malaysia ===

In Malaysia, getting into medical school is regarded as difficult, due to high fees and a rigorous selection process. Some new medical schools do offer a foundation in medicine course before admission into a full-time medical programme. Most government, and some private medical schools offer M.D., and others mostly offer MBBS degrees.


=== Myanmar ===

As of 2015, there are six medical institutions in Myanmar - UM 1, UM 2, DSMA, UM Mdy, UM Mgy and the newly established UMTG.
Myanmar medical schools are government-funded and require Myanmar citizenship for eligibility. No private medical school exist at this moment. In Myanmar, admission to medical colleges is organized under the Department of Health Science, which is the branch of Ministry of Health and Sport of Myanmar.
A student can join one of the six medical universities of Myanmar if he gets the highest scores in the science combination of the matriculation examination. This exam is highly competitive. Entrance is solely based on this examination and academic records have very minor consequences on an application. The undergraduate program is five years plus one year for work experience in government hospitals. After medical school, Myanmar medical graduates are under contract to spend one year of internship and three years of tenure in rural areas before they are eligible for most residency positions. The degree granted is Bachelor of Medicine and Bachelor of Surgery (M.B.B.S.). Further postgraduate qualifications may be obtained as a Degree (M.Med. Sc) and (Dr.Med.Sc).


=== Nepal ===

In Nepal, medical studies start at undergraduate level. As of 2016, there are twenty institutions recognised by the Nepal Medical Council. There are four main medical bodies in Nepal:
Tribhuvan University (own college: Institute of Medicine Maharajgunj, affiliated colleges: National Medical College, Janaki Medical College, Universal College of Medical Sciences, Gandaki Medical College, Chitwan Medical College, Kist Medical College, Nepal Army Institute of Health Science)
Kathmandu University (own college: Kathmandu University School of Medical Sciences (KUSMS), Affiliated colleges: Manipal College of Medical Sciences, Kathmandu Medical College, Nepal Medical College, Nepalgunj Medical College, College of Medical Sciences, Nobel Medical College, Lumbini Medical College, Birat Medical College, Devdaha Medical College)
B. P. Koirala Institute of Health Sciences.
Patan Academy of Health Sciences


=== New Zealand ===

New Zealand medical programs are undergraduate-entry programs of six years duration. Students are considered for acceptance only after a year of undergraduate basic sciences or, as alternative, following the completion of a bachelor's degree. There are two main medical schools in New Zealand: the University of Auckland and the University of Otago. Each of these has subsidiary medical schools such as Otago's Wellington School of Medicine and Health Sciences and Auckland's Waikato Clinical School.
The first year of the medical degree is the basic sciences year, which comprises study in chemistry, biology, physics, and biochemistry as well as population health and behavioural sciences. The following two years are spent studying human organ systems and pathological processes in more detail as well as professional and communication development. Toward the end of the third year, students begin direct contact with patients in hospital settings.
The clinical years begin fully at the beginning of year 4, where students rotate through various areas of general clinical medicine with rotation times varying from between two and six weeks. Year 5 continues this pattern, focusing more on specialized areas of medicine and surgery. Final medical school exams (exit exams) are actually held at the end of year 5, which is different from most other countries, where final exams are held near the very end of the medical degree. Final exams must be passed before the student is allowed to enter year 6.The final year (Year 6) of medical school is known as the ""Trainee Intern"" year, wherein a student is known as a ""Trainee Intern"" (commonly referred to in the hospitals as a ""T.I.""). Trainee interns repeat most rotations undertaken in years 4 and 5 but at a higher level of involvement and responsibility for patient care. Trainee interns receive a stipend grant from the New Zealand government (not applicable for international students). At the current time, this is $NZ 26,756/year (about $US 18,500). Trainee interns have responsibility under supervision for the care of about one-third the patient workload of a junior doctor. However, all prescriptions and most other orders (e.g., radiology requests and charting of IV fluids) made by trainee interns must be countersigned by a registered doctor.
New Zealand medical schools currently award the degrees of Bachelor of Medicine and Bachelor of Surgery (MBChB).Upon completion of the 6th year, students go on to become ""House Officers,"" also known as ""House Surgeons"" for 1–2 years where they rotate through specialities in the first year and then begin to narrow down to what they'd like to do for speciality training in the second year. After 2 years of house officer work they apply to get into a training scheme and start to train towards the speciality.


=== Pakistan ===

In Pakistan a medical school is more often referred to as a medical college. A medical college is affiliated with a university as a department. There are however several medical universities and medical institutes with their own medical colleges. All medical colleges and universities are regulated by the respective provincial department of health. They however have to be recognized after meeting a set criteria by a central regulatory authority called Pakistan Medical and Dental Council (PMDC) in Islamabad. There are almost equal number of government and private medical colleges and universities, with their number exceeding 50. Admission to a government medical college is highly competitive. Entrance into the medical colleges is based on merit under the guidelines of PMDC. Both the academic performance at the college (high school, grades 11-12) level and an entrance test like MCAT are taken into consideration for the eligibility to enter most of the medical colleges. After successfully completing five years of academic and clinical training in the medical college and affiliated teaching hospitals the graduates are awarded a Bachelor of Medicine and Bachelor of Surgery (MBBS) degree. The graduates are then eligible to apply for a medical license from the PMDC. A house job of one-year duration is mandatory in a teaching hospital after completing five years of academic and clinical training in the medical college.


=== People's Republic of China ===

Medical education is normally a five-year Bachelor degree, including one-year internship (or clinical rotation, during which students are actively involved in patient care) before the final degree is awarded. Clinical specialization usually involves a two- or three-year Master degree. Acceptance is based on the national entrance examination used for all universities. In all over China, the Bachelor of Medicine and Bachelor of Surgery (MBBS) Degree courses have been always taught in Chinese medium. It was ONLY from 2004, that the Chinese Government and the Ministry of Education of China (MoE) allowed few of the universities to impart this medical degree course in English medium.


=== Philippines ===

The Dominicans, under the Spanish Government, established the oldest medical school in the Philippines in 1871, known as the Faculty of Medicine and Surgery (at that time was one with the University of Santo Tomas Faculty of Pharmacy, also considered the oldest pharmacy school in the Philippines) of the Pontifical and Royal University of Santo Tomas in Intramuros, Manila.
Medical education in the Philippines became widespread under the American administration. The Americans, led by the insular government's Secretary of the Interior, Dean Worcester, built the University of the Philippines College of Medicine and Surgery in 1905. By 1909, nursing instruction was also begun at the Philippine Normal School.
At present there are a number of medical schools in the Philippines, notable examples include the University of the Philippines College of Medicine, Our Lady of Fatima University, Far Eastern University – Nicanor Reyes Medical Foundation, Saint Louis University International School of Medicine, De La Salle Medical and Health Sciences Institute, University of Santo Tomas Faculty of Medicine and Surgery, Pamantasan ng Lungsod ng Maynila, UERMMMC College of Medicine, St. Luke's College of Medicine–William H. Quasha Memorial, Cebu Doctors' University,[1] Uv Gullas College Of Medicine]] Cebu Institute of Medicine, Mindanao State University College of Medicine, Cagayan State University College of Medicine in Tuguegarao, Southwestern University - Matias H. Aznar Memorial College of Medicine Inc., West Visayas State University in Iloilo City, University of St. La Salle College of Medicine in Bacolod City, Davao Medical School Foundation in Davao City, Xavier University – Ateneo de Cagayan, Dr. Jose P. Rizal School of Medicine in Cagayan de Oro, Ago medical educational center AMEC-BCCM in Legazpi, Bicol and University of Northern Philippines in Vigan.
In 1994, the Ateneo de Zamboanga University-School of Medicine, then known as Zamboanga Medical School Foundation was established. By 2003, it became the first medical school in the country to offer a double degree program leading to the degrees Doctor of Medicine and Master of Public Health.
Any college graduate may apply for medical school given that they satisfy the requirements set by the institutions. There is also a test known as the National Medical Admission Test or NMAT. Scores are given on a percentile basis and a high ranking is a must to enter the top medical schools in the country.
In most institutions, medical education lasts for four years. Basic subjects are taken up in the first and second years, while clinical sciences are studied in the second and third years. In their fourth year, students rotate in the various hospital departments, spending up to two months each in the fields of internal medicine, surgery, obstetrics and gynecology, and pediatrics, and several weeks in the other specialties. After this, students graduate with a Doctorate in Medicine and apply for postgraduate internship (PGI) in an accredited hospital of their choice. After PGI, the student is eligible to take the Medical Licensure Examination. Passing the examinations confers the right to practice medicine as well as to apply in a Residency Training Program.


=== Republic of China (Taiwan) ===

The medical education in the Republic of China (Taiwan) is usually 7 years (6-year learning plus 1-year internship) in duration, starting right after high schools. 
The first 2 years in the 7-year system is composed of basic sciences and liberal art courses. Doctor-patient classes are emphasized, and most schools require compulsory amounts of volunteer hours.
Clinical sciences are compressed into a two-year program in the 3rd and 4th years. 
The duration of clerkships and internships varies from school to school, but all of them end at the 7th grade.
Taiwan's medical education began in 1897 and is over 100 years old now. Students graduate with a Doctor of Medicine (MD) degree. Starting from the year 2013, incoming students will have a 6+2 year curriculum, in which the first 6 years are oriented similarly as before and the last two years are Post Graduate Years; this change aims to increase primary care capabilities of medical school graduates.


=== Saudi Arabia ===

In Saudi Arabia medical education is free for all Saudi citizens. A medical student must pass an entrance examination and complete a 1-year pre-medical course containing some basic medical subjects including: Biology, Organic Chemistry, Inorganic Chemistry, Physics, Medical Biostatistics, and English for medical uses. Passing this year is commonly considered as the most challenging. It offers an MBBS (Bachelor of Medicine, Bachelor of Surgery) degree. after one pre-medical course, five medical years and one training year.
By 2010, there are 24 medical schools in KSA- 21 nonprofit and three private medical schools.
The last college opened was Sulaiman AlRajhi Colleges with its partnership with Maastricht in the Netherlands.


=== Singapore ===
Currently, there are 3 medical schools in Singapore. 2 of them offers undergraduate (5 years degree) and the other offers postgraduate (4 years) entry.

Yong Loo Lin School of Medicine (undergraduate)
Duke–NUS Medical School (postgraduate)
Lee Kong Chian School of Medicine (undergraduate)


=== South Korea ===

Currently, there are 41 medical schools in South Korea. Medical programs in South Korea used to be direct-entry programs such as in the UK, taking six years to complete. However, most universities were going through a transition from direct-entry to a 4+4 year system, such as those found in the United States and Canada. Recently, about half of the universities are converting back to six years direct-entry program by 2015, and almost all of the universities are converting it back by 2017.


=== Sri Lanka ===

There are eight medical schools in Sri Lanka that teach evidence based (sometimes called ""western"") medicine. The oldest medical school is the Faculty of Medicine, University of Colombo, established as Ceylon Medical School in 1870. There are medical faculties in Peradeniya, Kelaniya, Sri Jayawardanepura, Galle, Batticaloa, Jaffna and Rajarata as well.
Kelaniya Medical Faculty initially started as the North Colombo Medical College (NCMC), a private medical institution. It was one of the earliest private higher educational institutions (1980). Heavy resistance by the medical professionals, university students and other professionals led to its nationalization and to its renaming as the Kelaniya Medical Faculty.
Faculty of Health-Care Sciences is the faculty that offers MBBS together with other para-medical courses. It is an entity of the Eastern University - Sri Lanka.
The Open International University for Complementary Medicines (OIUCM), established under World Health Organization teaches various field of Medicines and related program of Environmental Sciences. despite having basic problems of training programme.
Postgraduate Institute of Medicine (PGIM) is the only institution that provides specialist training of medical doctors.
The Institute of Indigenous Medicine of the University of Colombo, the Gampaha Wickramarachchi Ayurvedhic Medicine Institute of the University of Kelaniya and the Faculty of Siddha Medicine, University of Jaffna teach Ayurvedha/ Unani / Siddha Medicine.


=== Thailand ===

The first medical school in Thailand was established back in 1890 at Siriraj Hospital, which is now become Faculty of Medicine Siriraj Hospital, Mahidol University. Currently, there are 26 medical programs offered nationwide. Most of the Thai medical schools are government-funded and require Thai citizenship for eligibility. Two private medical schools exist at the moment. Some Thais choose to attend private medical schools or attend a medical school in a foreign country due to relatively few openings and extremely competitive entrance examination scores required for enrollment in public medical schools.
The Thai medical education is a six-year system, consisting of 1 year in basic-science, 2 years in pre-clinical training, and 3 years for clinical training. Upon graduation, all medical students must pass national medical licensing examinations and a university-based comprehensive test. After medical school, newly graduated doctors are under contract to spend a year of internship and 2 years of tenure in rural areas before they are eligible for any other residency positions or specialized training, mostly in locations outside Bangkok.
Students will receive Doctor of Medicine (MD) degree at the end of the process. This degree is equivalent to a master's degree in Thailand.


== Europe ==


=== Albania ===

There are four Medical Schools (Fakultete te Mjeksise) in Albania:

University of Tirana Faculty of Medicine
Kristal University Faculty of Medicine
WORLDWIDE University Faculty of Medicine
Zonja e Keshillit te MireThese medical schools are usually affiliated with regional hospitals. The course of study lasts 6 years. Students are conferred degree Doctor of Medicine (M.D.) upon graduation.


=== Austria ===
Medical University of Vienna
Sigmund Freud University Vienna, Medical School
Medical University of Graz
Medical University of Innsbruck
Paracelsus Medical University, Salzburg
The Faculty of Medicine at the Johannes Kepler University Linz
Karl Landsteiner University of Health Sciences (Karl Landsteiner Privatuniversität für Gesundheitswissenschaften), Krems


=== Belarus ===

There are 4 Medical Schools (Medical Universities) in Belarus:

Belarusian State Medical University, Minsk (belarusian: Беларускі дзяржаўны медыцынскі ўніверсітэт; Russian: Белорусский государственный медицинский университет) - which contains the famous Bosef Institute for AIDS Research.
Gomel State Medical University (belarusian: Гомельскі дзяржаўны медыцынскі ўніверсітэт; Russian: Гомельский государственный медицинский университет)
Grodno State Medical University (belarusian: Гродненскі дзяржаўны медыцынскі ўніверсітэт; Russian: Гродненский государственный медицинский университет)
Vitebsk State Order of Peoples' Friendship Medical University (belarusian: Віцебскі дзяржаўны медыцынскі ўніверсітэт; Russian: Витебский государственный ордена Дружбы народов медицинский университет)


=== Bosnia and Herzegovina ===

There are five Medical Schools (Medicinski Fakultet) in Bosnia and Herzegovina:

University of Banja Luka School of Medicine
University of Sarajevo Medical School
University of Tuzla Medical School
University of East Sarajevo Medical School (Foca)
University of Mostar Medical SchoolThese medical schools are usually affiliated with regional hospitals.
The course of study lasts 6 years or 12 semesters. Students are conferred degree Doctor of Medicine (M.D.) upon graduation.

AdmissionsEntry to BH Medical Schools are very competitive due to limited places imposed by the government quota.
Students are required to complete Secondary School Leaving Diploma (Gimnazija-Gymnasium (school) or Medicinska skola matura/svedocanstvo/svjedodzba).
Entrance examination is usually held in June/July. Combined score of Secondary School Diploma assessment (on scale 1–5, with 2 minimum passing grade and 5 maximum grade) and entrance examination is taken into consideration. Usually, 5 in Chemistry, Biology, Mathematics, and Physics are required for entry to medicine.

CurriculumCourse structure is more traditional and divided in pre-clinical (year 1-3) /clinical part (year 3-6) and subject-based.
Practical examinations are held throughout the degree (Anatomy, Biochemistry, Pathology, Physiology practicals etc.). Dissection is part of all medical curricula in Bosnian and Herz. Medical Schools.


=== Bulgaria ===

In Bulgaria, a medical school is a type of college or a faculty of a university. The medium of instruction is officially in Bulgarian. A six- to one-year course in Bulgarian language is required prior to admittance to the medical program. For European candidates, an exam in Biology and Chemistry in Bulgarian is also required. While a number of Bulgarian medical schools have now started offering medical programmes in English, Bulgarian is still required during the clinical years.Students join medical school after completing high-school. Admission offers are made by individual medical schools. Bulgarian applicants have to pass entrance examinations in the subjects of Biology and Chemistry. The competitive result of every candidate is the based on their marks these exams plus their secondary-school certificate marks in the same subjects. Those applicants with the highest results achieved are classified for admission.
The course of study is offered as a six-year program. The first 2 years are pre-clinical, the next 3 years are clinical training and the sixth year is the internship year, during which students work under supervision at the hospitals. During the sixth year, students have to appear for 'state exams' in the 5 major subjects of Internal Medicine, Surgery, Gynaecology and Obstetrics, Social Medicine, and Pediatrics. Upon successful completion of the six years of study and the state exams the degree of 'Physician' is conferred.
For specialization, graduates have to appear for written tests and interviews to obtain a place in a specialization program. For specialization in general medicine, general practice lasts three years, cardiology lasts four years, internal medicine lasts five years, and general surgery lasts five years.


=== Croatia ===

In Croatia, there are four out of seven universities that offer a medical degree, the University of Zagreb (offers medical studies in English), University of Rijeka (offers medical studies in English), University of Split (also offers medical studies in English), and the University of Osijek. The Medical schools are a faculties of those four universities. Medical students enroll into medical school after finishing secondary education, typically after a Gymnasium, or after a five-year nursing school, or any other high school lasting four years. During the application process, their high school grades, and the grades of their matriculation exam at the end of high school (Matura) and the score at the obligatory admission exam are taken into account, and the best students are enrolled.
The course of study lasts 6 years or 12 semesters. During the first 3 years, students are engaged in pre-clinical courses (Anatomy, Histology, Chemistry, Physics, Cell Biology, Genetics, Physiology, Biochemistry, Immunology, Pathologic Physiology And Anatomy, Pharmacology, Microbiology, etc.). Contact with patients begins at the third year. The remaining 3 years are composed of rotations at various departments, such as Internal Medicine, Neurology, Radiology, Dermatology, Psychiatry, Surgery, Pediatrics, Gynecology and Obstetrics, Anesthesiology, and others. During each academic year, students also enroll into two or three elective courses. After each rotation, the students take a total of about 60 exams. In the end, the students must pass a final multiple-choice exam comprising questions about clinical courses, after which they finally gain an MD, and the title of Doctor of Medicine, which they put after their name. Now the doctors must complete a one-year, supervised, paid internship in a hospital of their choice, after which they take the state (license) examination, which is an eight-part oral examination containing the eight most important clinical branches. After that, the doctors are eligible to practice medicine as general practitioners. Residencies are offered at various hospitals throughout Croatia, and at numerous medical specialities.


=== Czech Republic ===
Medical study in Czech Republic has a long tradition dating from the 14th century, with the first medical school starting at the First Faculty of Medicine, Charles University in Prague in 1348, making it the 11th oldest in the world and highly prestigious. Students from all over the world are attracted to study medicine in Czech Republic because of the high standards of education provided. Most Czech Universities offer a 6-year General Medicine program in Czech and in English separately for international students.
The admission to medical studies in Czech Republic is based on the performance in high school diploma (Biology, Chemistry and Physics), English proficiency and performance in the entrance exams. Entrance examination is conducted at the university and by some representative offices abroad. The entrance exams are competitive due to students from all over the world fighting to secure a place. After the entrance exams, successful candidates are further scrutinised by conducting interviews.
Most of the international students studying medicine in the Czech Republic originate from USA, Canada, UK, Norway, Sweden, Germany, Israel, Malaysia and the Middle East.
Most faculties of Medicine in Czech Republic have been approved by the U.S. Department of Education for participation in Federal Student Financial Aid Programs and is listed in the Directory of Postsecondary Institutions published by the U.S. Department of Education. The qualifications are also approved in Canada by the Canadian Ministry of Education and Training, and in the UK by the General Medical Council. Most medical schools are globally recognised and carry a good reputation.
There are nine public government owned medical schools in the Czech Republic:

First Faculty of Medicine, Charles University in Prague
Second Faculty of Medicine, Charles University in Prague
Third Faculty of Medicine, Charles University in Prague
Faculty of Medicine in Plzeň, Charles University in Prague
Faculty of Medicine in Hradec Králové, Charles University in Prague
Faculty of Medicine, Masaryk University
Faculty of Medicine and Dentistry, Palacký University Olomouc
Faculty of Medicine, University of OstravaThere is one military medical school, Faculty of Military Health Sciences, University of Defence.


=== Denmark ===

In Denmark, basic medical education is given in four universities: University of Copenhagen, Aarhus University, University of Southern Denmark and Aalborg University. The study consists of three years of bachelor and three years of candidate studies, roughly reflecting the preclinical and clinical fields. After six years, the title of Candidate of Medicine (M.D.) is attained, and after swearing the Danish medical pledge upon graduation, a text from 1815 inspired by the Hippocratic Oath, the medical license (Danish: autorisation) is issued by the Department of Health.Medical school is usually followed by a year of residency called clinical basic education (Danish: klinisk basisuddannelse or KBU) which upon completion grants the right to practice medicine without supervision. After this, the doctor can pursue one of 38 specialisations which must start within five years after completing the clinical basic education. If the MD pursues a research or university career, sometimes he or she will skip the clinical basic education and remain a basic MD without the right to practice medicine independently.
The Danish word for a licensed physician is læge. The word 'doktor' for a physician is used only in demotic speech, but is by some people erroneously assumed to be a title prefix of all physicians. The title of doctor (dr.med. or in full doctor medicinæ) is not equivalent to an M.D. in the English language, but reserved for candidates of medicine who have attained a higher doctorate. The Danish/Norwegian dr.med. title is a degree above the PhD and above the German Dr.med.


=== Finland ===

In Finland, basic medical education is given in five universities: Helsinki, Kuopio, Oulu, Tampere and Turku. Admission is regulated by an entrance examination. Studies involve an initial two-year preclinical period of mainly theoretical courses in anatomy, biochemistry, pharmacology etc. However, students have contact with patients from the beginning of their studies. The preclinical period is followed by a four-year clinical period, when students participate in the work of various hospitals and health care centres, learning necessary medical skills. Some Finnish universities have integrated clinical and preclinical subjects along the six-year course, diverging from the traditional program. A problem-based learning method is widely used, and inclusion of clinical cases in various courses and preclinical subjects is becoming common. All medical schools have research programs for students who wish to undertake scientific work. The duration of basic medical education is six years and the course leads to the degree of Licentiate of Medicine.


=== France ===

Medical studies in France are organized as follow:   

Right after graduating from high school with a baccalaureat, any student can register at a university of medicine (there are about 30 of them throughout the country). At the end of first year, an internal ranking examination takes place in each of these universities in order to implement the numerus clausus.
First year consists mainly of theoretical classes such as biophysics and biochemistry, anatomy, ethics or histology. Passing first year is commonly considered as challenging and requires hard and continuous work. Each student can only try twice. For example, the Université René Descartes welcomes about 2000 students in first year and only 300 after numerus clausus.
The second and third year are usually mainly quite theoretical although the teachings are often accompanied by placements in the field (e.g. internships as nurses or in the emergency room, depending on the university).
During 4th, 5th and 6th years, medical students get a special status called 'Externe' (In some universities, such as Pierre et Marie Curie, the 'Externe' status is given starting in the 3rd year). They work as interns every morning at the hospital plus a few night shifts a month and study in the afternoon. Each internship lasts between 3 and 4 months and takes place in a different department. Med students get 5 weeks off a year.
At the end of sixth year, they need to pass a national ranking exam, which will determine their specialty. Indeed, the first student gets to choose first, then the second, etcetera. Usually students work pretty hard during 5th and 6th years in order to train properly for the national ranking exam. During these years, actual practice at the hospital and some theoretical courses are meant to balance the training.
Such externs' average wage stands between 100 and 300 euros a month.
After that ranking exams, students can start as residents in the specialty they have been able to pick. That is the point from which they also start getting paid.
Towards the end of the medical program, French medical students are provided with more responsibilities and are required to defend a thesis. At the conclusion of the thesis defense, French medical students receive a State Diploma of Doctor of Medicine (MD) or ""Diplôme d'Etat de Doctorat en Medecine"" for general medicine. For those who are in speciality training will also receive a Diploma of Specialized Studies (DES= Diplôme d'Etudes Specialisees) to mark their specialties. Some students may also receive a Diploma of Specialized Complementary Studies (DESC = Diplôme d'Etudes Specialisees Complementaires).


=== Germany ===

In Germany, admission to medical schools is currently administered jointly by the Stiftung für Hochschulzulassung (SfH), a centralized federal organization, and the universities themselves. The most important criterion for admission is the Numerus clausus, the final GPA scored by the applicant on the Abitur (highest secondary school diploma). However, in light of the recent gain in influence of medical schools in regards to applicant selection, additional criteria are being used to select students for admission. These criteria vary among medical faculties and the final Abitur GPA is always a core indicator and strongly influences admission. Admission remains highly competitive. A very small number of slots per semester are reserved for selected applicants which already hold a university degree (Zweitstudium) and for medical officer candidates (Sanitätsoffizieranwärter).
The first two years of medical school consist of the so-called pre-clinical classes. During this time, the students are instructed in the basic sciences (e.g. physics, chemistry, biology, anatomy, physiology, biochemistry, etc.) and must pass a federal medical exam (Erster Abschnitt der ärztlichen Prüfung), administered nationally. Upon completion, the students advance to the clinical stage, where they receive three years of training and education in the clinical subjects (e.g., internal medicine, surgery, obstetrics and gynecology, pediatrics, pharmacology, pathology, etc.). After these three years, they have to pass the second federal medical exam (Zweiter Abschnitt der ärztlichen Prüfung) before continuing with the sixth and final year. The last year of medical school consists of the so-called ""practical year"" (Praktisches Jahr, PJ). Students are required to spend three four-month clerkships, two of them in a hospital (internal medicine and surgery) as well as one elective, which can be one of the other clinical subjects (e. g. family medicine, anesthesiology, neurology, pediatrics, radiology etc.).
After at least six years of medical school, the students graduate with a final federal medical exam (Dritter Abschnitt der ärztlichen Prüfung). Graduates receive the license to practice medicine or dentistry and the professional title of physician (Arzt) or dentist (Zahnarzt). The academic degrees Doctor of Medicine (Dr. med.) and Doctor of dental Medicine (Dr. med. dent.) are awarded if the graduate has, in addition, successfully completed a scientific study and dissertation. It is a doctoral degree and therefore different from the MD or DDS degrees in the U.S., which as professional degrees are awarded after passing the final exams and do not require additional scientific work. Many medical students opt to perform their thesis during their studies at medical school, but only a fraction of them is able to finish the dissertation-process during their studies. The requirements for getting a Dr. med. degree across the board are not as hard as for the doctor in natural science (Dr. rer. nat.). Therefore, many critics advocate to adopt a system similar to that of the Anglo-Saxon countries with an MD as a professional degree and a PhD showing additional scientific qualification. 
If physicians wish to open up a doctor's office, they are required to further complete residency in order to fulfill the federal requirements of becoming Facharzt (specialized in a certain field of medicine like internal medicine, surgery, pediatrics etc.). Oral and maxillofacial surgeons must complete both studies, medicine and dentistry, then afterwards specializing another 5 years.
There are 36 medical faculties in Germany.


=== Greece ===
There are seven medical schools in Greece. The most prominent one of them is the University of Athens Medical School. The rest of them are in Patras, Thessaloniki, Ioannina, Larissa, Heraklion, and Alexandroupoli. The duration of the studies in Greece is 6 years.


=== Hungary ===
Hungary has four medical schools, in Budapest, Debrecen, Pécs and Szeged. Medical school takes six years to complete, of which the last year is a practical year. Students receive the degree dr. med. univ. or dr. for short, equivalent to the M.D. degree upon graduation. All Hungarian medical schools have programs fully taught in English.


=== Iceland ===
In Iceland, admission to medical school requires passing an organized test, controlled by the University of Iceland, which anyone with a gymnasium degree can take. Only the top 48 scores on the exam are granted admission each year. Medical school in Iceland takes 6 years to complete. Students receive a cand.med. degree upon graduation. Following this, Icelandic regulations require 12 months of clinical internship before granting a full medical license. This internship consists of internal medicine (4 months), surgery (2 months), family medicine (3 months) and a three-month elective period. Upon receiving a license to practice, a physician can start specialist training, in Iceland or abroad.


=== Ireland ===

There are six medical schools in Ireland. They are at Trinity College Dublin, the Royal College of Surgeons in Ireland, University College Dublin, University College Cork, University of Limerick and the National University of Ireland, Galway (the National University of Ireland is the degree-awarding institution for all except the University of Limerick and Trinity College). Training lasts four, five or six years, with the last two years in the affiliated teaching hospitals (UCD - St. Vincents University Hospital, Mater Misericordiae University Hospital) (Trinity - St. James's Hospital, Tallaght University Hospital) (UCC - Cork University Hospital) (RCSI - Beaumont Hospital, Connolly Hospital, University Hospital Waterford).
For Programmes that are six years in length, entry is based on secondary school qualifications. Programmes that are four years in length require previous university degrees. The Royal College of Surgeons in Ireland and the University of Limerick were the first medical institutions to offer Graduate Entry Medicine of four years in duration in the Ireland. This is now also offered in University College Dublin and University College Cork. The National University of Ireland, Galway also launched a graduate entry programme in 2010.
Medical education is regulated by the Irish Medical Council, the statutory body that is also responsible for maintaining a register of medical practitioners. After graduation with the degrees of BM BS (Bachelor of Medicine and Bachelor of Surgery) or MB BCh BAO (Medicinae Baccalaureus, Baccalaureus in Chirurgia, Baccalaureus in Arte Obstetricia), a doctor is required to spend one year as an intern under supervision before full registration is permitted. Graduates of the Royal College of Surgeons in Ireland also receive the traditional ""Licenciate of the Royal Colleges of Surgeons and Physicians in Ireland"" (LRCP&SI), which was awarded before the Royal College of Surgeons in Ireland became an Affiliate of the National University of Ireland and thus was allowed grant degrees, under the Medical Practitioners Act (1978).


=== Italy ===
In Italy, the contents of the medical school admission test is decided each year by the Ministry of Education, Universities and Research (MIUR) and consists of sixty questions divided in five categories: logics and ""general education"" (""cultura generale""), mathematics, physics, chemistry, and biology. Results are expressed in a national ranking.
As a general rule, all state-run medical schools in the country administer it on the same day, whereas all privately run medical schools administer it on another day, so that a candidate may take the test once for state-run schools and once for a private school of his or her choice, but no more.
Some universities in Italy provide an international degree course in medicine taught entirely in English for both Italian and non-Italian students. A number of these medical schools are at public universities, and have relatively low tuition fees compared to the English-speaking world, because the cost of the medical education is subsidized by the state for both Italian and non-Italian students. These public medical schools include the International Medical School at the University of Milan, the University of Pavia, Rome ""La Sapienza"", Rome ""Tor Vergata"", Naples Federico II, the Second University of Naples, the University of Messina and the University of Bari. These universities require applicants to rank highly on the International Medical Admissions Test. Italy also has private or parochial, more expensive English-language medical schools such as Vita-Salute San Raffaele University, Università Campus Bio-Medico in Rome and Humanitas University in Milan, and at the Università Cattolica del Sacro Cuore Rome campus.
Medicine is one of the university faculties implementing numerus clausus (""numero chiuso""): the overall number of medical students admitted every year is constant, as each medical school is assigned a maximum number of new admission per year by MIUR.
Medical school lasts 6 years (12 semesters). Traditionally, the first three years are devoted to ""biological"" subjects (physics, chemistry, biology, biochemistry, genetics, anatomy, physiology, immunology, pathophysiology, microbiology, and usually English language courses), whereas the later three years are devoted to ""clinical"" subjects. However, most schools are increasingly devoting the second semester of the third year to clinical subjects and earlier patient contact. In most schools, there are about 36 exams over the 6-year cycle, as well as a number of compulsory rotations and elective activities.
At the end of the cycle, students have to discuss a final thesis before a board of professors; the subject of this thesis may be a review of academic literature or an experimental work, and usually takes more than a year to complete, with most students beginning an internato (internship) in the subject of their choice in their fifth or sixth year. The title awarded at the end of the discussion ceremony is that of ""Dottore Magistrale"", styled in English as a Doctor of Medicine, which in accordance with the Bologna process is comparable with a master's degree qualification or a US MD.
After graduating, new doctors must complete a three-month, unpaid, supervised tirocinio post-laurea (""post-degree placement"") consisting of two months in their university hospital (one month in a medical service and one in a surgical service) as well as one month shadowing a general practitioner. After getting a statement of successful completion of each month from their supervisors, new doctors take the esame di stato (""state exame"") to obtain full license to practise medicine. They will then have to register with one of the branches of the Ordine dei Medici (""Order of Physicians""), which are based in each of the Provinces of Italy.
Registration makes new doctors legally able to practice medicine without supervision. They will then have to choose between various career paths, each usually requiring a specific admission exam: most either choose to train as general practitioner (a 3-year course run by each Region, including both general practice and rotation at non-university hospitals), or to enter a Scuola di Specializzazione (""specialty school"") at a university hospital 4-year or 5-year course.


=== Lithuania ===
Lithuania has two medical schools, in Kaunas and Vilnius. Studies are of six years, of which the last year is a practical year. All Lithuanian medical schools have programs in English.


=== Netherlands and Belgium ===

In the Netherlands and Belgium, medical students receive 6 years of university education prior to their graduation.
In the Netherlands, students used to receive four years of preclinical training, followed by two years of clinical training (co-assistentschappen, or co-schappen for short) in hospitals. However, for a number of medical schools this has recently changed to three years of preclinical training, followed by three years of clinical training. At least one medical faculty, that of the Utrecht University, clinical training already begins in the third year of medical school. After 6 years, students graduate as basisartsen (comparable to Doctors of Medicine). As a result of the Bologna process, medical students in the Netherlands now receive a bachelor's degree after three years in medical school and a master's degree upon graduation. Prospective students can apply for medical education directly after finishing the highest level of secondary school, vwo; previous undergraduate education is not a precondition for admittance.
The Belgian medical education is much more based on theoretical knowledge than the Dutch system. In the first 3 years, which are very theoretical and lead to a university bachelor degree, general scientific courses are taken such as chemistry, biophysics, physiology, biostatistics, anatomy, virology, etc. To enter the bachelor course in Flanders, prospective students have to pass an exam, as a result of the numerus clausus. In the French-speaking part of Belgium, only the best students that pass the first year of the bachelor course in medicine are admitted to the second and third year.
After the bachelor courses, students are allowed to enter the 'master in medicine' courses, which consist of 4 years of theoretical and clinical study. In general, the first 2 master years are very theoretical and teach the students in human pathology, diseases, pharmacology. The third year is a year full of internships in a wide range of specialities in different clinics. The seventh, final year serves as a kind of 'pre-specialization' year in which the students are specifically trained in the specialty they wish to pursue after medical school. This contrasts with the Dutch approach, in which graduates are literally 'basic doctors' (basisartsen) who have yet to decide on a specialty.


=== Norway ===

Medical education in Norway begins with a six- to six-and-a-half-year undergraduate university program. Admission requires a very high GPA from secondary school - medicine consistently ranks as the most difficult university programme to be admitted to in Norway. Furthermore, certain high school subjects are required for admission (chemistry, mathematics and physics). The first two years consists almost wholly of preclinical science subjects, followed by integration of clinical training the remaining four years in a spiral approach. Upon completion, students are awarded a candidatus/candidata medicinae (cand. med.) degree (corresponding to e.g. and MD in the USA) and medical license. Those completing a research programme (Forskerlinje) get this added to their degree. Following this, a minimum of 18 months of internship (turnustjeneste) is required before applying on a specialist training in Norway. The internship consist of 6 months of internal medicine, 6 months of surgery and 6 months family medicine. There are currently 43 recognized medical specialties in Norway. Optionally it is possible to pursue the title of doctor medicinae (dr. med.), by publishing multiple research papers through a university research group followed by completing a dissertation.


=== Poland ===


=== Portugal ===
In Portugal, the medical course is a postgraduate degree, so a prior graduation from an undergraduate course (3 to 4 years) in areas involving health such as biology, nursing and  pharmaceutical sciences, among others, is necessary for applying for the Master's in Medicine (3 years). Most students (~80%) enter Medical School by joining an Integrated Master's degreee in Medicine, this course is composed by an undergraduate course in ""Basic Health Sciences"" (""Licenciatura em Ciencias Basicas da Saude"") (3 years) that involves chemistry, general biology and health and, after that, the master's (3 years) which is the clinical course. Access to the Integrated Master's Course in Medicine is gained through National Exams in Biology, Chemistry and Mathematics. After obtaining their Master's degree, students must register with Order of Medics (the national medical association) and take a final examination: the students with the best grades are accepted into the Medical Speciality of their choice. The rest can either wait another year and retake the exam, do less specialized work or seek a residency program abroad.  After the exam, all students must complete a one year general internship program that enables them to practice medicine autonomously.
This is the list of all Medical Schools in Portugal:

Universidade do Minho, Braga
Universidade do Algarve, Faro
Faculdade de Medicina da Universidade de Coimbra, Coimbra
Faculdade de Ciências da Saúde, Covilhã
Faculdade de Medicina da Universidade de Lisboa, Lisboa
Faculdade de Ciências Médicas da Universidade Nova de Lisboa, Lisboa
Faculdade de Medicina da Universidade do Porto, Porto
Abel Salazar Biomedical Sciences Institute, Porto


=== Romania ===

In Romania, medical school is a department of a medical university, which typically includes Dentistry and Pharmacy departments as well. The name facultate is used for departments in their universities too, but the Medicine departments distinguish themselves by the length of studies (6 years), which grants to graduates a status equivalent to that of a Master in Science. The Medicine departments are also marked by reduced flexibility - in theory, a student in a regular university can take courses from different departments, like Chemistry and Geography (although it usually does not happen, majors being clearly defined), while the medical universities do not have any extra offers for their students, due to their specialization. Admission to medical faculty is usually awarded by passing a Human Biology, Organic Chemistry and/or Physics test. The program lasts 6 years, with first 2 years being preclinical and last 4 years being mostly clinical. After these six years, one has to take the national licence exam (which consists of mostly clinically oriented questions, but some questions also deal with basic sciences) and has to write a thesis in any field he/she studied. Final award is Doctor-Medic (titlu onorific) (shortened Dr.), which is not an academic degree (similar to Germany). All graduates have to go through residency and specialization exams after that in order to practice, although older graduates had different requirements and training (e.g., clinical rotations similar to sub-internship) and might still be able to practice Family Medicine / General Medicine.


=== Russia ===

Medical schools in Russia offer a 6-year curriculum leading to award Doctor of Medicine (MD) ""Physician"".
Russian medical authorities reluctantly agrees with inclusion in list of international medical schools FAIMER-IMED. FAIMER can't include medical schools without cooperation from Russia. For example, Orel State University Medical Institute isn't included in this list.


=== Sweden ===

Medical education in Sweden begins with a five-and-a-half-year undergraduate university program leading to the degree ""Master of Science in Medicine"" (Swedish: Läkarexamen). Following this, the National Board of Health and Welfare requires a minimum of 18 months of clinical internship (Swedish: Allmäntjänstgöring) before granting a medical license to be fully qualified as Medical Doctor (MD).This internship consists of surgery (3–6 months), internal medicine (3–6 months), psychiatry (three months) and family medicine (six months). Upon receiving a license to practice, a physician is able to apply for a post to start specialist training. There are currently 52 recognized medical specialties in Sweden. The specialist training has a duration of minimum five years, which upon completion grants formal qualification as a specialist.


=== Switzerland ===

There are five universities granting medical degrees in Switzerland (plus the University of Fribourg and the ETH Zurich that provide the bachelor but not the master in medicine) and five university hospitals:

Faculty of Medicine of the University of Basel (see also University Hospital of Basel)
Faculty of Medicine of the University of Bern (see also University Hospital of Bern)
Faculty of Medicine of the University of Geneva (see also University Hospital of Geneva)
Faculty of Biology and Medicine of the University of Lausanne (see also University Hospital of Lausanne)
Faculty of Medicine of the University of Zürich (see also University Hospital of Zürich)
Faculty of Health Sciences and Technology of the ETH Zurich


=== Turkey ===
All high school graduates who wish to pursue further education are required to take an MCQ exam. The exam covers most of the high school and secondary school curricula.
A student who scores high enough gets a place in a faculty of his/her desire. Entrance to medical schools is extremely competitive, only very top scoring students are accepted to medical schools.
Medical education takes six years, first three years being Pre-clinical years and the latter three being Clinical years. Right after graduation, graduates can either work as GPs or take another exam called TUS (Medical Specialization Examination) to do residency in a particular department of a particular hospital.
Most of the medical schools in Turkey are state schools but the number of private schools is on the rise. MCQ exam (YGS and LYS) scores required to be accepted to private medical schools are lower compared to their public counterparts. The language of instruction is, in general, Turkish, but few universities also offer schools with English as the language of instruction. This makes Turkey a popular place to study medicine for students from nearby areas like the Balkans, the Middle East, and to a lesser extent North Africa.


=== Ukraine ===
Medical degrees in Ukraine were offered only in institutions called medical universities, which are separate from traditional universities. However, some medical schools are now associated with classical universities. These include:

Ternopil State Medical University
Danylo Halytsky Lviv National Medical University
Kharkiv National Medical University
Dnipropetrovsk State Medical Academy
Ivano-Frankivsk National Medical University
Bukovinian State Medical University
Zaporizhia State Medical University
Ukrainian Medical Stomatological Academy
Donetsk National Medical University
Bogomolets National Medical University Of Ukraine
Crimea State Medical University
Luhansk State Medical University
Odessa National Medical University
Vinnytsia National Pirogov Memorial Medical University
School of Medicine of V N Karazin Kharkiv National University
Medical Faculty of Sumy State University
Medical Faculty of Uzhgorod University
Medical Faculty of Dnipropetrovsk National University
Kyiv Medical University of UAFM


=== United Kingdom ===

Due to the UK code for higher education, first degrees in medicine comprise an integrated programme of study and professional practice spanning several levels. While the final outcomes of the qualifications themselves typically meet the Expectations of the descriptor for higher education qualification at level 7 (the UK master's degree). These degrees may retain, for historical reasons, ""Bachelor of Medicine, Bachelor of Surgery"" and are abbreviated to MBChB or MBBS.There are currently 32 institutions that offer medical degrees in the United Kingdom. Completion of a medical degree in the UK results in the award of the degrees of Bachelor of Medicine and Bachelor of Surgery. Admission requirements to the schools varies; most insist on solid A-Levels/Highers, a good performance in an aptitude test such as the UKCAT, the BMAT or the GAMSAT, and usually an interview. As of 2008 the UK has approximately 8000 places for medical students.Methods of education range from courses that offer a problem-based learning approach (alongside lectures etc.), and others having a more traditional pre-clinical/clinical structure. Others combine several approaches in an integrated approach.

Following qualification, UK doctors enter a generalised two-year, competency-based ""foundation programme"", gaining full GMC (General Medical Council) registration at the end of foundation year one, and applying for specialist training (in medicine, surgery, general practice etc.) after foundation year two.
Many medical schools offer intercalated degree programmes to allow students to focus on an area of research outside their medical degree for a year.
Some medical schools offer graduate entry programmes, which are four years long. The name refers to the fact that students on these courses already have a degree in another subject (i.e. they are graduates). Due to the shorter length of the course, the timetable of these degrees are more intense and the holidays are shorter, compared to students on the 5-year course. In terms of entrance requirements, the 4-year degree restricts entry to those who already hold a first degree, and have previously worked in an area of healthcare. The first degree doesn't necessarily have to be a BSc degree (this is the criteria for some of the medical schools), whereas other medical schools specify that the prior degree has to be in a science subject. Competition for this course is fierce, with students having to also sit an entrance exam prior to being considered for an interview.
Medical schools typically admit more students into undergraduate programmes than into graduate entry programmes.


== Medical students ==

A person accepted into a medical school and enrolled in an educational program in medicine, with the goal of becoming a medical doctor, is referred to as a medical student. Medical students are generally considered to be at the earliest stage of the medical career pathway. In some locations they are required to be registered with a government body.
Medical students typically engage in both basic science and practical clinical coursework during their tenure in medical school. Course structure and length vary greatly among countries (see above).


=== Bullying ===

Medical students, perhaps being vulnerable because of their relatively low status in health care settings, commonly experience verbal abuse, humiliation and harassment (nonsexual or sexual). Discrimination based on gender and race is less common.


=== Burnout and depression ===

A meta-analysis in the American journal JAMA suggested depressive symptoms in 24% to 29% of all medical students and 25% to 33% of all resident physicians. ""Burnout"" in medical students, in addition, seems to be associated with increased likelihood of subsequent suicidal ideation, although whether the concept of burnout is a valid way to measure the effects of chronic occupational stress exposure in physicians and physician trainees has been questioned.It has been estimated by a US study that approximately 14% of medical students have symptoms of moderate to severe depression, and roughly 5% have suicidal thoughts at some point during training. 
Internationally depression as well as distress in medical school is widely studied and gained more attention over the years. A recent study among German medical students at international universities displayed the significantly higher risk of depression symptoms being 2.4 times higher than the average population. 23.5% of these German medical students showed clinically relevant depressive symptoms.  In a South Korean study, 40% of medical students appeared to have depression. Medical students with more severe depression also may be less likely to seek treatment, largely from fear that faculty members would view them as being unable to handle their responsibilities. Students who feel that they lack a social support system are 10 times more likely to be depressed compared with students that consider themselves to have good social support.Approximately 10% experience suicidal ideation during medical school.Lemon and Stone hypothesised in what has become termed the 'Lemon Stone Hypothesis', that medical students from lower socioeconomic backgrounds increase in prevalence during times of national economic adversity. Their hypothesis was a formulation of Becker Maimans' health belief model and Adaption theory. This hypothesis has, to some extent, been supported by a series of surveys.


== See also ==
American Association of Colleges of Osteopathic Medicine (AACOM)
American Medical College Application Service (AMCAS)
American Association of Colleges of Podiatric Medicine (AACPM)
Bimaristan (historical medical schools)
Flexner Report
Graduate Australian Medical Schools Admissions Test (GAMSAT) [UK, Australia, Ireland]
International medical graduate
List of medical schools
Medical College Admission Test (MCAT) [United States, Canada]
Society of General Internal Medicine (SGIM)
Undergraduate Medicine and Health Sciences Admission Test (UMAT) [Australia]
University Clinical Aptitude Test (UCAT) [UK, Australia, New Zealand]


== Notes ==


== References ==


== External links ==
Association of American Medical Colleges
American Medical Student Association
The Medical Schools Council (UK)
International Federation of Medical Students' Associations (IFMSA)"
"A medical device is any device intended to be used for medical purposes. Medical devices benefit patients by helping health care providers diagnose and treat patients and helping patients overcome sickness or disease, improving their quality of life.  Significant potential for hazards are inherent when using a device for medical purposes and thus medical devices must be proved safe and effective with reasonable assurance before regulating governments allow marketing of the device in their country. As a general rule, as the associated risk of the device increases the amount of testing required to establish safety and efficacy also increases.  Further, as associated risk increases the potential benefit to the patient must also increase.
Discovery of what would be considered a medical device by modern standards dates as far back as c. 7000 BC in Baluchistan where Neolithic dentists used flint-tipped drills and bowstrings.  Study of archeology and Roman medical literature also indicate that many types of medical devices were in widespread use during the time of ancient Rome.  In the United States it wasn't until the Federal Food, Drug, and Cosmetic Act (FD&C Act) in 1938 that medical devices were regulated.  Later in 1976, the Medical Device Amendments to the FD&C Act established medical device regulation and oversight as we know it today in the United States.  Medical device regulation in Europe as we know it today came into effect in the 1993 by what is collectively known as the Medical Device Directive (MDD).  On May 26, 2017 the Medical Device Regulation (MDR) replaced the MDD.
Medical devices vary in both their intended use and indications for use. Examples range from simple, low-risk devices such as tongue depressors, medical thermometers, disposable gloves, and bedpans to complex, high-risk devices that are implanted and sustain life. One example of high-risk devices are those with Embedded software such as pacemakers, and which assist in the conduct of medical testing, implants, and prostheses. Items as intricate as housings for cochlear implants are manufactured through the deep drawn and shallow drawn manufacturing processes. The design of medical devices constitutes a major segment of the field of biomedical engineering.
The global medical device market reached roughly US$209 billion in 2006 and was estimated to be between $220 and US$250 billion in 2013. The United States controls ~40% of the global market followed by Europe (25%), Japan (15%), and the rest of the world (20%).  Although collectively Europe has a larger share, Japan has the second largest country market share.  The largest market shares in Europe (in order of market share size) belong to Germany, Italy, France, and the United Kingdom.  The rest of the world comprises regions like (in no particular order) Australia, Canada, China, India, and Iran.  This article discusses what constitutes a medical device in these different regions and throughout the article these regions will be discussed in order of their global market share.


== History ==


== Definition ==
A global definition for medical device is difficult to establish because there are numerous regulatory bodies worldwide overseeing the marketing of medical devices.  Although these bodies often collaborate and discuss the definition in general, there are subtle differences in wording that prevent a global harmonization of the definition of a medical device, thus the appropriate definition of a medical device depends on the region.  Often a portion of the definition of a medical device is intended to differentiate between medical devices and drugs, as the regulatory requirements of the two are different.  Definitions also often recognize In vitro diagnostics as a subclass of medical devices and establish accessories as medical devices.


== Definitions by Region ==


=== United States (Food and Drug Administration) ===
Section 201(h) of the Federal Food Drug & Cosmetic (FD&C) Act defines a device as an ""instrument, apparatus, implement, machine, contrivance, implant, in vitro reagent, or other similar or related article, including a component part, or accessory which is:

recognized in the official National Formulary, or the United States Pharmacopoeia, or any supplement to them
Intended for use in the diagnosis of disease or other conditions, or in the cure, mitigation, treatment, or prevention of disease, in man or other animals, or
Intended to affect the structure or any function of the body of man or other animals, andwhich does not achieve its primary intended purposes through chemical action within or on the body of man or other animals and which is not dependent upon being metabolized for the achievement of its primary intended purposes. The term 'device' does not include software functions excluded pursuant to section 520(o).""


=== European Union ===
According to Article 1 of Council Directive 93/42/EEC, ‘medical device’ means any ""instrument, apparatus, appliance, software, material or other article, whether used alone or in combination, including the software intended by its manufacturer to be used specifically for diagnostic and/or therapeutic purposes and necessary for its proper application, intended by the manufacturer to be used for human beings for the purpose of:

diagnosis, prevention, monitoring, treatment or alleviation of disease,
diagnosis, monitoring, treatment, alleviation of or compensation for an injury or handicap,
investigation, replacement or modification of the anatomy or of a physiological process,
control of conception,and which does not achieve its principal intended action in or on the human body by pharmacological, immunological or metabolic means, but which may be assisted in its function by such means;""


==== Legal framework ====
Based on the New Approach, rules that relate to safety and performance of medical devices were harmonised in the EU in the 1990s. The New Approach, defined in a European Council Resolution of May 1985, represents an innovative way of technical harmonisation. It aims to remove technical barriers to trade and dispel the consequent uncertainty for economic operators, to facilitate free movement of goods inside the EU.
The core legal framework consists of three directives: 

Directive 90/385/EEC regarding active implantable medical devices
Directive 93/42/EEC regarding medical devices
Directive 98/79/EC regarding in vitro diagnostic medical devices (Until 2022, the In Vitro Diagnosis Regulation (IVDR) will replace the EU’s current Directive on In-Vitro Diagnostic (98/79/EC)).They aim at ensuring a high level of protection of human health and safety and the good functioning of the Single Market. These three main directives have been supplemented over time by several modifying and implementing directives, including the last technical revision brought about by Directive 2007/47 EC.The government of each Member State must appoint a competent authority responsible for medical devices. The competent authority (CA) is a body with authority to act on behalf of the member state to ensure that member state government transposes requirements of medical device directives into national law and applies them. The CA reports to the minister of health in the member state. The CA in one Member State has no jurisdiction in any other member state, but exchanges information and tries to reach common positions.
In the UK, for example, the Medicines and Healthcare products Regulatory Agency (MHRA) acts as a CA. In Italy it is the Ministero Salute (Ministry of Health) Medical devices must not be mistaken with medicinal products. In the EU, all medical devices must be identified with the CE mark. The conformity of a medium or high risk medical device with relevant regulations is also assessed by an external entity, the Notified Body, before it can be placed on the market.
In September 2012, the European Commission proposed new legislation aimed at enhancing safety, traceability, and transparency. The regulation was adopted in 2017.
The future core legal framework consists of two regulations:

The Medical Devices Regulation (MDR (EU) 2017/745)
The regulation on in vitro diagnostic medical devices (IVDR (EU) 2017/746)


=== Japan ===
Article 2, Paragraph 4, of the Pharmaceutical Affairs Law (PAL) defines medical devices as ""instruments and apparatus intended for use in diagnosis, cure or prevention of diseases in humans or other animals; intended to affect the structure or functions of the body of man or other animals.""


=== Rest of the World ===


==== Canada ====

The term medical device, as defined in the Food and Drugs Act, is ""any article, instrument, apparatus or contrivance, including any component, part or accessory thereof, manufactured, sold or represented for use in: the diagnosis, treatment, mitigation or prevention of a disease, disorder or abnormal physical state, or its symptoms, in a human being; the restoration, correction or modification of a body function or the body structure of a human being; the diagnosis of pregnancy in a human being; or the care of a human being during pregnancy and at and after the birth of a child, including the care of the child. It also includes a contraceptive device but does not include a drug.""The term covers a wide range of health or medical instruments used in the treatment, mitigation, diagnosis or prevention of a disease or abnormal physical condition. Health Canada reviews medical devices to assess their safety, effectiveness, and quality before authorizing their sale in Canada.  According to the Act, medical device does not include any device that is intended for use in relation to animals.""


== Regulation and Oversight ==


=== Risk Classification ===

The regulatory authorities recognize different classes of medical devices based on their potential for harm if misused, design complexity, and their use characteristics.  Each country or region defines these categories in different ways. The authorities also recognize that some devices are provided in combination with drugs, and regulation of these combination products takes this factor into consideration.
Classifying medical devices based on their risk is essential for maintaining patient and staff safety while simultaneously facilitating the marketing of medical products.  By establishing different risk classifications, lower risk devices, for example, a stethoscope or tongue depressor, are not required to undergo the same level of testing that higher risk devices such as artificial pacemakers undergo.  Establishing a hierarchy of risk classification allows regulatory bodies to provide flexibility when reviewing medical devices.


=== Classification by Region ===


==== United States ====

Under the Food, Drug, and Cosmetic Act, the U.S. Food and Drug Administration recognizes three classes of medical devices, based on the level of control necessary to assure safety and effectiveness.
Class I
Class II
Class IIIThe classification procedures are described in the Code of Federal Regulations, Title 21, part 860  (usually known as 21 CFR 860).Class I devices are subject to the least regulatory control and are not intended to help support or sustain life or be substantially important in preventing impairment to human health, and may not present an unreasonable risk of illness or injury.  Examples of Class I devices include elastic bandages, examination gloves, and hand-held surgical instruments.Class II devices are subject to special labeling requirements, mandatory performance standards and postmarket surveillance.  Examples of Class II devices include acupuncture needles, powered wheelchairs, infusion pumps, air purifiers, surgical drapes, stereotaxic navigation systems, and surgical robots.Class III devices are usually those that support or sustain human life, are of substantial importance in preventing impairment of human health, or present a potential, unreasonable risk of illness or injury and require premarket approval. Examples of Class III devices include implantable pacemaker, pulse generators, HIV diagnostic tests, automated external defibrillators, and endosseous implants.


==== European Union (EU) and European Free Trade Association (EFTA) ====
The classification of medical devices in the European Union is outlined in Article IX of the Council Directive 93/42/EEC and Annex VIII of the EU medical device regulation. There are basically four classes, ranging from low risk to high risk.

Class I (including I sterile, I with measurement function, and class I reusable surgical instruments)
Class IIa
Class IIb
Class IIIThe authorization of medical devices is guaranteed by a Declaration of Conformity. This declaration is issued by the manufacturer itself, but for products in Class Is, Im, Ir, IIa, IIb or III, it must be verified by a Certificate of Conformity issued by a Notified Body. A Notified Body is a public or private organisation that has been accredited to validate the compliance of the device to the European Directive.  Medical devices that pertain to class I (on condition they do not require sterilization or do not measure a function) can be marketed purely by self-certification.
The European classification depends on rules that involve the medical device's duration of body contact, invasive character, use of an energy source, effect on the central circulation or nervous system, diagnostic impact, or incorporation of a medicinal product. Certified medical devices should have the CE mark on the packaging, insert leaflets, etc.. These packagings should also show harmonised pictograms and EN standardised logos to indicate essential features such as instructions for use, expiry date, manufacturer, sterile, don't reuse, etc.
In November 2018 the Federal Administrative Court of Switzerland decided that the ""Sympto"" app, used to analyze a woman's menstrual cycle, was a medical device because it calculates a fertility window for each woman using personal data.  The manufacturer,  Sympto-Therm Foundation, argued that this was a didactic, not a medical process.  the court laid down that an app is a medical device if it is to be used for any of the medical purposes provided by law, and creates or modifies health information by calculations or comparison,
providing information about an individual patient.


==== Japan ====
Medical devices (excluding in vitro diagnostics) in Japan are classified into four classes based on risk:
Class I
Class II
Class III
Class IVClasses I and II distinguish between extremely low and low risk devices.  Classes III and IV, moderate and high risk respectively, are highly and specially controlled medical devices.  In vitro diagnostics have three risk classifications.


==== Rest of the World ====
For the remaining regions in the world the risk classifications are generally similar to the United States, European Union, and Japan or are a variant combining two or more of the three countries' risk classifications.


===== Australia =====
The classification of medical devices in Australia is outlined in section 41BD of the Therapeutic Goods Act 1989 and Regulation 3.2 of the Therapeutic Goods Regulations 2002, under control of the Therapeutic Goods Administration. Similarly to the EU classification, they rank in several categories, by order of increasing risk and associated required level of control. Various rules identify the device's category


===== Canada =====

The Medical Devices Bureau of Health Canada recognizes four classes of medical devices based on the level of control necessary to assure the safety and effectiveness of the device. Class I devices present the lowest potential risk and do not require a licence. Class II devices require the manufacturer's declaration of device safety and effectiveness, whereas Class III and IV devices present a greater potential risk and are subject to in-depth scrutiny. A guidance document for device classification is published by Health Canada.Canadian classes of medical devices correspond to the European Council Directive 93/42/EEC (MDD) devices:
Class IV (Canada) generally corresponds to Class III (ECD),
Class III (Canada) generally corresponds to Class IIb (ECD),
Class II (Canada) generally corresponds to Class IIa (ECD), and
Class I (Canada) generally corresponds to Class I (ECD)Examples include surgical instruments (Class I), contact lenses and ultrasound scanners (Class II),
orthopedic implants and hemodialysis machines (Class III), and cardiac pacemakers (Class IV).


===== Iran =====
Iran produces about 2,000 types of medical devices and medical supplies, such as appliances, dental supplies, disposable sterile medical items, laboratory machines, various biomaterials and dental implants. 400 Medical products are produced at the C and D risk class with all of them licensed by the Iranian Health Ministry in terms of safety and performance based on EU-standards.
Some Iranian medical devices are produced according to the European Union standards.
Some producers in Iran export medical devices and supplies which adhere to European Union standards to applicant countries, including 40 Asian and European countries.
Some Iranian producers export their products to foreign countries.


=== Standardization and regulatory concerns ===
The ISO standards for medical devices are covered by ICS 11.100.20 and 11.040.01. The quality and risk management regarding the topic for regulatory purposes is convened by ISO 13485 and ISO 14971. ISO 13485:2016 is applicable to all  providers and manufacturers of medical devices, components, contract services and distributors of medical devices. The standard is the basis for regulatory compliance in local markets, and most export markets. Additionally, ISO 9001:2008 sets precedence because it signifies that a company engages in the creation of new products. It requires that the development of manufactured products have an approval process and a set of rigorous quality standards and development records before the product is distributed. Further standards are IEC 60601-1 which is for electrical devices (mains-powered as well as battery powered), EN 45502-1 which is for Active implantable medical devices, and IEC 62304 for medical software.  The US FDA also published a series of guidances for industry regarding this topic against 21 CFR 820 Subchapter H—Medical Devices. Subpart B includes quality system requirements, an important component of which are design controls (21 CFR 820.30). To meet the demands of these industry regulation standards, a growing number of medical device distributors are putting the complaint management process at the forefront of their quality management practices. This approach further mitigates risks and increases visibility of quality issues.Starting in the late 1980s the FDA increased its involvement in reviewing the development of medical device software. The precipitant for change was a radiation therapy device (Therac-25) that overdosed patients because of software coding errors. FDA is now focused on regulatory oversight on medical device software development process and system-level testing.A 2011 study by Dr. Diana Zuckerman and Paul Brown of the National Center for Health Research, and Dr. Steven Nissen of the Cleveland Clinic, published in the Archives of Internal Medicine, showed that most medical devices recalled in the last five years for ""serious health problems or death"" had been previously approved by the FDA using the less stringent, and cheaper, 510(k) process.  In a few cases, the devices had been deemed so low-risk that they did not they did not undergo any FDA regulatory review. Of the 113 devices recalled, 35 were for cardiovascular issues. This study was the topic of Congressional hearings re-evaluating FDA procedures and oversight.
A 2014 study by Dr. Diana Zuckerman, Paul Brown, and Dr. Aditi Das of the National Center for Health Research, published in JAMA Internal Medicine, examined the scientific evidence that is publicly available about medical implants that were cleared by the FDA 510(k) process from 2008–2012.  They found that scientific evidence supporting “substantial equivalence” to other devices already on the market was required by law to be publicly available, but the information was available for only 16% of the randomly selected implants, and only 10% provided clinical data.  Of the more than 1,100 predicate implants that the new implants were substantially equivalent to, only 3% had any publicly available scientific evidence, and only 1% had clinical evidence of safety or effectiveness. The researchers concluded that publicly available scientific evidence on implants was needed to protect the public health.

In 2014-2015 a new international agreement, the Medical Device Single Audit Program (MDSAP), was put in place with five participant countries: Australia, Brazil, Canada, Japan, and the United States.  The aim of this program was to ""develop a process that allows a single audit, or inspection to ensure the medical device regulatory requirements for all five countries are satisfied"".In 2017, a study by Dr. Jay Ronquillo and Dr. Diana Zuckerman published in the peer-reviewed policy journal Milbank Quarterly found that electronic health records and other device software were recalled due to life-threatening flaws. The article pointed out the lack of safeguards against hacking and other cybersecurity threats, stating “current regulations are necessary but not sufficient for ensuring patient safety by identifying and eliminating dangerous defects in software currently on the market”. They added that legislative changes resulting from the law entitled the 21st Century Cures Act “will further deregulate health IT, reducing safeguards that facilitate the reporting and timely recall of flawed medical software that could harm patients"".
A study by Dr. Stephanie Fox-Rawlings and colleagues at the National Center for Health Research, published in 2018 in the policy journal Milbank Quarterly, investigated whether studies reviewed by the FDA for high-risk medical devices are proven safe and effective for women, minorities, or patients over 65 years of age. The law encourages patient diversity in clinical trials submitted to the FDA for review, but does not require it. The study determined that most high-risk medical devices are not tested and analyzed to ensure that they are safe and effective for all major demographic groups, particularly racial and ethnic minorities and people over 65. Therefore, they do not provide information about safety or effectiveness that would help patients and physicians make well informed decisions.
In 2018, an investigation involving journalists across 36 countries coordinated by the International Consortium of Investigative Journalists (ICIJ) prompted calls for reform in the United States, particularly around the 510(k) substantial equivalence process; the investigation prompted similar calls in the UK and Europe Union.


==== Packaging standards ====

Medical device packaging is highly regulated. Often medical devices and products are sterilized in the package.
Sterility must be maintained throughout distribution to allow immediate use by physicians. A series of special packaging tests measure the ability of the package to maintain sterility. Relevant standards include:

ASTM F2097 – Standard Guide for Design and Evaluation of Primary Flexible Packaging for Medical Products
ASTM F2475-11 – Standard Guide for Biocompatibility Evaluation of Medical Device Packaging Materials
EN 868 Packaging materials and systems for medical devices to be sterilized, General requirements and test methods
ISO 11607 Packaging for terminally sterilized medical devicesPackage testing is part of a quality management system including verification and validation.  It is important to document and ensure that packages meet regulations and end-use requirements.  Manufacturing processes must be controlled and validated to ensure consistent performance. EN ISO 15223-1 defines symbols that can be used to convey important information on packaging and labeling.


==== Biocompatibility standards ====
ISO 10993 - Biological Evaluation of Medical Devices


==== Cleanliness standards ====
Medical device cleanliness has come under greater scrutiny since 2000, when Sulzer Orthopedics recalled several thousand metal hip implants that contained a manufacturing residue. Based on this event, ASTM established a new task group (F04.15.17) for established test methods, guidance documents, and other standards to address cleanliness of medical devices. This task group has issued two standards for permanent implants to date: 1. ASTM F2459: Standard test method for extracting residue from metallic medical components and quantifying via gravimetric analysis 2. ASTM F2847: Standard Practice for Reporting and Assessment of Residues on Single Use Implants 3. ASTM F3172: Standard Guide for Validating Cleaning Processes Used During the Manufacture of Medical DevicesIn addition, the cleanliness of re-usable devices has led to a series of standards, including:

ASTM E2314: Standard Test Method for Determination of Effectiveness of Cleaning Processes for Reusable Medical Instruments Using a Microbiologic Method (Simulated Use Test)""
ASTM D7225: Standard Guide for Blood Cleaning Efficiency of Detergents and Washer-Disinfectors
ASTM F3208: Standard Guide for Selecting Test Soils for Validation of Cleaning Methods for Reusable Medical DevicesThe ASTM F04.15.17 task group is working on several new standards that involve designing implants for cleaning, selection and testing of brushes for cleaning reusable devices, and cleaning assessment of medical devices made by additive manufacturing. Additionally, the FDA is establishing new guidelines for reprocessing reusable medical devices, such as orthoscopic shavers, endoscopes, and suction tubes. New research was published in ACS Applied Interfaces and Material to keep Medical Tools pathogen free.


==== Safety standards ====


== Design, prototyping, and product development ==

Medical device manufacturing requires a level of process control according to the classification of the device. Higher risk; more controls.  When in the initial R&D phase, manufacturers are now beginning to design for manufacturability. This means products can be more precision-engineered to for production to result in shorter lead times, tighter tolerances and more advanced specifications and prototypes. These days, with the aid of CAD or modelling platforms, the work is now much faster, and this can act also as a tool for strategic design generation as well as a marketing tool.Failure to meet cost targets will lead to substantial losses for an organisation. In addition, with global competition, the R&D of new devices is not just a necessity, it is an imperative for medical device manufacturers. The realisation of a new design can be very costly, especially with the shorter product life cycle. As technology advances, there is typically a level of quality, safety and reliability that increases exponentially with time.For example, initial models of the artificial cardiac pacemaker were external support devices that transmits pulses of electricity to the heart muscles via electrode leads on the chest. The electrodes contact the heart directly through the chest, allowing stimulation pulses to pass through the body. Recipients of this typically suffered infection at the entrance of the electrodes, which led to the subsequent trial of the first internal pacemaker, with electrodes attached to the myocardium by thoracotomy. Future developments led to the isotope-power source that would last for the lifespan of the patient.


== Software ==


=== Mobile medical applications ===
With the rise of smartphone usage in the medical space, in 2013, the FDA issued to regulate mobile medical applications and protect users from their unintended use, soon followed by European and other regulatory agencies. This guidance distinguishes the apps subjected to regulation based on the marketing claims of the apps. Incorporation of the guidelines during the development phase of such apps can be considered as developing a medical device; the regulations have to adapt and propositions for expedite approval may be required due to the nature of 'versions' of mobile application development.On September 25, 2013 the FDA released a draft guidance document for regulation of mobile medical applications, to clarify what kind of mobile apps related to health would not be regulated, and which would be.


=== Cybersecurity ===

Medical devices such as pacemakers, insulin pumps, operating room monitors, defibrillators, and surgical instruments, including deep-brain stimulators, can incorporate the ability to transmit vital health information from a patient's body to medical professionals. Some of these devices can be remotely controlled. This has engendered concern about privacy and security issues, human error, and technical glitches with this technology. While only a few studies have looked at the susceptibility of medical devices to hacking, there is a risk.  In 2008, computer scientists proved that pacemakers and defibrillators can be hacked wirelessly via radio hardware, an antenna, and a personal computer. These researchers showed they could shut down a combination heart defibrillator and pacemaker and reprogram it to deliver potentially lethal shocks or run out its battery.  Jay Radcliff, a security researcher interested in the security of medical devices, raised fears about the safety of these devices.  He shared his concerns at the Black Hat security conference. Radcliff fears that the devices are vulnerable and has found that a lethal attack is possible against those with insulin pumps and glucose monitors.  Some medical device makers downplay the threat from such attacks and argue that the demonstrated attacks have been performed by skilled security researchers and are unlikely to occur in the real world.  At the same time, other makers have asked software security experts to investigate the safety of their devices.  As recently as June 2011, security experts showed that by using readily available hardware and a user manual, a scientist could both tap into the information on the system of a wireless insulin pump in combination with a glucose monitor.  With the PIN of the device, the scientist could wirelessly control the dosage of the insulin.  Anand Raghunathan, a researcher in this study, explains that medical devices are getting smaller and lighter so that they can be easily worn. The downside is that additional security features would put an extra strain on the battery and size and drive up prices.  Dr. William Maisel offered some thoughts on the motivation to engage in this activity.  Motivation to do this hacking might include acquisition of private information for financial gain or competitive advantage; damage to a device manufacturer's reputation; sabotage; intent to inflict financial or personal injury or just satisfaction for the attacker.  Researchers suggest a few safeguards.  One would be to use rolling codes.  Another solution is to use a technology called ""body-coupled communication"" that uses the human skin as a wave guide for wireless communication. On 28 December 2016 the US Food and Drug Administration released its recommendations that are not legally enforceable for how medical device manufacturers should maintain the security of Internet-connected devices.Similar to hazards, cybersecurity threats and vulnerabilities cannot be eliminated entirely but must be managed and reduced to a reasonable level.  When designing medical devices, the tier of cybersecurity risk should be determined early in the process in order to establish a cybersecurity vulnerability and management approach (including a set of cybersecurity design controls).  The medical device design approach employed should be consistent with the NIST Cybersecurity Framework for managing cybersecurity-related risks.
In August 2013, the FDA released over 20 regulations aiming to improve the security of data in medical devices, in response to the growing risks of limited cybersecurity.


== Medical equipment ==

Medical equipment (also known as armamentarium) is designed to aid in the diagnosis, monitoring or treatment of medical conditions.


=== Types ===
There are several basic types:

Diagnostic equipment includes medical imaging machines, used to aid in diagnosis. Examples are ultrasound and MRI machines, PET and CT scanners, and x-ray machines.
Treatment equipment includes infusion pumps, medical lasers and LASIK surgical machines.
Life support equipment is used to maintain a patient's bodily function.  This includes medical ventilators, incubators, anaesthetic machines, heart-lung machines, ECMO, and dialysis machines.
Medical monitors allow medical staff to measure a patient's medical state. Monitors may measure patient vital signs and other parameters including ECG, EEG, and blood pressure.
Medical laboratory equipment automates or helps analyze blood, urine, genes, and dissolved gases in the blood.
Diagnostic Medical Equipment may also be used in the home for certain purposes, e.g. for the control of diabetes mellitus
Therapeutic: physical therapy machines like continuous passive range of motion (CPM) machinesThe identification of medical devices has been recently improved by the introduction of Unique Device Identification (UDI) and standardised naming using the Global Medical Device Nomenclature (GMDN) which have been endorsed by the International Medical Device Regulatory Forum (IMDRF).A biomedical equipment technician (BMET) is a vital component of the healthcare delivery system. Employed primarily by hospitals, BMETs are the people responsible for maintaining a facility's medical equipment. BMET mainly act as an interface between doctor and equipment.


=== Medical Equipment Donation ===
There are challenges surrounding the availability of medical equipment from a global health perspective, with low-resource countries unable to obtain or afford essential and life-saving equipment. In these settings, well-intentioned equipment donation from high- to low-resource settings is a frequently used strategy to address this through individuals, organisations, manufacturers and charities. However, issues with maintenance, availability of biomedical equipment technicians (BMET), supply chains, user education and the appropriateness of donations means these frequently fail to deliver the intended benefits. The WHO estimates that 95% of medical equipment in low- and middle-income countries (LMICs) is imported and 80% of it is funded by international donors or foreign governments. While up to 70% of medical equipment in sub-Saharan Africa is donated, only 10%–30% of donated equipment becomes operational. A review of current practice and guidelines for the donation of medical equipment for surgical and anaesthesia care in LMICs has demonstrated a high level of complexity within the donation process and numerous shortcomings. Greater collaboration and planning between donors and recipients is required together with evaluation of donation programs and concerted advocacy to educate donors and recipients on existing equipment donation guidelines and policies


== Academic resources ==
Medical & Biological Engineering & Computing
Expert Review of Medical Devices
Journal of Clinical Engineering


=== University Based Research Packaging Institutes ===
University of Minnesota - Medical Devices Center (MDC)
University of Strathclyde - Strathclyde Institute of Medical Devices (SIMD)
Flinders University - Medical Device Research Institute (MDRI)
Michigan State University - School of Packaging (SoP)
IIT Bombay - Biomedical Engineering and Technology (incubation) Centre (BETiC)


== References ==


== External links ==
US Food and Drug Administration – Center for Devices and Radiological Health
Premarket Notification (510k)
Premarket Approval (PMA)
FDA – Is the Product a Medical Device?
MHRA - Medical devices regulation and safety
EC - Medical devices
Health Canada - List of Recognized Standards for Medical Devices (International)
ISO - Standards catalogue: 11.040.01: Medical equipment in general
Radio Frequency Wireless Technology in Medical Devices - Guidance for Industry and Food and Drug Administration Staff. FDA (2013)
A History of Medical Device Regulation & Oversight in the United States.FDA (2019)"
"Medical imaging is the technique and process of creating visual representations of the interior of a body for clinical analysis and medical intervention, as well as visual representation of the function of some organs or tissues (physiology). Medical imaging seeks to reveal internal structures hidden by the skin and bones, as well as to diagnose and treat disease. Medical imaging also establishes a database of normal anatomy and physiology to make it possible to identify abnormalities. Although imaging of removed organs and tissues can be performed for medical reasons, such procedures are usually considered part of pathology instead of medical imaging.
As a discipline and in its widest sense, it is part of biological imaging and incorporates radiology, which uses the imaging technologies of X-ray radiography, magnetic resonance imaging,  ultrasound, endoscopy, elastography, tactile imaging, thermography, medical photography, nuclear medicine functional imaging techniques as positron emission tomography (PET) and single-photon emission computed tomography (SPECT).
Measurement and recording techniques that are not primarily designed to produce images, such as electroencephalography (EEG), magnetoencephalography (MEG), electrocardiography (ECG), and others, represent other technologies that produce data susceptible to representation as a parameter graph vs. time or maps that contain data about the measurement locations. In a limited comparison, these technologies can be considered forms of medical imaging in another discipline.
As of 2010, 5 billion medical imaging studies had been conducted worldwide. Radiation exposure from medical imaging in 2006 made up about 50% of total ionizing radiation exposure in the United States. Medical imaging equipment are manufactured using technology from the semiconductor industry, including CMOS integrated circuit chips, power semiconductor devices, sensors such as image sensors (particularly CMOS sensors) and biosensors, and processors such as microcontrollers, microprocessors, digital signal processors, media processors and system-on-chip devices. As of 2015, annual shipments of medical imaging chips amount to 46 million units and $1.1 billion.Medical imaging is often perceived to designate the set of techniques that noninvasively produce images of the internal aspect of the body. In this restricted sense, medical imaging can be seen as the solution of mathematical inverse problems. This means that cause (the properties of living tissue) is inferred from effect (the observed signal). In the case of medical ultrasound, the probe consists of ultrasonic pressure waves and echoes that go inside the tissue to show the internal structure. In the case of projectional radiography, the probe uses X-ray radiation, which is absorbed at different rates by different tissue types such as bone, muscle, and fat.
The term ""noninvasive"" is used to denote a procedure where no instrument is introduced into a patient's body, which is the case for most imaging techniques used.


== Types ==

In the clinical context, ""invisible light"" medical imaging is generally equated to radiology or ""clinical imaging"" and the medical practitioner responsible for interpreting (and sometimes acquiring) the images is a radiologist. ""Visible light"" medical imaging involves digital video or still pictures that can be seen without special equipment.  Dermatology and wound care are two modalities that use visible light imagery. Diagnostic radiography designates the technical aspects of medical imaging and in particular the acquisition of medical images. The radiographer or radiologic technologist is usually responsible for acquiring medical images of diagnostic quality, although some radiological interventions are performed by radiologists.
As a field of scientific investigation, medical imaging constitutes a sub-discipline of biomedical engineering, medical physics or medicine depending on the context: Research and development in the area of instrumentation, image acquisition (e.g., radiography), modeling and quantification are usually the preserve of biomedical engineering, medical physics, and computer science; Research into the application and interpretation of medical images is usually the preserve of radiology and the medical sub-discipline relevant to medical condition or area of medical science (neuroscience, cardiology, psychiatry, psychology, etc.) under investigation. Many of the techniques developed for medical imaging also have scientific and industrial applications.


=== Radiography ===

Two forms of radiographic images are in use in medical imaging. Projection radiography and fluoroscopy, with the latter being useful for catheter guidance. These 2D techniques are still in wide use despite the advance of 3D tomography due to the low cost, high resolution, and depending on the application, lower radiation dosages with 2D technique. This imaging modality utilizes a wide beam of x rays for image acquisition and is the first imaging technique available in modern medicine.

Fluoroscopy produces real-time images of internal structures of the body in a similar fashion to radiography, but employs a constant input of x-rays, at a lower dose rate. Contrast media, such as barium, iodine, and air are used to visualize internal organs as they work. Fluoroscopy is also used in image-guided procedures when constant feedback during a procedure is required. An image receptor is required to convert the radiation into an image after it has passed through the area of interest. Early on this was a fluorescing screen, which gave way to an Image Amplifier (IA) which was a large vacuum tube that had the receiving end coated with cesium iodide, and a mirror at the opposite end. Eventually the mirror was replaced with a TV camera.
Projectional radiographs, more commonly known as x-rays, are often used to determine the type and extent of a fracture as well as for detecting pathological changes in the lungs. With the use of radio-opaque contrast media, such as barium, they can also be used to visualize the structure of the stomach and intestines – this can help diagnose ulcers or certain types of colon cancer.


=== Magnetic resonance imaging ===

A magnetic resonance imaging instrument (MRI scanner), or ""nuclear magnetic resonance (NMR) imaging"" scanner as it was originally known, uses powerful magnets to polarize and excite hydrogen nuclei (i.e., single protons) of water molecules in human tissue, producing a detectable signal which is spatially encoded, resulting in images of the body. The MRI machine emits a radio frequency (RF) pulse at the resonant frequency of the hydrogen atoms on water molecules. Radio frequency antennas (""RF coils"") send the pulse to the area of the body to be examined. The RF pulse is absorbed by protons, causing their direction with respect to the primary magnetic field to change. When the RF pulse is turned off, the protons ""relax"" back to alignment with the primary magnet and emit radio-waves in the process. This radio-frequency emission from the hydrogen-atoms on water is what is detected and reconstructed into an image. The resonant frequency of a spinning magnetic dipole (of which protons are one example) is called the Larmor frequency and is determined by the strength of the main magnetic field and the chemical environment of the nuclei of interest. MRI uses three electromagnetic fields: a very strong (typically 1.5 to 3 teslas) static magnetic field to polarize the hydrogen nuclei, called the primary field; gradient fields that can be modified to vary in space and time (on the order of 1 kHz) for spatial encoding, often simply called gradients; and a spatially homogeneous radio-frequency (RF) field for manipulation of the hydrogen nuclei to produce measurable signals, collected through an RF antenna.
Like CT, MRI traditionally creates a two-dimensional image of a thin ""slice"" of the body and is therefore considered a tomographic imaging technique. Modern MRI instruments are capable of producing images in the form of 3D blocks, which may be considered a generalization of the single-slice, tomographic, concept. Unlike CT, MRI does not involve the use of ionizing radiation and is therefore not associated with the same health hazards. For example, because MRI has only been in use since the early 1980s, there are no known long-term effects of exposure to strong static fields (this is the subject of some debate; see 'Safety' in MRI) and therefore there is no limit to the number of scans to which an individual can be subjected, in contrast with X-ray and CT. However, there are well-identified health risks associated with tissue heating from exposure to the RF field and the presence of implanted devices in the body, such as pacemakers. These risks are strictly controlled as part of the design of the instrument and the scanning protocols used.
Because CT and MRI are sensitive to different tissue properties, the appearances of the images obtained with the two techniques differ markedly. In CT, X-rays must be blocked by some form of dense tissue to create an image, so the image quality when looking at soft tissues will be poor. In MRI, while any nucleus with a net nuclear spin can be used, the proton of the hydrogen atom remains the most widely used, especially in the clinical setting, because it is so ubiquitous and returns a large signal. This nucleus, present in water molecules, allows the excellent soft-tissue contrast achievable with MRI.
A number of different pulse sequences can be used for specific MRI diagnostic imaging (multiparametric MRI or mpMRI). It is possible to differentiate tissue characteristics by combining two or more of the following imaging sequences, depending on the information being sought: T1-weighted (T1-MRI), T2-weighted (T2-MRI), diffusion weighted imaging (DWI-MRI), dynamic contrast enhancement (DCE-MRI), and spectroscopy (MRI-S). For example, imaging of prostate tumors is better accomplished using T2-MRI and DWI-MRI than T2-weighted imaging alone.  The number of applications of mpMRI for detecting disease in various organs continues to expand, including liver studies, breast tumors, pancreatic tumors, and assessing the effects of vascular disruption agents on cancer tumors.


=== Nuclear medicine ===

Nuclear medicine encompasses both diagnostic imaging and treatment of disease, and may also be referred to as molecular medicine or molecular imaging and therapeutics.  Nuclear medicine uses certain properties of isotopes and the energetic particles emitted from radioactive material to diagnose or treat various pathology. Different from the typical concept of anatomic radiology, nuclear medicine enables assessment of physiology. This function-based approach to medical evaluation has useful applications in most subspecialties, notably oncology, neurology, and cardiology. Gamma cameras and PET scanners are used in e.g. scintigraphy, SPECT and PET to detect regions of biologic activity that may be associated with a disease. Relatively short-lived isotope, such as 99mTc is administered to the patient. Isotopes are often preferentially absorbed by biologically active tissue in the body, and can be used to identify tumors or fracture points in bone. Images are acquired after collimated photons are detected by a crystal that gives off a light signal, which is in turn amplified and converted into count data.

Scintigraphy (""scint"") is a form of diagnostic test wherein radioisotopes are taken internally, for example, intravenously or orally. Then, gamma cameras capture and form two-dimensional images from the radiation emitted by the radiopharmaceuticals.
SPECT is a 3D tomographic technique that uses gamma camera data from many projections and can be reconstructed in different planes. A dual detector head gamma camera combined with a CT scanner, which provides localization of functional SPECT data, is termed a SPECT-CT camera, and has shown utility in advancing the field of molecular imaging. In most other medical imaging modalities, energy is passed through the body and the reaction or result is read by detectors. In SPECT imaging, the patient is injected with a radioisotope, most commonly Thallium 201TI, Technetium 99mTC, Iodine 123I, and Gallium 67Ga. The radioactive gamma rays are emitted through the body as the natural decaying process of these isotopes takes place. The emissions of the gamma rays are captured by detectors that surround the body. This essentially means that the human is now the source of the radioactivity, rather than the medical imaging devices such as  X-ray or CT.
Positron emission tomography (PET) uses coincidence detection to image functional processes. Short-lived positron emitting isotope, such as 18F, is incorporated with an organic substance such as glucose, creating F18-fluorodeoxyglucose, which can be used as a marker of metabolic utilization. Images of activity distribution throughout the body can show rapidly growing tissue, like tumor, metastasis, or infection. PET images can be viewed in comparison to computed tomography scans to determine an anatomic correlate. Modern scanners may integrate PET, allowing PET-CT, or PET-MRI to optimize the image reconstruction involved with positron imaging. This is performed on the same equipment without physically moving the patient off of the gantry. The resultant hybrid of functional and anatomic imaging information is a useful tool in non-invasive diagnosis and patient management.Fiduciary markers are used in a wide range of medical imaging applications. Images of the same subject produced with two different imaging systems may be correlated (called image registration) by placing a fiduciary marker in the area imaged by both systems.  In this case, a marker which is visible in the images produced by both imaging modalities must be used.  By this method, functional information from SPECT or positron emission tomography can be related to anatomical information provided by magnetic resonance imaging (MRI). Similarly, fiducial points established during MRI can be correlated with brain images generated by magnetoencephalography to localize the source of brain activity.


=== Ultrasound ===

Medical ultrasound uses high frequency broadband sound waves in the megahertz range that are reflected by tissue to varying degrees to produce (up to 3D) images. This is commonly associated with imaging the fetus in pregnant women. Uses of ultrasound are much broader, however.  Other important uses include imaging the abdominal organs, heart, breast, muscles, tendons, arteries and veins.  While it may provide less anatomical detail than techniques such as CT or MRI, it has several advantages which make it ideal in numerous situations, in particular that it studies the function of moving structures in real-time, emits no ionizing radiation, and contains speckle that can be used in elastography. Ultrasound is also used as a popular research tool for capturing raw data, that can be made available through an ultrasound research interface, for the purpose of tissue characterization and implementation of new image processing techniques. The concepts of ultrasound differ from other medical imaging modalities in the fact that it is operated by the transmission and receipt of sound waves. The high frequency sound waves are sent into the tissue and depending on the composition of the different tissues; the signal will be attenuated and returned at separate intervals.  A path of reflected sound waves in a multilayered structure can be defined by an input acoustic impedance (ultrasound sound wave) and the Reflection and transmission coefficients of the relative structures. It is very safe to use and does not appear to cause any adverse effects. It is also relatively inexpensive and quick to perform. Ultrasound scanners can be taken to critically ill patients in intensive care units, avoiding the danger caused while moving the patient to the radiology department. The real-time moving image obtained can be used to guide drainage and biopsy procedures. Doppler capabilities on modern scanners allow the blood flow in arteries and veins to be assessed.


=== Elastography ===

Elastography is a relatively new imaging modality that maps the elastic properties of soft tissue. This modality emerged in the last two decades. Elastography is useful in medical diagnoses, as elasticity can discern healthy from unhealthy tissue for specific organs/growths. For example, cancerous tumours will often be harder than the surrounding tissue, and diseased livers are stiffer than healthy ones. There are several elastographic techniques based on the use of ultrasound, magnetic resonance imaging and tactile imaging. The wide clinical use of ultrasound elastography is a result of the implementation of technology in clinical ultrasound machines. Main branches of ultrasound elastography include Quasistatic Elastography/Strain Imaging, Shear Wave Elasticity Imaging (SWEI), Acoustic Radiation Force Impulse imaging (ARFI), Supersonic Shear Imaging (SSI), and Transient Elastography. In the last decade a steady increase of activities in the field of elastography is observed demonstrating successful application of the technology in various areas of medical diagnostics and treatment monitoring.


=== Photoacoustic imaging ===

Photoacoustic imaging is a recently developed hybrid biomedical imaging modality based on the photoacoustic effect. It combines the advantages of optical absorption contrast with an ultrasonic spatial resolution for deep imaging in (optical) diffusive or quasi-diffusive regime. Recent studies have shown that photoacoustic imaging can be used in vivo for tumor angiogenesis monitoring, blood oxygenation mapping, functional brain imaging, and skin melanoma detection, etc.


=== Tomography ===

Tomography is the imaging by sections or sectioning. The main such methods in medical imaging are:

X-ray computed tomography (CT), or Computed Axial Tomography (CAT) scan, is a helical tomography technique (latest generation), which traditionally produces a 2D image of the structures in a thin section of the body. In CT, a beam of X-rays spins around an object being examined and is picked up by sensitive radiation detectors after having penetrated the object from multiple angles. A computer then analyses the information received from the scanner's detectors and constructs a detailed image of the object and its contents using the mathematical principles laid out in the Radon transform. It has a greater ionizing radiation dose burden than projection radiography; repeated scans must be limited to avoid health effects. CT is based on the same principles as X-Ray projections but in this case, the patient is enclosed in a surrounding ring of detectors assigned with 500–1000 scintillation detectors (fourth-generation X-Ray CT scanner geometry). Previously in older generation scanners, the X-Ray beam was paired by a translating source and detector. Computed tomography has almost completely replaced focal plane tomography in X-ray tomography imaging.
Positron emission tomography (PET) also used in conjunction with computed tomography, PET-CT, and magnetic resonance imaging PET-MRI.
Magnetic resonance imaging (MRI) commonly produces tomographic images of cross-sections of the body. (See separate MRI section in this article.)


=== Echocardiography ===

When ultrasound is used to image the heart it is referred to as an echocardiogram.  Echocardiography allows detailed structures of the heart, including chamber size, heart function, the valves of the heart, as well as the pericardium (the sac around the heart) to be seen.  Echocardiography uses 2D, 3D, and Doppler imaging to create pictures of the heart and visualize the blood flowing through each of the four heart valves. Echocardiography is widely used in an array of patients ranging from those experiencing symptoms, such as shortness of breath or chest pain, to those undergoing cancer treatments. Transthoracic ultrasound has been proven to be safe for patients of all ages, from infants to the elderly, without risk of harmful side effects or radiation, differentiating it from other imaging modalities. Echocardiography is one of the most commonly used imaging modalities in the world due to its portability and use in a variety of applications. In emergency situations, echocardiography is quick, easily accessible, and able to be performed at the bedside, making it the modality of choice for many physicians.


=== Functional near-infrared spectroscopy ===

FNIR Is a relatively new non-invasive imaging technique. NIRS (near infrared spectroscopy) is used for the purpose of functional neuroimaging and has been widely accepted as a brain imaging technique.


=== Magnetic Particle Imaging ===
Using superparamagnetic iron oxide nanoparticles, magnetic particle imaging (MPI) is a developing diagnostic imaging technique used for tracking superparamagnetic iron oxide nanoparticles.  The primary advantage is the high sensitivity and specificity, along with the lack of signal decrease with tissue depth.  MPI has been used in medical research to image cardiovascular performance, neuroperfusion, and cell tracking.


== In pregnancy ==

Medical imaging may be indicated in pregnancy because of pregnancy complications, a pre-existing disease or an acquired disease in pregnancy, or routine prenatal care. Magnetic resonance imaging (MRI) without MRI contrast agents as well as obstetric ultrasonography are not associated with any risk for the mother or the fetus, and are the imaging techniques of choice for pregnant women. Projectional radiography, CT scan and nuclear medicine imaging result some degree of ionizing radiation exposure, but have with a few exceptions much lower absorbed doses than what are associated with fetal harm. At higher dosages, effects can include miscarriage, birth defects and intellectual disability.


== Maximizing imaging procedure use ==
The amount of data obtained in a single MR or CT scan is very extensive. Some of the data that radiologists discard could save patients time and money, while reducing their exposure to radiation and risk of complications from invasive procedures. Another approach for making the procedures more efficient is based on utilizing additional constraints, e.g., in some medical imaging modalities one can improve the efficiency of the data acquisition by taking into account the fact the reconstructed density is positive.


== Creation of three-dimensional images ==
Volume rendering techniques have been developed to enable CT, MRI and ultrasound scanning software to produce 3D images for the physician. Traditionally CT and MRI scans produced 2D static output on film. To produce 3D images, many scans are made and then combined by computers to produce a 3D model, which can then be manipulated by the physician. 3D ultrasounds are produced using a somewhat similar technique.
In diagnosing disease of the viscera of the abdomen, ultrasound is particularly sensitive on imaging of biliary tract, urinary tract and female reproductive organs (ovary, fallopian tubes).  As for example, diagnosis of gallstone by dilatation of common bile duct and stone in the common bile duct.
With the ability to visualize important structures in great detail, 3D visualization methods are a valuable resource for the diagnosis and surgical treatment of many pathologies. It was a key resource for the famous, but ultimately unsuccessful attempt by Singaporean surgeons to separate Iranian twins Ladan and Laleh Bijani in 2003. The 3D equipment was used previously for similar operations with great success.
Other proposed or developed techniques include:

Diffuse optical tomography
Elastography
Electrical impedance tomography
Optoacoustic imaging
Ophthalmology
A-scan
B-scan
Corneal topography
Optical coherence tomography
Scanning laser ophthalmoscopySome of these techniques are still at a research stage and not yet used in clinical routines.


== Non-diagnostic imaging ==
Neuroimaging has also been used in experimental circumstances to allow people (especially disabled persons) to control outside devices, acting as a brain computer interface.
Many medical imaging software applications are used for non-diagnostic imaging, specifically because they  don't have an FDA approval and  not allowed to use in clinical research for patient diagnosis. Note that many clinical research studies are not designed for patient diagnosis anyway.


== Archiving and recording ==

Used primarily in ultrasound imaging, capturing the image produced by a medical imaging device is required for archiving and telemedicine applications. In most scenarios, a frame grabber is used in order to capture the video signal from the medical device and relay it to a computer for further processing and operations.


=== DICOM ===
The Digital Imaging and Communication in Medicine (DICOM) Standard is used globally to store, exchange, and transmit medical images. The DICOM Standard incorporates protocols for imaging techniques such as radiography, computed tomography (CT), magnetic resonance imaging (MRI), ultrasound, and radiation therapy.


=== Compression of medical images ===
Medical imaging techniques produce very large amounts of data, especially from CT, MRI and PET modalities.  As a result, storage and communications of electronic image data are prohibitive without the use of compression.  JPEG 2000 is the state-of-the-art image compression DICOM standard for storage and transmission of medical images.  The cost and feasibility of accessing large image data sets over low or various bandwidths are further addressed by use of another DICOM standard, called JPIP, to enable efficient streaming of the JPEG 2000 compressed image data.


=== Medical imaging in the cloud ===
There has been growing trend to migrate from on-premise PACS to a Cloud Based PACS. A recent article by Applied Radiology said, ""As the digital-imaging realm is embraced across the healthcare enterprise, the swift transition from terabytes to petabytes of data has put radiology on the brink of information overload. Cloud computing offers the imaging department of the future the tools to manage data much more intelligently.""


== Use in pharmaceutical clinical trials ==
Medical imaging has become a major tool in clinical trials since it enables rapid diagnosis with visualization and quantitative assessment.
A typical clinical trial goes through multiple phases and can take up to eight years. Clinical endpoints or outcomes are used to determine whether the therapy is safe and effective. Once a patient reaches the endpoint, he or she is generally excluded from further experimental interaction. Trials that rely solely on clinical endpoints are very costly as they have long durations and tend to need large numbers of patients.
In contrast to clinical endpoints, surrogate endpoints have been shown to cut down the time required to confirm whether a drug has clinical benefits. Imaging biomarkers (a characteristic that is objectively measured by an imaging technique, which is used as an indicator of pharmacological response to a therapy) and surrogate endpoints have shown to facilitate the use of small group sizes, obtaining quick results with good statistical power.Imaging is able to reveal subtle change that is indicative of the progression of therapy that may be missed out by more subjective, traditional approaches.  Statistical bias is reduced as the findings are evaluated without any direct patient contact.
Imaging techniques such as positron emission tomography (PET) and magnetic resonance imaging (MRI) are routinely used in oncology and neuroscience areas,. For example, measurement of tumour shrinkage is a commonly used surrogate endpoint in solid tumour response evaluation.  This allows for faster and more objective assessment of the effects of anticancer drugs.  In Alzheimer's disease, MRI scans of the entire brain can accurately assess the rate of hippocampal atrophy, while PET scans can measure the brain's metabolic activity by measuring regional glucose metabolism, and beta-amyloid plaques using tracers such as Pittsburgh compound B (PiB).  Historically less use has been made of quantitative medical imaging in other areas of drug development although interest is growing.An imaging-based trial will usually be made up of three components:

A realistic imaging protocol.  The protocol is an outline that standardizes (as far as practically possible) the way in which the images are acquired using the various modalities (PET, SPECT, CT, MRI).  It covers the specifics in which images are to be stored, processed and evaluated.
An imaging centre that is responsible for collecting the images, perform quality control and provide tools for data storage, distribution and analysis.  It is important for images acquired at different time points are displayed in a standardised format to maintain the reliability of the evaluation.  Certain specialised imaging contract research organizations provide end to end medical imaging services, from protocol design and site management through to data quality assurance and image analysis.
Clinical sites that recruit patients to generate the images to send back to the imaging centre.


== Shielding ==
Lead is the main material used for radiographic shielding against scattered X-rays.
In magnetic resonance imaging, there is MRI RF shielding as well as magnetic shielding to prevent external disturbance of image quality.


== Privacy protection ==
Medical imaging are generally covered by laws of medical privacy. For example, in the United States the Health Insurance Portability and Accountability Act (HIPAA) sets restrictions for health care providers on utilizing protected health information, which is any individually identifiable information relating to the past, present, or future physical or mental health of any individual. While there has not been any definitive legal decision in the matter, at least one study has indicated that medical imaging may contain biometric information that can uniquely identify a person, and so may qualify as PHI.The UK General Medical Council's ethical guidelines indicate that the Council does not require consent prior to secondary uses of X-ray images.


== Industry ==
Organizations in the medical imaging industry include manufacturers of imaging equipment, freestanding radiology facilities, and hospitals.
The global market for manufactured devices was estimated at $5 billion in 2018. Notable manufacturers as of 2012 included Fujifilm, GE, Siemens Healthineers, Philips, Shimadzu, Toshiba, Carestream Health, Hitachi, Hologic, and Esaote. In 2016, the manufacturing industry was characterized as oligopolistic and mature; new entrants included in Samsung and Neusoft Medical.In the United States, as estimate as of 2015 places the US market for imaging scans at about $100b, with 60% occurring in hospitals and 40% occurring in freestanding clinics, such as the RadNet chain.


== Copyright ==


=== United States ===
As per chapter 300 of the Compendium of U.S. Copyright Office practices, ""the Office will not register works produced by a machine or mere mechanical process that operates randomly or automatically without any creative input or intervention from a human author."" including ""Medical imaging produced by x-rays, ultrasounds, magnetic resonance imaging, or other diagnostic equipment."" This position differs from the broad copyright protections afforded to photographs. While the Copyright Compendium is an agency statutory interpretation and not legally binding, courts are likely to give deference to it if they find it reasonable. Yet, there is no U.S. federal case law directly addressing the issue of the copyrightability of x-ray images.


==== Derivatives ====

An extensive definition of the term derivative work is given by the United States Copyright Act in 17 U.S.C. § 101:

A “derivative work” is a work based upon one or more preexisting works, such as a translation... art reproduction, abridgment, condensation, or any other form in which a work may be recast, transformed, or adapted. A work consisting of editorial revisions, annotations, elaborations, or other modifications which, as a whole, represent an original work of authorship, is a “derivative work”.
17 U.S.C. § 103(b) provides:

The copyright in a compilation or derivative work extends only to the material contributed by the author of such work, as distinguished from the preexisting material employed in the work, and does not imply any exclusive right in the preexisting material. The copyright in such work is independent of, and does not affect or enlarge the scope, duration, ownership, or subsistence of, any copyright protection in the preexisting material.


=== Germany ===
In Germany, X-ray images as well as MRI, Medical ultrasound, PET and scintigraphy images are protected by (copyright-like) related rights or neighbouring rights. This protection does not require creativity (as would be necessary for regular copyright protection) and lasts only for 50 years after image creation, if not published within 50 years, or for 50 years after the first legitimate publication. The letter of the law grants this right to the ""Lichtbildner"", i.e. the person who created the image. The literature seems to uniformly consider the medical doctor, dentist or veterinary physician as the rights holder, which may result from the circumstance that in Germany many x-rays are performed in ambulatory setting


=== United Kingdom ===
Medical images created in the United Kingdom will normally be protected by copyright due to ""the high level of skill, labour and judgement required to produce a good quality x-ray, particularly to show contrast between bones and various soft tissues"". The Society of Radiographers believe this copyright is owned by employer (unless the radiographer is self-employed—though even then their contract might require them to transfer ownership to the hospital). This copyright owner can grant certain permissions to whoever they wish, without giving up their ownership of the copyright. So the hospital and its employees will be given permission to use such radiographic images for the various purposes that they require for medical care. Physicians employed at the hospital will, in their contracts, be given the right to publish patient information in journal papers or books they write (providing they are made anonymous). Patients may also be granted permission to ""do what they like with"" their own images.


=== Sweden ===
The Cyber Law in Sweden states: ""Pictures can be protected as photographic works or as photographic pictures. The former requires a higher level of originality; the latter protects all types of photographs, also the ones taken by amateurs, or within medicine or science. The protection requires some sort of photographic technique being used, which includes digital cameras as well as holograms created by laser technique. The difference between the two types of work is the term of protection, which amounts to seventy years after the death of the author of a photographic work as opposed to fifty years, from the year in which the photographic picture was taken.""Medical imaging may possibly be included in the scope of ""photography"", similarly to a U.S. statement that ""MRI images, CT scans, and the like are analogous to photography.""


== See also ==
Medical image sharing


== Notes ==


== References ==


== Further reading ==


== External links ==
Medical imaging at Curlie"
"Medicine is the science and practice of establishing the diagnosis, prognosis, treatment, and prevention of disease. Medicine encompasses a variety of health care practices evolved to maintain and restore health by the prevention and treatment of illness. Contemporary medicine applies biomedical sciences, biomedical research, genetics, and medical technology to diagnose, treat, and prevent injury and disease, typically through pharmaceuticals or surgery, but also through therapies as diverse as psychotherapy, external splints and traction, medical devices, biologics, and ionizing radiation, amongst others.Medicine has been practiced since prehistoric times, during most of which it was an art (an area of skill and knowledge) frequently having connections to the religious and philosophical beliefs of local culture. For example, a medicine man would apply herbs and say prayers for healing, or an ancient philosopher and physician would apply bloodletting according to the theories of humorism. In recent centuries, since the advent of modern science, most medicine has become a combination of art and science (both basic and applied, under the umbrella of medical science). While stitching technique for sutures is an art learned through practice, the knowledge of what happens at the cellular and molecular level in the tissues being stitched arises through science.
Prescientific forms of medicine are now known as traditional medicine and folk medicine. They remain commonly used with, or instead of, scientific medicine and are thus called alternative medicine. As an example, evidence on the effectiveness of acupuncture is ""variable and inconsistent"" for any condition, but is generally safe when done by an appropriately trained practitioner. In contrast, alternative treatments outside the bounds not just of scientific medicine, but also outside the bounds of safety and efficacy are termed quackery. This can encompass an array of practices and practitioners, irrespective of whether they are prescientific (traditional medicine and folk medicine) or modern pseudo-scientific, including chiropractic which rejects modern scientific germ theory of disease (instead believing without evidence that human diseases are caused by invisible subluxation of the bones, predominantly of the spine and less so of other bones), with just over half of chiropractors also rejecting the science of immunization.


== Etymology ==
Medicine (UK:  (listen), US:  (listen)) is the science and practice of the diagnosis, prognosis, treatment, and prevention of disease. The word ""medicine"" is derived from Latin medicus, meaning ""a physician"".


== Clinical practice ==

Medical availability and clinical practice varies across the world due to regional differences in culture and technology. Modern scientific medicine is highly developed in the Western world, while in developing countries such as parts of Africa or Asia, the population may rely more heavily on traditional medicine with limited evidence and efficacy and no required formal training for practitioners. In the developed world, evidence-based medicine is not universally used in clinical practice; for example, a 2007 survey of literature reviews found that about 49% of the interventions lacked sufficient evidence to support either benefit or harm.In modern clinical practice, physicians and physician assistants personally assess patients in order to diagnose, prognose, treat, and prevent disease using clinical judgment. The doctor-patient relationship typically begins an interaction with an examination of the patient's medical history and medical record, followed by a medical interview and a physical examination. Basic diagnostic medical devices (e.g. stethoscope, tongue depressor) are typically used. After examination for signs and interviewing for symptoms, the doctor may order medical tests (e.g. blood tests), take a biopsy, or prescribe pharmaceutical drugs or other therapies. Differential diagnosis methods help to rule out conditions based on the information provided. During the encounter, properly informing the patient of all relevant facts is an important part of the relationship and the development of trust. The medical encounter is then documented in the medical record, which is a legal document in many jurisdictions. Follow-ups may be shorter but follow the same general procedure, and specialists follow a similar process. The diagnosis and treatment may take only a few minutes or a few weeks depending upon the complexity of the issue.
The components of the medical interview and encounter are:

Chief complaint (CC): the reason for the current medical visit. These are the 'symptoms.' They are in the patient's own words and are recorded along with the duration of each one. Also called 'chief concern' or 'presenting complaint'.
History of present illness (HPI): the chronological order of events of symptoms and further clarification of each symptom. Distinguishable from history of previous illness, often called past medical history (PMH). Medical history comprises HPI and PMH.
Current activity: occupation, hobbies, what the patient actually does.
Medications (Rx): what drugs the patient takes including prescribed, over-the-counter, and home remedies, as well as alternative and herbal medicines/herbal remedies. Allergies are also recorded.
Past medical history (PMH/PMHx): concurrent medical problems, past hospitalizations and operations, injuries, past infectious diseases or vaccinations, history of known allergies.
Social history (SH): birthplace, residences, marital history, social and economic status, habits (including diet, medications, tobacco, alcohol).
Family history (FH): listing of diseases in the family that may impact the patient. A family tree is sometimes used.
Review of systems (ROS) or systems inquiry: a set of additional questions to ask, which may be missed on HPI: a general enquiry (have you noticed any weight loss, change in sleep quality, fevers, lumps and bumps? etc.), followed by questions on the body's main organ systems (heart, lungs, digestive tract, urinary tract, etc.).The physical examination is the examination of the patient for medical signs of disease, which are objective and observable, in contrast to symptoms that are volunteered by the patient and not necessarily objectively observable. The healthcare provider uses sight, hearing, touch, and sometimes smell (e.g., in infection, uremia, diabetic ketoacidosis). Four actions are the basis of physical examination: inspection, palpation (feel), percussion (tap to determine resonance characteristics), and auscultation (listen), generally in that order although auscultation occurs prior to percussion and palpation for abdominal assessments.The clinical examination involves the study of:

Vital signs including height, weight, body temperature, blood pressure, pulse, respiration rate, and hemoglobin oxygen saturation
General appearance of the patient and specific indicators of disease (nutritional status, presence of jaundice, pallor or clubbing)
Skin
Head, eye, ear, nose, and throat (HEENT)
Cardiovascular (heart and blood vessels)
Respiratory (large airways and lungs)
Abdomen and rectum
Genitalia (and pregnancy if the patient is or could be pregnant)
Musculoskeletal (including spine and extremities)
Neurological (consciousness, awareness, brain, vision, cranial nerves, spinal cord and peripheral nerves)
Psychiatric (orientation, mental state, mood, evidence of abnormal perception or thought).It is to likely focus on areas of interest highlighted in the medical history and may not include everything listed above.
The treatment plan may include ordering additional medical laboratory tests and medical imaging studies, starting therapy, referral to a specialist, or watchful observation. Follow-up may be advised. Depending upon the health insurance plan and the managed care system, various forms of ""utilization review"", such as prior authorization of tests, may place barriers on accessing expensive services.The medical decision-making (MDM) process involves analysis and synthesis of all the above data to come up with a list of possible diagnoses (the differential diagnoses), along with an idea of what needs to be done to obtain a definitive diagnosis that would explain the patient's problem.
On subsequent visits, the process may be repeated in an abbreviated manner to obtain any new history, symptoms, physical findings, and lab or imaging results or specialist consultations.


== Institutions ==

Contemporary medicine is in general conducted within health care systems. Legal, credentialing and financing frameworks are established by individual governments, augmented on occasion by international organizations, such as churches. The characteristics of any given health care system have significant impact on the way medical care is provided.
From ancient times, Christian emphasis on practical charity gave rise to the development of systematic nursing and hospitals and the Catholic Church today remains the largest non-government provider of medical services in the world. Advanced industrial countries (with the exception of the United States) and many developing countries provide medical services through a system of universal health care that aims to guarantee care for all through a single-payer health care system, or compulsory private or co-operative health insurance. This is intended to ensure that the entire population has access to medical care on the basis of need rather than ability to pay. Delivery may be via private medical practices or by state-owned hospitals and clinics, or by charities, most commonly by a combination of all three.
Most tribal societies provide no guarantee of healthcare for the population as a whole. In such societies, healthcare is available to those that can afford to pay for it or have self-insured it (either directly or as part of an employment contract) or who may be covered by care financed by the government or tribe directly.

Transparency of information is another factor defining a delivery system. Access to information on conditions, treatments, quality, and pricing greatly affects the choice by patients/consumers and, therefore, the incentives of medical professionals. While the US healthcare system has come under fire for lack of openness, new legislation may encourage greater openness. There is a perceived tension between the need for transparency on the one hand and such issues as patient confidentiality and the possible exploitation of information for commercial gain on the other.


=== Delivery ===

Provision of medical care is classified into primary, secondary, and tertiary care categories.

Primary care medical services are provided by physicians, physician assistants, nurse practitioners, or other health professionals who have first contact with a patient seeking medical treatment or care. These occur in physician offices, clinics, nursing homes, schools, home visits, and other places close to patients. About 90% of medical visits can be treated by the primary care provider. These include treatment of acute and chronic illnesses, preventive care and health education for all ages and both sexes.
Secondary care medical services are provided by medical specialists in their offices or clinics or at local community hospitals for a patient referred by a primary care provider who first diagnosed or treated the patient. Referrals are made for those patients who required the expertise or procedures performed by specialists. These include both ambulatory care and inpatient services, Emergency departments, intensive care medicine, surgery services, physical therapy, labor and delivery, endoscopy units, diagnostic laboratory and medical imaging services, hospice centers, etc. Some primary care providers may also take care of hospitalized patients and deliver babies in a secondary care setting.
Tertiary care medical services are provided by specialist hospitals or regional centers equipped with diagnostic and treatment facilities not generally available at local hospitals. These include trauma centers, burn treatment centers, advanced neonatology unit services, organ transplants, high-risk pregnancy, radiation oncology, etc.
Modern medical care also depends on information – still delivered in many health care settings on paper records, but increasingly nowadays by electronic means.
In low-income countries, modern healthcare is often too expensive for the average person. International healthcare policy researchers have advocated that ""user fees"" be removed in these areas to ensure access, although even after removal, significant costs and barriers remain.Separation of prescribing and dispensing is a practice in medicine and pharmacy in which the physician who provides a medical prescription is independent from the  pharmacist who provides the prescription drug. In the Western world there are centuries of tradition for separating pharmacists from physicians. In Asian countries, it is traditional for physicians to also provide drugs.


== Branches ==

Working together as an interdisciplinary team, many highly trained health professionals besides medical practitioners are involved in the delivery of modern health care. Examples include: nurses, emergency medical technicians and paramedics, laboratory scientists, pharmacists, podiatrists, physiotherapists, respiratory therapists, speech therapists, occupational therapists, radiographers, dietitians, and bioengineers, medical physics, surgeons, surgeon's assistant, surgical technologist.
The scope and sciences underpinning human medicine overlap many other fields. Dentistry, while considered by some a separate discipline from medicine, is a medical field.
A patient admitted to the hospital is usually under the care of a specific team based on their main presenting problem, e.g., the cardiology team, who then may interact with other specialties, e.g., surgical, radiology, to help diagnose or treat the main problem or any subsequent complications/developments.
Physicians have many specializations and subspecializations into certain branches of medicine, which are listed below. There are variations from country to country regarding which specialties certain subspecialties are in.
The main branches of medicine are:

Basic sciences of medicine; this is what every physician is educated in, and some return to in biomedical research
Medical specialties
Interdisciplinary fields, where different medical specialties are mixed to function in certain occasions.


=== Basic sciences ===
Anatomy is the study of the physical structure of organisms. In contrast to macroscopic or gross anatomy, cytology and histology are concerned with microscopic structures.
Biochemistry is the study of the chemistry taking place in living organisms, especially the structure and function of their chemical components.
Biomechanics is the study of the structure and function of biological systems by means of the methods of Mechanics.
Biostatistics is the application of statistics to biological fields in the broadest sense. A knowledge of biostatistics is essential in the planning, evaluation, and interpretation of medical research. It is also fundamental to epidemiology and evidence-based medicine.
Biophysics is an interdisciplinary science that uses the methods of physics and physical chemistry to study biological systems.
Cytology is the microscopic study of individual cells.
Embryology is the study of the early development of organisms.
Endocrinology is the study of hormones and their effect throughout the body of animals.
Epidemiology is the study of the demographics of disease processes, and includes, but is not limited to, the study of epidemics.
Genetics is the study of genes, and their role in biological inheritance.
Histology is the study of the structures of biological tissues by light microscopy, electron microscopy and immunohistochemistry.
Immunology is the study of the immune system, which includes the innate and adaptive immune system in humans, for example.
Medical physics is the study of the applications of physics principles in medicine.
Microbiology is the study of microorganisms, including protozoa, bacteria, fungi, and viruses.
Molecular biology is the study of molecular underpinnings of the process of replication, transcription and translation of the genetic material.
Neuroscience includes those disciplines of science that are related to the study of the nervous system. A main focus of neuroscience is the biology and physiology of the human brain and spinal cord. Some related clinical specialties include neurology, neurosurgery and psychiatry.
Nutrition science (theoretical focus) and dietetics (practical focus) is the study of the relationship of food and drink to health and disease, especially in determining an optimal diet. Medical nutrition therapy is done by dietitians and is prescribed for diabetes, cardiovascular diseases, weight and eating disorders, allergies, malnutrition, and neoplastic diseases.
Pathology as a science is the study of disease—the causes, course, progression and resolution thereof.
Pharmacology is the study of drugs and their actions.
Gynecology is the study of female reproductive system.
Photobiology is the study of the interactions between non-ionizing radiation and living organisms.
Physiology is the study of the normal functioning of the body and the underlying regulatory mechanisms.
Radiobiology is the study of the interactions between ionizing radiation and living organisms.
Toxicology is the study of hazardous effects of drugs and poisons.


=== Specialties ===

In the broadest meaning of ""medicine"", there are many different specialties. In the UK, most specialities have their own body or college, which has its own entrance examination. These are collectively known as the Royal Colleges, although not all currently use the term ""Royal"". The development of a speciality is often driven by new technology (such as the development of effective anaesthetics) or ways of working (such as emergency departments); the new specialty leads to the formation of a unifying body of doctors and the prestige of administering their own examination.
Within medical circles, specialities usually fit into one of two broad categories: ""Medicine"" and ""Surgery."" ""Medicine"" refers to the practice of non-operative medicine, and most of its subspecialties require preliminary training in Internal Medicine. In the UK, this was traditionally evidenced by passing the examination for the Membership of the Royal College of Physicians (MRCP) or the equivalent college in Scotland or Ireland. ""Surgery"" refers to the practice of operative medicine, and most subspecialties in this area require preliminary training in General Surgery, which in the UK leads to membership of the Royal College of Surgeons of England (MRCS). At present, some specialties of medicine do not fit easily into either of these categories, such as radiology, pathology, or anesthesia. Most of these have branched from one or other of the two camps above; for example anaesthesia developed first as a faculty of the Royal College of Surgeons (for which MRCS/FRCS would have been required) before becoming the Royal College of Anaesthetists and membership of the college is attained by sitting for the examination of the Fellowship of the Royal College of Anesthetists (FRCA).


==== Surgical specialty ====

Surgery is an ancient medical specialty that uses operative manual and instrumental techniques on a patient to investigate or treat a pathological condition such as disease or injury, to help improve bodily function or appearance or to repair unwanted ruptured areas (for example, a perforated ear drum). Surgeons must also manage pre-operative, post-operative, and potential surgical candidates on the hospital wards. Surgery has many sub-specialties, including general surgery, ophthalmic surgery, cardiovascular surgery, colorectal surgery, neurosurgery, oral and maxillofacial surgery, oncologic surgery, orthopedic surgery, otolaryngology, plastic surgery, podiatric surgery, transplant surgery, trauma surgery, urology, vascular surgery, and pediatric surgery. In some centers, anesthesiology is part of the division of surgery (for historical and logistical reasons), although it is not a surgical discipline. Other medical specialties may employ surgical procedures, such as ophthalmology and dermatology, but are not considered surgical sub-specialties per se.
Surgical training in the U.S. requires a minimum of five years of residency after medical school. Sub-specialties of surgery often require seven or more years. In addition, fellowships can last an additional one to three years. Because post-residency fellowships can be competitive, many trainees devote two additional years to research. Thus in some cases surgical training will not finish until more than a decade after medical school. Furthermore, surgical training can be very difficult and time-consuming.


==== Internal specialty ====

Internal medicine is the medical specialty dealing with the prevention, diagnosis, and treatment of adult diseases. According to some sources, an emphasis on internal structures is implied. In North America, specialists in internal medicine are commonly called ""internists."" Elsewhere, especially in Commonwealth nations, such specialists are often called physicians. These terms, internist or physician (in the narrow sense, common outside North America), generally exclude practitioners of gynecology and obstetrics, pathology, psychiatry, and especially surgery and its subspecialities.
Because their patients are often seriously ill or require complex investigations, internists do much of their work in hospitals. Formerly, many internists were not subspecialized; such general physicians would see any complex nonsurgical problem; this style of practice has become much less common. In modern urban practice, most internists are subspecialists: that is, they generally limit their medical practice to problems of one organ system or to one particular area of medical knowledge. For example, gastroenterologists and nephrologists specialize respectively in diseases of the gut and the kidneys.In the Commonwealth of Nations and some other countries, specialist pediatricians and geriatricians are also described as specialist physicians (or internists) who have subspecialized by age of patient rather than by organ system. Elsewhere, especially in North America, general pediatrics is often a form of primary care.
There are many subspecialities (or subdisciplines) of internal medicine:

Training in internal medicine (as opposed to surgical training), varies considerably across the world: see the articles on medical education and physician for more details. In North America, it requires at least three years of residency training after medical school, which can then be followed by a one- to three-year fellowship in the subspecialties listed above. In general, resident work hours in medicine are less than those in surgery, averaging about 60 hours per week in the US. This difference does not apply in the UK where all doctors are now required by law to work less than 48 hours per week on average.


==== Diagnostic specialties ====
Clinical laboratory sciences are the clinical diagnostic services that apply laboratory techniques to diagnosis and management of patients. In the United States, these services are supervised by a pathologist. The personnel that work in these medical laboratory departments are technically trained staff who do not hold medical degrees, but who usually hold an undergraduate medical technology degree, who actually perform the tests, assays, and procedures needed for providing the specific services. Subspecialties include transfusion medicine, cellular pathology, clinical chemistry, hematology, clinical microbiology and clinical immunology.
Pathology as a medical specialty is the branch of medicine that deals with the study of diseases and the morphologic, physiologic changes produced by them. As a diagnostic specialty, pathology can be considered the basis of modern scientific medical knowledge and plays a large role in evidence-based medicine. Many modern molecular tests such as flow cytometry, polymerase chain reaction (PCR), immunohistochemistry, cytogenetics, gene rearrangements studies and fluorescent in situ hybridization (FISH) fall within the territory of pathology.
Diagnostic radiology is concerned with imaging of the body, e.g. by x-rays, x-ray computed tomography, ultrasonography, and nuclear magnetic resonance tomography. Interventional radiologists can access areas in the body under imaging for an intervention or diagnostic sampling.
Nuclear medicine is concerned with studying human organ systems by administering radiolabelled substances (radiopharmaceuticals) to the body, which can then be imaged outside the body by a gamma camera or a PET scanner. Each radiopharmaceutical consists of two parts: a tracer that is specific for the function under study (e.g., neurotransmitter pathway, metabolic pathway, blood flow, or other), and a radionuclide (usually either a gamma-emitter or a positron emitter). There is a degree of overlap between nuclear medicine and radiology, as evidenced by the emergence of combined devices such as the PET/CT scanner.
Clinical neurophysiology is concerned with testing the physiology or function of the central and peripheral aspects of the nervous system. These kinds of tests can be divided into recordings of: (1) spontaneous or continuously running electrical activity, or (2) stimulus evoked responses. Subspecialties include electroencephalography, electromyography, evoked potential, nerve conduction study and polysomnography. Sometimes these tests are performed by techs without a medical degree, but the interpretation of these tests is done by a medical professional.


==== Other major specialties ====
The following are some major medical specialties that do not directly fit into any of the above-mentioned groups:

Anesthesiology (also known as anaesthetics): concerned with the perioperative management of the surgical patient. The anesthesiologist's role during surgery is to prevent derangement in the vital organs' (i.e. brain, heart, kidneys) functions and postoperative pain. Outside of the operating room, the anesthesiology physician also serves the same function in the labor and delivery ward, and some are specialized in critical medicine.
Dermatology is concerned with the skin and its diseases. In the UK, dermatology is a subspecialty of general medicine.
Emergency medicine is concerned with the diagnosis and treatment of acute or life-threatening conditions, including trauma, surgical, medical, pediatric, and psychiatric emergencies.
Family medicine, family practice, general practice or primary care is, in many countries, the first port-of-call for patients with non-emergency medical problems. Family physicians often provide services across a broad range of settings including office based practices, emergency department coverage, inpatient care, and nursing home care.
Obstetrics and gynecology (often abbreviated as OB/GYN (American English) or Obs & Gynae (British English)) are concerned respectively with childbirth and the female reproductive and associated organs. Reproductive medicine and fertility medicine are generally practiced by gynecological specialists.
Medical genetics is concerned with the diagnosis and management of hereditary disorders.
Neurology is concerned with diseases of the nervous system. In the UK, neurology is a subspecialty of general medicine.
Ophthalmology is exclusively concerned with the eye and ocular adnexa, combining conservative and surgical therapy.
Pediatrics (AE) or paediatrics (BE) is devoted to the care of infants, children, and adolescents. Like internal medicine, there are many pediatric subspecialties for specific age ranges, organ systems, disease classes, and sites of care delivery.
Pharmaceutical medicine is the medical scientific discipline concerned with the discovery, development, evaluation, registration, monitoring and medical aspects of marketing of medicines for the benefit of patients and public health.
Physical medicine and rehabilitation (or physiatry) is concerned with functional improvement after injury, illness, or congenital disorders.
Podiatric medicine is the study of, diagnosis, and medical & surgical treatment of disorders of the foot, ankle, lower limb, hip and lower back.
Psychiatry is the branch of medicine concerned with the bio-psycho-social study of the etiology, diagnosis, treatment and prevention of cognitive, perceptual, emotional and behavioral disorders. Related non-medical fields include psychotherapy and clinical psychology.
Preventive medicine is the branch of medicine concerned with preventing disease.
Community health or public health is an aspect of health services concerned with threats to the overall health of a community based on population health analysis.


=== Interdisciplinary fields ===
Some interdisciplinary sub-specialties of medicine include:

Aerospace medicine deals with medical problems related to flying and space travel.
Addiction medicine deals with the treatment of addiction.
Medical ethics deals with ethical and moral principles that apply values and judgments to the practice of medicine.
Biomedical Engineering is a field dealing with the application of engineering principles to medical practice.
Clinical pharmacology is concerned with how systems of therapeutics interact with patients.
Conservation medicine studies the relationship between human and animal health, and environmental conditions. Also known as ecological medicine, environmental medicine, or medical geology.
Disaster medicine deals with medical aspects of emergency preparedness, disaster mitigation and management.
Diving medicine (or hyperbaric medicine) is the prevention and treatment of diving-related problems.
Evolutionary medicine is a perspective on medicine derived through applying evolutionary theory.
Forensic medicine deals with medical questions in legal context, such as determination of the time and cause of death, type of weapon used to inflict trauma, reconstruction of the facial features using remains of deceased (skull) thus aiding identification.
Gender-based medicine studies the biological and physiological differences between the human sexes and how that affects differences in disease.
Hospice and Palliative Medicine is a relatively modern branch of clinical medicine that deals with pain and symptom relief and emotional support in patients with terminal illnesses including cancer and heart failure.
Hospital medicine is the general medical care of hospitalized patients. Physicians whose primary professional focus is hospital medicine are called hospitalists in the United States and Canada. The term Most Responsible Physician (MRP) or attending physician is also used interchangeably to describe this role.
Laser medicine involves the use of lasers in the diagnostics or treatment of various conditions.
Medical humanities includes the humanities (literature, philosophy, ethics, history and religion), social science (anthropology, cultural studies, psychology, sociology), and the arts (literature, theater, film, and visual arts) and their application to medical education and practice.
Health informatics is a relatively recent field that deal with the application of computers and information technology to medicine.
Nosology is the classification of diseases for various purposes.
Nosokinetics is the science/subject of measuring and modelling the process of care in health and social care systems.
Occupational medicine is the provision of health advice to organizations and individuals to ensure that the highest standards of health and safety at work can be achieved and maintained.
Pain management (also called pain medicine, or algiatry) is the medical discipline concerned with the relief of pain.
Pharmacogenomics is a form of individualized medicine.
Podiatric medicine is the study of, diagnosis, and medical treatment of disorders of the foot, ankle, lower limb, hip and lower back.
Sexual medicine is concerned with diagnosing, assessing and treating all disorders related to sexuality.
Sports medicine deals with the treatment and prevention and rehabilitation of sports/exercise injuries such as muscle spasms, muscle tears, injuries to ligaments (ligament tears or ruptures) and their repair in athletes, amateur and professional.
Therapeutics is the field, more commonly referenced in earlier periods of history, of the various remedies that can be used to treat disease and promote health.
Travel medicine or emporiatrics deals with health problems of international travelers or travelers across highly different environments.
Tropical medicine deals with the prevention and treatment of tropical diseases. It is studied separately in temperate climates where those diseases are quite unfamiliar to medical practitioners and their local clinical needs.
Urgent care focuses on delivery of unscheduled, walk-in care outside of the hospital emergency department for injuries and illnesses that are not severe enough to require care in an emergency department. In some jurisdictions this function is combined with the emergency department.
Veterinary medicine; veterinarians apply similar techniques as physicians to the care of animals.
Wilderness medicine entails the practice of medicine in the wild, where conventional medical facilities may not be available.
Many other health science fields, e.g. dietetics


== Education and legal controls ==

Medical education and training varies around the world. It typically involves entry level education at a university medical school, followed by a period of supervised practice or internship, or residency. This can be followed by postgraduate vocational training. A variety of teaching methods have been employed in medical education, still itself a focus of active research. In Canada and the United States of America, a Doctor of Medicine degree, often abbreviated M.D., or a Doctor of Osteopathic Medicine degree, often abbreviated as D.O. and unique to the United States, must be completed in and delivered from a recognized university.
Since knowledge, techniques, and medical technology continue to evolve at a rapid rate, many regulatory authorities require continuing medical education. Medical practitioners upgrade their knowledge in various ways, including medical journals, seminars, conferences, and online programs.  A database of objectives covering medical knowledge, as suggested by national societies across the United States, can be searched at http://data.medobjectives.marian.edu/.

In most countries, it is a legal requirement for a medical doctor to be licensed or registered. In general, this entails a medical degree from a university and accreditation by a medical board or an equivalent national organization, which may ask the applicant to pass exams. This restricts the considerable legal authority of the medical profession to physicians that are trained and qualified by national standards. It is also intended as an assurance to patients and as a safeguard against charlatans that practice inadequate medicine for personal gain. While the laws generally require medical doctors to be trained in ""evidence based"", Western, or Hippocratic Medicine, they are not intended to discourage different paradigms of health.
In the European Union, the profession of doctor of medicine is regulated. A profession is said to be regulated when access and exercise is subject to the possession of a specific professional qualification.
The regulated professions database contains a list of regulated professions for doctor of medicine in the EU member states, EEA countries and Switzerland. This list is covered by the Directive 2005/36/EC.
Doctors who are negligent or intentionally harmful in their care of patients can face charges of medical malpractice and be subject to civil, criminal, or professional sanctions.


== Medical ethics ==

Medical ethics is a system of moral principles that apply values and judgments to the practice of medicine. As a scholarly discipline, medical ethics encompasses its practical application in clinical settings as well as work on its history, philosophy, theology, and sociology. Six of the values that commonly apply to medical ethics discussions are:

autonomy – the patient has the right to refuse or choose their treatment. (Voluntas aegroti suprema lex.)
beneficence – a practitioner should act in the best interest of the patient. (Salus aegroti suprema lex.)
justice – concerns the distribution of scarce health resources, and the decision of who gets what treatment (fairness and equality).
non-maleficence – ""first, do no harm"" (primum non-nocere).
respect for persons – the patient (and the person treating the patient) have the right to be treated with dignity.
truthfulness and honesty – the concept of informed consent has increased in importance since the historical events of the Doctors' Trial of the Nuremberg trials, Tuskegee syphilis experiment, and others.Values such as these do not give answers as to how to handle a particular situation, but provide a useful framework for understanding conflicts. When moral values are in conflict, the result may be an ethical dilemma or crisis. Sometimes, no good solution to a dilemma in medical ethics exists, and occasionally, the values of the medical community (i.e., the hospital and its staff) conflict with the values of the individual patient, family, or larger non-medical community. Conflicts can also arise between health care providers, or among family members. For example, some argue that the principles of autonomy and beneficence clash when patients refuse blood transfusions, considering them life-saving; and truth-telling was not emphasized to a large extent before the HIV era.


== History ==


=== Ancient world ===
Prehistoric medicine incorporated plants (herbalism), animal parts, and minerals. In many cases these materials were used ritually as magical substances by priests, shamans, or medicine men. Well-known spiritual systems include animism (the notion of inanimate objects having spirits), spiritualism (an appeal to gods or communion with ancestor spirits); shamanism (the vesting of an individual with mystic powers); and divination (magically obtaining the truth). The field of medical anthropology examines the ways in which culture and society are organized around or impacted by issues of health, health care and related issues.
Early records on medicine have been discovered from ancient Egyptian medicine, Babylonian Medicine, Ayurvedic medicine (in the Indian subcontinent), classical Chinese medicine (predecessor to the modern traditional Chinese medicine), and ancient Greek medicine and Roman medicine.
In Egypt, Imhotep (3rd millennium BCE) is the first physician in history known by name. The oldest Egyptian medical text is the Kahun Gynaecological Papyrus from around 2000 BCE, which describes gynaecological diseases. The Edwin Smith Papyrus dating back to 1600 BCE is an early work on surgery, while the Ebers Papyrus dating back to 1500 BCE is akin to a textbook on medicine.In China, archaeological evidence of medicine in Chinese dates back to the Bronze Age Shang Dynasty, based on seeds for herbalism and tools presumed to have been used for surgery. The Huangdi Neijing, the progenitor of Chinese medicine, is a medical text written beginning in the 2nd century BCE and compiled in the 3rd century.In India, the surgeon Sushruta described numerous surgical operations, including the earliest forms of plastic surgery. Earliest records of dedicated hospitals come from Mihintale in Sri Lanka where evidence of dedicated medicinal treatment facilities for patients are found.

In Greece, the Greek physician Hippocrates, the ""father of modern medicine"", laid the foundation for a rational approach to medicine. Hippocrates introduced the Hippocratic Oath for physicians, which is still relevant and in use today, and was the first to categorize illnesses as acute, chronic, endemic and epidemic, and use terms such as, ""exacerbation, relapse, resolution, crisis, paroxysm, peak, and convalescence"". The Greek physician Galen was also one of the greatest surgeons of the ancient world and performed many audacious operations, including brain and eye surgeries. After the fall of the Western Roman Empire and the onset of the Early Middle Ages, the Greek tradition of medicine went into decline in Western Europe, although it continued uninterrupted in the Eastern Roman (Byzantine) Empire.
Most of our knowledge of ancient Hebrew medicine during the 1st millennium BC comes from the Torah, i.e. the Five Books of Moses, which contain various health related laws and rituals. The Hebrew contribution to the development of modern medicine started in the Byzantine Era, with the physician Asaph the Jew.


=== Middle Ages ===

The concept of hospital as institution to offer medical care and possibility of a cure for the patients due to the ideals of Christian charity, rather than just merely a place to die, appeared in the Byzantine Empire.Although the concept of uroscopy was known to Galen, he did not see the importance of using it to localize the disease. It was under the Byzantines with physicians such of Theophilus Protospatharius that they realized the potential in uroscopy to determine disease in a time when no microscope or stethoscope existed. That practice eventually spread to the rest of Europe.After 750 CE, the Muslim world had the works of Hippocrates, Galen and Sushruta translated into Arabic, and Islamic physicians engaged in some significant medical research. Notable Islamic medical pioneers include the Persian polymath, Avicenna, who, along with Imhotep and Hippocrates, has also been called the ""father of medicine"". He wrote The Canon of Medicine which became a standard medical text at many medieval European universities, considered one of the most famous books in the history of medicine. Others include Abulcasis, Avenzoar, Ibn al-Nafis, and Averroes. Persian  physician Rhazes was one of the first to question the Greek theory of humorism, which nevertheless remained influential in both medieval Western and medieval Islamic medicine. Some volumes of Rhazes's work Al-Mansuri, namely ""On Surgery"" and ""A General Book on Therapy"", became part of the medical curriculum in European universities. Additionally, he has been described as a doctor's doctor, the father of pediatrics, and a pioneer of ophthalmology. For example, he was the first to recognize the reaction of the eye's pupil to light. The Persian Bimaristan hospitals were an early example of public hospitals.In Europe, Charlemagne decreed that a hospital should be attached to each cathedral and monastery and the historian Geoffrey Blainey likened the activities of the Catholic Church in health care during the Middle Ages to an early version of a welfare state: ""It conducted hospitals for the old and orphanages for the young; hospices for the sick of all ages; places for the lepers; and hostels or inns where pilgrims could buy a cheap bed and meal"". It supplied food to the population during famine and distributed food to the poor. This welfare system the church funded through collecting taxes on a large scale and possessing large farmlands and estates. The Benedictine order was noted for setting up hospitals and infirmaries in their monasteries, growing medical herbs and becoming the chief medical care givers of their districts, as at the great Abbey of Cluny. The Church also established a network of cathedral schools and universities where medicine was studied. The Schola Medica Salernitana in Salerno, looking to the learning of Greek and Arab physicians, grew to be the finest medical school in Medieval Europe.

However, the fourteenth and fifteenth century Black Death devastated both the Middle East and Europe, and it has even been argued that Western Europe was generally more effective in recovering from the pandemic than the Middle East. In the early modern period, important early figures in medicine and anatomy emerged in Europe, including Gabriele Falloppio and William Harvey.
The major shift in medical thinking was the gradual rejection, especially during the Black Death in the 14th and 15th centuries, of what may be called the 'traditional authority' approach to science and medicine. This was the notion that because some prominent person in the past said something must be so, then that was the way it was, and anything one observed to the contrary was an anomaly (which was paralleled by a similar shift in European society in general – see Copernicus's rejection of Ptolemy's theories on astronomy). Physicians like Vesalius improved upon or disproved some of the theories from the past. The main tomes used both by medicine students and expert physicians were Materia Medica and Pharmacopoeia.
Andreas Vesalius was the author of De humani corporis fabrica, an important book on human anatomy. Bacteria and microorganisms were first observed with a microscope by Antonie van Leeuwenhoek in 1676, initiating the scientific field microbiology. Independently from Ibn al-Nafis, Michael Servetus rediscovered the pulmonary circulation, but this discovery did not reach the public because it was written down for the first time in the ""Manuscript of Paris"" in 1546, and later published in the theological work for which he paid with his life in 1553. Later this was described by Renaldus Columbus and Andrea Cesalpino. Herman Boerhaave is sometimes referred to as a ""father of physiology"" due to his exemplary teaching in Leiden and textbook 'Institutiones medicae' (1708). Pierre Fauchard has been called ""the father of modern dentistry"".


=== Modern ===

Veterinary medicine was, for the first time, truly separated from human medicine in 1761, when the French veterinarian Claude Bourgelat founded the world's first veterinary school in Lyon, France. Before this, medical doctors treated both humans and other animals.
Modern scientific biomedical research (where results are testable and reproducible) began to replace early Western traditions based on herbalism, the Greek ""four humours"" and other such pre-modern notions. The modern era really began with Edward Jenner's discovery of the smallpox vaccine at the end of the 18th century (inspired by the method of inoculation earlier practiced in Asia), Robert Koch's discoveries around 1880 of the transmission of disease by bacteria, and then the discovery of antibiotics around 1900.
The post-18th century modernity period brought more groundbreaking researchers from Europe. From Germany and Austria, doctors Rudolf Virchow, Wilhelm Conrad Röntgen, Karl Landsteiner and Otto Loewi made notable contributions. In the United Kingdom, Alexander Fleming, Joseph Lister, Francis Crick and Florence Nightingale are considered important. Spanish doctor Santiago Ramón y Cajal is considered the father of modern neuroscience.
From New Zealand and Australia came Maurice Wilkins, Howard Florey, and Frank Macfarlane Burnet.
Others that did significant work include William Williams Keen, William Coley, James D. Watson (United States); Salvador Luria (Italy); Alexandre Yersin (Switzerland); Kitasato Shibasaburō (Japan); Jean-Martin Charcot, Claude Bernard, Paul Broca (France); Adolfo Lutz (Brazil); Nikolai Korotkov (Russia); Sir William Osler (Canada); and Harvey Cushing (United States).

As science and technology developed, medicine became more reliant upon medications. Throughout history and in Europe right until the late 18th century, not only animal and plant products were used as medicine, but also human body parts and fluids. Pharmacology developed in part from herbalism and some drugs are still derived from plants (atropine, ephedrine, warfarin, aspirin, digoxin, vinca alkaloids, taxol, hyoscine, etc.). Vaccines were discovered by Edward Jenner and Louis Pasteur.
The first antibiotic was arsphenamine (Salvarsan) discovered by Paul Ehrlich in 1908 after he observed that bacteria took up toxic dyes that human cells did not. The first major class of antibiotics was the sulfa drugs, derived by German chemists originally from azo dyes.
Pharmacology has become increasingly sophisticated; modern biotechnology allows drugs targeted towards specific physiological processes to be developed, sometimes designed for compatibility with the body to reduce side-effects. Genomics and knowledge of human genetics and human evolution is having increasingly significant influence on medicine, as the causative genes of most monogenic genetic disorders have now been identified, and the development of techniques in molecular biology, evolution, and genetics are influencing medical technology, practice and decision-making.
Evidence-based medicine is a contemporary movement to establish the most effective algorithms of practice (ways of doing things) through the use of systematic reviews and meta-analysis. The movement is facilitated by modern global information science, which allows as much of the available evidence as possible to be collected and analyzed according to standard protocols that are then disseminated to healthcare providers. The Cochrane Collaboration leads this movement. A 2001 review of 160 Cochrane systematic reviews revealed that, according to two readers, 21.3% of the reviews concluded insufficient evidence, 20% concluded evidence of no effect, and 22.5% concluded positive effect.


== Quality, efficiency, and access ==
Evidence-based medicine, prevention of medical error (and other ""iatrogenesis""), and avoidance of unnecessary health care are a priority in modern medical systems. These topics generate significant political and public policy attention, particularly in the United States where healthcare is regarded as excessively costly but population health metrics lag similar nations.Globally, many developing countries lack access to care and access to medicines. As of 2015, most wealthy developed countries provide health care to all citizens, with a few exceptions such as the United States where lack of health insurance coverage may limit access.


== Traditional medicine ==

The World Health Organization (WHO) defines traditional medicine as ""the sum total of the knowledge, skills, and practices based on the theories, beliefs, and experiences indigenous to different cultures, whether explicable or not, used in the maintenance of health as well as in the prevention, diagnosis, improvement or treatment of physical and mental illness."" Practices known as traditional medicines include Ayurveda, Siddha medicine, Unani, ancient Iranian medicine, Irani, Islamic medicine, traditional Chinese medicine, traditional Korean medicine, acupuncture, Muti, Ifá, and traditional African medicine.
The WHO stated that ""inappropriate use of traditional medicines or practices can have negative or dangerous effects"" and that ""further research is needed to ascertain the efficacy and safety"" of several of the practices and medicinal plants used by traditional medicine systems. As example, Indian Medical Association regard traditional medicine practices, such as Ayurveda and Siddha medicine, as quackery. Practitioners of traditional medicine are not authorized to practice medicine in India unless trained at a qualified medical institution, registered with the government, and listed as registered physicians annually in The Gazette of India. Identifying practitioners of traditional medicine, the Supreme Court of India stated in 2018 that ""unqualified, untrained quacks are posing a great risk to the entire society and playing with the lives of people without having the requisite training and education in the science from approved institutions"".


== See also ==


== References =="
"Medicalization or medicalisation (see spelling differences) is the process by which human conditions and problems come to be defined and treated as medical conditions, and thus become the subject of medical study, diagnosis, prevention, or treatment. Medicalization can be driven by new evidence or hypotheses about conditions; by changing social attitudes or economic considerations; or by the development of new medications or treatments.
Medicalization is studied from a sociologic perspective in terms of the role and power of professionals, patients, and corporations, and also for its implications for ordinary people whose self-identity and life decisions may depend on the prevailing concepts of health and illness. Once a condition is classified as medical, a medical model of disability tends to be used in place of a social model. Medicalization may also be termed ""pathologization"" or (pejoratively) ""disease mongering"". Since medicalization is the social process through which a condition becomes a medical disease in need of treatment, medicalization may be viewed as a benefit to human society. According to this view, the identification of a condition as a disease will lead to the treatment of certain symptoms and conditions, which will improve overall quality of life.


== Development of the concept ==
The concept of medicalization was devised by sociologists to explain how medical knowledge is applied to behaviors which are not self-evidently medical or biological. The term medicalization entered the sociology literature in the 1970s in the works of Irving Zola, Peter Conrad and Thomas Szasz, among others. According to Dr. Cassell's book, The Nature of Suffering and the Goals of Medicine (2004), the expansion of medical social control is being justified as a means of explaining deviance. These sociologists viewed medicalization as a form of social control in which medical authority expanded into domains of everyday existence, and they rejected medicalization in the name of liberation. This critique was embodied in works such as Conrad's ""The discovery of hyperkinesis: notes on medicalization of deviance"", published in 1973 (hyperkinesis was the term then used to describe what we might now call ADHD). Nevertheless, opium was used to pacify children in ancient Egypt before 2000 BC.
These sociologists did not believe medicalization to be a new phenomenon, arguing that medical authorities had always been concerned with social behavior and traditionally functioned as agents of social control (Foucault, 1965; Szasz,1970; Rosen). However, these authors took the view that increasingly sophisticated technology had extended the potential reach of medicalization as a form of social control, especially in terms of ""psychotechnology"" (Chorover,1973).
In the 1975 book Limits to medicine: Medical nemesis (1975), Ivan Illich put forth one of the earliest uses of the term ""medicalization"". Illich, a philosopher, argued that the medical profession harms people through iatrogenesis, a process in which illness and social problems increase due to medical intervention. Illich saw iatrogenesis occurring on three levels: the clinical, involving serious side effects worse than the original condition; the social, whereby the general public is made docile and reliant on the medical profession to cope with life in their society; and the structural, whereby the idea of aging and dying as medical illnesses effectively ""medicalized"" human life and left individuals and societies less able to deal with these ""natural"" processes.
The concept of medicalization dovetailed with some aspects of the 1970s feminist movement. Critics such as Ehrenreich and English (1978) argued that women's bodies were being medicalized by the predominantly male medical profession. Menstruation and pregnancy had come to be seen as medical problems requiring interventions such as hysterectomies.
Marxists such as Vicente Navarro (1980) linked medicalization to an oppressive capitalist society. They argued that medicine disguised the underlying causes of disease, such as social inequality and poverty, and instead presented health as an individual issue. Others examined the power and prestige of the medical profession, including the use of terminology to mystify and of professional rules to exclude or subordinate others.
Tiago Correia (2017) offers an alternative perspective on medicalization. He argues that medicalization needs to be detached from biomedicine to overcome much of the criticism it has faced, and to protect its value in contemporary sociological debates. Building on Gadamer's hermeneutical view of medicine, he focuses on medicine's common traits, regardless of empirical differences in both time and space. Medicalization and social control are viewed as distinct analytical dimensions that in practice may or may not overlap. Correia contends that the idea of ""making things medical"" needs to include all forms of medical knowledge in a global society, not simply those forms linked to the established (bio)medical professions. Looking at ""knowledge"", beyond the confines of professional boundaries, may help us understand the multiplicity of ways in which medicalization can exist in different times and societies, and allow contemporary societies to avoid such pitfalls as ""demedicalization"" (through a turn towards complementary and alternative medicine) on the one hand, or the over-rapid and unregulated adoption of biomedical medicine in non-western societies on the other. The challenge is to determine what medical knowledge is present, and how it is being used to medicalize behaviors and symptoms.


== Professionals, patients, corporations and society ==
Several decades on the definition of medicalization is complicated, if for no other reason than because the term is so widely used. Many contemporary critics position pharmaceutical companies in the space once held by doctors as the supposed catalysts of medicalization. Titles such as ""The making of a disease"" or ""Sex, drugs, and marketing"" critique the pharmaceutical industry for shunting everyday problems into the domain of professional biomedicine. At the same time, others reject as implausible any suggestion that society rejects drugs or drug companies and highlight that the same drugs that are allegedly used to treat deviances from societal norms also help many people live their lives. Even scholars who critique the societal implications of brand-name drugs generally remain open to these drugs' curative effects — a far cry from earlier calls for a revolution against the biomedical establishment. The emphasis in many quarters has come to be on ""overmedicalization"" rather than ""medicalization"" in itself.
Others, however, argue that in practice the process of medicalization tends to strip subjects of their social context, so they come to be understood in terms of the prevailing biomedical ideology, resulting in a disregard for overarching social causes such as unequal distribution of power and resources. A series of publications by Mens Sana Monographs have focused on medicine as a corporate capitalist enterprise.

The physician's role in this present-day notion of medicalization is similarly complex. On the one hand, the doctor remains an authority figure who prescribes pharmaceuticals to patients. However, in some countries, such as the US, ubiquitous direct-to-consumer advertising encourages patients to ask for particular drugs by name, thereby creating a conversation between consumer and drug company that threatens to cut the doctor out of the loop. Additionally, there is a widespread concern regarding the extent of the pharmaceutical marketing direct to doctors and other healthcare professionals. Examples of this direct marketing are visits by salespeople, funding of journals, training courses or conferences, incentives for prescribing, and the routine provision of ""information"" written by the pharmaceutical company.
The role of patients in this economy has also changed. Once regarded as passive victims of medicalization, patients can now occupy active positions as advocates, consumers, or even agents of change.
The antithesis of medicalization is the process of paramedicalization, where human conditions come under the attention of alternative medicine, traditional medicine or any of numerous non-medical health approaches. Medicalization and paramedicalization can sometimes be contradictory and conflicting, but they also support and strengthen each other since they both ensure that questions of health and illness stay in sharp focus in defining human conditions and problems.


== Areas ==
A 2002 editorial in the British Medical Journal warned of inappropriate medicalization leading to disease mongering, where the boundaries of the definition of illnesses are expanded to include personal problems as medical problems or risks of diseases are emphasized to broaden the market for medications. The authors noted:

Inappropriate medicalisation carries the dangers of unnecessary labelling, poor treatment decisions, iatrogenic illness, and economic waste, as well as the opportunity costs that result when resources are diverted away from treating or preventing more serious disease. At a deeper level it may help to feed unhealthy obsessions with health, obscure or mystify sociological or political explanations for health problems, and focus undue attention on pharmacological, individualised, or privatised solutions.

For many years, marginalized psychiatrists (such as Peter Breggin, Paula Caplan, Thomas Szasz) and outside critics (such as Stuart A. Kirk) have ""been accusing psychiatry of engaging in the systematic medicalization of normality"". More recently these concerns have come from insiders who have worked for and promoted the American Psychiatric Association (e.g., Robert Spitzer, Allen Frances).Benjamin Rush, the father of American psychiatry, claimed that Black people had black skin because they were ill with hereditary leprosy. Consequently, he considered vitiligo as a ""spontaneous cure"".According to Franco Basaglia and his followers, whose approach pointed out the role of psychiatric institutions in the control and medicalization of deviant behaviors and social problems, psychiatry is used as the provider of scientific support for social control to the existing establishment, and the ensuing standards of deviance and normality brought about repressive views of discrete social groups. As scholars have long argued, governmental and medical institutions code menaces to authority as mental diseases during political disturbances.The HIV/AIDS pandemic allegedly caused from the 1980s a ""profound re-medicalization of sexuality"". The diagnosis of premenstrual dysphoric disorder has caused some controversy, and psychologist Peggy Kleinplatz has criticized the diagnosis as the medicalization of normal human behavior, that occurred while fluoxetine (also known as Prozac) was being repackaged as a PMDD therapy under the trade named Sarafem. Although it has received less attention, it is claimed that masculinity has also faced medicalization, being deemed damaging to health and requiring regulation or enhancement through drugs, technologies or therapy.According to Kittrie, a number of phenomena considered ""deviant"", such as alcoholism, drug addiction, prostitution, pedophilia, and masturbation (""self-abuse""), were originally considered as moral, then legal, and now medical problems. Innumerable other conditions such as obesity, smoking cigarettes, draft malingering, bachelorhood, divorce, unwanted pregnancy, kleptomania, and grief, have been declared a disease by medical and psychiatric authorities who hold impeccable institutional credentials. Due to these perceptions, peculiar deviants were subjected to moral, then legal, and now medical modes of social control. Similarly, Conrad and Schneider concluded their review of the medicalization of deviance by identifying three major paradigms that have reigned over deviance designations in different historical periods: deviance as sin; deviance as crime; and deviance as sickness.According to Mike Fitzpatrick, resistance to medicalization was a common theme of the gay liberation, anti-psychiatry, and feminist movements of the 1970s, but now there is actually no resistance to the advance of government intrusion in lifestyle if it is thought to be justified in terms of public health. Moreover, the pressure for medicalization also comes from society itself. Feminists, who once opposed state intervention as oppressive and patriarchal, now demand more coercive and intrusive measures to deal with child abuse and domestic violence.According to Thomas Szasz, ""the therapeutic state swallows up everything human on the seemingly rational ground that nothing falls outside the province of health and medicine, just as the theological state had swallowed up everything human on the perfectly rational ground that nothing falls outside the province of God and religion"".


== See also ==

Interventionism (medicine)
Medical model
Sociology of health and illness


== References ==


== Further reading ==
Conrad, Peter (2007). The Medicalization of Society: On the Transformation of Human Conditions into Treatable Disorders. Johns Hopkins University Press. ISBN 9780801892349.
Horwitz, Allan, and Wakefield, Jerome (2007).The Loss of Sadness: How Psychiatry Has Transformed Normal Sadness into Depressive Disorder. Oxford University Press.
Lane, Christopher (2007). Shyness: How Normal Behavior Became a Sickness. Yale University Press.
Illich, Ivan (July 1975). ""The medicalization of life"". Journal of Medical Ethics. 1 (2): 73–77. doi:10.1136/jme.1.2.73. PMC 1154458. PMID 809583.
Jamoulle, Marc (February 2015). ""Quaternary prevention, an answer of family doctors to overmedicalization"" (PDF). International Journal of Health Policy and Management. 4 (2): 61–64. doi:10.15171/ijhpm.2015.24. PMC 4322627. PMID 25674569.
Hatch, Anthony Ryan (2019). Silent Cells: The Secret Drugging of Captive America. Minnesota: University of Minnesota Press. pp. 184 pages. ISBN 978-1517907433. OCLC 1097608624."
"Medical cannabis, or medical marijuana (MMJ), is cannabis and cannabinoids that are prescribed by physicians for their patients. The use of cannabis as medicine has not been rigorously tested due to production and governmental restrictions, resulting in limited clinical research to define the safety and efficacy of using cannabis to treat diseases. Preliminary evidence suggests that cannabis can reduce nausea and vomiting during chemotherapy, improve appetite in people with HIV/AIDS, reduces chronic pain and muscle spasms and treats severe forms of epilepsy.Short-term use increases the risk of minor and major adverse effects. Common side effects include dizziness, feeling tired, vomiting, and hallucinations. Long-term effects of cannabis are not clear. Concerns include memory and cognition problems, risk of addiction, schizophrenia in young people, and the risk of children taking it by accident.The Cannabis plant has a history of medicinal use dating back thousands of years in many cultures. Some American medical organizations have requested removal of cannabis from the list of Schedule I controlled substances maintained by the United States federal government, followed by regulatory and scientific review. Others oppose its legalization, such as the American Academy of Pediatrics.Medical cannabis can be administered through various methods, including capsules, lozenges, tinctures, dermal patches, oral or dermal sprays, cannabis edibles, and vaporizing or smoking dried buds. Synthetic cannabinoids are available for prescription use in some countries, such as dronabinol and nabilone. Countries that allow the medical use of whole-plant cannabis include Australia, Canada, Chile, Colombia, Germany, Greece, Israel, Italy, the Netherlands, Peru, Poland, Portugal, and Uruguay. In the United States, 33 states and the District of Columbia have legalized cannabis for medical purposes, beginning with the passage of California's Proposition 215 in 1996. Although cannabis remains prohibited for any use at the federal level, the Rohrabacher–Farr amendment was enacted in December 2014, limiting the ability of federal law to be enforced in states where medical cannabis has been legalized.


== Classification ==
The National Institute on Drug Abuse defines medical cannabis as ""using the whole, unprocessed marijuana plant or its basic extracts to treat symptoms of illness and other conditions"".A Cannabis plant includes more than 400 different chemicals, of which about 70 are cannabinoids. In comparison, typical government-approved medications contain only one or two  chemicals. The number of active chemicals in cannabis is one reason why treatment with cannabis is difficult to classify and study.A 2014 review stated that the variations in ratio of CBD-to-THC in botanical and pharmaceutical preparations determines the therapeutic vs psychoactive effects (CBD attenuates THC's psychoactive effects) of cannabis products.


== Medical uses ==

Overall research into the health effects of medical cannabis has been of low quality and it is not clear whether it is a useful treatment for any condition, or whether harms outweight any benefit. There is no consistent evidence that it helps with chronic pain and muscle spasms. Low quality evidence suggests its use for reducing nausea during chemotherapy, improving appetite in HIV/AIDS, improving sleep, and improving tics in Tourette syndrome. When usual treatments are ineffective, cannabinoids have also been recommended for anorexia, arthritis, glaucoma, and migraine. 
It is unclear whether American states might be able to mitigate the adverse effects of the opioid epidemic by prescribing medical cannabis as an alternative pain management drug.It is recommended that cannabis use be stopped in pregnancy.


=== Nausea and vomiting ===
Medical cannabis is somewhat effective in chemotherapy-induced nausea and vomiting (CINV) and may be a reasonable option in those who do not improve following preferential treatment. Comparative studies have found cannabinoids to be more effective than some conventional antiemetics such as prochlorperazine, promethazine, and metoclopramide in controlling CINV, but these are used less frequently because of side effects including dizziness, dysphoria, and hallucinations. Long-term cannabis use may cause nausea and vomiting, a condition known as cannabinoid hyperemesis syndrome (CHS).A 2016 Cochrane review said that cannabinoids were ""probably effective"" in treating chemotherapy-induced nausea in children, but with a high side-effect profile (mainly drowsiness, dizziness, altered moods, and increased appetite). Less common side effects were ""ocular problems, orthostatic hypotension, muscle twitching, pruritus, vagueness, hallucinations, lightheadedness and dry mouth"".


=== HIV/AIDS ===
Evidence is lacking for both efficacy and safety of cannabis and cannabinoids in treating patients with HIV/AIDS or for anorexia associated with AIDS. As of 2013, current studies suffer from the effects of bias, small sample size, and lack of long-term data.


=== Pain ===
Research into the use of cannabis for treating chronic pain has yielded inconsistent results for neuropathic pain, spasms associated with multiple sclerosis and pain from rheumatic disorders. Cannabis is not effective at treating chronic cancer pain.When cannabis is inhaled to relieve pain, blood levels of cannabinoids rise faster than when oral products are used, peaking within three minutes and attaining an analgesic effect in seven minutes.A 2011 review considered cannabis to be generally safe, and it appears safer than opioids in palliative care.


=== Neurological conditions ===
Cannabis' efficacy is not clear in treating neurological problems, including multiple sclerosis (MS) and movement problems. Evidence also suggests that oral cannabis extract is effective for reducing patient-centered measures of spasticity. A trial of cannabis is deemed to be a reasonable option if other treatments have not been effective. Its use for MS is approved in ten countries. A 2012 review found no problems with tolerance, abuse, or addiction.  In the United States, cannabidiol, one of the cannabinoids found in the marijuana plant, has been approved for treating two severe forms of epilepsy, Lennox-Gastaut syndrome and Dravet syndrome.


=== Posttraumatic stress disorder ===

There is no good evidence that medical cannabis is effective for treating posttraumatic stress disorder, and its use for this purpose is not recommended.


== Adverse effects ==


=== Medical use ===
There is insufficient data to draw strong conclusions about the safety of medical cannabis. Typically, adverse effects of medical cannabis use are not serious; they include tiredness, dizziness, increased appetite, and cardiovascular and psychoactive effects. Other effects can include impaired short-term memory; impaired motor coordination; altered judgment; and paranoia or psychosis at high doses. Tolerance to these effects develops over a period of days or weeks. The amount of cannabis normally used for medicinal purposes is not believed to cause any permanent cognitive impairment in adults, though long-term treatment in adolescents should be weighed carefully as they are more susceptible to these impairments. Withdrawal symptoms are rarely a problem with controlled medical administration of cannabinoids. The ability to drive vehicles or to operate machinery may be impaired until a tolerance is developed.  Although supporters of medical cannabis say that it is safe, further research is required to assess the long-term safety of its use.


=== Recreational use ===

Tetrahydrocannabinol (THC), the principal psychoactive constituent of the cannabis plant, has low toxicity while the LD50 (dose of THC needed to kill 50% of tested rodents) is high. Acute effects may include anxiety and panic, impaired attention, and memory (while intoxicated), an increased risk of psychotic symptoms, and possibly increased risk of accidents if a person drives a motor vehicle while intoxicated. Psychotic episodes are well-documented and typically resolve within minutes or hours. There have been few reports of symptoms lasting longer.According to the United States Department of Health and Human Services, there were 455,000 emergency room visits associated with cannabis use in 2011. These statistics include visits in which the patient was treated for a condition induced by or related to recent cannabis use. The drug use must be ""implicated"" in the emergency department visit, but does not need to be the direct cause of the visit. Most of the illicit drug emergency room visits involved multiple drugs. In 129,000 cases, cannabis was the only implicated drug.Effects of chronic use may include bronchitis, a cannabis dependence syndrome, and subtle impairments of attention and memory. These deficits persist while chronically intoxicated. Compared to non-smokers, people who smoked cannabis regularly in adolescence exhibit reduced connectivity in specific brain regions associated with memory, learning, alertness, and executive function. One study suggested that sustained heavy, daily, adolescent onset cannabis use over decades is associated with a decline in IQ by age 38, with no effects found in those who initiated cannabis use later, or in those who ceased use earlier in adulthood. A follow-up review found that IQ deficit may be a precursor, rather than result, of cannabis use, and that social and environmental factors are a likely influence.There has been a  limited amount of studies that have looked at the effects of smoking cannabis on the respiratory system.  Chronic heavy marijuana smoking is associated with coughing, production of sputum, wheezing, coughing, and other symptoms of chronic bronchitis. Regular cannabis use has not been shown to cause significant abnormalities in lung function.Cannabis smoke contains thousands of organic and inorganic chemical compounds. This tar is chemically similar to that found in tobacco smoke, and over fifty known carcinogens have been identified in cannabis smoke, including nitrosamines, reactive aldehydes, and polycyclic hydrocarbons, including benz[a]pyrene. Light and moderate use of cannabis is not believed to increase risk of lung or upper airway cancer. Evidence for causing these cancers is mixed concerning heavy, long-term use. In general there are far lower risks of pulmonary complications for regular cannabis smokers when compared with those of tobacco. Combustion products are not present when using a vaporizer, consuming THC in pill form, or consuming cannabis edibles.
There is serious suspicion among cardiologists, spurring research but falling short of definitive proof, that cannabis use has the potential to contribute to cardiovascular disease.  Cannabis is believed to be an aggravating factor in rare cases of arteritis, a serious condition that in some cases leads to amputation. Because 97% of case-reports also smoked tobacco, a formal association with cannabis could not be made. If arteritis turns out to be a distinct clinical entity, it might be the consequence of vasoconstrictor activity observed from delta-8-THC and delta-9-THC.  Other serious cardiovascular events including myocardial infarction, stroke, sudden cardiac death, and cardiomyopathy have been reported to be temporally associated with cannabis use. Research in these events is complicated because cannabis is often used in conjunction with tobacco, and drugs such as alcohol and cocaine. These putative effects can be taken in context of a wide range of cardiovascular phenomena regulated by the endocannabinoid system and an overall role of cannabis in causing decreased peripheral resistance and increased cardiac output, which potentially could pose a threat to those with cardiovascular disease.Cannabis usually causes no tolerance or withdrawal symptoms except in heavy users. In a survey of heavy users 42.4% experienced withdrawal symptoms when they tried to quit marijuana such as craving, irritability, boredom, anxiety and sleep disturbances. About 9% of those who experiment with marijuana eventually become dependent. The rate goes up to one in six among those who begin use as adolescents, and one-quarter to one-half of those who use it daily according to a NIDA review. A 2013 review estimates daily use is associated with a 10-20% rate of dependence. The highest risk of cannabis dependence is found in those with a history of poor academic achievement, deviant behavior in childhood and adolescence, rebelliousness, poor parental relationships, or a parental history of drug and alcohol problems.A 2013 literature review found that exposure to marijuana had biologically-based physical, mental, behavioral and social health consequences and was ""associated with diseases of the liver (particularly with co-existing hepatitis C), lungs, heart, and vasculature"". There are numerous other reasons why people look for medical cannabis and to make people aware of whether they are eligible to accept medical cannabis as a dose, there are numerous websites that are currently providing online consultations through video calling. People are provided licenses with the help of which, they can either grow medical cannabis, or purchase it legally throughout the state. This is done only after precisely reviewing the applications of patients.


=== Cognitive effects ===
A 2011 systematic review evaluated published studies of the acute and long-term cognitive effects of cannabis.  THC intoxication is well established to impair cognitive functioning on an acute basis, including effects on the ability to plan, organize, solve problems, make decisions, and control impulses. The extent of this impact may be greater in novice users, and paradoxically, those habituated to high-level ingestion may have reduced cognition during withdrawal.  Studies of long-term effects on cognition have provided conflicting results, with some studies finding no difference between long-term abstainers and never-users and others finding long-term deficits.  The discrepancies between studies may reflect greater long-term effects among heavier users relative to occasional users, and greater duration of effect among those with heavy use as adolescents compared to later in life.  A second systematic review focused on neuroimaging studies found little evidence supporting an effect of cannabis use on brain structure and function. A 2003 meta-analysis concluded that any long-term cognitive effects were relatively modest in magnitude and limited to certain aspects of learning and memory.


=== Impact on psychosis ===
Exposure to THC can cause acute transient psychotic symptoms in healthy individuals and people with schizophrenia.A 2007 meta analysis concluded that cannabis use reduced the average age of onset of psychosis by 2.7 years relative to non-cannabis use.  A 2005 meta analysis concluded that adolescent use of cannabis increases the risk of psychosis, and that the risk is dose-related. A 2004 literature review on the subject concluded that cannabis use is associated with a two-fold increase in the risk of psychosis, but that cannabis use is ""neither necessary nor sufficient"" to cause psychosis. A French review from 2009 came to a conclusion that cannabis use, particularly that before age 15, was a factor in the development of schizophrenic disorders.


=== Other potential long-term effects ===
A 2008 National Institutes of Health study of 19 chronic heavy marijuana users with cardiac and cerebral abnormalities (averaging 28 g to 272 g (1 to 9+ oz) weekly) and 24 controls found elevated levels of apolipoprotein C-III (apoC-III) in the chronic smokers. An increase in apoC-III levels induces the development of hypertriglyceridemia.


== Pharmacology ==
The genus Cannabis contains two species which produce useful amounts of psychoactive cannabinoids: Cannabis indica and Cannabis sativa, which are listed as Schedule I medicinal plants in the US; a third species, Cannabis ruderalis, has few psychogenic properties. Cannabis contains more than 460 compounds; at least 80 of these are cannabinoids – chemical compounds that interact with cannabinoid receptors in the brain. As of 2012, more than 20 cannabinoids were being studied by the U.S. FDA.The most psychoactive cannabinoid found in the cannabis plant is tetrahydrocannabinol (or delta-9-tetrahydrocannabinol, commonly known as THC). Other cannabinoids include delta-8-tetrahydrocannabinol, cannabidiol (CBD), cannabinol (CBN), cannabicyclol (CBL), cannabichromene (CBC) and cannabigerol (CBG); they have less psychotropic effects than THC, but may play a role in the overall effect of cannabis. The most studied are THC, CBD and CBN.CB1 and CB2 are the primary cannabinoid receptors responsible for several of the effects of cannabinoids, although other receptors may play a role as well. Both belong to a group of receptors called G protein-coupled receptors (GPCRs). CB1 receptors are found in very high levels in the brain and are thought to be responsible for psychoactive effects. CB2 receptors are found peripherally throughout the body and are thought to modulate pain and inflammation.


=== Absorption ===
Cannabinoid absorption is dependent on its route of administration.
Inhaled and vaporized THC have similar absorption profiles to smoked THC, with a bioavailability ranging from 10 to 35%. Oral administration has the lowest bioavailability of approximately 6%, variable absorption depending on the vehicle used, and the longest time to peak plasma levels  (2 to 6 hours) compared to smoked or vaporized THC.Similar to THC, CBD has poor oral bioavailability, approximately 6%. The low bioavailability is largely attributed to significant first-pass metabolism in the liver and erratic absorption from the gastrointestinal tract. However, oral administration of CBD has a faster time to peak concentrations (2 hours) than THC.Due to the poor bioavailability of oral preparations, alternative routes of administration have been studied, including sublingual and rectal. These alternative formulations maximize bioavailability and reduce first-pass metabolism. Sublingual administration in rabbits yielded bioavailability of 16% and time to peak concentration of 4 hours. Rectal administration in monkeys doubled bioavailability to 13.5% and achieved peak blood concentrations within 1 to 8 hours after administration.


=== Distribution ===
Like cannabinoid absorption, distribution is also dependent on route of administration. Smoking and inhalation of vaporized cannabis have better absorption than do other routes of administration, and therefore also have more predictable distribution. THC is highly protein bound once absorbed, with only 3% found unbound in the plasma. It distributes rapidly to highly vascularized organs such as the heart, lungs, liver, spleen, and kidneys, as well as to various glands. Low levels can be detected in the brain, testes, and unborn fetuses, all of which are protected from systemic circulation via barriers. THC further distributes into fatty tissues a few days after administration due to its high lipophilicity, and is found deposited in the spleen and fat after redistribution.


=== Metabolism ===
Delta-9-THC is the primary molecule responsible for the effects of cannabis. Delta-9-THC is metabolized in the liver and turns into 11-OH-THC. 11-OH-THC is the first metabolic product in this pathway. Both Delta-9-THC and 11-OH-THC are psychoactive. The metabolism of THC into 11-OH-THC plays a part in the heightened psychoactive effects of edible cannabis.Next, 11-OH-THC is metabolized in the liver into 11-COOH-THC, which is the second metabolic product of THC. 11-COOH-THC is not psychoactive.Ingestion of edible cannabis products lead to a slower onset of effect than the inhalation of it because the THC travels to the liver first through the blood before it travels to the rest of the body. Inhaled cannabis can result in THC going directly to the brain, where it then travels from the brain back to the liver in recirculation for metabolism. Eventually, both routes of metabolism result in the metabolism of psychoactive THC to inactive 11-COOH-THC.


=== Excretion ===
Due to substantial metabolism of THC and CBD, their metabolites are excreted mostly via feces, rather than by urine. After delta-9-THC is hydroxylated into 11-OH-THC via CYP2C9, CYP2C19, and CYP3A4, it undergoes phase II metabolism into more than 30 metabolites, a majority of which are products of glucuronidation. Approximately 65% of THC is excreted in feces and 25% in the urine, while the remaining 10% is excreted by other means. The terminal half-life of THC is 25 to 36 hours, whereas for CBD it is 18 to 32 hours.CBD is hydroxylated by P450 liver enzymes into 7-OH-CBD. Its metabolites are products of primarily CYP2C19 and CYP3A4 activity, with potential activity of CYP1A1, CYP1A2, CYP2C9, and CYP2D6. Similar to delta-9-THC, a majority of CBD is excreted in feces and some in the urine. The terminal half-life is approximately 18–32 hours.


== Administration ==

Smoking has been the means of administration of cannabis for many users, but it is not suitable for the use of cannabis as a medicine. It was the most common method of medical cannabis consumption in the US as of 2013. It is difficult to predict the pharmacological response to cannabis because concentration of cannabinoids varies widely, as there are different ways of preparing it for consumption (smoked, applied as oils, eaten, infused into other foods,  or drunk) and a lack of production controls. The potential for adverse effects from smoke inhalation makes smoking a less viable option than oral preparations. Cannabis vaporizers have gained popularity because of a perception among users that fewer harmful chemicals are ingested when components are inhaled via aerosol rather than smoke. Cannabinoid medicines are available in pill form (dronabinol and nabilone) and liquid extracts formulated into an oromucosal spray (nabiximols). Oral preparations are ""problematic due to the uptake of cannabinoids into fatty tissue, from which they are released slowly, and the significant first-pass liver metabolism, which breaks down Δ9THC and contributes further to the variability of plasma concentrations"".The US Food and Drug Administration (FDA) has not approved smoked cannabis for any condition or disease, as it deems that evidence is lacking concerning safety and efficacy. The FDA issued a 2006 advisory against smoked medical cannabis stating: ""marijuana has a high potential for abuse, has no currently accepted medical use in treatment in the United States, and has a lack of accepted safety for use under medical supervision.""


== History ==


=== Ancient ===
Cannabis, called má 麻 (meaning ""hemp; cannabis; numbness"") or dàmá 大麻 (with ""big; great"") in Chinese, was used in Taiwan for fiber starting about 10,000 years ago. The botanist Hui-lin Li wrote that in China, ""The use of Cannabis in medicine was probably a very early development. Since ancient humans used hemp seed as food, it was quite natural for them to also discover the medicinal properties of the plant."" Emperor Shen-Nung, who was also a pharmacologist, wrote a book on treatment methods in 2737 BCE that included the medical benefits of cannabis. He recommended the substance for many ailments, including constipation, gout, rheumatism, and absent-mindedness. Cannabis is one of the 50 ""fundamental"" herbs in traditional Chinese medicine.The Ebers Papyrus (c. 1550 BCE) from Ancient Egypt describes medical cannabis. The ancient Egyptians used hemp (cannabis) in suppositories for relieving the pain of hemorrhoids.Surviving texts from ancient India confirm that cannabis' psychoactive properties were recognized, and doctors used it for treating a variety of illnesses and ailments, including insomnia, headaches, gastrointestinal disorders, and pain, including during childbirth.The Ancient Greeks used cannabis to dress wounds and sores on their horses, and in humans, dried leaves of cannabis were used to treat nose bleeds, and cannabis seeds were used to expel tapeworms.In the medieval Islamic world, Arabic physicians made use of the diuretic, antiemetic, antiepileptic, anti-inflammatory, analgesic and antipyretic properties of Cannabis sativa, and used it extensively as medication from the 8th to 18th centuries.


=== Landrace strains ===

Cannabis seeds may have been used for food, rituals or religious practices in ancient Europe and China. Harvesting the plant led to the spread of cannabis throughout Eurasia about 10,000 to 5,000 years ago, with further distribution to the Middle East and Africa about 2,000 to 500 years ago. A landrace strain of cannabis developed over centuries. They are cultivars of the plant that originated in one specific region.
Widely cultivated strains of cannabis, such as ""Afghani"" or ""Hindu Kush"", are indigenous to the Pakistan and Afghanistan regions, while ""Durban Poison"" is native to Africa. There are approximately 16 landrace strains of cannabis identified from Pakistan, Jamaica, Africa, Mexico, Central America and Asia.


=== Modern ===
An Irish physician, William Brooke O'Shaughnessy, is credited with introducing cannabis to Western medicine. O'Shaughnessy discovered cannabis in the 1830s while living abroad in India, where he conducted numerous experiments investigating the drug's medical utility (noting in particular its analgesic and anticonvulsant effects).  He returned to England with a supply of cannabis in 1842, after which its use spread through Europe and the United States.  Cannabis was entered into the United States Pharmacopeia in 1850.The use of cannabis in medicine began to decline by the end of the 19th century, due to difficulty in controlling dosages and the rise in popularity of synthetic and opium-derived drugs.  Also, the advent of the hypodermic syringe allowed these drugs to be injected for immediate effect, in contrast to cannabis which is not water-soluble and therefore cannot be injected.In the United States, the medical use of cannabis further declined with the passage of the Marihuana Tax Act of 1937, which imposed new regulations and fees on physicians prescribing cannabis.  Cannabis was removed from the U.S. Pharmacopeia in 1941, and officially banned for any use with the passage of the Controlled Substances Act of 1970.Cannabis began to attract renewed interest as medicine in the 1970s and 1980s, in particular due to its use by cancer and AIDS patients who reported relief from the effects of chemotherapy and wasting syndrome.  In 1996, California became the first U.S. state to legalize medical cannabis in defiance of federal law.  In 2001, Canada became the first country to adopt a system regulating the medical use of cannabis.

		
		
		


== Society and culture ==


=== Legal status ===

Countries that have legalized the medical use of cannabis include Australia, Brazil, Canada, Chile, Colombia, Croatia, Cyprus, Czech Republic, Finland, Germany, Greece, Israel, Italy, Jamaica, Lebanon, Luxembourg, North Macedonia, Malta, the Netherlands, New Zealand, Peru, Poland, Portugal, Sri Lanka, Thailand, the United Kingdom, and Uruguay.  Other countries have more restrictive laws that allow only the use of isolated cannabinoid drugs such as Sativex or Epidiolex.  Countries with the most relaxed policies include Canada, Uruguay, and the Netherlands, where cannabis can be purchased without need for a prescription.  In Mexico, THC content of medical cannabis is limited to one percent.  The same limit applies in Switzerland, but no prescription is required to purchase.  In the United States, the legality of medical cannabis varies by state.Cannabis is in Schedule IV of the United Nations' Single Convention on Narcotic Drugs, making it subject to special restrictions. Article 2 provides for the following, in reference to Schedule IV drugs:

A Party shall, if in its opinion the prevailing conditions in its country render it the most appropriate means of protecting the public health and welfare, prohibit the production, manufacture, export and import of, trade in, possession or use of any such drug except for amounts which may be necessary for medical and scientific research only, including clinical trials therewith to be conducted under or subject to the direct supervision and control of the Party.
The convention thus allows countries to outlaw cannabis for all non-research purposes but lets nations choose to allow use for medical and scientific purposes if they believe total prohibition is not the most appropriate means of protecting health and welfare. The convention requires that states that permit the production or use of medical cannabis must operate a licensing system for all cultivators, manufacturers, and distributors and ensure that the total cannabis market of the state shall not exceed that required ""for medical and scientific purposes"".


==== United States ====

In the United States, the use of cannabis for medical purposes is legal in 33 states, four out of five permanently inhabited U.S. territories, and the District of Columbia.  An additional 14 states have more restrictive laws allowing the use of low-THC products.  Cannabis remains illegal at the federal level under the Controlled Substances Act, which classifies it as a Schedule I drug with a high potential for abuse and no accepted medical use.  In December 2014, however, the Rohrabacher–Farr amendment was signed into law, prohibiting the Justice Department from prosecuting individuals acting in accordance with state medical cannabis laws.


=== Economics ===


==== Distribution ====

The method of obtaining medical cannabis varies by region and by legislation. In the US, most consumers grow their own or buy it from cannabis dispensaries in states where it is legal. Marijuana vending machines for selling or dispensing cannabis are in use in the United States and are planned to be used in Canada. In 2014, the startup Meadow began offering on-demand delivery of medical marijuana in the San Francisco Bay Area, through their mobile app.


==== Insurance ====
In the United States, health insurance companies may not pay for a medical marijuana prescription as the Food and Drug Administration must approve any substance for medicinal purposes. Before this can happen, the FDA must first permit the study of the medical benefits and drawbacks of the substance, which it has not done since it was placed on Schedule I of the Controlled Substances Act in 1970. Therefore, all expenses incurred fulfilling a medical marijuana prescription will possibly be incurred as out-of-pocket.  However, the New Mexico Court of Appeals has ruled that workers' compensation insurance must pay for prescribed marijuana as part of the state's Medical Cannabis Program.


=== Positions of medical organizations ===
Medical organizations that have issued statements in support of allowing access to medical cannabis include the American Nurses Association, American Public Health Association, American Medical Student Association, National Multiple Sclerosis Society, Epilepsy Foundation, and Leukemia & Lymphoma Society.Organizations that have issued statements in opposition to the legalization of medical cannabis include the American Academy of Pediatrics, American Psychiatric Association, and American Society of Addiction Medicine.  However, the AAP also supports rescheduling for the purpose of facilitating research.The American Medical Association and American College of Physicians do not take a position on the legalization of medical cannabis, but have called for the Schedule I classification to be reviewed. The American Academy of Family Physicians also does not take a position, but does support rescheduling to better facilitate research.  The American Heart Association says that ""many of the concerning health implications of cannabis include cardiovascular diseases"" but that it supports rescheduling to allow ""more nuanced ... marijuana legislation and regulation"" and to ""reflect the existing science behind cannabis"".  The American Cancer Society and American Psychological Association have noted the obstacles that exist for conducting research on cannabis, and have called on the federal government to better enable scientific study of the drug.
Cancer Research UK say that while cannabis is being studied for therapeutic potential, ""claims that there is solid 'proof' that cannabis or cannabinoids can cure cancer is highly misleading to patients and their families, and builds a false picture of the state of progress in this area"".


=== Recreational use ===
The authors of a report on a 2011 survey of medical cannabis users say that critics have suggested that some users ""game the system"" to obtain medical cannabis ostensibly for treatment of a condition, but then use it for nonmedical purposes – though the truth of this claim is hard to measure.  The report authors suggested rather that medical cannabis users occupied a ""continuum"" between medical and nonmedical use.


=== Brand names ===
In the US, the FDA has approved two oral cannabinoids for use as medicine: dronabinol and nabilone. Dronabinol, synthetic THC, is listed as Schedule II. Nabilone, a synthetic cannabinoid, is also Schedule II, indicating high potential for side effects and addiction. Both received approval for sale in the US in 1985, under the brand names Marinol and Cesamet. Nabiximols, an oromucosal spray derived from two strains of Cannabis sativa and containing THC and CBD, is not approved in the United States, but is approved in several European countries, Canada, and New Zealand as of 2013. As of 2018, medical marijuana in Canada is being legally distributed to registered patients in bud, drops and capsule forms by such companies as Canopy Growth Corp. and Aurora Cannabis.

As an antiemetic, these medications are usually used when conventional treatment for nausea and vomiting associated with cancer chemotherapy fail to work.Nabiximols is used for treatment of spasticity associated with MS when other therapies have not worked, and when an initial trial demonstrates ""meaningful improvement"". Trials for FDA approval in the US are underway. It is also approved in several European countries for overactive bladder and vomiting. When sold under the trade name Sativex as a mouth spray, the prescribed daily dose in Sweden delivers a maximum of 32.4 mg of THC and 30 mg of CBD; mild to moderate dizziness is common during the first few weeks.Relative to inhaled consumption, peak concentration of oral THC is delayed, and it may be difficult to determine optimal dosage because of variability in patient absorption.In 1964, Albert Lockhart and Manley West began studying the health effects of traditional cannabis use in Jamaican communities. They developed, and in 1987 gained permission to market, the pharmaceutical ""Canasol"", one of the first cannabis extracts.


== Research ==

Medical cannabis research includes any medical research on using cannabis as a treatment for any medical condition. For reasons including increased popular support of cannabis use, a trend of cannabis legalization, and the perception of medical usefulness, more scientists are doing medical cannabis research. Medical cannabis is unusually broad as a treatment for many conditions, each of which has its own state of research. Similarly, various countries conduct and respond to medical cannabis research in different ways.


== See also ==

Charlotte's Web (cannabis)
Chinese herbology
Tilden's Extract


== References ==


== Further reading ==


== External links ==
Medical cannabis at Curlie, links to websites about medical cannabis
Information on Cannabis and Cannabinoids from the U.S. National Cancer Institute
Information on cannabis (marihuana, marijuana) and the cannabinoids from Health Canada
The Center for Medicinal Cannabis Research of the University of California
Medical Marijuana – a 2014–2015 three-part CNN documentary produced by Sanjay Gupta"
"Medical privacy or health privacy is the practice of maintaining the security and confidentiality of patient records. It involves both the conversational discretion of health care providers and the security of medical records. The terms can also refer to the physical privacy of patients from other patients and providers while in a medical facility. Modern concerns include the degree of disclosure to insurance companies, employers, and other third parties. The advent of electronic medical records (EMR) and patient care management systems (PCMS) have raised new concerns about privacy, balanced with efforts to reduce duplication of services and medical errors.Many countries - including Australia, Canada, Turkey, the United Kingdom, the United States, New Zealand, and the Netherlands - have enacted laws that try to protect people's privacy. However, many of these laws have proven to be less effective in practice than in theory. The United States passed the Health Insurance Portability and Accountability Act (HIPAA) in 1996 in an attempt to increase privacy precautions within medical institutions.


== History of Medical Privacy ==
Prior to the technological boom, medical institutions relied on the paper medium to file individual's medical data. Nowadays more and more information is stored within electronic databases. Research shows that it is safer to have information stored within a paper medium as it is harder to physically steal data, whilst digital records are vulnerable to access by hackers.In order to reform the healthcare privacy issues in the early 1990s, researchers looked into the use of credit cards and smart cards to allow access to their medical information without fear of stolen information. The “smart” card allowed the storage and processing of information to be stored in a singular microchip, yet people were fearful of having so much information stored in a single spot that could easily be accessed. This “smart” card included an individual's social security number as an important piece of identification that can lead to identity theft if  databases are breached. Additionally, there was a fear that people would target these medical cards because they have information that can be of value to many different third parties including employers, pharmaceutical companies, drug marketers, and insurance reviewers.In response to the lack of medical privacy, there was a movement to create better medical privacy protection, but nothing has been officially passed. The Medical Information Bureau was thus created to prevent insurance fraud, yet it has since become a significant source of medical information for over 750 life insurance companies; thus, it is very dangerous as it is a target of privacy breachers. Although the electronic filing system of medical information has increased efficiency and administration costs have been reduced, there are negative aspects to consider. The electronic filing system allows for individual's information to be more susceptible to outsiders; even though their information is stored on a singular card. Therefore, the medical card serves as a false sense of security as it does not protect their information completely.


=== Patient care management systems (PCMS) ===
With the technological boom, there has been an expansion of the record filing system and many hospitals have therefore adopted new PCMS. PCMS are large medical records that hold many individuals' personal data. These have become critical to the efficiency of storing medical information because of high volumes of paperwork, the ability to quickly share information between medical institutions, and the increased mandatory reporting to the government. PCMS have ultimately increased the productivity of data record utilization and have created a large dependence on technology within the medical field.
It has also led to social and ethical issues because of the basic human rights that can be a casualty for this expansion of knowledge. Hospitals and health information services are now more likely to share information with third party companies. Thus, there needs to be a reform to specify the rules of the hospital personnel who have the access to medical records. This has led to the discussion of privacy rights and created safeguards that will help data keepers understand situations where it is ethical to share an individual's medical information, provide ways for individuals to gain access to their own records, and determine who has ownership of those records. Additionally, it is used to ensure that a person's identity is kept confidential in research or statistical purposes and understand the process to make individual's aware that their health information is being used. Thus, a balance between privacy and confidentiality must occur in order to limit the amount of information disclosed and keep the occupations of physicians in check by constricting the information flow


=== Electronic Medical Records (EMR) ===

Electronic medical records (EMR) are a more efficient way of storing medical information, yet there are many negative aspects of this type of filing system as well. Hospitals are willing to adopt this type of filing system, yet only if they are able to ensure the protection of patient information.Researchers found that state legislation and regulation of medical privacy laws reduce the amount of hospitals that adopt EMR by more than 24%. This is ultimately due to the decreasing positive network externalities that are created by additional state protections. With increases in restrictions against the diffusion of medical information, hospitals have neglected to adopt the new EMR's because privacy laws restrict health information exchanges. With decreasing amounts of medical institutions adopting the EMR filing system, the federal government's plan to have a national health network will be stopped. The national network will ultimately cost the US$156 billion in investments, yet in order for this to happen, the government needs to place higher emphasis on protecting individual medical privacy. Many politicians and business leaders find that EMR's allow for more efficiency in both time and money, yet they neglect to address the decreasing privacy protections, demonstrating the significant trade off between EMR's and individual privacy.


==== Privacy and Electronic Health Records (EHRs) ====
The three goals of information security, including electronic information security, are confidentiality, integrity, and availability. Organizations are attempting to meet these goals, referred to as the C.I.A. Triad, which is the ""practice of defending information from unauthorized access, use, disclosure, disruption, modification, inspection, recording or destruction.""
In a 2004 editorial in the Washington Post, U.S. Senators Bill Frist and Hillary Clinton supported this observation, stating ""[patients] need...information, including access to their own health records... At the same time, we must ensure the privacy of the systems, or they will undermine the trust they are designed to create"". A 2005 report by the California Health Care Foundation found that ""67 percent of national respondents felt 'somewhat' or 'very concerned' about the privacy of their personal medical records"".
The importance of privacy in electronic health records became prominent with the passage of the American Recovery and Reinvestment Act (ARRA) in 2009. One of the provisions (known as the Health Information Technology for Economic and Clinical Health [HITECH] Act) of the ARRA mandated incentives to clinicians for the implementation of electronic health records by 2015.Privacy advocates in the United States have raised concerns about unauthorized access to personal data as more medical practices switch from paper to electronic medical records. The Office of the National Coordinator for Health Information Technology (ONC) explained that some of the safety measures that EHR systems can utilize are passwords and pin numbers that control access to such systems, encryption of information, and an audit trail to keep track of the changes made to records.
Providing patient access to EHRs is strictly mandated by HIPAA's Privacy Rule. One study found that each year there are an estimated 25 million compelled authorizations for the release of personal health records. Researchers, however, have found new security threats open up as a result. Some of these security and privacy threats include hackers, viruses, and worms. These privacy threats are made more prominent by the emergence of ""cloud computing"", which is the use of shared computer processing power. Health care organizations are increasingly using cloud computing as a way to handle large amounts of data. This type of data storage, however, is susceptible to natural disasters, cybercrime and technological terrorism, and hardware failure. Health information breaches accounted for the 39 percent of all breaches in 2015. IT Security costs and implementations are needed to protect health institutions against security and data breaches.


==== Health screening cases ====
Although privacy issues with the health screening is a great concern among individuals and organizations, there has been little focus on the amount of work being done within the law to maintain the privacy expectation that people desire. Many of these issues lie within the abstractness of the term “privacy” as there are many different interpretations of the term, especially in the context of the law. Prior to 1994, there had been no cases regarding screening practices and the implications towards an individual's medical privacy, unless it was regarding HIV and drug testing. Within Glover v Eastern Nebraska Community Office of Retardation, an employee sued her employer against violating her 4th amendment rights because of unnecessary HIV testing. The court ruled in favor of the employer and argued that it was unreasonable search to have it tested. However, this was only one of the few precedents that people have to use. With more precedents, the relationships between employees and employers will be better defined. Yet with more requirements, testing among patients will lead to additional standards for meeting health care standards. Screening has become a large indicator for diagnostic tools, yet there are concerns with the information that can be gained and subsequently shared with other people other than the patient and healthcare provider


== Third party issues ==
One of the main dangers to an individual's privacy are private corporations because of the profits they can receive from privacy-violating information. Privacy merchants are made up of two groups - one that tries to collect people's personal information while the other focuses on using client's information to market company products. Subsequently, privacy merchants purchase information from other companies, such as health insurance companies, if there is not sufficient information from their own research. Privacy merchants target health insurance companies because, nowadays, they collect huge amounts of personal information and keep them in large databases. They often require patients to provide more information that is needed for purposes other than that of doctors and other medical workers.Additionally, people's information can be linked to other information outside of the medical field. For example, many employers use insurance information and medical records as an indicator of work ability and ethic. The selling of privacy information can also lead employers to make lots of money; however, this happens to many people without their consent or knowledge.
Within the United States, in order to define clear privacy laws regarding medical privacy, Title 17 thoroughly explains the ownership of one's data and adjusted the law so that people have more control over their own property. The Privacy Act of 1974 offers more restrictions regarding what corporations can access outside of an individual's consent.States have created additional supplements to medical privacy laws. With HIPAA, many individuals were pleased to see the federal government take action in protecting the medical information of individuals. Yet when people looked into it, there was proof that the government was still protecting the rights of corporations. Many rules were seen as more of suggestions and the punishment for compromising the privacy of its patients were minimal. Even if release of medical information requires consent, blank authorizations can be allowed and will not ask for individuals for additional consent later on.Although there is a large group of people who oppose the selling of individual's medical information, there are groups such as the Health Benefits Coalition, the Healthcare Leadership Council, and the Health Insurance Association of America that are against the new reforms for data protection as it can ruin their work and profits. Furthermore, it is not the government that is the reason for many issues with medical privacy, but it is the large corporations that are trying to make profits off of our data.


=== Efforts to protect health information ===
With the lack of help from the Department of Health and Human Services there is a conflict of interest that has been made clear. Some wish to place individual betterment as more important, while others focus more on external benefits from outside sources. The issues that occur when there are problems between the two groups are also not adequately solved which leads to controversial laws and effects. Individual interests take precedence over the benefits of society as a whole and are often viewed as selfish and for the gain of capital value. If the government does not make any more future changes to the current legislation, countless organizations and people will have access to individual medical information.In 1999, the Gramm-Leach-Biley Act (GLBA) addressed the insurance privacy debate regarding medical privacy. Yet, there were many issues with the implementation. One issue was that there were inconsistent regulation requirements within the different states due to preexisting laws. Secondly, it was difficult to combine the pre-existing laws with the new framework. And thirdly, in order for the federal government to implement these new rules, they needed state legislature to pass it.GLBA aimed to regulate financial institutions so that corporations could not affect people's insurance. Because of the difficulty of the implementation of the GLBA, state legislatures are able to interpret the laws themselves and create initiatives to protect the medical privacy. When states are creating their own independent legislature, they create standards that understand the impact of the legislation. If they stray from the standard laws, they must be valid and fair. The new legislation must protect the rights of businesses and allow them to continue to function despite federally regulated competition. Patients gain benefits from these new services and standards through the flow of information that is considerate with medical privacy expectations.These regulations should focus more on the consumer versus the benefits and political exploitation. Many times, regulations are for the personal gain of the corporation, therefore, state legislatures be wary of this and try to prevent it to the best of their abilities. Medical privacy is not a new issue within the insurance industry, yet the problems regarding exploitation continue to reoccur; there is more focus on taking advantage of the business environment for personal gain.In 2001, President George W. Bush passed additional regulations to HIPAA in order to better protect the privacy of individual medical information. These new regulations were supposed to safeguard health information privacy by creating extensive solutions for the privacy of patients. The new regulation goals included being notified once an individual's information is inspected, amend any medical records, and request communication opportunities to discuss information disclosure.However, there are exceptions to when the disclosure of PHI can be inspected. This includes specific conditions among law enforcement, judicial and administrative proceedings, parents, significant others, public health, health research, and commercial marketing. These aspects of lack of privacy have caused an alarming amount of gaps within privacy measures.
Ultimately, there is still an issue on how to ensure privacy securities; in response, the government has created new regulations that makes trade offs between an individual's privacy and public benefit. These new regulations, however, still cover individually identifiable health information - any data that contains information unique to an individual. However, non-identifiable data is not covered as the government claims it will cause minimal damage to a person's privacy. It also covers all health care organizations, covers businesses as well.
Additionally, under new HIPAA additions, the state legislation is more protective than national laws because it created more obligations for organizations to follow. Ultimately, the new rules called for expansive requirements that created better safety measures for individuals. Yet, there are still ways that businesses and healthcare organizations can be exempt from disclosure rules for all individuals. Thus, the HHS needs to find more ways to balance personal and public trade offs within medical laws. This creates a need for extra government intervention to enforce legislation and new standards to decrease the amount of threats against an individual's privacy of health data.


== Effects of changing medical privacy laws ==


=== Physician-Patient Relationships ===
Patients want to be able to share medical information with their physicians, yet they worry about potential privacy breaches that can occur when they release financial and confidential medical information. In order to ensure better protection, the government has created frameworks for keeping information confidential - this includes being transparent about procedures, disclosure and protection of information, and monitoring of these new rules to ensure that people's information.


==== Effects of Technological Advances ====
Recently physicians and patients have started to use email as an additional communication tool for treatment and medical interactions. This way of communication is not “new”, but its effects on doctor patient relationships has created new questions regarding legal, moral, and financial problems.The American Medical Informatics Association has characterized medical emails as way to communicate “medical advice, treatment, and information exchanged professionally”; yet, the “spontaneity, permanence, and information power characterizing” role is significant because of its unknown affects. However, the use of emails allows for increased access, immediate aid, and increased interactions between patients and doctors. There are many benefits and negative aspects of using emails; doctors feel a new sense of negative responsibility to respond to emails outside of the office, but also find benefits with facilitating rapid responses to patient's questions.Additionally, the use of email between physicians and their patients will continue to grow because of the increasing use of the Internet. With the Internet, patients are able to ask for medical advice and treatment, yet issues regarding confidentiality and legal issues come up. Ultimately, emails between a physician and patient are supposed to be used as a supplement for face to face interactions, not for casual messages. If used properly, physicians could use emails as a way to supplement interactions and provide more medical aid to those who need it immediately.


==== Traditional beliefs on doctor-patient relationship ====
Although many people believe that the technological changes are the reason for fear of sharing medical privacy, there is a theory that states that institutional ideals between doctors and their patients have created the fear of sharing medical privacy information. Although levels of confidentiality are changing, individuals often feel the need to share more information with their doctors in order to get diagnosed correctly. Because of this, people are concerned with how much information their physicians have. This information could be transferred to other third party companies. However, there is a call for smaller emphasis on sharing and confidentiality in order to rid patients from their fears of information breaching. There is a common belief that the confidentiality of one's information also only protects the doctors and not the patients, therefore there is a negative stigma towards revealing too much information. Thus it causes patients to not share vital information relevant to their illnesses.


== Medical privacy standards and laws by country ==


=== Australia – eHealth ===
On July 1, 2012, the Australian Government launched the Personally Controlled Electronic Health Record (PCEHR) (eHealth) system. Once the system is fully implemented, it will incorporate an electronic summary prepared by nominated healthcare providers along with consumer-provided notes. Further, the summary will include information on the individual's allergies, adverse reactions, medications, immunizations, diagnoses, and treatments. The consumer notes will operate as a personal medical diary that only the individual can view and edit. The opt-in system gives people the option to choose whether to register for the eHealth record or not.As of January 2016, the Commonwealth Department of Health changed the name PCEHR  to My Health Record.


==== Privacy – Governance ====
The Personally Controlled Electronic Health Records Act 2012 and Privacy Act 1988 governs how eHealth record information is managed and protected. The PCEHR System Operator abides by the Information Privacy Principles in the Privacy Act 1988 (Commonwealth) as well as any applicable State or Territory privacy laws. A Privacy Statement sets out the application of the collection of personal information by the System Operator.  The statement includes an explanation of the types of personal information collected, what the information is used for, and how the information is stored.  The statement covers measures in place to protect personal information from misuse, loss, unauthorized access, modification, and disclosure.


==== Privacy – Security measures ====
Security measures include audit trails so that patients can see who has accessed their medical records along with the time the records were accessed. Other measures include the use of encryption as well as secure logins and passwords. Patient records are identified using an Individual Health Identifier (IHI), assigned by Medicare, the IHI service provider.


==== Privacy – Issues ====
A 2012 nationwide survey in Australia assessed privacy concerns on patients' health care decisions, which could impact patient care.  Results listed that 49.1% of Australian patients stated they have withheld or would withhold information from their health care provider based on privacy concerns.
How does consent impact privacy?One concern is that personal control of the eHealth record via consent does not guarantee the protection of privacy. It is argued that a narrow definition, 'permission' or 'agreement', does not provide protection for privacy and is not well represented in Australian legislation. The PCEHR allows clinicians to assume consent by consumer participation in the system; however, the needs of the consumer may not be met. Critics argue that the broader definition of 'informed consent' is required, as it encompasses the provision of relevant information by the healthcare practitioner, and understanding of that information by the patient.
Is it legitimate to use personal information for public purposes?Data from the PCEHR is to be predominantly used in patient healthcare, but other uses are possible, for policy, research, audit and public health purposes.  The concern is that in the case of research, what is allowed goes beyond existing privacy legislation.
What are ‘illegitimate’ uses of health information?The involvement of pharmaceutical companies is viewed as potentially problematic. If they are perceived by the public to be more concerned with profit than public health, public acceptance of their use of PCEHRs could be challenged. Also perceived as problematic, is the potential for parties other than health care practitioners, such as insurance companies, employers, police or the government, to use information in a way which could result in discrimination or disadvantage.
What are the potential implications of unwanted disclosure of patient information?Information 'leakage' is seen as having the potential to discourage both patient and clinician from participating in the system. Critics argue the PCEHR initiative can only work, if a safe, effective continuum of care within a trusting patient/clinician relationship is established. If patients lose trust in the confidentiality of their eHealth information, they may withhold sensitive information from their health care providers. Clinicians may be reluctant to participate in a system where they are uncertain about the completeness of the information.
Are there sufficient safeguards for the protection of patient information?Security experts have questioned the registration process, where those registering only have to provide a Medicare card number, and names and birth dates of family members to verify their identity. Concerns have also been raised by some stakeholders, about the inherent complexities of the limited access features. They warn that access to PCEHR record content, may involve transfer of information to a local system, where PCEHR access controls would no longer apply.


=== Canada ===
The privacy of patient information is protected at both the federal level and provincial level in Canada.  The health information legislation established the rules that must be followed for the collection, use, disclosure and protection of health information by healthcare workers known as ""custodians"". These custodians have been defined to include almost all healthcare professionals (including all physicians, nurses, chiropractors, operators of ambulances and operators of nursing homes). In addition to the regulatory bodies of specific healthcare workers, the provincial privacy commissions are central to the protection of patient information.
Much of the current legislation concerning privacy and patient information was enacted since 2000 as a result of the proliferation of the use electronic mobile devices in Canada. As a result, both large and small private businesses created smartphone and EMR solutions that comply with applicable legislation.


=== Turkey ===
The privacy of patient information is guaranteed by articles 78 and 100 of legal code 5510.
On the other hand, the Social Security Institution (SGK), which regulates and administers state-sponsored social security / insurance benefits, sells patient information after allegedly anonymizing the data, confirmed on October 25, 2014.


=== United Kingdom ===
The National Health Service is increasingly using electronic health records, but until recently, the records held by individual NHS organisations, such as General Practitioners, NHS Trusts, dentists and pharmacies, were not linked. Each organisation was responsible for the protection of patient data it collected. The care.data programme, which proposed to extract anonymised data from GP surgeries into a central database, aroused considerable opposition.
In 2003, the NHS made moves to create a centralized electronic registry of medical records. The system is protected by the UK's Government Gateway, which was built by Microsoft.  This program is known as the Electronic Records Development and the Implementation Programme (ERDIP). The NHS National Program for IT was  criticized for its lack of security and lack of patient privacy. It was one of the projects that caused the Information Commissioner to warn about the danger of the country ""sleepwalking"" into a surveillance society. Pressure groups opposed to ID cards also campaigned against the centralized registry.
Newspapers feature stories about lost computers and memory sticks but a more common and longstanding problem is about staff accessing records that they have no right to see.  It has always been possible for staff to look at paper records, and in most cases, there is no track of record.  Therefore, electronic records make it possible to keep track of who has accessed which records. NHS Wales has created the National Intelligent Integrated Audit System which provides ""a range of automatically generated reports, designed to meet the needs of our local health boards and trusts, instantly identifying any potential issues when access has not been legitimate"".  Maxwell Stanley Consulting will use a system called Patient Data Protect (powered by VigilancePro) which can spot patterns – such as whether someone is accessing data about their relatives or colleagues.


=== United States ===

Since 1974, numerous federal laws have been passed in the United States to specify the privacy rights and protections of patients, physicians, and other covered entities to medical data. Many states have passed its own laws to try and better protect the medical privacy of their citizens.
An important national law regarding medical privacy is the Health Insurance Portability and Accountability Act of 1996 (HIPAA), yet there are many controversies regarding the protection rights of the law.


==== Health Insurance Portability and Accountability Act of 1996 (HIPAA) ====

The most comprehensive law passed is the Health Insurance Portability and Accountability Act of 1996 (HIPAA), which was later revised after the Final Omnibus Rule in 2013. HIPAA provides a federal minimum standard for medical privacy, sets standards for uses and disclosures of protected health information (PHI), and provides civil and criminal penalties for violations.
Prior to HIPAA, only certain groups of people were protected under medical laws such as individuals with HIV or those who received Medicare aid. HIPAA provides protection of health information and supplements additional state and federal laws; yet it should be understood that the law's goal is to balance public health benefits, safety, and research while protecting the medical information of individuals. Yet many times, privacy is compromised for the benefits of the research and public health.
According to HIPAA, the covered entities that must follow the law's set mandates are health plans, health care clearinghouses, and health care providers that electronically transmit PHI. Business associates of these covered entities are also subject to HIPAA's rules and regulations.
In 2008, Congress passed the Genetic Information Nondiscrimination Act of 2008 (GINA), which aimed to prohibit genetic discrimination for individuals seeking health insurance and employment. The law also included a provision which mandated that genetic information held by employers be maintained in a separate file and prohibited disclosure of genetic information except in limited circumstances.
In 2013, after GINA was passed, the HIPAA Omnibus Rule amended HIPAA regulations to include genetic information in the definition of Protected Health Information (PHI). This rule also expanded HIPAA by broadening the definition of business associates to include any entity that sends or accesses PHI such as health IT vendors.


===== Controversies =====
Contrary to popular belief, the Health Insurance Portability and Accountability Act (HIPAA) does not provide strong medical privacy protections as it only provides regulations that disclose certain information.The government authorizes the access of an individual's health information for “treatment, payment, and health care options without patient consent”. Additionally, HIPAA rules are very broad and do not protect an individual from unknown privacy threats. Additionally, a patient would not be able to identify the reason for breach due to inconsistent requirements. Because of limited confidentiality, HIPAA facilitates the sharing of medical information as there is little limitation from different organizations. Information can easily be exchanged between medical institutions and other non-medical institutions because of the little regulation of HIPAA - some effects  include job loss due to credit score sharing or loss of insurance.Additionally, doctors are not required to keep patients information confidential because in many cases patient consent is now optional. Patients are often unaware of the lack of privacy they have as medical processes and forms do not explicitly state the extent of how protected they are. Physicians believe that overall, HIPAA will cause unethical and non-professional mandates that can affect a person's privacy and therefore, they in response have to provide warnings about their privacy concerns. Because physicians are not able to ensure a person's privacy, there is a higher chance that patients will be less likely to get treatment and share what their medical concerns are. Individuals have asked for better consent requirements by asking if physicians can warn them prior to the sharing of any personal information. Patients want to be able to share medical information with their physicians, yet they worry about potential breaches that can release financial information and other confidential information and with that fear, they are wary of who may have access.In order to ensure better protection, the government has created frameworks for keeping information confidential - some of which include being transparent about procedures, disclosure and protection of information, and monitoring of these new rules to ensure that people's information is not affected by breaches. Although there are many frameworks to ensure the protection of basic medical data, many organizations do not have these provisions in check. HIPAA gives a false hope to patients and physicians as they are unable to protect their own information. Patients have little rights regarding their medical privacy rights and physicians cannot guarantee those.


====== Hurricane Katrina ======
HIPAA does not protect the information of individuals as the government is able to publish certain information when they find it necessary. The government is exempted from privacy rules regarding national security. HIPAA additionally allows the authorization of protected health information (PHI) in order to aid in threats to public health and safety as long as it follows the good faith requirement - the idea that disclosing of information is necessary to the benefit of the public. The Model State Emergency Powers Act (MSEHPA) gives the government the power to “suspend regulations, seize property, quarantine individuals and enforce vaccinations” and requires that healthcare providers give information regarding potential health emergencies"".In regards to Hurricane Katrina, many people in Louisiana relied on Medicaid and their PHI was subsequently affected. People's medical privacy rights were soon waived in order for patient's to get the treatment they needed. Yet, many patients were unaware that their rights had been waived. In order to prevent the sharing of personal information in future natural disasters, a website was created in order to protect people's medical data. Ultimately, Katrina showed that the government was unprepared to face a national health scare.


====== Medical data outside of HIPAA ======
Many patients mistakenly believe that HIPAA protects all health information. HIPAA does not usually cover fitness trackers, social media sites and other health data created by the patient. Health information can be disclosed by patients in emails, blogs, chat groups, or social media sites including those dedicated to specific illnesses, ""liking"" web pages about diseases, completing online health and symptom checkers, and donating to health causes. In addition, credit card payments for physician visit co-pays, purchase of over the counter (OTC) medications, home testing products, tobacco products, and visits to alternative practitioners are also not covered by HIPAA.
A 2015 study reported over 165,000 health apps available to consumers. Disease treatment and management account for nearly a quarter of consumer apps. Two-thirds of the apps target fitness and wellness, and ten percent of these apps can collect data from a device or sensor. Since the Food and Drug Administration (FDA) only regulates medical devices and most of these applications are not medical devices, they do not require FDA approval. The data from most apps are outside HIPAA regulations because they do not share data with healthcare providers. ""Patients may mistakenly assume that mobile apps are under the scope of HIPAA since the same data, such as heart rate, may be collected by an application that is accessible to their physician and covered by HIPAA, or on a mobile app that is not accessible to the physician and not covered by HIPAA.


====== Changes ======
In 2000, there was a new surge to add new regulations to HIPAA. It included the following goals: to protect individual medical information by providing secure access and control of their own information, improving healthcare quality by creating a more trust between consumers and their healthcare providers and third party organizations, and improve the efficiency of the medical system through new rules and regulations put forth by the local governments, individuals, and organizations.The implementation of these new goals was complicated by the change in administrations (Clinton to Bush), so it was difficult for the changes to be successfully implemented. HIPAA, in theory, should apply to all insurance companies, services, and organizations, yet there are exceptions to who actually qualifies under these categories.
Yet, within each category, there are specific restrictions that are different in every category. There are no universal laws that can be easily applied that are easy for organizations can follow. Thus, many states have neglected to implement these new policies. Additionally, there are new patient rights that call for better protection and disclosure of health information. However, like the new rules regarding insurance companies, the enforcement of the legislation is limited and not effective as they are too broad and complex. Therefore, it is difficult for many organizations to ensure the privacy of these people. Enforcing these new requirements also causes companies to spend many resources that they are not willing to use and enforce, which ultimately leads to further problems regarding the invasion of an individual's medical privacy.


==== Oregon-specific laws ====
The Oregon Genetic Privacy Act (GPA) states that “an individual’s genetic information is the property of the individual”. The idea of an individual's DNA being compared to property occurred when research caused an individual's privacy to be threatened. Many individuals believed that their genetic information was “more sensitive, personal, and potentially damaging than other types of medical information.” Thus, people started calling for more protections. People started to question the how their DNA would be able to stay anonymous within research studies and argued that the identity of an individual could be exposed if the research was later shared. As a result, there was a call for individuals to treat their DNA as property and protect it through property rights. Therefore, individuals can control the disclosure of their information without extra questioning and research. Many people believed that comparing one's DNA to property was inappropriate, yet individuals argued that property and privacy are interconnected because they both want to protect the right to control one's body.Many research and pharmaceutical companies showed opposition because they were worried about conflicts that might arise regarding privacy issues within their work. Individuals, on the other hand, continued to support the act because they wanted protection over their own DNA. As a result, lawmakers created a compromise that included a property clause, that would give individuals protection rights, but also included provisions that would allow research to be done without much consent, limiting the benefits of the provisions. Afterwards, a committee was created to study the effects of the act and how it affected the way it was analyzed and stored. They found that the act benefited many individuals who did not want their privacy being shared with others and therefore the law was officially implemented in 2001.


==== Connecticut-specific laws ====
In order to solve HIPAA issues within Connecticut, state legislatures tried to create better provisions to protect the people living within the state. One of the issues that Connecticut tried to solve were issues with consent. Within the consent clause, health plans and health care clearinghouses do not need to receive consent from individuals because of a general provider consent form with gives healthcare providers permission to disclose all medical information. The patient thus does not get notification when their information is being shared afterwards.Connecticut, like many other states, tried to protect individual's information from disclosure of information through additional clauses that would protect them from businesses initiatives. In order to do so, Connecticut legislature passed the Connecticut Insurance Information and Privacy Protect Act, which provides additional protections of individual medical information. If third parties neglect to follow this law, they will be fined, may face jail time, and may have their licenses suspended. Yet, even in these additional provisions, there were many holes within this legislation that allowed for businesses agreements to be denied and subsequently, information was compromised. Connecticut is still working to shift its divergent purposes to creating more stringent requirements that create better protections through clear provisions of certain policies.


==== California-specific laws ====
In California, the Confidentiality of Medical Information Act (CMIA), provides more stringent protections than the federal statutes. HIPAA expressly provides that more stringent state laws like CMIA, will override HIPAA's requirements and penalties. More specifically, CMIA prohibits providers, contractors and health care service plans from disclosing PHI without prior authorization.
These medical privacy laws also set a higher standard for health IT vendors or vendors of an individual's personal health record (PHR) by applying such statutes to vendors, even if they are not business associates of a covered entity. CMIA also outlines penalties for violating the law. These penalties range from liability to the patient (compensatory damages, punitive damages, attorneys’ fees, costs of litigation) to civil and even criminal liability.Likewise, California's Insurance Information and Privacy Protection Act (IIPPA) protects against unauthorized disclosure of PHI by prohibiting unapproved information sharing for information collected from insurance applications and claims resolution.


=== New Zealand ===
In New Zealand, the Health Information Privacy Code (1994) sets specific rules for agencies in the health sector to better ensure the protection of individual privacy. The code addresses the health information collected, used, held and disclosed by health agencies. For the health sector, the code takes the place of the information privacy principles.


=== Netherlands ===
The introduction of a nationwide system for the exchange of medical information and access to electronic patient records led to much discussion in the Netherlands.


== Privacy for research participants ==

In the course of having or being part of a medical practice, doctors may obtain information that they wish to share with the medical or research community. If this information is shared or published, the privacy of the patients must be respected. Likewise, participants in medical research that are outside the realm of direct patient care have a right to privacy as well.


== See also ==


== References ==


== External links ==
European Standards on Confidentiality and Privacy in Healthcare
Opt out of the NHS Spine, or the NHS Confidentiality campaign
Electronic Frontier Foundation on medical privacy"
"Medical restraints are physical restraints used during certain medical procedures to restrain patients with the minimum of discomfort and pain and to prevent them from injuring themselves or others.


== Rationale ==
There are many kinds of mild, safety-oriented medical restraints which are widely used.  For example, the use of bed rails is routine in many hospitals and other care facilities, as the restraint prevents patients from rolling out of bed accidentally.  Newborns frequently wear mittens to prevent accidental scratching.  Some wheelchair users use a belt or a tray to keep them from falling out of their wheelchairs.  In fact, not using these kinds of restraints when needed can lead to legal liability for preventable injuries.Medical restraints are generally used to prevent people with severe physical or mental disorders from harming themselves or others.  A major goal of most medical restraints is to prevent injuries due to falls. Other medical restraints are intended to prevent a harmful behavior, such as hitting people.
Ethically and legally, once a person is restrained, the safety and well being of the restrained person falls upon the restrainer, appropriate to the type and severity of the restraining method.  For example, a person who is placed in a secured room should be checked at regular intervals for indications of distress.  At the other extreme, a person who is rendered semi-conscious by pharmacological (or chemical) sedation should be constantly monitored by a well-trained individual who is dedicated to protecting the restrained person's physical and medical safety.  Failure to properly monitor a restrained individual may result in criminal and civil prosecution, depending on jurisdiction.
Although medical restraints, used properly, can help prevent injury, they can also be dangerous. The United States Food and Drug Administration (FDA) estimated in 1992 that improper use of restraints results in at least 100 deaths each year, most by strangulation. FDA also noted reports of injuries — including broken bones and burns — caused by the improper use of restraints. Medical restraints in psychiatric hospitals in Japan are sometimes kept on patients for weeks and months 
, and they are thought to have caused several deaths due to deep vein thrombosis and pulmonary embolism.  More information about Japanese use of restraints is described in the page on physical restraints.
Because of the potential for abuse, the use of medical restraints is regulated in many jurisdictions. At one time in California, psychiatric restraint was viewed as a treatment. However, with the passing of SB-130, which became law in 2004, the use of psychiatric restraint(s) is no longer viewed as a treatment, but can be used as a behavioral intervention when an individual is in imminent danger of serious harm to self or others.


== Types ==
There are many types of medical restraint:

Four-point restraints, fabric body holders, straitjackets are typically only used temporarily during psychiatric emergencies.
Restraint masks to prevent patients from biting in retaliation to medical authority in situations where a patient is known to be violent.
Lap and wheelchair belts, or trays that clip across the front of a wheelchair so that the user can't fall out easily, may be used regularly by patients with neurological disorders which affect balance and movement.
All four side rails being in the upright position on a bed can be considered a restraint.
Safety vests and jackets can be placed on a patient like any other vest garment. They typically have a long strap at each end that can be tied behind a chair or to the sides of a bed to prevent injury or to settle patients for satisfying basic needs such as eating and sleeping. Posey vests are commonly used with elderly patients who are at risk of serious injury from falling.
Limb restraints to prevent unwanted activity in various limbs. They are wrapped around the wrists or ankles, and tied to the side of a bed, to prevent self-harm and harm to medical staff.
Mittens to prevent scratching are common for newborns, but may also be used on psychiatric patients or patients who manage to use their hands to undo limb restraints.
A Papoose board can be used for babies and young children.
Chemical restraints are drugs that are administered to restrict the freedom of movement or to sedate a patient.


== Manual techniques ==
A number of private national and regional companies teach physical (non-mechanical) restraint techniques for companies and agencies that care for or have custody of people who might become aggressive. The strategies vary widely, with many based on police or martial art pain compliance techniques, with others using only pain-free techniques. Most also emphasize verbal de-escalation and defusing skills before using any physical skills. A non-inclusive list:

Crisis Consultant Group (CCG) Non-Violent Physical technique.
The Mandt System.
Non Abusive Psychological and Physical Intervention (NAPPI).
Non-Violent Crisis Intervention (NVCI) techniques.
Professional Crisis Management (PCM).
Professional Assault Crisis Training (ProACT).
Therapeutic Crisis Intervention (TCI).


== Adverse effects ==
Throughout the last decade or so, there has been an increasing amount of evidence and literature supporting the idea of a restraint free environment due to their contradictory and dangerous effects. This is due to the adverse outcomes associated with restraint use, which include: falls and injuries, incontinence, circulation impairment, agitation, social isolation, and even death.


== Applicable laws ==
Current United States law requires that most involuntary medical restraints may only be used when ordered by a physician. Such a physician's order, which is subject to renewal upon expiration if necessary, is valid only for a maximum of 24 hours.


=== Japan ===
Japanese law states that psychiatric hospitals may use restraints on patients only if there is a danger that the patients will harm themselves or others. The law also states that a designated psychiatrist must approve the use of restraints and examine the patient at least every 12 hours to determine whether the situation has changed and the patient should be removed from restraints.
However in practice, Japanese psychiatric hospitals use restraints fairly often and for long periods.  Despite being required to certify every 12 hours whether a patient still needs restraints, Japanese psychiatric hospitals keep patients in restraints for a much longer time than hospitals in other countries. According to a survey conducted on 689 patients in 11 psychiatric hospitals in Japan, the average time spent in physical restraints is 96 days.
Meanwhile, the average time in most other developed countries is at most several hours to tens of hours. 
The number of people who are physically restrained in Japanese psychiatric hospitals continues to increase. In 2014 more than 10,000 people were restrained-the highest ever recorded, and more than double the number a decade earlier. It is thought that some of that increase includes older patients with dementia.  As a result, the Japanese Ministry of health has revised its guidelines for elderly people in nursing homes to have more restrictions against body restraints. The changes took effect on 1 April 2018.


=== United Kingdom ===
The Millfields Charter is an electronic charter which promotes an end to the teaching to frontline healthcare staff of all prone (face down) restraint holds. In June 2013 the UK government announced that it was considering a ban on the use of face-down restraint in English mental health hospitals.Face down restraints are used more often on women and girls than on men.  51 out of 58 mental health trusts use restraints unnecessarily when other techniques would work.  Organisations opposed to restraints include Mind and Rethink Mental Illness. YoungMinds and Agenda claim restraints are “frightening and humiliating” and “re-traumatises” patients especially women and girls who have previously been victims of physical and/or sexual abuse.  The charities sent an open letter to health secretary, Jeremy Hunt showing evidence from 'Agenda, the alliance for women and girls at risk', revealing that patients are routinely restrained in some mental health units while others use non-physical ways to calm patients or stop self-harm.  According to the letter over half of women with psychiatric problems have suffered abuse, restraint can cause physical harm, can frighten and humiliate the victim.  Restraint, specially face down restraint can re-traumatise patients who previously suffered violence and abuse. “Mental health units are meant to be caring, therapeutic environments, for people feeling at their most vulnerable, not places where physical force is routine.”
Government guidelines state that face down restraint should not be used at all and other types of physical restraint are only for last resort.  Research by Agenda found one fifth of women and girl patients in mental health units had suffered physical restraint. Some trusts averaged over twelve face down restraints per female patient.  Over 6% of women, close to 2,000 were restrained face-down in total more than 4,000 times. The figures vary widely between regions.
Some trusts hardly use restraints, others use them routinely.  A woman patient was in several hospitals and units at times for a decade with mental health issues, she said in some units she suffered restraints two or three times daily.  Katharine Sacks-Jones director of Agenda, maintains trusts use restraint when alternatives would work.  Sacks-Jones maintains women her group speak to repeatedly describe face down restraint as a traumatic experience.  On occasions male nurses have used it when a woman did not want her medication. “If you are a woman who has been sexually or physically abused, and mental health problems in women often have close links to violence and abuse, then a safer environment has to be just that: safe and not a re-traumatising experience. (...) Face-down restraint hurts, it is dangerous, and there are some big questions around why it is used more on women than men.”  The use of restraints in UK psychiatric facilities is increasing.""


== See also ==
Sedation
Locking clothing
Restraint chair
Spit hood
Physical restraint


== References ==


== External links =="
"A medical assistant, also known as a  ""clinical assistant"" or healthcare assistant in the USA is an allied health professional who supports the work of physicians, physician assistants and other health professionals, usually in a clinic setting. Medical assistants can become certified through an accredited program. Medical assistants perform routine tasks and procedures in a medical clinic.
A ""medical assistant"" may be certified or registered, or may be a loosely defined group (covering related occupational titles such as ""medical office assistant"", ""clinical assistant"", ""assistant medical officer"", or ""ophthalmic assistant""). The occupation should not be confused with physician assistants, who are licensed professionals trained to practice medicine and perform surgical procedures in collaboration with a physician.
In military settings, occupations that provide primary medical care may go under similar titles, while other occupations may have different titles with similar responsibilities, such as medical assistant in the U.K. Royal Navy or hospital corpsman in the U.S. Navy.


== Overview ==
Medical assistants perform routine clinical and administrative duties under the direct supervision of a physician or other health care professional. Medical assistants perform many administrative duties, including answering telephones, greeting patients, updating and filing patients' medical records, filling out insurance forms, handling correspondence, scheduling appointments, arranging for hospital admission and laboratory services, and handling billing and book keeping. Duties vary according to laws of the jurisdiction and may include taking medical histories and recording vital signs, explaining treatment procedures to patients, preparing patients for examination, and assisting during diagnostic examinations. Medical assistants collect and prepare laboratory specimens or perform basic laboratory tests on the premises, dispose of contaminated supplies, and sterilize medical instruments. They instruct patients about medications and special diets, prepare and administer medications as directed, authorize drug refills as directed, telephone prescriptions to a pharmacy, draw blood, prepare patients for X-rays, take electrocardiograms, remove sutures, and change dressings. They also facilitate communication between the patient and other health care professionals.Some jurisdictions allow medical assistants to perform more advanced procedures, such as giving injections or taking X-rays, after passing a test or taking a course.
According to the International Standard Classification of Occupations, medical assistants normally require formal training in health services provision for competent performance in their jobs. Formal education usually occurs in post secondary institutions such as vocational schools, technical institutes, community colleges, proprietary colleges, online educational programs or junior colleges. Medical assistant training programs most commonly lead to a certificate or a diploma, which take around one year to complete, or an associate degree, which takes around two years. Study topics include medical terminology, anatomy and physiology, and programs may include a clinical internship, sometimes referred to as ""externship"", wherein the student works as a medical assistant in a medical clinic.


== Bangladesh ==
In Bangladesh, medical assistants are known as Sub Assistant Community Medical Officer (SACMO). Medical assistants (now to be designated as sub-assistant community medical officer) assist the medical officers posted at health facilities at the upazila health complex level and below. Medical assistants are produced by Medical Assistants Training School (MATS). They get registration from Bangladesh Medical and Dental Council as an assistant  medical  practitioner.


== Canada ==
In Canada, medical assistants typically complete an educational program that prepares them to perform special assisting and secretarial duties for physicians, dentists, nurses, health care facilities, and other health service providers. Instructional programs include courses in business and medical communications, medical terminology, principles of health care operations, public relations and interpersonal communications, software applications, record-keeping and filing systems, scheduling and meeting planning,  policies and regulations, and professional standards and ethics.Medical assistant job responsibilities vary depending on the nature and size of the health care facility where the individual works, but typically involve multiple administrative duties such as scheduling appointments, handling private medical documents, and assisting patients with the admissions process.


== Malaysia ==
In Malaysia, medical assistants are known as Assistant Medical Officers (AMO). They complete a three and half year diploma in medical assistant (DMA) undergraduate program recognized by the Malaysian Qualifications Agency. They work independently or with limited supervision of a physician to provide healthcare services to largely underserved populations. The occupation is more similar to that of clinical officers in Tanzania and elsewhere.


== United States ==
In the United States, medical assistants have traditionally held jobs almost exclusively in ambulatory care centers, urgent care facilities, and clinics, but this is now changing. Medical assistants now find employment in both private and public hospitals, inpatient and outpatient facilities, as well as assisted living facilities, administrative and clinical settings, or general practice and specialty doctor's offices. According to the U.S. Department of Labor's Occupational Outlook Handbook, 2014–15 Edition, employment of medical assistants is expected to grow by 29%, much faster than the average for all occupations through 2022.


=== Education and training ===
The New America Foundation has criticized medical assistant programs, particularly those run by profit-making schools like Kaplan and Everest Institute. Many graduates of the school cannot find full-time work, or cannot find work at all, cannot make enough to pay their loans, and go into default. According to the Department of Labor, median annual salary for medical assistants in 2011 was $29,100, but students with medical-assistant certificates typically earned less than $20,000. In some programs, graduates earned less than $15,080, the minimum wage, which means they were working part-time. For example, Drake College of Business, Elizabeth, NJ, charges $18,000, but 31% of graduates defaulted on loans. A few public community colleges have successful programs where graduates make more than $25,000 a year.In the U.S., an institution's medical assisting program may be accredited by the Commission on Accreditation of Allied Health Education Programs (CAAHEP) or the Accrediting Bureau of Health Education Schools (ABHES) if its graduates plan to become certified or registered. Accreditation is a requirement of certification agencies such as the American Association of Medical Assistants (AAMA), the American Medical Technologists (AMT) and the National Health Career Association (NHA). Currently there are in excess of 600 CAAHEP accredited programs in can than 500 institutions, and more than 200 accredited by ABHES. Accreditation by CAAHEP, ABHES or other accreditation associations requires that the institution's medical assisting program meets specific educational standards and provides sufficient classroom, lecture, and laboratory time.


=== Certification ===
Professional certification is a way to measure competency of a medical assistant at an entry-level job. Certification for medical assistants is voluntary and optional, though encouraged by the American Association of Medical Assistants (AAMA) and a number of other certification bodies. Employers increasingly prefer or even require that the medical assistants they hire be certified.In the United States, different organizations certify medical assistants. For one, the American Association of Medical Assistants (AAMA) was founded in 1956. Certification may be achieved by taking the CMA (AAMA) Certification Examination offered by the AAMA Certifying Board in consultation with the National Board of Medical Examiners, which also administers many national exams for physicians. The CMA (AAMA) exam is offered throughout the year at computer-based testing centers across the country. Only individuals who have successfully completed a CAAHEP or ABHES accredited medical assisting program are eligible for the CMA (AAMA) Certification Examination. Those who successfully complete the CMA (AAMA) Certification Examination earn the CMA (AAMA) credential, a title which then follows postnominally. A CMA (AAMA) must re-certify every 60 months by continuing education or re-examination in order to maintain certification.
Other credential options include becoming a registered medical assistant (RMA). Credentialing is voluntary. The American Medical Technologists (AMT) agency is responsible for certifying MAs who choose this course. The AMT first began offering this certification in 1972. AMT has its own conventions and committees, bylaws, state chapters, officers, registrations, and re validation examinations. To become eligible to hold the title of RMA, a student must either pass a medical assisting curriculum at a school that accredited by the National Commission for Certifying Agencies (NCCA), or possess a minimum of five years experience.
The National Center for Competency Testing (NCCT) is an independent credentialing organization that has administered more than 400,000 certification exams across the United States since 1989. Its National Certified Medical Assistant certification program has earned accreditation by the National Commission for Certifying Agencies (NCCA). Candidates who meet all medical assistant eligibility requirements and pass the NCCT national certification examination earn the credential NCMA (NCCT). NCCT accepts candidates from approved medical assistant programs in colleges/universities and provides additional experiential-based qualifying routes. Once certified, the NCMA (NCCT) must complete 14 clock hours of continuing education annually to maintain the credential.


== See also ==
Assistant Medical Officer
Hospital Corpsman
Medical Assistant (Royal Navy)


== References ==


== External links ==
U.S. Bureau of Labor Statistics"
"Doctor of Medicine (abbreviated M.D., from the Latin Medicinae Doctor) is a medical degree, the meaning of which varies between different jurisdictions. In Canada and most other countries, the M.D. denotes an undergraduate degree awarded upon graduation from medical school. In the United States, and some other countries, the M.D. denotes a professional graduate degree. In the United States, this generally arose because many in 18th-century medical professions trained in Scotland, which used the M.D. degree nomenclature. In England, however, Bachelor of Medicine, Bachelor of Surgery was used and eventually in the 19th century became the standard in Scotland too. Thus, in the United Kingdom, Ireland and other countries, the M.D. is a research doctorate, higher doctorate, honorary doctorate or applied clinical degree restricted to those who already hold a professional degree in medicine; in those countries, the equivalent professional to the North American and some others use of M.D. is still typically titled Bachelor of Medicine, Bachelor of Surgery (M.B.B.S.).


== History ==

In 1703, the University of Glasgow's first medical graduate, Samuel Benion, was issued with the academic degree of Doctor of Medicine.University medical education in England culminated with the MB qualification, and in Scotland the M.D., until in the mid-19th century the public bodies who regulated medical practice at the time required practitioners in Scotland as well as England to hold the dual Bachelor of Medicine and Bachelor of Surgery degrees (MB BS/MBChB/MB BChir/BM BCh etc.). North American medical schools switched to the tradition of the ancient universities of Scotland and began granting the M.D. title rather than the MB beginning in the late 18th century. The Columbia University College of Physicians and Surgeons in New York (which at the time was referred to as King's College of Medicine) was the first American university to grant the M.D. degree instead of the MB.Early medical schools in North America that granted the Doctor of Medicine degrees were Columbia, Penn, Harvard, Maryland, and McGill. These first few North American medical schools that were established were (for the most part) founded by physicians and surgeons who had been trained in England and Scotland.
A feminine form, ""Doctress of Medicine"" or Medicinae Doctrix, was also used by the New England Female Medical College in Boston in the 1860s. In most countries having a Doctor of Medicine degree does not mean that the individual will be allowed to practice medicine. Typically a doctor must go through a residency for at least four years and take some form of licensing examination in their jurisdiction.


== By country ==


=== Professional degrees ===


==== Afghanistan ====
In Afghanistan, medical education begins after high school. No pre-medicine courses or bachelor's degree is required. Eligibility is determined through the rank applicants obtain in the public university entrance exam held every year throughout the country. Entry to medical school is competitive, and only students with the highest ranks are accepted into medical programs. The primary medical degree is completed in 7 years. According to the new medical curriculum (from 2016), during the 12th semester, medical students must complete research on a medical topic and provide a thesis as part of their training. Medical graduates are awarded a certificate in general medicine, regarded ""MD"" and validated by the ""Ministry of Higher Education of Afghanistan"". All physicians are to obtain licensing and a medical council registration number from the ""Ministry of Public Health"" before they officially begin to practice. They may subsequently specialize in a specific medical field at medical schools offering the necessary qualifications. After graduation, students may complete residency.
The MD specification:
Before the civil wars in Afghanistan, medical education used to be taught by foreign professors or Afghan professors who studied medical education abroad. The Kabul medical institute certified the students as ""Master of Medicine"". After the civil wars, medical education has extremely changed, and the MD certification has been reduced to ""Medicine Bachelor"".


==== Argentina ====
In Argentina, the First Degree of Physician or Physician Diplomate (Spanish: Título de Médico) is equivalent to the North American MD Degree with six years of intensive studies followed by usually three or four years of residency as a major specialty in a particular empiric field, consisting of internships, social services and sporadic research. Only by holding a Medical Title can the postgraduate student apply for the Doctor degree through a Doctorate in Medicine program approved by the National Commission for University Evaluation and Accreditation.


==== Australia ====

Historically, Australian medical schools have followed the British tradition by conferring the degrees of Bachelor of Medicine and Bachelor of Surgery (MBBS) to its graduates whilst reserving the title of Doctor of Medicine (MD) for their research training degree, analogous to the PhD, or for their higher or honorary doctorates. Although the majority of Australian MBBS degrees have been graduate programs since the 1990s, under the previous Australian Qualifications Framework (AQF) they remained categorized as Level 7 Bachelor's degrees together with other undergraduate programs.
The latest version of the AQF includes the new category of Level 9 Master's (Extended) degrees which permits the use of the term 'Doctor' in the styling of the degree title of relevant professional programs. As a result, various Australian medical schools have replaced their MBBS degrees with the MD to resolve the previous anomalous nomenclature. With the introduction of the Master's level MD, universities have also renamed their previous medical research doctorates. The University of Melbourne was the first to introduce the MD in 2011 as a basic medical degree, and has renamed its research degree to Doctor of Medical Science (DMedSc).


==== Austria ====
In Austria, medical studies (medicine or dentistry) take 6 years full-time. In medicine, the first two years comprise basic fields of medicine such as anatomy, biology, chemistry, physics, physiology, etc., the next three years consist of all medical fields in the narrower sense with frequent bedside training and medical traineeships while the sixth and last year is dedicated solely to working in a clinic. After this, a specific 6-year training (e.g. in internal medicine, paediatrics, ENT, pathology) or 4 year (GP) can be started; without this training, working with patients is forbidden. There is no central placement test for said specialist training, only a board-registered spot as a resident/registrar is needed. As with all other studies in Austria, there is no tuition but compulsory students' insurance (approx. 38 € per year). A specific entrance exam (MedAT, Medizin-Aufnahmetest, medicine acceptance test) has to be taken but is open only once a year in summer; a fee of 110 € has to be paid. In 2019, 16.443 persons registered for the MedAT and 12.960 took the test. 1.680 university places for both medicine and dentistry are offered each year with 95% of all places for EU citizens and 75% for applicants with an Austrian higher education entrance qualification/GCE A-levels. Many Germans who are denied studying in their home country try to study medicine in Austria; hence this quota was introduced and approved by the EU as most of them leave upon graduation.The title of ""Doktor"" is granted to physicians (Dr. med. univ., Doctor medicinae universae, Dr. der gesamten Heilkunde = Dr. ""of the entire art of healing"") and dentists (Dr. med. dent., Doctor medicinae dentinae), who do not possess doctorate degrees, but Master's level 6 year-training, similar to the American MD or DDS. although they have to write a diploma thesis of approx. 50-100 pages. Some of which are published in peer-reviewed journals while others are not. A post-graduate research doctorate (Dr. scient. med., Dr. scientiae medicinae, or PhD) can be obtained after a three years post-graduate study at a medical university.
All doctors may be addressed as ""Doktor ______"", and the title is usually contracted to ""Dr. ______"". In many everyday-day settings in Austria, also outside the clinic, it is common to address medical doctors solely as ""Herr/Frau Doktor"" (Mr./Ms./Mrs. doctor) without any specific family name (especially in rural areas and small villages, and by older people), and they are often viewed as the ""real doctors"". Among themselves, MDs don't use ""doctor"" as an appellation but just ""Herr Kollege/Frau Kollegin"" (Mr./Ms/Mrs. = ""dear"" colleague). Consistent use of ""Doktor"" when addressing another medical doctor is seen as confrontative and mockery.


==== Belgium ====
In French-speaking part of Belgium, the medical degree awarded after six years of study is ""Docteur en Médecine"". Physicians would then have to register with the Ordre des Médecins to practice medicine in the country.


==== Bosnia and Herzegovina ====
In Bosnia and Herzegovina, the title of ""doktor medicine"" (abbreviated ""dr. med."") is awarded upon completion of six years of study at a Faculty of Medicine (""medicinski fakultet"") immediately after high school.


==== Bulgaria ====
At the end of the six-year medical programs from Bulgarian medical schools, medical students are awarded the academic degree Master/Magister in Medicine and the professional title Physician - Doctor of Medicine (MD / MA ).


==== Cambodia ====
After 6 years of general medical education (a foundation year plus 5 years), all students will graduate with a Bachelor of Medical Sciences (BMedSc, Khmer: បរិញ្ញាប័ត្រ វិទ្យាសាស្រ្តវេជ្ជសាស្ត្រ), equivalent to Bachelor of Science, Bachelor of Surgery (MBBS). This degree does not allow graduates to work independently as a physician, but it is possible for those who wish to continue to master's degrees in other fields relating to medical sciences such as public health, epidemiology, biomedical science, and nutrition.
Medical graduates, who wish to be fully qualified as physicians or specialists must follow the process as below:

General Practitioner's (GP) course of 8 years (BMedSc plus a 2-year internship). Clinical rotation during the internship is modulated within four main disciplines (general medicine, surgery, gynecology, and pediatrics). The medical certification awarded is Diploma of Doctor of Medicine (MD, Khmer: បណ្ឌិតវេជ្ជសាស្ត្រ ឬ វេជ្ជបណ្ឌិត) – equivalent to a master's degree [?].
After graduating with BMedSc; any students who wish to enter a 'Residency Training Program', are required to sit for an Residency Entrance Exam. The duration of the programs takes 4 years after either BMedSc or MD  (BMedSc or MD plus 4 years of specialization). Once the graduates have successfully defended their practical thesis, they are awarded the Diploma of Specialized Doctor (MD with specialization, Khmer: សញ្ញាប័ត្រ៖ វេជ្ជបណ្ឌិតឯកទេស, lit. 'Professional Doctorate').All medical graduates must complete a 'Thesis Defense' and pass the National Exit Exam (Khmer: ប្រឡងចេញថ្នាក់ជាតិក្នុងវិស័យសុខាភិបាល) to become either GPs or medical or surgical specialists. Last but importantly, those GPs or MDs have to register their name in the Cambodian Medical Committee (CMC) to receive the liscense to see patients, and pay for the registration every year.


==== Canada ====

In Canada, the M.D. is the degree required to practice medicine. McGill University Faculty of Medicine is the only medical school in Canada that continues to award the M.D., C.M. degrees (abbreviated M.D.C.M.). M.D.C.M. is from the Latin Medicinae Doctorem et Chirurgiae Magistrum meaning ""Doctor of Medicine and Master of Surgery"". Upon graduation, students enter into a residency phase of training. Prior to obtaining an independent practicing license from a provincial regulatory body, students must complete the Medical Council of Canada Qualifying Examination to obtain the Licentiate of the Medical Council of Canada (LMCC) qualification.


==== China ====
In China, many prestigious research universities such as Peking Union Medical College, Peking University Health Science Center, and Shanghai Jiao Tong University offer the 8-year Doctor of Medicine program. In the meantime, the majority of primary medical training comes in the form of a 5-year Bachelor of Medicine degree, which includes 2.5 years of basic science and biomedical science training and 2.5 years of clerkship training. Graduates from such programs are eligible to sit for Medical Doctor License Examination in China providing they are working as resident physicians in a hospital. Many of the young doctors do seek further training by entering a 3-year Master of Medicine (clinical track) program or 5-year Doctor of Medicine (clinical track). Some take a job/promotion after the 3-year program and work for a number of years and then take on another 3 years of training to get the ultimate Doctor of Medicine degree.


==== Croatia ====
In Croatia, the title of ""doktor medicine"" (abbreviated ""dr. med."") is awarded upon completion of six years of study at a Faculty of Medicine (""medicinski fakultet"") immediately after high school.


==== Cuba ====
In Cuba, the title of ""Doctor en Medicina"" (Doctor in Medicine) is awarded upon completion of six years of study at a University of Medical Sciences after high school. Medicine was one of the four foundational careers of the first Cuban university named Real y Pontificia Universidad de San Jeronimo de La Habana (current University of Havana) founded in 1728.


==== Dominican Republic ====
In the Dominican Republic, it is known as ""Doctor en Medicina"" (Doctor in Medicine). In 1511 the Spanish Catholic church founded the first university of the Americas in Santo Domingo present capital of modern-day Dominican Republic and name it Universidad Santo Tomas de Aquino (today Universidad Autonoma de Santo Domingo). In 1630 this university graduated the first medical doctors of the Americas and amongst the graduates some Native Americans included.


==== Ecuador ====
In Ecuador, medical school begins after graduating high-school. There are two options; applying to public or private universities. Both private and public university select their candidates based on entrance exams. Public universities are free while private universities cost around 6,000 - US$12,000 a year. In most universities, the carrier lasts for 6 years. After graduating, students obtain a degree of “médico” or ""médico cirujano"", depending which one is offered by each university. Both degrees are equivalent to doctor of medicine (MD).


==== France ====

After graduating from high school with a Baccalaureat, any student can register at a university of medicine (there are about 30 of them throughout the country). Until 2018, at the end of the first year, an internal ranking examination took place at each of these universities in order to implement the numerus clausus. This ranking examination and the numerus clausus has since been abolished. First year consists primarily of theoretical classes such as biophysics and biochemistry, anatomy, ethics or histology. Passing first year is generally considered very challenging, requiring hard and continuous work. Each student can only try twice. For example, the Université René Descartes welcomes about 2,000 students in the first year and only 300 after numerus clausus.
The second and third year are usually quite theoretical although the teachings are often accompanied by placements in the field (e.g., internships as nurses or in the emergency room, depending on the university).
During their fourth, fifth and sixth years, medical students get a special status called ""externe"" (In some universities, such as Pierre et Marie Curie, the externe status is given beginning in the third year). They work as interns every morning at the hospital plus a few night shifts a month and study in the afternoon. Each internship lasts between three and four months and takes place in a different department. Med students get five weeks off a year.
At the end of the sixth year, they need to pass a national ranking exam, which will determine their specialty. The first student gets to choose first, then the second, etcetera. Usually, students work hard during the fifth and sixth years in order to train properly for the national ranking exam. During these years, actual practice at the hospital and in conjunction with some theoretical courses are meant to balance the training. Such externs' average wage stands between 100 and 300 euros a month.
After taking those ranking exams, students can start as residents in the specialty they have been able to pick. That is the point from which they also start getting paid.
Towards the end of the medical program, French medical students are provided with more responsibilities and are required to defend a thesis; however, unlike a PhD thesis, no original research is actually necessary to write an MD thesis.  At the conclusion of the thesis defense, French medical students receive a State Diploma of Doctor of Medicine (MD, French: diplôme d'Etat de docteur en médecine). Every new doctor must then proceed to a Diploma of Specialised Studies (DES, French: diplôme d'Etudes spécialisées) to mark their specialty.  Some students may also receive a Diploma of Complementary Specialized Studies (DESC, French: diplôme d'Etudes spécialisées complémentaires).


==== Georgia ====
In Georgia, medical universities in Georgia offer a 6-year curriculum leading to award Doctor of Medicine (MD) ""Physician"" ""Medical Doctor (MD), a European medical degree which is valid throughout the world. Some of the reputed medical universities include Tbilisi State Medical University, Akaki Tsereteli State University and Petre Shotadze Tbilisi Medical Academy


==== Germany ====

After at least six years of medical school, the students graduate with a final federal medical exam (Dritter Abschnitt der ärztlichen Prüfung). Graduates receive their license to practice medicine and the professional title of physician (Arzt). About 80% of them additionally obtain the academic degree Doctor of Medicine (Dr. med.). The European Research Council ruled in 2010 that a Dr. med. doctorate alone is not considered equivalent to a PhD research degree for the purpose of selection for ERC Starting Grants, requiring additional evidence (e.g., proof of an appointment that requires doctoral equivalency, such as a post-doctoral fellowship) for the overall training to be considered equivalent to a PhD.


==== Guyana ====
In Guyana, Doctor of Medicine (MD) degree is awarded after the completion of 4 years or 5 years of study. Texila American University, Green Heart University, American International School of Medicine, Alexander American University, Lincoln American University provides medicine programs.


==== Hungary ====
In Hungary, after six years of medical school, which includes a sixth-year internship, students are awarded the degree of 'orvosdoktor' (Doctor of Medicine) degrees.


==== Indonesia ====
In Indonesia, the title of ""dokter"" (dr.) is awarded after 3-3.5 years of study (at least) and 1.5–2 years of clinical course in university hospitals. After a medical student finished those five years of study, they need to take ""Uji Kompetensi Mahasiswa Program Profesi Dokter"" (UKMPPD). If they pass the test, they can take Hippocrates Oath and the title of Dokter (dr.) is entitled before their name. Then they need to take a year-long internship course in primary health care clinics (also known as Puskesmas) or primary hospitals all over the country to practice as general practitioner under supervision of senior doctors. Those who wished to further their study into specialties can take graduate course of medicine of their preference and will be entitled with ""Specialist of ..."" after their name (e.g.: Sp.A for Spesialis Anak = Pediatrician). Graduate course of medicine is equal with residency program which is required the candidates to study for four years and hospital internship. Note that ""dr."" is used for medical graduates, while Dr. (or wrongfully DR.), that is Doktor is used for PhD holders.


==== Iran ====
In Iran, Medical education begins after high school. No pre-med course or BSc degree is required. The eligibility is determined through the rank applicants obtain in the public university entrance exam being held every year throughout the country. The entry to medical school is competitive and only students with the highest rank are accepted into medical program. The primary medical degree is completed in 7–7.5 years. On the final years (last 1–2 years) medical students need to do a research on a medical topic and provide thesis as part of their trainings. Medical graduates are awarded a certificate in general medicine, called ""Professional Doctorate in Medicine"" validated by the ""Ministry of Health and Medical Education of Iran"". All physicians will obtain license and medical council registration number from the ""Medical Council of Iran"" before they officially begin to practice. They may subsequently specialize in a specific medical field at medical schools offering the necessary qualifications.


==== Israel ====

There are six university medical schools in Israel, including the Technion in Haifa, Ben Gurion University in Be'er Sheva, Tel Aviv University, the Hebrew University in Jerusalem, the Medical school of the Bar-Ilan University in Safed and Ariel University. They all follow the European 6-year model except Bar-Ilan University and Ariel University, which has a four-year program similar to the US system. However, as of 2009, Tel Aviv University has introduced a four-year program similar to the US system for students with a bachelor's degree in certain biological sciences. The entrance requirements of the various schools of medicine are very strict. Israeli students require a high school Baccalaureate average above 100 and psychometric examination grade over 740, which corresponds to the 99th percentile. Candidates achieving these demanding cognitive requirements are then selected according to their ranking in the Mor and Mirkam MMI personality tests. Approximately 30% of applicants pass the Mor and Mirkam tests and are accepted into medical school. The demand for medical education is strong and growing, and there is a lack of doctors in Israel. The Technion Medical School, Ben Gurion University, and Tel Aviv University Sackler Faculty of Medicine offer 4-year MD programs for American students who have American college degrees and have taken the MCAT interested in completing rigorous medical education in Israel before returning to the US or Canada. In Israel, the degree of Doctor of Medicine (MD) is considered to be equivalent to a master's degree academically and legally.


==== Italy ====
In Italy, before the Bologna process, the degree of ""Dottore in Medicina e Chirurgia"" (literally Doctor in Medicine and Surgery, from the Latin Medicinae Doctor et Chirurgiae) is awarded after completion of at least six years of study and clinical training in a university and after the submission of a thesis, that consists of original research.
However, spurred by the Bologna process, a major reform instituted in 1999 to align University programmes with the more universal system of undergraduate (Bachelor's degree) and postgraduate studies (Master's and Doctoral degrees) and as such the degree of 'Dottore in Medicina e Chirurgia' is no longer offered and was replaced with the 'Laurea Magistrale in Medicina e Chirurgia' (Master of Medicine and Surgery). In this context, the new Laurea Magistrale a ciclo unico in Medicina e Chirurgia is a six-year second cycle degree, equivalent to a master's degree (360 ECTS credits) which can be earned in a six-year programme and requires a scientific research thesis. Consequently, the new medical degrees in Italy is considered to be equivalent to a Master's degree academically and legally.


==== Latvia ====
In Latvia, the duration of basic medical education is six years and the course leads to the degree of Doctor of Medicine.


==== Malaysia ====
In Malaysia, there are two types of MDs, one being for a basic medical degree while the other being a doctoral degree, depending on the awarding universities. The basic medical degree MDs (Similar to the MBBS awarded by other local universities) are awarded by both private and public universities, mostly are trained as a undergraduate 5-year course, however, with the establishment of Perdana University, it became the first university in Malaysia to provide a 4-year graduate entry course. Examples of universities in Malaysia offering the M.D degree are University Sains Malaysia, National University of Malaysia, University Putra Malaysia, UCSI University, etc. MDs are being awarded as a doctoral degree in public universities such as University of Malaya.


==== Philippines ====

In the Philippines, the MD is a first professional degree in medicine. To be accepted in Philippine medical schools, one must have finished a college degree before one can proceed to have a medical education. It is attained by either completing a 4-year degree or a 5-year degree (with internship included) from an accredited institution private and public Medical School by the Association of Philippine Medical Colleges and the Commission on Higher Education. The  MD degree does not permit the practice of medicine but qualifies the degree-holder to apply for registration to the Professional Regulatory Commission. Registration to the Commission through completion of internship and examinations will grant the privilege of practicing medicine in the Philippines. Moreover, the licensed Physician has the option to proceed for medical specialization and the taking of diplomate board examinations conducted by the respective board of medical specialists in a particular field.


==== Poland ====
In Poland the title of lekarz (physician, medical doctor) or ""lek."" is granted after completing a 6-year medical program (students apply to it directly after graduating high school). Many medical schools in Poland also offer medicine programs in English, which award the Doctor of Medicine (MD) degree. In contrast, a higher doctoral academic research degree in medicine resembling a PhD is named ""dr n. med."" or doktor nauk medycznych (Doctor of Medical Sciences). Specialization is valued similarly to a specialization in the English system. It is not a pre-requisite for a ""dr. n. med."" which is an academic, not a professional title in Poland.


==== Romania ====
Romanian medical programs last for 6 years (including clinical practice), which is the long-cycle first professional degree and concludes with a final licensing examination (licența), based on the dissertation of the student's original research. The degree awarded is 'Doctor-Medic' and graduates are entitled to use the title ""Dr.""


==== Russia ====

Medical universities in Russia offer a six-year curriculum leading to award a professional graduate degree, called qualification (degree) of ""specialist"" (Diploma of Specialist; in medicine, Diploma of Physician (Doctor of Medicine)).Whereas, the title of Doctor of Medical Sciences (Russian: доктор медицинских наук, ""doktor medicinskix nauk"" abbreviated д. м. н.) is a higher research doctoral degree, which may be earned after the Candidate of Medical Sciences (the latter is informally regarded in Russia as equivalent to the Ph.D.).


==== Serbia ====
In Serbia, MD degree is awarded upon completion of six years of study at a Faculty of Medicine immediately after high school.


==== Singapore ====
The American Duke University has a medical school based in Singapore (Duke-NUS Medical School), and follows the North-American model of styling its first professional degree ""Doctor of Medicine"" (""MD""), consid. By contrast, the Yong Loo Lin School of Medicine at the National University of Singapore confers MB BS as the first professional degree.


==== Slovakia ====
Slovakia's medical education is offered at three medical schools in the country. Two of them are faculties of the Comenius University, which are the Faculty of Medicine in Bratislava, and the Jessenius School of Medicine in Martin, while the third one is the Pavol Josef Šafarik University in Košice. Both the Jessenius School of Medicine and the Faculty of Medicine in Košice has several international students. The Jessenius School of Medicine has almost a thousand international students, most from Norway.
Admission to the medical schools is based on entrance examination that can be undergone once a year. The program is a 6 year program in general medicine with a strictly preclinical and clinical division. The preclinical years are the two first, and are purely theoretical. They consist of subjects such as cell biology, genetics, biophysics, medical chemistry, anatomy, biochemistry, histology, embryology and so on. From the third year onwards, the study is integrated with practical learning at the faculty’s associated teaching hospital, including major multi-year subjects such internal medicine, surgery, pediatrics, etc. In the sixth and final year, the student must pass four final state examinations and defend a self-composed thesis in order to graduate with a professional doctorate granting them the title of MUDr. for practicing in Slovakia or the Czech Republic or MD when practicing outside of Slovakia.


==== Slovenia ====
In Slovenia, the title of ""doktor medicine"" (abbreviated ""dr. med."") is awarded upon completion of six years of study at one of the two Slovenian Faculties of Medicine (""medicinska fakulteta"") in Ljubljana or Maribor. Studying at these faculties is only possible if the student has finished a gymnasium/grammar school (""gimnazija"") with a general diploma called ""splošna matura"".


==== South Korea ====
In South Korea, there is a Medical Doctor (MD) license.
The medical educations in South Korea (Republic of Korea) are 6 or 4 years in duration, 6-year courses starting right after high schools, and 4-year course starting after 4-year's university education (to start the 4-year course, the student needs a bachelor's degree). The first 2 years in the 6-year system is composed of basic sciences and liberal art courses.


==== Taiwan ====

In Taiwan, the MD is a first awarded professional degree that goes up and beyond the limits of upper education.


==== Thailand ====
The Thai medical education follows the 6-year European system, consisting of 1 year in basic-science, 2 years in pre-clinical training, and 3 years for clinical training. Upon graduation, all medical students must pass national medical licensing examinations and a university-based comprehensive test. After medical school, newly graduated doctors are under contract to spend a year of internship and 2 years of tenure in rural areas before they are eligible for any other residency positions or specialized training. The students will receive Doctor of Medicine (MD) degree. However, the degree is equivalent to master's degree in Thailand. Specialty training after the MD degree requires at least 4–6 years residency program in the training university hospitals and must pass the board examination. Board-certified specialized degree is equivalent to doctorate degree.


==== Tunisia ====
In Tunisia, education is free for all Tunisian citizens and for foreigners who have scholarships. The oldest Medical school is a faculty of the University of Tunis.  There are four medicine faculties situated in the major cities of Tunis, Sfax, Sousse and Monastir. Admission is bound to the success and score in the baccalaureate examination. Admission score threshold is very high, based on competition among all applicants throughout the nation. Medical school curriculum consists of six years.  The first two years are medical theory (PCEM), containing all basic sciences related to medicine, and the last four years (DCEM) consists of clinical issues related to all medical specialties.  During these last four years, the student gets the status of ""Externe"". The student has to attend at the university hospital every day, rotating around all wards. Every period is followed by a clinical exam regarding the student's knowledge in that particular specialty.  After those five years, there are two years on internship, in which the student is a physician but under the supervision of the chief doctor; the student rotates over the major and most essential specialties during period of four months each. After that, student has the choice of either passing the residency national exam or extending his internship for another year, after which he gains the status of family physician. The residency program consists of four to five years in the specialty he qualifies, depending on his score in the national residency examination under the rule of highest score chooses first. Whether the student chooses to be a family doctor or a specialist, he has to write a doctoral thesis, which he will be defending in front of a jury, after which he gains his degree of Docteur d'état en Medecine (MD).


==== Turkey ====
In Turkey, the title of ""Tıp Doktoru"" (literally ""Doctor of Medicine"") is awarded upon completion of six years continuous study started with five years university education include three years basic sciences, two years clinical courses followed by one year of internship in university hospitals. The internal structure and methodology of training varies among universities; however vertical integration between basic and clinical sciences and horizontal integration between disciplines have become more prevalent approaches as well as student oriented practices. Regardless of the university, the whole program is equvalent to a combined degree of bachelors and masters, thus every students graduates with a masters degree. The graduates, becoming Doctors of Medicine, are eligible to practice general medicine through state assigned slots, start residency training through a state exam called ""TUS""(short for ""Tıpta Uzmanlık Sınavı""), or apply for a PhD program in a relevant field.


==== Ukraine ====

In Ukraine, by 2018, graduates of the school with completed secondary education that have coped with the relevant exams (in the disciplines designated by these universities) in the nationwide system for assessing graduates' knowledge - EIT (Ukrainian: ЗНО, External independent testing) based on the rating - may be admitted to the Medical Universities.Ukrainian medical universities offer a 6-year curriculum, which should end with the passing of the State Complex Examination. The graduate receives the Diploma of the State Standard with the title ""Specialist Diploma"", which specifies a specialty and qualification (for example, ""Physician""), or ""Magister's Diploma"" also of a state standard. After that, the graduate according to the rating division (at the university) is required to undergo a practical internship course (working as a doctor under the supervision of an experienced doctor) with a duration of 2 to 3 years, in the corresponding specialty. Successful completion of internship implies that an intern passes an examination on a specialty, including testing  and receives a certificate of a specialist physician of the Ministry of Health, which is a formal permission for practical activity.Thus, the American MD and the Ukrainian Physician have identical titles. On the other hand, the colloquial (not official terminology) Doctor of Medicine means that a Physician with a higher education successfully defended his thesis, after a 2-year postgraduate course and corresponding term of research (Candidate of Medical Sciences before 2015, or Ph.D. after 2015 - till 2020), which is closer to the English system of degrees.


==== United States ====
In the United States, the M.D. awarded by medical schools is a ""Professional Doctorate"" (as opposed to the Doctor of Philosophy degree which requires a focus on research) and is accredited by the Liaison Committee on Medical Education (LCME), an independent body sponsored by the Association of American Medical Colleges, and the American Medical Association (AMA).In addition to the M.D., the Doctor of Osteopathic Medicine (D.O.) is an equivalent professional doctoral degree for physicians and surgeons offered by medical schools in the United States.  According to Harrison's Principles of Internal Medicine, ""the training, practice, credentialing, licensure, and reimbursement of osteopathic physicians is virtually indistinguishable from those of M.D. physicians, with 4 years of osteopathic medical school followed by specialty and subspecialty training and certification.""
Admission to medical school in the United States is highly competitive, and in the United States there were 21,869 matriculants to medical school out of 53,371 applicants (≈41%) in 2019. Before entering medical school, students are required to complete a four-year undergraduate degree and take the Medical College Admission Test (MCAT); however, some combined undergraduate-medical programs exist. Before graduating from a medical school and being awarded the Doctor of Medicine degree, students are required to take the United States Medical Licensing Examination (USMLE) Step 1 and both the clinical knowledge and clinical skills parts of Step 2. The MD degree is typically earned in four years. Following the awarding of the MD, physicians who wish to practice in the United States are required to complete at least one internship year (PGY-1) and pass the USMLE Step 3. In order to receive board eligible or board accredited status in a specialty of medicine such as general surgery or internal medicine, physicians undergo additional specialized training in the form of a residency. Those who wish to further specialize in areas such as cardiology or infectious diseases then complete a fellowship. Depending upon the physician's chosen field, residencies and fellowships involve an additional three to eight years of training after obtaining the MD. This can be lengthened with additional research years, which can last one, two, or more years.Even though the M.D. is a professional degree and not a research doctorate (i.e., a Ph.D.), many holders of the M.D. degree conduct clinical and basic scientific research and publish in peer-reviewed journals during training and after graduation; an academic physician whose work emphasizes basic research is called a physician-scientist. Combined medical and research training is offered through programs granting an MD-PhD. The National Institutes of Health (NIH), through its Medical Scientist Training Program, funds M.D.-Ph.D. training programs at many universities. Some M.D.s choose a research career and receive funding from the NIH as well as other sources such as the Howard Hughes Medical Institute. The United States Department of Education and the National Science Foundation do not include the M.D. or other professional doctorates among the degrees that are equivalent to research doctorates.


==== Venezuela ====
After graduating from high school in Venezuela students can apply for federal appointment to a six-year medical program within a University. Only Public Universities offer this degree in Venezuela. Any student can apply for federal appointment by Ministry of Higher Education. So that, the student is allowed to register at university and follow a medical program. This a six-year program divided within three cycles. First cycle: Theory and lectures (1-2), second cycle: pre-clinical training (3-4) and third cycle: clinical training (5-6).First year consists mainly of theoretical classes, however there are practice since first day in laboratories and institutes, such as biochemistry, anatomy which included lectures and teaching sessions with cadavers in dissection tables, Molecular Biology, histology, embryology and many others general subjects.The second year is usually mainly quite theoretical although most teaching sessions takes place in laboratories. After completing these  years the student know how the human body is and how it works. Also, any extrinsic agent that can modify its functions. There is also Medical Exercise demonstration which included guided visit to primarily care centers during a complete semester or year-round depending on universities.
During third year medical students start studying pharmacology, pathology and physical examination. Passing successfully first, second and third year is commonly considered a filter, almost half of previously admitted students leave voluntarily.
The fourth year medical students enter on the field starting to visit hospitals and healthcare services. This is called Pre-Clinical Cycle were they acquire deep knowledge about clinical examination visiting specialized units such as Internal Medicine, Trauma and orthopedics, surgery and gynecology and obstetrics. They start to be member of a medical team. Every morning at the hospital, plus one night shifts per week, and lectures in the afternoon. Each internship lasts between six and four months and takes place in a different department.
The fifth and sixth year are very similar but this time they applied their previously earned clinical knowledge and skills starting to follow patients independently. At the end of the sixth year, they need to pass a highly supervised medical practice examination in an unserved outpatient center or specialized hospital in order to earn the degree. During these years, there is training at the hospital almost exclusively. Very little theoretical courses are meant to balance the training. Once completed they earn a university degree and a title granted by the Bolivarian Republic of Venezuela as ""Medical Surgeon"" this is considered equivalent to a M.D degree.There is also a five years program the ""Médico Integral Comunitario"" title and degree granted by newly created universities and headed by Cuban nationals from the Cuba - Venezuela cooperation agreements. This program has been subject of controversy in the country over the legitimacy of the Cuban doctors' licensure for teaching and practice medicine.After graduation, recently graduate doctors acquire the right to use Dr. before their names but still must follow a one-year exercise in the countryside or a two years training in a specialized hospital. So that, They can be enabled to practice medicine with a full licence in Venezuela and the right to work as a medical doctor, generally as a general practitioner (Artículo 8). That is the point from which they also start getting paid.
They can follow specialized studies which usually last between 3 or 5 years depending on specialization  and furthermore a phD for relevant research activities which usually take at least three years more.


=== Postgraduate clinical degrees ===


==== Bhutan ====
In Bhutan, a medical doctor who completes 4 to 5 years of medical school is awarded with MBBS or Dr.title by their respective universities ( usually from universities in Sri Lanka, India, Thailand and Bangladesh). Upon recognition by Bhutan Health and Medical council, they work as medical doctor in country. M.D title is usually given to those who completes 3 to 4 years of residency for specialised course like surgery, medicine pediatrics, etc.


==== India ====
The MBBS (Bachelor of Medicine/Bachelor of Surgery) degree represents the first (undergraduate) level of training required to be licensed as a physician (other degrees in alternative medicine are present like BAMS, BHMS, BSMS etc.) and the MS or MD degree is a postgraduate degree, representative of speciality training. The equivalent training in the US or Canada would be the completion of a medical (post-graduate) degree. Eligibility for the MS or MD course is restricted to medical graduates holding the MBBS degree.
The MBBS course is for five and a half years, and training imparted is as follows:

Pre-clinical (Anatomy, Physiology, and Biochemistry)
Para-clinical (Pathology, Microbiology, Pharmacology, Forensic Medicine and Community Medicine)
Clinical (Ophthalmology, Otorhinolaryngology, General Medicine, General Surgery, Pediatrics and Obstetrics/Gynecology; with speciality rotations such as Orthopaedics, Radiology, etc.).After five and a half years of study and the successful completion of an examination, which includes both theoretical and practical elements, in a pre-clinical or clinical subject of a non-surgical nature [e.g. Anatomy (since the subject deals with study of anatomy through dissecting cadavers, thus given an MD degree), Physiology, Pharmacology, Internal Medicine, Pediatrics, Pathology, Microbiology] the candidate receives MD degree, whereas in a clinical subject of a surgical nature (e.g. General Surgery, Orthopaedics, Obstetrics/Gynaecology, Ophthalmology), the candidate receives the equivalent degree Master of Surgery (MS).
A second alternate qualification termed DNB [Diplomate of National Board], is considered equivalent to the MD and MS degrees. This can be obtained by passing the exam conducted by the National Board of Examinations after completing 5.5 years of post-MBBS residency training in teaching hospitals recognised by the board. The College of Physicians & Surgeons of Bombay, India (Established 1912) also awards higher postgraduate degrees in clinical and pre-clinical specialities, called FCPS; it involves five and a half years of study and the successful completion of an examination, which includes both theoretical and practical elements, and a research thesis and a viva. The FCPS is representative of speciality clinical training, and equivalent to MD/MS/DNB/Ph.D Medical in Medical Doctorate in other parts of the world. Until 2007, the Government of India and the Medical Council of India recognised the FCPS qualification - since then, this is being done by State Medical Councils.
After obtaining the first postgraduate degree, that is MD/MS/FCPS/DNB/Ph.D Medical, one can go for further specialisation in medical or surgical fields. This involves a highly competitive entrance examination. This course has three years of additional training and requires the submission of a dissertation (thesis). This is considered a clinical doctorate as the focus is on preparing a super-specialist with adequate clinical as well as research training. After the dissertation is approved and the exit examination (theory and practical) is cleared, the degree awarded is DM (Doctor of Medicine), Ph.D Medical . Based on the specific field of training, the degree awarded is DM in Cardiac Anaesthesia, Cardiology, Neurology, Nephrology, Gastroenterology, Neuroradiology, Critical Care, Pulmonology, Hematology, Medical Oncology, Clinical Pharmacology, Pediatric Critical Care, Pediatric Neurology, Neonataology, Pediatric Gastroenterology, Neuroanaesthesia, etc. For surgical superspecialities the degree awarded is MCh (Magister Chirurgiae), like MCh in Cardio-thoracic and Vascular Surgery, Endocrine Surgery, Neurosurgery, Surgical Gastroenterology, Urology, Plastic Surgery, Pediatric Surgery etc. DM and MCh are the clinical equivalent of a Doctorate degree.  A third alternate qualification is DNB (superspecialties), offered by National Board of Examinations, like DNB in Cardiology, Neurology, Cardiac Surgery, Neurosurgery.
Following DM or MCh, one can further go for postdoctoral fellowship programs of one-year duration in specific subspecialties like Cardiac Electrophysiology, Invasive cardiology, Pediatric cardiology, Epilepsy, stroke, electroencephalography, movement disorders, neuromuscular disorders, cerebrovascular surgery, skull base surgery, neurocritical care, pediatric cardiac surgery etc. offered by prestigious government institutes and abroad.


==== Pakistan ====
In Pakistan MBBS is the undergraduate degree. The MD is a higher doctorate, awarded by medical universities based on successful completion of a residency program of four to six years' duration in a university hospital. Many universities are offering MD. Parallel to MD, MS is a higher doctorate awarded on successful completion of four to six years' duration of a residency program in surgical field.


==== Sri Lanka ====
In Sri Lanka, the MD degree is a higher postgraduate degree that is awarded by the Postgraduate Institute of Medicine after completion of a postgraduate course, examinations and speciality training. The MD degree in Sri Lanka is representative of specialty training in clinical, para clinical, and preventive medicine (e.g., general medicine, cardiology, nephrology, oncology, para clinical such as microbiology, haematology and preventive such as community medicine). Entry for the MD course is open only for medical graduates holding the MBBS degree (with a duration of five and a half years), and training is obtained in medical disciplines that are non-surgical in nature (e.g., internal medicine, radiology, pathology, etc.) After three or four years of study and the successful completion of an examination with written as well as cases and via examinations, the MD degree in the respective field of study is awarded. In community medicine and medical administration, part I examination consists of a theoretical exam while the degree is conferred after completion of a thesis as a PhD. This thesis has to be completed within a period of five years. After successfully defending the academic thesis, the MD degree is conferred to the candidate. The MD degree holder is certified as a board certified specialist by the respective board of study of the Postgraduate Institute of Medicine after he or she undergoes 2–4 years of local and foreign training depending on the specialty/subspecialty selected.


=== Research degrees ===


==== United Kingdom, Ireland and some Commonwealth countries ====
The entry-level first professional degree in these countries for the practice of medicine is that of Bachelor of Medicine and Bachelor of Surgery (MBBS, MB, MB BCh BAO, BMBS, MBBChir, or MBChB). This degree typically requires between four and six years of study and clinical training, and is equivalent to the North American MD degree. Due to the UK code for higher education, first degrees in medicine comprise an integrated programme of study and professional practice spanning several levels. These degrees may retain, for historical reasons, ""Bachelor of Medicine, Bachelor of Surgery"" and are abbreviated to MBChB, MBBS or BMBS.In the UK, Ireland and many Commonwealth countries, the MD is a postgraduate research degree in medicine. At most universities, this takes the form of a first doctorate, analogous to the Ph.D., awarded upon submission of a thesis and a successful viva. The thesis may consist of new research undertaken on a full- or part-time basis, with much less supervision (in the UK) than for a Ph.D., or a portfolio of previously published work.In order to be eligible to apply for an MD degree from a UK or Commonwealth University one must hold either a ""Bachelor of Medicine, Bachelor of Surgery"" (MBBS, MBChB, BMBS for example) degree, or an equivalent U.S.-MD degree and must usually have at least five years of postgraduate experience. Therefore, graduates from the MBBS/MBChB/BMBS degrees do not hold doctorates; however, physicians holding these degrees are referred to as ""doctor"" as they are fully licensed as medical practitioners. In some commonwealth nations, these interns are designated as ""house officers"".
Traditionally, the MD in the UK and Commonwealth was a higher doctorate (similar to a DSc) awarded upon submission of a portfolio of published work representing a substantial contribution to medical research. Many universities have now changed its status, but this has happened only recently: for example, the University of Cambridge in 2012 introduced a new higher degree of MedScD (more akin to the ScD degree) awarded on the basis of a career's contribution to the science or art of medicine, while redesignating the MD as an initial research doctorate awarded on the basis of a thesis.; Oxford, which had changed the regulations for the MD degree to bring it more in line with initial doctorates in 2002, removed its status as a higher doctorate after a review in 2016. Some Commonwealth institutions retain the MD as a higher degree, such as the relatively new James Cook University).
In the case where the MD is awarded (either as a first or higher doctorate) for previously published research, the candidate is usually required to be either a graduate or a full-time member of staff, of several years' standing of the university in question.


=== Equivalent degrees in other countries ===
In Bangladesh, the basic medical degree is the MBBS. After completing the intermediate level of education (12 years) the candidate must undergo 5 years of medical training in any medical college to achieve the MBBS degree. After obtaining the degree, the candidate needs to undergo one year of internship to obtain BMDC (Bangladesh medical and dental council) accreditation in order to practice in the country.
In mainland China, some medical schools award MBBS to foreign students while all medical schools award Bachelor of Medicine to nationals. Some MD degrees are higher academic research degrees.
In Colombia, the medicine faculties of the universities awards the title of ""Medico Cirujano"" after taking 12 semesters of studies on  ""all clinic and surgery discipline a two semester on internship. After receiving the degree there is a mandatory year ""obliged social work"" were the doctors practice as GP in the countryside. Residency programs last between 3–4 years depends on the specialty.
The Czech and Slovak title MUDr. (Medicinae Universae doctor or doktor medicíny) is a professional doctorate granted upon completion of six years pregraduate Master's study at medical schools. The postgraduate academic research degree in medicine is a PhD degree.
The Danish and Norwegian Candidatus medicinae or Candidata medicinae degrees (cand. med.) is awarded after completing a six-year medical programme, to which students apply directly upon finishing secondary school. The programme usually includes a small thesis. However, the cand. med. degree must not be confused with the previous Danish and Norwegian Dr. Med. degree, which is a separate degree from the Ph.D. and represents a higher degree of medical research experience. It typically consists of at least 5–6 original publications.
In Finland, the duration of basic medical education is six years and the course leads to the degree of Licentiate of Medicine.
In Greece, after a six-year study, a medical student acquires his medical degree and the right to use ""Δρ."", (Dr.) before his name. This is considered equivalent to the MD title.
In Kosovo, there are medical high schools. Students from elementary school can choose to attend the medical high school, which lasts 3 years. When they finish the 3 years of medical high school, they practice for 4 months. After that, they can be a nurse or they can go to medical facilities in Pristina, with the education there taking around 6 years, including practice, to become a doctor.
In Mexico and Peru, schools of medicine award the ""Título de Médico Cirujano"" degree after completing either six or seven years of study. This curriculum includes a rotating internship year and a year of social service providing care to an underserved community.
In Nepal, a MBBS degree is awarded. This is an undergraduate level degree, which is awarded after completion of four and half years of medical school followed by one year of clinical internship. Most medical schools also offer postgraduate M.D and M.S. degrees, which requires three years of further training. Post-doctorate D.M. and M.Ch. terminal degrees are awarded by a few elite institutions after three more years of super-speciality training.
In the Netherlands, medical students receive six years of university education prior to their graduation. Prospective students can apply for medical education directly after finishing the highest level of secondary school, vwo; previous undergraduate education is not a precondition for admittance. Medical students receive three years of preclinical training, followed by three years of clinical training (co-assistentschappen, or co-schappen) in hospitals. At one medical faculty (Utrecht University), clinical training already begins in the third year of medical school. After 6 years, students graduate as Basisartsen (""base physician""). As a result of the Bologna process, medical students in the Netherlands receive a bachelor's degree (BSc) concluding successfully three years of medical university curriculum, and a master's degree (MSc) upon successful graduation. After graduation, physicians can apply for, and complete a R&D based doctorate, earning them a PhD in Medicine. Contrary to popular (international) daily use, the title ""MD"" does not exist, is not granted, nor recognised for Dutch physicians. Furthermore, no specific notation signifying board registration exists for physicians in the Netherlands.
In Belgium, Belgian medical education is much more based on theoretical knowledge than the Dutch system. In the first three years, which are very theoretical and lead to a university bachelor's degree, general scientific courses are taken such as chemistry, biophysics, physiology, biostatistics, anatomy, virology, etc. To enter the bachelor course in Flanders, prospective students have to pass an exam, as a result of the numerus clausus. After the bachelor courses, students are allowed to enter the 'master in medicine' courses, which consist of three years of theoretical and clinical study. In general, the first two master years are very theoretical and teach the students human pathology, diseases and pharmacology.  The third year is a year full of internships in a wide range of specialities in different clinics. The seventh, final year serves as a kind of 'pre-specialization' year in which the students are specifically trained in the specialty they wish to pursue after medical school. This contrasts with the Dutch approach, in which graduates are literally 'basic doctors' (basisartsen) who have yet to decide on a specialty.
In Portugal, to practice medicine, a master's degree in medicine (awarded after a 6-year Integrated master's program in medicine) is mandatory. Before the 2007 Bologna Process, the same course was only a Licentiate Degree. After the 6-year program, students must go through the National Seriation Exam (Prova Nacional de Seriação), and then a year of General Medical Internship (Ano Comum). When the internship ends, the students are placed in their choice of Medical Specialty, according to their ranking in the aforementioned Exam and the vacancies available for each medical specialty. Only when each student finishes the Medical Internship, will they be allowed to practice medicine without supervision. Entry to the Integrated Masters Program in Medicine is done directly after High School, based on the student's grade - each year there are about 1800 new Medical Students in Portugal, in 8 different Medical Schools.
In Sudan the awarded degree in most of the medical schools is, Bachelor of Medicine and Basic Surgery (MBBS). In schools that are based on the English system of medical teaching, the degree is granted after six years of studying. As for the schools that are adopting the American system, they grant their students the degree of MBBS in only five years.
In Sweden, medical education begins with a five-and-a-half-year undergraduate university program leading to the degree ""Master of Science in Medicine"" (Swedish: Läkarexamen). Following this, the National Board of Health and Welfare requires a minimum of 18 months of clinical internship (Swedish: AT (Allmäntjänstgöring)) before granting a medical license (Swedish: Läkarlegitimation) to be fully qualified as the Swedish equivalent to Medical Doctor (MD). This internship consists of surgery (3–6 months), internal medicine (3–6 months), psychiatry (three months) and family medicine (six months). Upon receiving a license to practice, a physician is able to apply for a post to start specialist training. There are currently 52 recognised medical specialties in Sweden. The specialist training (Swedish: ST (Specialiseringstjänstgöring)) has a duration of minimum five years, which upon completion grants formal qualification as a specialist.


=== Other postgraduate clinical degrees ===
There is also a similar advanced professional degree to the postgraduate MD: the Master of Surgery (usually ChM or MS, but MCh in Scotland, Ireland, Wales and at Oxford and MChir at Cambridge). The equivalence of these degrees, but their differing names, prevents the need for surgeons (addressed as Mr. in the UK) having to revert to the title Dr., which they once held as new MBBS graduates.
In Ireland, where the basic medical qualification includes a degree in obstetrics, there is a similar higher degree of Master of the Art of Obstetrics (MAO). A Master of Midwifery was formerly examined by the Worshipful Society of Apothecaries of London (hence MMSA) but fell into abeyance in the 1960s; in this case, the term Master referred not to a university degree but rather a professional rank that is common among craft guilds.
In East Africa, the medical schools in Kenya, Tanzania and Uganda award the degree of Master of Medicine (MMed) degree in both surgical and medical specialty disciplines following a three to six-year period of instruction ,in Ethiopia students first finish high school then took university entrance exam then based on their result (it is highly competative) then start medical school until recently but now students take another 1 year in university studying common course then take another exam to join medicine after that the students begin studying preclinical for 3 years studying anatomy, physiology, biochemistry, histology, embryology, pathology, pharmacology, microbiology and other minor courses of public health then at 4th year studemts join the clinical rotation ranging from physical examination and history taking to different  specialities like internal medicine, surgery, pediatrics and gynobs for two years and other minor specialities like psychiatry, opthamology, dematology, ENT after finishing these courses students take qualification exam and become intern doctors for one year then graduate as general practitioner and serve two or more years on primary hospitals then by taking national resedency exam and join their apeciality based on their result.  .
In West Africa, the West African College of Physicians and the West African College of Surgeons award the Fellowship of the West African College of Physicians (FWACP) and the Fellowship of the West African College of Surgeons (FWACS) in medical and surgical disciplines respectively after a minimum of four-year residency training period.
The Doctor of Osteopathic Medicine or DO degree allows the same practice rights in the United States and Canada to the MD degree and Doctors of Osteopathic Medicine are fully licensed physicians. Holders of the MD degree must pass MD level board exams while DO holders can pass either the DO (COMLEX) exam or MD exam (USMLE). Similarly, MDs must attend MD rated residency and fellowship programs while DOs can attend either MD programs or Osteopathic (DO) programs. As a result of this, the Accreditation Council for Graduate Medical Education (ACGME) are currently transitioning to a single accreditation system for medical residencies in the U.S.  The American MD degree is also recognized by most countries in the world, while DO physicians are only licensed to practice the full scope of medicine and surgery in 65 countries.


== References =="
"Medical terminology is language used to precisely describe the human body including its components, processes, conditions affecting it, and procedures performed upon it. Medical terminology is used in the field of medicine.
Medical terminology has quite regular morphology, the same prefixes and suffixes are used to add meanings to different roots. The root of a term often refers to an organ, tissue, or condition. For example, in the disorder hypertension, the prefix ""hyper-"" means ""high"" or ""over"", and the root word ""tension"" refers to pressure, so the word ""hypertension"" refers to abnormally high blood pressure. The roots, prefixes and suffixes are often derived from Greek or Latin, and often quite dissimilar from their English-language variants. This regular morphology means that once a reasonable number of morphemes are learnt it becomes easy to understand very precise terms assembled from these morphemes. Much medical language is anatomical terminology, concerning itself with the names of various parts of the body.


== Discussion ==
In forming or understanding a word root, one needs a basic comprehension of the terms and the source language. The study of the origin of words is called etymology. For example, if a word was to be formed to indicate a condition of kidneys, there are two primary roots – one from Greek (νεφρός nephr(os)) and one from Latin (ren(es)). Renal failure would be a condition of kidneys, and nephritis is also a condition, or inflammation, of the kidneys. The suffix -itis means inflammation, and the entire word conveys the meaning inflammation of the kidney. To continue using these terms, other combinations will be presented for the purpose of examples: The term supra-renal is a combination of the prefix supra- (meaning ""above""), and the word root for kidney, and the entire word means ""situated above the kidneys"". The word ""nephrologist"" combines the root word for kidney to the suffix -ologist with the resultant meaning of ""one who studies the kidneys"".
The formation of plurals should usually be done using the rules of forming the proper plural form in the source language. Greek and Latin each have differing rules to be applied when forming the plural form of the word root. Often such details can be found using a medical dictionary.


== Morphology ==

Medical terminology often uses words created using prefixes and suffixes in Latin and Ancient Greek. In medicine, their meanings, and their etymology, are informed by the language of origin. Prefixes and suffixes, primarily in Greek—but also in Latin, have a droppable -o-. Medical roots generally go together according to language: Greek prefixes go with Greek suffixes and Latin prefixes with Latin suffixes. Although it is technically considered acceptable to create hybrid words, it is strongly preferred not to mix different lingual roots. Examples of well-accepted medical words that do mix lingual roots are neonatology and quadriplegia.
Prefixes do not normally require further modification to be added to a word root because the prefix normally ends in a vowel or vowel sound, although in some cases they may assimilate slightly and an in- may change to im- or syn- to sym-.
Suffixes are attached to the end of a word root to add meaning such as condition, disease process, or procedure.
In the process of creating medical terminology, certain rules of language apply. These rules are part of language mechanics called linguistics.  The word root is developed to include a vowel sound following the term to add a smoothing action to the sound of the word when applying a suffix. The result is the formation of a new term with a vowel attached (word root + vowel) called a combining form. In English, the most common vowel used in the formation of the combining form is the letter -o-, added to the word root. For example if there is an inflammation of the stomach and intestines, this would be written as gastro- and enter- plus -itis, gastroenteritis.
Suffixes are categorized as either (1) needing the combining form, or (2) not needing the combining form since they start with a vowel.


== See also ==


== References =="
"A medical laboratory or clinical laboratory is a laboratory where clinical pathology tests are carried out on clinical specimens to obtain information about the health of a patient to aid in diagnosis, treatment, and prevention of disease. Clinical Medical laboratories are an example of applied science, as opposed to research laboratories that focus on basic science, such as found in some academic institutions.
Medical laboratories vary in size and complexity and so offer a variety of testing services.  More comprehensive services can be found in acute-care hospitals and medical centers, where 70% of clinical decisions are based on laboratory testing.  Doctors offices and clinics, as well as skilled nursing and long-term care facilities, may have laboratories that provide more basic testing services. Commercial medical laboratories operate as independent businesses and provide testing that is otherwise not provided in other settings due to low test volume or complexity.


== Departments ==
In hospitals and other patient-care settings, laboratory medicine is provided by the Department of Pathology, and generally divided into two sections, each of which will be subdivided into multiple specialty areas. The two sections are:

Anatomic pathology: areas included here are histopathology, cytopathology, and electron microscopy.
Clinical pathology, which typically includes the following areas:Clinical Microbiology: This encompasses several different sciences, including bacteriology, virology, parasitology, immunology, and mycology.
Clinical Chemistry: This area typically includes automated analysis of blood specimens, including tests related to enzymology, toxicology and endocrinology.
Hematology: This area includes automated and manual analysis of blood cells. It also often includes coagulation.
Blood Bank involves the testing of blood specimens in order to provide blood transfusion and related services.
Molecular diagnostics DNA testing may be done here, along with a subspecialty known as cytogenetics.
Reproductive biology testing is available in some laboratories, including Semen analysis, Sperm bank and assisted reproductive technology.Layouts of clinical laboratories in health institutions vary greatly from one facility to another. For instance, some health facilities have a single laboratory for the microbiology section, while others have a separate lab for each specialty area.

The following is an example of a typical breakdown of the responsibilities of each area:

Microbiology includes culturing of clinical specimens, including feces, urine, blood, sputum, cerebrospinal fluid, and synovial fluid, as well as possible infected tissue. The work here is mainly concerned with cultures, to look for suspected pathogens which, if found, are further identified based on biochemical tests. Also, sensitivity testing is carried out to determine whether the pathogen is sensitive or resistant to a suggested medicine. Results are reported with the identified organism(s) and the type and amount of drug(s) that should be prescribed for the patient.
Parasitology is where specimens are examined for parasites.  For example, fecal samples may be examined for evidence of intestinal parasites such as tapeworms or hookworms.
Virology is concerned with identification of viruses in specimens such as blood, urine, and cerebrospinal fluid.
Hematology analyzes whole blood specimens to perform full blood counts, and includes the examination of Blood films.  Other specialized tests include cell counts on various bodily fluids.
Coagulation testing determines various blood clotting times, coagulation factors, and platelet function.
Clinical Biochemistry commonly performs dozens of different tests on serum or plasma. These tests, mostly automated, includes quantitative testing for a wide array of substances, such as lipids, blood sugar, enzymes, and hormones.
Toxicology is mainly focused on testing for pharmaceutical and recreational drugs. Urine and blood samples are the common specimens.
Immunology/Serology uses the process of antigen-antibody interaction as a diagnostic tool. Compatibility of transplanted organs may also be determined with these methods.
Immunohematology, or Blood bank determines blood groups, and performs compatibility testing on donor blood and recipients. It also prepares blood components, derivatives, and products for transfusion. This area determines a patient's blood type and Rh status, checks for antibodies to common antigens found on red blood cells, and cross matches units that are negative for the antigen.
Urinalysis tests urine for many analytes, including microscopically. If more precise quantification of urine chemicals is required, the specimen is processed in the clinical biochemistry lab.
Histopathology processes solid tissue removed from the body (biopsies) for evaluation at the microscopic level.
Cytopathology examines smears of cells from all over the body (such as from the cervix) for evidence of inflammation, cancer, and other conditions.
Molecular diagnostics includes specialized tests involving DNA analysis.
Cytogenetics involves using blood and other cells to produce a DNA karyotype. This can be helpful in cases of prenatal diagnosis (e.g. Down's syndrome) as well as in some cancers which can be identified by the presence of abnormal chromosomes.
Surgical pathology examines organs, limbs, tumors, fetuses, and other tissues biopsied in surgery such as breast mastectomies.


== Medical laboratory staff ==

The staff of clinical laboratories may include:

Pathologist
Clinical Biochemist
laboratory' Assistant (LA)
Biomedical Scientist (BMS) in the UK, Medical Laboratory Scientist (MT, MLS or CLS) in the US or Medical Laboratory Technologist in Canada
Medical Laboratory Technician/Clinical Laboratory Technician (MLT or CLT in US)
Medical Laboratory Assistant (MLA)
Phlebotomist (PBT)
Histotechnologist/Histology Technician


== Labor shortages ==
The United States has a documented shortage of working laboratory professionals.  For example, as of 2016 vacancy rates for Medical Laboratory Scientists ranged from 5% to 9% for various departments.  The decline is primarily due to retirements, and to at-capacity educational programs that cannot expand which limits the number of new graduates.  Professional organizations and some state educational systems are responding by developing ways to promote the lab professions in an effort to combat this shortage.  The National Center For Workforce Analysis has estimated that by 2025 there will be a 24% increase in demand for lab professionals.


== Types of laboratory ==
In most developed countries, there are two main types of lab processing the majority of medical specimens. Hospital laboratories are attached to a hospital, and perform tests on their patients. Private (or community) laboratories receive samples from general practitioners, insurance companies, clinical research sites and other health clinics for analysis. For extremely specialised tests, samples may go to a research laboratory.  Some tests involve specimens sent between different labs for uncommon tests. For example, in some cases it may be more cost effective if a particular laboratory specializes in a less common tests, receiving specimens (and payment) from other labs, while sending other specimens to other labs for those tests they do not perform.
In many countries there are specialized types of Medical Laboratories according to the types of investigations carried out. Organisations that provide blood products for transfusion to hospitals, such as The Red Cross, will provide access to their reference laboratory for their customers. Some laboratories specialize in Molecular diagnostic and cytogenetic testing, in order to provide information regarding diagnosis and treatment of genetic or cancer-related disorders.


== Specimen processing and work flow ==
In a hospital setting, sample processing will usually start with a set of samples arriving with a test request, either on a form or electronically via the laboratory information system (LIS). Inpatient specimens will already be labeled with patient and testing information provided by the LIS.  Entry of test requests onto the LIS system involves typing (or scanning where barcodes are used) in the laboratory number, and entering the patient identification, as well as any tests requested. This allows laboratory analyzers, computers and staff to recognize what tests are pending, and also gives a location (such as a hospital department, doctor or other customer) for results reporting.
Once the specimens are assigned a laboratory number by the LIS, a sticker is typically printed that can be placed on the tubes or specimen containers.  This label has a barcode that can be scanned by automated analyzers and test requests uploaded to the analyzer from the LIS.
Specimens are prepared for analysis in various ways. For example, chemistry samples are usually centrifuged and the serum or plasma is separated and tested. If the specimen needs to go on more than one analyzer, it can be divided into separate tubes.
Many specimens end up in one or more sophisticated automated analysers, that process a fraction of the sample to return one or more test results. Some laboratories use robotic sample handlers (Laboratory automation) to optimize the workflow and reduce the risk of contamination from sample handling by the staff.
The work flow in a hospital laboratory is usually heaviest from 2:00 am to 10:00 am.  Nurses and doctors generally have their patients tested at least once a day with common tests such as complete blood counts and chemistry profiles.  These orders are typically drawn during a morning run by phlebotomists for results to be available in the patient's charts for the attending physicians to consult during their morning rounds.  Another busy time for the lab is after 3:00 pm when private practice physician offices are closing.  Couriers will pick up specimens that have been drawn throughout the day and deliver them to the lab.  Also, couriers will stop at outpatient drawing centers and pick up specimens. These specimens will be processed in the evening and overnight to ensure results will be available the following day.


== Laboratory informatics ==
The large amount of information processed in laboratories is managed by a system of software programs, computers, and terminology standards that exchange data about patients, test requests, and test results known as a Laboratory information system or LIS.  The LIS is often interfaced with the hospital information system, EHR and/or Laboratory instruments. Formats for terminologies for test processing and reporting are being standardized  with systems such as Logical Observation Identifiers Names and Codes (LOINC) and Nomenclature for Properties and Units terminology (NPU terminology).
These systems enable hospitals and labs to order the correct test requests for each patient, keep track of individual patient and specimen histories, and help guarantee a better quality of results.  Results are made available to care providers electronically or by printed hard copies for patient charts.


== Result analysis, validation and interpretation ==
According to various regulations, such as the international ISO 15189 norm, all pathological laboratory results must be verified by a competent professional. In some countries, staffs composed of clinical scientists do the majority of this work inside the laboratory with certain abnormal results referred to the relevant pathologist. Clinical scientists have the responsibility for limited interpretation of testing results in their discipline in many countries. Interpretation of results can be assisted by some software in order to validate normal or non-modified results.
In other testing areas, only professional medical staff (pathologist or clinical biologist) is involved with interpretation and consulting.  Medical staff are sometimes also required in order to explain pathology results to physicians. For a simple result given by phone or to explain a technical problem, often a medical technologist or medical lab scientist can provide additional information.
Medical Laboratory Departments in some countries are exclusively directed by a specialized pathologist. In others, a consultant, medical or non-medical, may be the head the department. In Europe and some other countries, Clinical Scientists with a Masters level education may be qualified to head the department.  Others may have a PhD and can have an exit qualification equivalent to medical staff (e.g., FRCPath in the UK).
In France, only medical staff (Pharm.D. and M.D. specialized in anatomical pathology or clinical biology) can discuss pathological results.


== Medical laboratory accreditation ==
Credibility of medical laboratories is paramount to the health and safety of the patients relying on the testing services provided by these labs. Credentialing agencies vary by country. The international standard in use today for the accreditation of medical laboratories is ISO 15189 - Medical laboratories - Requirements for quality and competence.
In the United States, billions of dollars is spent on unaccredited lab tests, such as Laboratory developed tests which do not require accreditation or FDA approval; about a billion USD a year is spent on US autoimmune LDTs alone.  Accreditation is performed by the Joint Commission, College of American Pathologists, AAB (American Association of Bioanalysts), and other state and federal agencies.  Legislative guidelines are provided under CLIA 88 (Clinical Laboratory Improvement Amendments) which regulates Medical Laboratory testing and personnel.
The accrediting body in Australia is NATA, where all laboratories must be NATA accredited to receive payment from Medicare.
In France the accrediting body is COFRAC (COFRAC).  In 2010, modification of legislation established ISO 15189 accreditation as an obligation for all clinical laboratories.In the United Arab Emirates, the Dubai Accreditation Department (DAC) is the accreditation body that is internationally recognised by the International Laboratory Accreditation Cooperation (ILAC) for many facilities and groups, including Medical Laboratories, Testing and Calibration Laboratories, and Inspection Bodies.
In Hong Kong, the accrediting body is Hong Kong Accreditation Service (HKAS).  On 16 February 2004, HKAS launched its medical testing accreditation programme.
In Canada, laboratory accreditation is not mandatory, but is becoming more and more popular.  Accreditation Canada (AC) is the national reference. Different provincial oversight bodies mandate laboratories in EQA participations like LSPQ (Quebec), IQMH (Ontario) for example.


== Industry ==
The laboratory industry is a part of the broader healthcare and health technology industry. Companies exist at various levels, including clinical laboratory services, suppliers of instrumentation equipment and consumable materials, and suppliers and developers of diagnostic tests themselves (often by biotechnology companies).Clinical laboratory services includes large multinational corporations such LabCorp, Quest Diagnostics, and Sonic Healthcare but a significant portion of revenue, estimated at 60% in the United States, is generated by hospital labs. In 2018, the total global revenue for these companies was estimated to reach $146 billion by 2024. Another estimate places the market size at $205 billion, reaching $333 billion by 2023. The American Association for Clinical Chemistry (AACC) represents professionals in the field.
Clinical laboratories are supplied by other multinational companies which focus on materials and equipment, which can be used for both scientific research and medical testing. The largest of these is Thermo Fisher Scientific. In 2016, global life sciences instrumentation sales were around $47 billion, not including consumables, software, and services. In general, laboratory equipment includes lab centrifuges, transfection solutions, water purification systems, extraction techniques, gas generators, concentrators and evaporators, fume hoods, incubators, biological safety cabinets, bioreactors and fermenters, microwave-assisted chemistry, lab washers, and shakers and stirrers.As of 2016, the in vitro diagnostics (IVD) market was estimated at a global value of around $45–50 billion, with six key companies: Roche Diagnostics, Abbott Diagnostics, Siemens, Johnson & Johnson Medical Devices and Diagnostics, Beckman Coulter and BioMerieux. Many of the companies sell capital equipment and supply consumables, and the devices are also used for industrial purposes such as food testing. Molecular diagnostics is estimated at 10% of total revenue, and half of that focused on infectious disease testing.


=== United States ===

In the United States, estimated total revenue as of 2016 was $75 billion, about 2% of total healthcare spending. In 2016, an estimated 60% of revenue was done by hospital labs, with 25% done by two independent companies (LabCorp and Quest). Hospital labs may also outsource their lab, known as outreach, to run tests; however, health insurers may pay the hospitals more than they would pay a laboratory company for the same test, but as of 2016, the markups were questioned by insurers. Rural hospitals, in particular, can bill for lab outreach under the Medicare's 70/30 shell rule.Laboratory developed tests are designed and developed inside a specific laboratory and do not require FDA approval; due to technological innovations, they have become more common and are estimated at a total value of $11 billion in 2016.Due to the rise of high-deductible health plans, laboratories have sometimes struggled to collect when billing patients; consequently, some laboratories have shifted to become more ""consumer-focused"".


== See also ==
Healthcare scientist
Laboratory automation
Automated analyser
ARUP Laboratories
Molecular diagnostics
Clinical chemistry
Medical lab technologist/technician
Point-of-care testing


== References =="
"An engine or motor is a machine designed to convert one form of energy into mechanical energy. Heat engines, like the internal combustion engine, burn a fuel to create heat which is then used to do work. Electric motors convert electrical energy into mechanical motion, pneumatic motors use compressed air, and clockwork motors in wind-up toys use elastic energy. In biological systems, molecular motors, like myosins in muscles, use chemical energy to create forces and ultimately motion.


== Terminology ==
The word engine derives from  Old French engin, from the Latin ingenium–the root of the word ingenious. Pre-industrial weapons of war, such as catapults, trebuchets and battering rams, were called siege engines, and knowledge of how to construct them was often treated as a military secret. The word gin, as in  cotton gin, is short for engine.  Most mechanical devices invented during the industrial revolution were described as engines—the steam engine being a notable example. However, the original steam engines, such as those by Thomas Savery, were not mechanical engines but pumps. In this manner, a fire engine in its original form was merely a water pump, with the engine being transported to the fire by horses.In modern usage, the term engine typically describes devices, like steam engines and internal combustion engines, that burn or otherwise consume fuel to perform mechanical work by exerting a torque or linear force (usually in the form of thrust). Devices converting heat energy into motion are commonly referred to simply as engines. Examples of engines which exert a torque include the familiar automobile gasoline and diesel engines, as well as turboshafts. Examples of engines which produce thrust include turbofans and rockets.
When the internal combustion engine was invented, the term motor was initially used to distinguish it from the steam engine—which was in wide use at the time, powering locomotives and other vehicles such as steam rollers. The term motor derives from the Latin verb moto which means to set in motion, or maintain motion. Thus a motor is a device that imparts motion.
Motor and engine are interchangeable in standard English. In some engineering jargons, the two words have different meanings, in which engine is a device that burns or otherwise consumes fuel, changing its chemical composition, and a motor is a device driven by electricity, air, or hydraulic pressure, which does not change the chemical composition of its energy source. However, rocketry uses the term rocket motor, even though they consume fuel.
A heat engine may also serve as a prime mover—a component that transforms the flow or changes in pressure of a fluid into mechanical energy. An automobile powered by an internal combustion engine may make use of various motors and pumps, but ultimately all such devices derive their power from the engine. Another way of looking at it is that a motor receives power from an external source, and then converts it into mechanical energy, while an engine creates power from pressure (derived directly from the explosive force of combustion or other chemical reaction, or secondarily from the action of some such force on other substances such as air, water, or steam).


== History ==


=== Antiquity ===
Simple machines, such as the club and oar (examples of the lever), are prehistoric. More complex engines using human power, animal power, water power, wind power and even steam power date back to antiquity. Human power was focused by the use of simple engines, such as the capstan, windlass or treadmill, and with ropes, pulleys, and block and tackle arrangements; this power was transmitted usually with the forces multiplied and the speed reduced. These were used in cranes and aboard ships in Ancient Greece, as well as in mines, water pumps and siege engines in Ancient Rome. The writers of those times, including Vitruvius, Frontinus and Pliny the Elder, treat these engines as commonplace, so their invention may be more ancient. By the 1st century AD, cattle and horses were used in mills, driving machines similar to those powered by humans in earlier times.
According to Strabo, a water powered mill was built in Kaberia of the kingdom of Mithridates during the 1st century BC. Use of water wheels in mills spread throughout the Roman Empire over the next few centuries. Some were quite complex, with aqueducts, dams, and sluices to maintain and channel the water, along with systems of gears, or toothed-wheels made of wood and metal to regulate the speed of rotation. More sophisticated small devices, such as the Antikythera Mechanism used complex trains of gears and dials to act as calendars or predict astronomical events. In a poem by Ausonius in the 4th century AD, he mentions a stone-cutting saw powered by water. Hero of Alexandria is credited with many such wind and steam powered machines in the 1st century AD, including the Aeolipile and the vending machine, often these machines were associated with worship, such as animated altars and automated temple doors.


=== Medieval ===
Medieval Muslim engineers employed gears in mills and water-raising machines, and used dams as a source of water power to provide additional power to watermills and water-raising machines. In the medieval Islamic world, such advances made it possible to mechanize many industrial tasks previously carried out by manual labour.
In 1206, al-Jazari employed a crank-conrod system for two of his water-raising machines. A rudimentary steam turbine device was described by Taqi al-Din in 1551 and by Giovanni Branca in 1629.In the 13th century, the solid rocket motor was invented in China. Driven by gunpowder, this simplest form of internal combustion engine was unable to deliver sustained power, but was useful for propelling weaponry at high speeds towards enemies in battle and for fireworks. After invention, this innovation spread throughout Europe.


=== Industrial Revolution ===

The Watt steam engine was the first type of steam engine to make use of steam at a pressure just above atmospheric to drive the piston helped by a partial vacuum. Improving on the design of the 1712 Newcomen steam engine, the Watt steam engine, developed sporadically from 1763 to 1775, was a great step in the development of the steam engine. Offering a dramatic increase in fuel efficiency, James Watt's design became synonymous with steam engines, due in no small part to his business partner, Matthew Boulton. It enabled rapid development of efficient semi-automated factories on a previously unimaginable scale in places where waterpower was not available. Later development led to steam locomotives and great expansion of railway transportation.
As for internal combustion piston engines, these were tested in France in 1807 by de Rivaz and independently, by the Niépce brothers. They were theoretically advanced by Carnot in 1824. In 1853–57 Eugenio Barsanti and Felice Matteucci invented and patented an engine using the free-piston principle that was possibly the first 4-cycle engine.The invention of an internal combustion engine which was later commercially successful was made during 1860 by Etienne Lenoir.
In 1877 the Otto cycle  was capable of giving a far higher power to weight ratio than steam engines and worked much better for many transportation applications such as cars and aircraft.


=== Automobiles ===
The first commercially successful automobile, created by Karl Benz, added to the interest in light and powerful engines. The lightweight gasoline internal combustion engine, operating on a four-stroke Otto cycle, has been the most successful for light automobiles, while the more efficient Diesel engine is used for trucks and buses. However, in recent years, turbo Diesel engines have become increasingly popular, especially outside of the United States, even for quite small cars.


==== Horizontally opposed pistons ====
In 1896, Karl Benz was granted a patent for his design of the first engine with horizontally opposed pistons. His design created an engine in which the corresponding pistons move in horizontal cylinders and reach top dead center simultaneously, thus automatically balancing each other with respect to their individual momentum. Engines of this design are often referred to as flat engines because of their shape and lower profile. They were used in the Volkswagen Beetle, the Citroën 2CV, some Porsche and Subaru cars, many BMW and Honda motorcycles, and propeller aircraft engines.


==== Advancement ====
Continuance of the use of the internal combustion engine for automobiles is partly due to the improvement of engine control systems (onboard computers providing engine management processes, and electronically controlled fuel injection). Forced air induction by turbocharging and supercharging have increased power outputs and engine efficiencies. Similar changes have been applied to smaller diesel engines giving them almost the same power characteristics as gasoline engines. This is especially evident with the popularity of smaller diesel engine propelled cars in Europe. Larger diesel engines are still often used in trucks and heavy machinery, although they require special machining not available in most factories. Diesel engines produce lower hydrocarbon and CO2 emissions, but greater particulate and NO x  pollution, than gasoline engines. Diesel engines are also 40% more fuel efficient than comparable gasoline engines.


==== Increasing power ====
In the first half of the 20th century, a trend of increasing engine power occurred, particularly in the U.S models. Design changes incorporated all known methods of increasing engine capacity, including increasing the pressure in the cylinders to improve efficiency, increasing the size of the engine, and increasing the rate at which the engine produces work. The higher forces and pressures created by these changes created engine vibration and size problems that led to stiffer, more compact engines with V and opposed cylinder layouts replacing longer straight-line arrangements.


==== Combustion efficiency ====
The design principles favoured in Europe, because of economic and other restraints such as smaller and twistier roads, leant toward smaller cars and corresponding to the design principles that concentrated on increasing the combustion efficiency of smaller engines. This produced more economical engines with earlier four-cylinder designs rated at 40 horsepower (30 kW) and six-cylinder designs rated as low as 80 horsepower (60 kW), compared with the large volume V-8 American engines with power ratings in the range from 250 to 350 hp, some even over 400 hp (190 to 260 kW).


==== Engine configuration ====
Earlier automobile engine development produced a much larger range of engines than is in common use today. Engines have ranged from 1- to 16-cylinder designs with corresponding differences in overall size, weight, engine displacement, and cylinder bores. Four cylinders and power ratings from 19 to 120 hp (14 to 90 kW) were followed in a majority of the models. Several three-cylinder, two-stroke-cycle models were built while most engines had straight or in-line cylinders. There were several V-type models and horizontally opposed two- and four-cylinder makes too. Overhead camshafts were frequently employed. The smaller engines were commonly air-cooled and located at the rear of the vehicle; compression ratios were relatively low. The 1970s and 1980s saw an increased interest in improved fuel economy, which caused a return to smaller V-6 and four-cylinder layouts, with as many as five valves per cylinder to improve efficiency. The Bugatti Veyron 16.4 operates with a W16 engine, meaning that two V8 cylinder layouts are positioned next to each other to create the W shape sharing the same crankshaft.
The largest internal combustion engine ever built is the Wärtsilä-Sulzer RTA96-C, a 14-cylinder, 2-stroke turbocharged diesel engine that was designed to power the Emma Mærsk, the largest container ship in the world when launched in 2006. This engine has a mass of 2,300 tonnes, and when running at 102 RPM (1.7 Hz) produces over 80 MW, and can use up to 250 tonnes of fuel per day.


== Types ==
An engine can be put into a category according to two criteria: the form of energy it accepts in order to create motion, and the type of motion it outputs.


=== Heat engine ===


==== Combustion engine ====
Combustion engines are heat engines driven by the heat of a combustion process.


==== Internal combustion engine ====

The internal combustion engine is an engine in which the combustion of a fuel (generally, fossil fuel) occurs with an oxidizer (usually air) in a combustion chamber. In an internal combustion engine the expansion of the high temperature and high pressure gases, which are produced by the combustion, directly applies force to components of the engine, such as the pistons or turbine blades or a nozzle, and by moving it over a distance, generates mechanical work.


==== External combustion engine ====

An external combustion engine (EC engine) is a heat engine where an internal working fluid is heated by combustion of an external source, through the engine wall or a heat exchanger. The fluid then, by expanding and acting on the mechanism of the engine produces motion and usable work. The fluid is then cooled, compressed and reused (closed cycle), or (less commonly) dumped, and cool fluid pulled in (open cycle air engine).
""Combustion"" refers to burning fuel with an oxidizer, to supply the heat. Engines of similar (or even identical) configuration and operation may use a supply of heat from other sources such as nuclear, solar, geothermal or exothermic reactions not involving combustion; but are not then strictly classed as external combustion engines, but as external thermal engines.
The working fluid can be a gas as in a Stirling engine, or steam as in a steam engine or an organic liquid such as n-pentane in an Organic Rankine cycle.  The fluid can be of any composition; gas is by far the most common, although even single-phase liquid is sometimes used.  In the case of the steam engine, the fluid changes phases between liquid and gas.


==== Air-breathing combustion engines ====
Air-breathing combustion engines are combustion engines that use the oxygen in atmospheric air to oxidise ('burn') the fuel, rather than carrying an oxidiser, as in a rocket. Theoretically, this should result in a better specific impulse than for rocket engines.
A continuous stream of air flows through the air-breathing engine. This air is compressed, mixed with fuel, ignited and expelled as the exhaust gas.

ExamplesTypical air-breathing engines include:

Reciprocating engine
Steam engine
Gas turbineairbreathing jet engine
Turbo-propeller enginePulse detonation engine
Pulse jet
Ramjet
Scramjet
Liquid air cycle engine/Reaction Engines SABRE.


==== Environmental effects ====
The operation of engines typically has a negative impact upon air quality and ambient sound levels. There has been a growing emphasis on the pollution producing features of automotive power systems. This has created new interest in alternate power sources and internal-combustion engine refinements. Though a few limited-production battery-powered electric vehicles have appeared, they have not proved competitive owing to costs and operating characteristics. In the 21st century the diesel engine has been increasing in popularity with automobile owners. However, the gasoline engine and the Diesel engine,  with their new emission-control devices to improve emission performance, have not yet been significantly challenged. A number of manufacturers have introduced hybrid engines, mainly involving a small gasoline engine coupled with an electric motor and with a large battery bank,  but these too have yet to make much of an inroad into the market shares of gasoline and Diesel engines.


==== Air quality ====
Exhaust gas from a spark ignition engine consists of the following: nitrogen 70 to 75% (by volume), water vapor 10 to 12%, carbon dioxide 10 to 13.5%, hydrogen 0.5 to 2%, oxygen 0.2 to 2%, carbon monoxide: 0.1 to 6%, unburnt hydrocarbons and partial oxidation products (e.g. aldehydes) 0.5 to 1%, nitrogen monoxide 0.01 to 0.4%, nitrous oxide <100 ppm, sulfur dioxide 15 to 60 ppm, traces of other compounds such as fuel additives and lubricants, also halogen and metallic compounds, and other particles. Carbon monoxide is highly toxic, and can cause carbon monoxide poisoning, so it is important to avoid any build-up of the gas in a confined space. Catalytic converters can reduce toxic emissions, but not completely eliminate them. Also, resulting greenhouse gas emissions, chiefly carbon dioxide, from the widespread use of engines in the modern industrialized world is contributing to the global greenhouse effect – a primary concern regarding global warming.


==== Non-combusting heat engines ====

Some engines convert heat from noncombustive processes into mechanical work, for example a nuclear power plant uses the heat from the nuclear reaction to produce steam and drive a steam engine, or a gas turbine in a rocket engine may be driven by decomposing hydrogen peroxide. Apart from the different energy source, the engine is often engineered much the same as an internal or external combustion engine. Another group of noncombustive engines includes thermoacoustic heat engines (sometimes called ""TA engines"") which are thermoacoustic devices which use high-amplitude sound waves to pump heat from one place to another, or conversely use a heat difference to induce high-amplitude sound waves. In general, thermoacoustic engines can be divided into standing wave and travelling wave devices.


=== Non-thermal chemically powered motor ===
Non-thermal motors usually are powered by a chemical reaction, but are not heat engines. Examples include:

Molecular motor – motors found in living things
Synthetic molecular motor.


=== Electric motor ===

An electric motor uses electrical energy to produce mechanical energy, usually through the interaction of magnetic fields and current-carrying conductors. The reverse process, producing electrical energy from mechanical energy, is accomplished by a generator or dynamo. Traction motors used on vehicles often perform both tasks. Electric motors can be run as generators and vice versa, although this is not always practical.
Electric motors are ubiquitous, being found in applications as diverse as industrial fans, blowers and pumps, machine tools, household appliances, power tools, and disk drives.  They may be powered by direct current (for example a battery powered portable device or motor vehicle), or by alternating current from a central electrical distribution grid. The smallest motors may be found in electric wristwatches. Medium-size motors of highly standardized dimensions and characteristics provide convenient mechanical power for industrial uses. The very largest electric motors are used for propulsion of large ships, and for such purposes as pipeline compressors, with ratings in the thousands of kilowatts. Electric motors may be classified by the source of electric power, by their internal construction, and by their application.

The physical principle of production of mechanical force by the interactions of an electric current and a magnetic field was known as early as 1821. Electric motors of increasing efficiency were constructed throughout the 19th century, but commercial exploitation of electric motors on a large scale required efficient electrical generators and electrical distribution networks.
To reduce the electric energy consumption from motors and their associated carbon footprints, various regulatory authorities in many countries have introduced and implemented legislation to encourage the manufacture and use of higher efficiency electric motors. A well-designed motor can convert over 90% of its input energy into useful power for decades. When the efficiency of a motor is raised by even a few percentage points, the savings, in kilowatt hours (and therefore in cost), are enormous. The electrical energy efficiency of a typical industrial induction motor can be improved by: 1) reducing the electrical losses in the stator windings (e.g., by increasing the cross-sectional area of the conductor, improving the winding technique, and using materials with higher electrical conductivities, such as copper), 2) reducing the electrical losses in the rotor coil or casting (e.g., by using materials with higher electrical conductivities, such as copper), 3) reducing magnetic losses by using better quality magnetic steel, 4) improving the aerodynamics of motors to reduce mechanical windage losses, 5) improving bearings to reduce friction losses, and 6) minimizing manufacturing tolerances. For further discussion on this subject, see Premium efficiency.)
By convention, electric engine refers to a railroad electric locomotive, rather than an electric motor.


=== Physically powered motor ===
Some motors are powered by potential or kinetic energy, for example some funiculars, gravity plane and ropeway conveyors have used the energy from moving water or rocks, and some clocks have a weight that falls under gravity. Other forms of potential energy include compressed gases (such as pneumatic motors), springs (clockwork motors) and elastic bands.
Historic military siege engines included large catapults, trebuchets, and (to some extent) battering rams were powered by potential energy.


==== Pneumatic motor ====

A pneumatic motor is a machine that converts potential energy in the form of compressed air into mechanical work. Pneumatic motors generally convert the compressed air to mechanical work through either linear or rotary motion.  Linear motion can come from either a diaphragm or piston actuator, while rotary motion is supplied by either a vane type air motor or piston air motor.  Pneumatic motors have found widespread success in the hand-held tool industry and continual attempts are being made to expand their use to the transportation industry.  However, pneumatic motors must overcome efficiency deficiencies before being seen as a viable option in the transportation industry.


==== Hydraulic motor ====

A hydraulic motor derives its power from a pressurized liquid. This type of engine is used to move heavy loads and drive machinery.


== Performance ==
The following are used in the assessment of the performance of an engine.


=== Speed ===
Speed refers to crankshaft rotation in piston engines and the speed of compressor/turbine rotors and electric motor rotors. It is measured in revolutions per minute (RPM).


=== Thrust ===
Thrust is the force exerted on an aircraft engine or its propeller after it has speeded up the air passing through it.


=== Torque ===
Torque is a turning moment on a shaft and is calculated by multiplying the force causing the moment by its distance from the shaft.


=== Power ===
Power is the measure of how fast work is done.


=== Efficiency ===

Efficiency is a measure of how much fuel is wasted in producing power.


=== Sound levels ===
Vehicle noise is predominantly from the engine at low vehicle speeds and from tires and the air flowing past the vehicle at higher speeds. Electric motors are quieter than internal combustion engines. Thrust-producing engines, such as turbofans, turbojets and rockets emit the greatest amount of noise due to the way their thrust-producing, high-velocity exhaust streams interact with the surrounding stationary air.
Noise reduction technology includes intake and exhaust system mufflers (silencers) on gasoline and diesel engines and noise attenuation liners in turbofan inlets.


== Engines by use ==
Particularly notable kinds of engines include:


== See also ==


== Notes ==


== References ==


== External links ==
Engine (technology) at the Encyclopædia Britannica
U.S. Patent 194,047
Detailed Engine Animations
Working 4-Stroke Engine – Animation
Animated illustrations of various engines
5 Ways to Redesign the Internal Combustion Engine
Article on Small SI Engines.
Article on Compact Diesel Engines.
Detailed Engine Classification"
"A steam engine is a heat engine that performs mechanical work using steam as its working fluid. The steam engine uses the force produced by steam pressure to push a piston back and forth inside a cylinder. This pushing force is transformed, by a connecting rod and flywheel, into rotational force for work. The term ""steam engine"" is generally applied only to reciprocating engines as just described, not to the steam turbine.
Steam engines are external combustion engines, where the working fluid is separated from the combustion products. The ideal thermodynamic cycle used to analyze this process is called the Rankine cycle.

In general usage, the term steam engine can refer to either complete steam plants (including boilers etc.) such as railway steam locomotives and portable engines, or may refer to the piston or turbine machinery alone, as in the beam engine and stationary steam engine.
Steam-driven devices were known as early as the aeolipile in the first century AD, with a few other uses recorded in the 16th and 17th century. Thomas Savery's dewatering pump used steam pressure operating directly on the water. The first commercially successful engine that could transmit continuous power to a machine was developed in 1712 by Thomas Newcomen. James Watt made a critical improvement by removing spent steam to a separate vessel for condensation, greatly improving the amount of work obtained per unit of fuel consumed. By the 19th century, stationary steam engines powered the factories of the Industrial Revolution. Steam engines replaced sail for ships, and steam locomotives operated on the railways.
Reciprocating piston type steam engines were the dominant source of power until the early 20th century, when advances in the design of electric motors and internal combustion engines gradually resulted in the replacement of reciprocating (piston) steam engines in commercial usage. Steam turbines replaced reciprocating engines in power generation, due to lower cost, higher operating speed, and higher efficiency.


== History ==


=== Early experiments ===
The first recorded rudimentary steam-powered ""engine"" was the aeolipile described by Hero of Alexandria, a mathematician and engineer in Roman Egypt in the first century AD. In the following centuries, the few steam-powered ""engines"" known were, like the aeolipile, essentially experimental devices used by inventors to demonstrate the properties of steam. A rudimentary steam turbine device was described by Taqi al-Din in Ottoman Egypt in 1551 and by Giovanni Branca in Italy in 1629. Jerónimo de Ayanz y Beaumont received patents in 1606 for 50 steam-powered inventions, including a water pump for draining inundated mines. Denis Papin, a Huguenot refugee, did some useful work on the steam digester in 1679, and first used a piston to raise weights in 1690.


=== Pumping engines ===
The first commercial steam-powered device was a water pump, developed in 1698 by Thomas Savery. It used condensing steam to create a vacuum which raised water from below and then used steam pressure to raise it higher. Small engines were effective though larger models were problematic. They had a limited lift height and were prone to boiler explosions. Savery's engine was used in mines, pumping stations and supplying water to water wheels that powered textile machinery. Savery's engine was of low cost. Bento de Moura Portugal introduced an improvement of Savery's construction ""to render it capable of working itself"", as described by John Smeaton in the Philosophical Transactions published in 1751. It continued to be manufactured until the late 18th century. One engine was still known to be operating in 1820.


=== Piston steam engines ===

The first commercially successful engine that could transmit continuous power to a machine was the atmospheric engine, invented by Thomas Newcomen around 1712. It improved on Savery's steam pump, using a piston as proposed by Papin. Newcomen's engine was relatively inefficient, and mostly used for pumping water. It worked by creating a partial vacuum by condensing steam under a piston within a cylinder. It was employed for draining mine workings at depths hitherto impossible, and for providing reusable water for driving waterwheels at factories sited away from a suitable ""head"". Water that passed over the wheel was pumped up into a storage reservoir above the wheel.
In 1780 James Pickard patented the use of a flywheel and crankshaft to provide rotative motion from an improved Newcomen engine.In 1720, Jacob Leupold described a two-cylinder high-pressure steam engine. The invention was published in his major work ""Theatri Machinarum Hydraulicarum"". The engine used two heavy pistons to provide motion to a water pump. Each piston was raised by the steam pressure and returned to its original position by gravity. The two pistons shared a common four-way rotary valve connected directly to a steam boiler.

The next major step occurred when James Watt developed (1763–1775) an improved version of Newcomen's engine, with a separate condenser. Boulton and Watt's early engines used half as much coal as John Smeaton's improved version of Newcomen's. Newcomen's and Watt's early engines were ""atmospheric"". They were powered by air pressure pushing a piston into the partial vacuum generated by condensing steam, instead of the pressure of expanding steam. The engine cylinders had to be large because the only usable force acting on them was atmospheric pressure.Watt developed his engine further, modifying it to provide a rotary motion suitable for driving machinery. This enabled factories to be sited away from rivers, and accelerated the pace of the Industrial Revolution.


=== High-pressure engines ===
The meaning of high pressure, together with an actual value above ambient, depends on the era in which the term was used. For early use of the term Van Reimsdijk refers to steam being at a sufficiently high pressure that it could be exhausted to atmosphere without reliance on a vacuum to enable it to perform useful work. Ewing 1894, p. 22 states that Watt's condensing engines were known, at the time, as low pressure compared to high pressure, non-condensing engines of the same period.
Watt's patent prevented others from making high pressure and compound engines. Shortly after Watt's patent expired in 1800, Richard Trevithick and, separately, Oliver Evans in 1801 introduced engines using high-pressure steam; Trevithick obtained his high-pressure engine patent in 1802, and Evans had made several working models before then. These were much more powerful for a given cylinder size than previous engines and could be made small enough for transport applications. Thereafter, technological developments and improvements in manufacturing techniques (partly brought about by the adoption of the steam engine as a power source) resulted in the design of more efficient engines that could be smaller, faster, or more powerful, depending on the intended application.The Cornish engine was developed by Trevithick and others in the 1810s. It was a compound cycle engine that used high-pressure steam expansively, then condensed the low-pressure steam, making it relatively efficient. The Cornish engine had irregular motion and torque though the cycle, limiting it mainly to pumping. Cornish engines were used in mines and for water supply until the late 19th century.


=== Horizontal stationary engine ===

Early builders of stationary steam engines considered that horizontal cylinders would be subject to excessive wear. Their engines were therefore arranged with the piston axis vertical. In time the horizontal arrangement became more popular, allowing compact, but powerful engines to be fitted in smaller spaces.
The acme of the horizontal engine was the Corliss steam engine, patented in 1849, which was a four-valve counter flow engine with separate steam admission and exhaust valves and automatic variable steam cutoff. When Corliss was given the Rumford Medal, the committee said that ""no one invention since Watt's time has so enhanced the efficiency of the steam engine"". In addition to using 30% less steam, it provided more uniform speed due to variable steam cut off, making it well suited to manufacturing, especially cotton spinning.


=== Road vehicles ===

The first experimental road-going steam-powered vehicles were built in the late 18th century, but it was not until after Richard Trevithick had developed the use of high-pressure steam, around 1800, that mobile steam engines became a practical proposition. The first half of the 19th century saw great progress in steam vehicle design, and by the 1850s it was becoming viable to produce them on a commercial basis. This progress was dampened by legislation which limited or prohibited the use of steam-powered vehicles on roads. Improvements in vehicle technology continued from the 1860s to the 1920s. Steam road vehicles were used for many applications. In the 20th century, the rapid development of internal combustion engine technology led to the demise of the steam engine as a source of propulsion of vehicles on a commercial basis, with relatively few remaining in use beyond the Second World War. Many of these vehicles were acquired by enthusiasts for preservation, and numerous examples are still in existence. In the 1960s, the air pollution problems in California gave rise to a brief period of interest in developing and studying steam-powered vehicles as a possible means of reducing the pollution. Apart from interest by steam enthusiasts, the occasional replica vehicle, and experimental technology, no steam vehicles are in production at present.


=== Marine engines ===

Near the end of the 19th century, compound engines came into widespread use. Compound engines exhausted steam into successively larger cylinders to accommodate the higher volumes at reduced pressures, giving improved efficiency. These stages were called expansions, with double- and triple-expansion engines being common, especially in shipping where efficiency was important to reduce the weight of coal carried. Steam engines remained the dominant source of power until the early 20th century, when advances in the design of the steam turbine, electric motors and internal combustion engines gradually resulted in the replacement of reciprocating (piston) steam engines, with shipping in the 20th-century relying upon the steam turbine.


=== Steam locomotives ===

As the development of steam engines progressed through the 18th century, various attempts were made to apply them to road and railway use. In 1784, William Murdoch, a Scottish inventor, built a model steam road locomotive. An early working model of a steam rail locomotive was designed and constructed by steamboat pioneer John Fitch in the United States probably during the 1780s or 1790s.
His steam locomotive used interior bladed wheels guided by rails or tracks.

The first full-scale working railway steam locomotive was built by Richard Trevithick in the United Kingdom and, on 21 February 1804, the world's first railway journey took place as Trevithick's unnamed steam locomotive hauled a train along the tramway from the Pen-y-darren ironworks, near Merthyr Tydfil to Abercynon in south Wales. The design incorporated a number of important innovations that included using high-pressure steam which reduced the weight of the engine and increased its efficiency. Trevithick visited the Newcastle area later in 1804 and the colliery railways in north-east England became the leading centre for experimentation and development of steam locomotives.Trevithick continued his own experiments using a trio of locomotives, concluding with the Catch Me Who Can in 1808. Only four years later, the successful twin-cylinder locomotive Salamanca by Matthew Murray was used by the edge railed rack and pinion Middleton Railway. In 1825 George Stephenson built the Locomotion for the Stockton and Darlington Railway. This was the first public steam railway in the world and then in 1829, he built The Rocket which was entered in and won the Rainhill Trials. The Liverpool and Manchester Railway opened in 1830 making exclusive use of steam power for both passenger and freight trains.
Steam locomotives continued to be manufactured until the late twentieth century in places such as China and the former East Germany (where the DR Class 52.80 was produced).


=== Steam turbines ===

The final major evolution of the steam engine design was the use of steam turbines starting in the late part of the 19th century. Steam turbines are generally more efficient than reciprocating piston type steam engines (for outputs above several hundred horsepower), have fewer moving parts, and provide rotary power directly instead of through a connecting rod system or similar means. Steam turbines virtually replaced reciprocating engines in electricity generating stations early in the 20th century, where their efficiency, higher speed appropriate to generator service, and smooth rotation were advantages. Today most electric power is provided by steam turbines. In the United States, 90% of the electric power is produced in this way using a variety of heat sources. Steam turbines were extensively applied for propulsion of large ships throughout most of the 20th century.


=== Present development ===

Although the reciprocating steam engine is no longer in widespread commercial use, various companies are exploring or exploiting the potential of the engine as an alternative to internal combustion engines. The company Energiprojekt AB in Sweden has made progress in using modern materials for harnessing the power of steam. The efficiency of Energiprojekt's steam engine reaches some 27–30% on high-pressure engines. It is a single-step, 5-cylinder engine (no compound) with superheated steam and consumes approx. 4 kg (8.8 lb) of steam per kWh.


== Components and accessories of steam engines ==
There are two fundamental components of a steam plant: the boiler or steam generator, and the ""motor unit"", referred to itself as a ""steam engine"". Stationary steam engines in fixed buildings may have the boiler and engine in separate buildings some distance apart. For portable or mobile use, such as steam locomotives, the two are mounted together.The widely used reciprocating engine typically consisted of a cast-iron cylinder, piston, connecting rod and beam or a crank and flywheel, and miscellaneous linkages. Steam was alternately supplied and exhausted by one or more valves. Speed control was either automatic, using a governor, or by a manual valve. The cylinder casting contained steam supply and exhaust ports.
Engines equipped with a condenser are a separate type than those that exhaust to the atmosphere.
Other components are often present; pumps (such as an injector) to supply water to the boiler during operation, condensers to recirculate the water and recover the latent heat of vaporisation, and superheaters to raise the temperature of the steam above its saturated vapour point, and various mechanisms to increase the draft for fireboxes. When coal is used, a chain or screw stoking mechanism and its drive engine or motor may be included to move the fuel from a supply bin (bunker) to the firebox.


=== Heat source ===
The heat required for boiling the water and raising the temperature of the steam can be derived from various sources, most commonly from burning combustible materials with an appropriate supply of air in a closed space (e.g., combustion chamber, firebox, furnace).  In the case of model or toy steam engines and a few full scale cases, the heat source can be an electric heating element.


=== Boilers ===

Boilers are pressure vessels that contain water to be boiled, and features that transfer the heat to the water as effectively as possible.
The two most common types are:

water-tube boiler – water is passed through tubes surrounded by hot gas
fire-tube boiler – hot gas is passed through tubes immersed in water, the same water also circulates in a water jacket surrounding the firebox and, in high-output locomotive boilers, also passes through tubes in the firebox itself (thermic syphons and security circulators)Fire-tube boilers were the main type used for early high-pressure steam (typical steam locomotive practice), but they were to a large extent displaced by more economical water tube boilers in the late 19th century for marine propulsion and large stationary applications.
Many boilers raise the temperature of the steam after it has left that part of the boiler where it is in contact with the water. Known as superheating it turns 'wet steam' into 'superheated steam'. It avoids the steam condensing in the engine cylinders, and gives a significantly higher efficiency.


=== Motor units ===

In a steam engine, a piston or steam turbine or any other similar device for doing mechanical work takes a supply of steam at high pressure and temperature and gives out a supply of steam at lower pressure and temperature, using as much of the difference in steam energy as possible to do mechanical work.
These ""motor units"" are often called 'steam engines' in their own right. Engines using compressed air or other gases differ from steam engines only in details that depend on the nature of the gas although compressed air has been used in steam engines without change.


=== Cold sink ===
As with all heat engines, the majority of primary energy must be emitted as waste heat at relatively low temperature.The simplest cold sink is to vent the steam to the environment. This is often used on steam locomotives to avoid the weight and bulk of condensers. Some of the released steam is vented up the chimney so as to increase the draw on the fire, which greatly increases engine power, but reduces efficiency.
Sometimes the waste heat from the engine is useful itself, and in those cases, very high overall efficiency can be obtained.
Steam engines in stationary power plants use surface condensers as a cold sink. The condensers are cooled by water flow from oceans, rivers, lakes, and often by cooling towers which evaporate water to provide cooling energy removal. The resulting condensed hot water (condensate), is then pumped back up to pressure and sent back to the boiler. A dry-type cooling tower is similar to an automobile radiator and is used in locations where water is costly. Waste heat can also be ejected by evaporative (wet) cooling towers, which use a secondary external water circuit that evaporates some of flow to the air.
River boats initially used a jet condenser in which cold water from the river is injected into the exhaust steam from the engine. Cooling water and condensate mix.  While this was also applied for sea-going vessels, generally after only a few days of operation the boiler would become coated with deposited salt, reducing performance and increasing the risk of a boiler explosion.  Starting about 1834, the use of surface condensers on ships eliminated fouling of the boilers, and improved engine efficiency.Evaporated water cannot be used for subsequent purposes (other than rain somewhere), whereas river water can be re-used. In all cases, the steam plant boiler feed water, which must be kept pure, is kept separate from the cooling water or air.


=== Water pump ===
Most steam engines have a means to supply boiler water whilst at pressure, so that they may be run continuously. Utility and industrial boilers commonly use multi-stage centrifugal pumps; however, other types are used. Another means of supplying lower-pressure boiler feed water is an injector, which uses a steam jet usually supplied from the boiler. Injectors became popular in the 1850s but are no longer widely used, except in applications such as steam locomotives. It is the pressurization of the water that circulates through the steam boiler that allows the water to be raised to temperatures well above 100 °C (212 °F) boiling point of water at one atmospheric pressure, and by that means to increase the efficiency of the steam cycle.


=== Monitoring and control ===

For safety reasons, nearly all steam engines are equipped with mechanisms to monitor the boiler, such as a pressure gauge and a sight glass to monitor the water level.
Many engines, stationary and mobile, are also fitted with a governor to regulate the speed of the engine without the need for human interference.
The most useful instrument for analyzing the performance of steam engines is the steam engine indicator. Early versions were in use by 1851, but the most successful indicator was developed for the high speed engine inventor and manufacturer Charles Porter by Charles Richard and exhibited at London Exhibition in 1862. The steam engine indicator traces on paper the pressure in the cylinder throughout the cycle, which can be used to spot various problems and calculate developed horsepower. It was routinely used by engineers, mechanics and insurance inspectors. The engine indicator can also be used on internal combustion engines. See image of indicator diagram below (in Types of motor units section).


=== Governor ===

The centrifugal governor was adopted by James Watt for use on a steam engine in 1788 after Watt's partner Boulton saw one on the equipment of a flour mill Boulton & Watt were building. The governor could not actually hold a set speed, because it would assume a new constant speed in response to load changes. The governor was able to handle smaller variations such as those caused by fluctuating heat load to the boiler. Also, there was a tendency for oscillation whenever there was a speed change. As a consequence, engines equipped only with this governor were not suitable for operations requiring constant speed, such as cotton spinning. The governor was improved over time and coupled with variable steam cut off, good speed control in response to changes in load was attainable near the end of the 19th century.


== Engine configuration ==


=== Simple engine ===
In a simple engine, or ""single expansion engine"" the charge of steam passes through the entire expansion process in an individual cylinder, although a simple engine may have one or more individual cylinders. It is then exhausted directly into the atmosphere or into a condenser. As steam expands in passing through a high-pressure engine, its temperature drops because no heat is being added to the system; this is known as adiabatic expansion and results in steam entering the cylinder at high temperature and leaving at lower temperature. This causes a cycle of heating and cooling of the cylinder with every stroke, which is a source of inefficiency.

The dominant efficiency loss in reciprocating steam engines is cylinder condensation and re-evaporation. The steam cylinder and adjacent metal parts/ports operate at a temperature about halfway between the steam admission saturation temperature and the saturation temperature corresponding to the exhaust pressure.  As high-pressure steam is admitted into the working cylinder, much of the high-temperature steam is condensed as water droplets onto the metal surfaces, significantly reducing the steam available for expansive work.  When the expanding steam reaches low pressure (especially during the exhaust stroke), the previously deposited water droplets that had just been formed within the cylinder/ports now boil away (re-evaporation) and this steam does no further work in the cylinder.There are practical limits on the expansion ratio of a steam engine cylinder, as increasing cylinder surface area tends to exacerbate the cylinder condensation and re-evaporation issues.  This negates the theoretical advantages associated with a high ratio of expansion in an individual cylinder.


=== Compound engines ===

A method to lessen the magnitude of energy loss to a very long cylinder was invented in 1804 by British engineer Arthur Woolf, who patented his Woolf high-pressure compound engine in 1805. In the compound engine, high-pressure steam from the boiler expands in a high-pressure (HP) cylinder and then enters one or more subsequent lower-pressure (LP) cylinders. The complete expansion of the steam now occurs across multiple cylinders, with the overall temperature drop within each cylinder reduced considerably.  By expanding the steam in steps with smaller temperature range (within each cylinder) the condensation and re-evaporation efficiency issue (described above) is reduced. This reduces the magnitude of cylinder heating and cooling, increasing the efficiency of the engine. By staging the expansion in multiple cylinders, variations of torque can be reduced. To derive equal work from lower-pressure cylinder requires a larger cylinder volume as this steam occupies a greater volume. Therefore, the bore, and in rare cases the stroke, are increased in low-pressure cylinders, resulting in larger cylinders.Double-expansion (usually known as compound) engines expanded the steam in two stages. The pairs may be duplicated or the work of the large low-pressure cylinder can be split with one high-pressure cylinder exhausting into one or the other, giving a three-cylinder layout where cylinder and piston diameter are about the same, making the reciprocating masses easier to balance.Two-cylinder compounds can be arranged as:

Cross compounds: The cylinders are side by side.
Tandem compounds: The cylinders are end to end, driving a common connecting rod
Angle compounds: The cylinders are arranged in a V (usually at a 90° angle) and drive a common crank.With two-cylinder compounds used in railway work, the pistons are connected to the cranks as with a two-cylinder simple at 90° out of phase with each other (quartered). When the double-expansion group is duplicated, producing a four-cylinder compound, the individual pistons within the group are usually balanced at 180°, the groups being set at 90° to each other. In one case (the first type of Vauclain compound), the pistons worked in the same phase driving a common crosshead and crank, again set at 90° as for a two-cylinder engine. With the three-cylinder compound arrangement, the LP cranks were either set at 90° with the HP one at 135° to the other two, or in some cases, all three cranks were set at 120°.The adoption of compounding was common for industrial units, for road engines and almost universal for marine engines after 1880; it was not universally popular in railway locomotives where it was often perceived as complicated. This is partly due to the harsh railway operating environment and limited space afforded by the loading gauge (particularly in Britain, where compounding was never common and not employed after 1930). However, although never in the majority, it was popular in many other countries.


=== Multiple-expansion engines ===

It is a logical extension of the compound engine (described above) to split the expansion into yet more stages to increase efficiency. The result is the multiple-expansion engine. Such engines use either three or four expansion stages and are known as triple- and quadruple-expansion engines respectively. These engines use a series of cylinders of progressively increasing diameter. These cylinders are designed to divide the work into equal shares for each expansion stage. As with the double-expansion engine, if space is at a premium, then two smaller cylinders may be used for the low-pressure stage. Multiple-expansion engines typically had the cylinders arranged inline, but various other formations were used. In the late 19th century, the Yarrow-Schlick-Tweedy balancing ""system"" was used on some marine triple-expansion engines. Y-S-T engines divided the low-pressure expansion stages between two cylinders, one at each end of the engine. This allowed the crankshaft to be better balanced, resulting in a smoother, faster-responding engine which ran with less vibration. This made the four-cylinder triple-expansion engine popular with large passenger liners (such as the Olympic class), but this was ultimately replaced by the virtually vibration-free turbine engine. It is noted, however, that triple-expansion reciprocating steam engines were used to drive the World War II Liberty ships, by far the largest number of identical ships ever built. Over 2700 ships were built, in the United States, from a British original design.The image in this section shows an animation of a triple-expansion engine. The steam travels through the engine from left to right. The valve chest for each of the cylinders is to the left of the corresponding cylinder.Land-based steam engines could exhaust their steam to atmosphere, as feed water was usually readily available. Prior to and during World War I, the expansion engine dominated marine applications, where high vessel speed was not essential. It was, however, superseded by the British invention steam turbine where speed was required, for instance in warships, such as the dreadnought battleships, and ocean liners. HMS Dreadnought of 1905 was the first major warship to replace the proven technology of the reciprocating engine with the then-novel steam turbine.


== Types of motor units ==


=== Reciprocating piston ===

In most reciprocating piston engines, the steam reverses its direction of flow at each stroke (counterflow), entering and exhausting from the same end of the cylinder. The complete engine cycle occupies one rotation of the crank and two piston strokes; the cycle also comprises four events – admission, expansion, exhaust, compression. These events are controlled by valves often working inside a steam chest adjacent to the cylinder; the valves distribute the steam by opening and closing steam ports communicating with the cylinder end(s) and are driven by valve gear, of which there are many types.The simplest valve gears give events of fixed length during the engine cycle and often make the engine rotate in only one direction. Many however have a reversing mechanism which additionally can provide means for saving steam as speed and momentum are gained by gradually ""shortening the cutoff"" or rather, shortening the admission event; this in turn proportionately lengthens the expansion period. However, as one and the same valve usually controls both steam flows, a short cutoff at admission adversely affects the exhaust and compression periods which should ideally always be kept fairly constant; if the exhaust event is too brief, the totality of the exhaust steam cannot evacuate the cylinder, choking it and giving excessive compression (""kick back"").In the 1840s and 1850s, there were attempts to overcome this problem by means of various patent valve gears with a separate, variable cutoff expansion valve riding on the back of the main slide valve; the latter usually had fixed or limited cutoff. The combined setup gave a fair approximation of the ideal events, at the expense of increased friction and wear, and the mechanism tended to be complicated. The usual compromise solution has been to provide lap by lengthening rubbing surfaces of the valve in such a way as to overlap the port on the admission side, with the effect that the exhaust side remains open for a longer period after cut-off on the admission side has occurred. This expedient has since been generally considered satisfactory for most purposes and makes possible the use of the simpler Stephenson, Joy and Walschaerts motions. Corliss, and later, poppet valve gears had separate admission and exhaust valves driven by trip mechanisms or cams profiled so as to give ideal events; most of these gears never succeeded outside of the stationary marketplace due to various other issues including leakage and more delicate mechanisms.


==== Compression ====
Before the exhaust phase is quite complete, the exhaust side of the valve closes, shutting a portion of the exhaust steam inside the cylinder. This determines the compression phase where a cushion of steam is formed against which the piston does work whilst its velocity is rapidly decreasing; it moreover obviates the pressure and temperature shock, which would otherwise be caused by the sudden admission of the high-pressure steam at the beginning of the following cycle.


==== Lead ====
The above effects are further enhanced by providing lead: as was later discovered with the internal combustion engine, it has been found advantageous since the late 1830s to advance the admission phase, giving the valve lead so that admission occurs a little before the end of the exhaust stroke in order to fill the clearance volume comprising the ports and the cylinder ends (not part of the piston-swept volume) before the steam begins to exert effort on the piston.


=== Uniflow (or unaflow) engine ===

Uniflow engines attempt to remedy the difficulties arising from the usual counterflow cycle where, during each stroke, the port and the cylinder walls will be cooled by the passing exhaust steam, whilst the hotter incoming admission steam will waste some of its energy in restoring the working temperature. The aim of the uniflow is to remedy this defect and improve efficiency by providing an additional port uncovered by the piston at the end of each stroke making the steam flow only in one direction. By this means, the simple-expansion uniflow engine gives efficiency equivalent to that of classic compound systems with the added advantage of superior part-load performance, and comparable efficiency to turbines for smaller engines below one thousand horsepower. However, the thermal expansion gradient uniflow engines produce along the cylinder wall gives practical difficulties..


=== Turbine engines ===

A steam turbine consists of one or more rotors (rotating discs) mounted on a drive shaft, alternating with a series of stators (static discs) fixed to the turbine casing. The rotors have a propeller-like arrangement of blades at the outer edge. Steam acts upon these blades, producing rotary motion. The stator consists of a similar, but fixed, series of blades that serve to redirect the steam flow onto the next rotor stage. A steam turbine often exhausts into a surface condenser that provides a vacuum. The stages of a steam turbine are typically arranged to extract the maximum potential work from a specific velocity and pressure of steam, giving rise to a series of variably sized high- and low-pressure stages. Turbines are only efficient if they rotate at relatively high speed, therefore they are usually connected to reduction gearing to drive lower speed applications, such as a ship's propeller. In the vast majority of large electric generating stations, turbines are directly connected to generators with no reduction gearing. Typical speeds are 3600 revolutions per minute (RPM) in the United States with 60 Hertz power, and 3000 RPM in Europe and other countries with 50 Hertz electric power systems. In nuclear power applications, the turbines typically run at half these speeds, 1800 RPM and 1500 RPM. A turbine rotor is also only capable of providing power when rotating in one direction. Therefore, a reversing stage or gearbox is usually required where power is required in the opposite direction.Steam turbines provide direct rotational force and therefore do not require a linkage mechanism to convert reciprocating to rotary motion. Thus, they produce smoother rotational forces on the output shaft. This contributes to a lower maintenance requirement and less wear on the machinery they power than a comparable reciprocating engine.

The main use for steam turbines is in electricity generation (in the 1990s about 90% of the world's electric production was by use of steam turbines) however the recent widespread application of large gas turbine units and typical combined cycle power plants has resulted in reduction of this percentage to the 80% regime for steam turbines. In electricity production, the high speed of turbine rotation matches well with the speed of modern electric generators, which are typically direct connected to their driving turbines. In marine service, (pioneered on the Turbinia), steam turbines with reduction gearing (although the Turbinia has direct turbines to propellers with no reduction gearbox) dominated large ship propulsion throughout the late 20th century, being more efficient (and requiring far less maintenance) than reciprocating steam engines. In recent decades, reciprocating Diesel engines, and gas turbines, have almost entirely supplanted steam propulsion for marine applications.Virtually all nuclear power plants generate electricity by heating water to provide steam that drives a turbine connected to an electrical generator. Nuclear-powered ships and submarines either use a steam turbine directly for main propulsion, with generators providing auxiliary power, or else employ turbo-electric transmission, where the steam drives a turbo generator set with propulsion provided by electric motors. A limited number of steam turbine railroad locomotives were manufactured. Some non-condensing direct-drive locomotives did meet with some success for long haul freight operations in Sweden and for express passenger work in Britain, but were not repeated. Elsewhere, notably in the United States, more advanced designs with electric transmission were built experimentally, but not reproduced. It was found that steam turbines were not ideally suited to the railroad environment and these locomotives failed to oust the classic reciprocating steam unit in the way that modern diesel and electric traction has done.


=== Oscillating cylinder steam engines ===

An oscillating cylinder steam engine is a variant of the simple expansion steam engine which does not require valves to direct steam into and out of the cylinder. Instead of valves, the entire cylinder rocks, or oscillates, such that one or more holes in the cylinder line up with holes in a fixed port face or in the pivot mounting (trunnion). These engines are mainly used in toys and models, because of their simplicity, but have also been used in full-size working engines, mainly on ships where their compactness is valued.


=== Rotary steam engines ===
It is possible to use a mechanism based on a pistonless rotary engine such as the Wankel engine in place of the cylinders and valve gear of a conventional reciprocating steam engine. Many such engines have been designed, from the time of James Watt to the present day, but relatively few were actually built and even fewer went into quantity production; see link at bottom of article for more details. The major problem is the difficulty of sealing the rotors to make them steam-tight in the face of wear and thermal expansion; the resulting leakage made them very inefficient. Lack of expansive working, or any means of control of the cutoff, is also a serious problem with many such designs.By the 1840s, it was clear that the concept had inherent problems and rotary engines were treated with some derision in the technical press. However, the arrival of electricity on the scene, and the obvious advantages of driving a dynamo directly from a high-speed engine, led to something of a revival in interest in the 1880s and 1890s, and a few designs had some limited success..
Of the few designs that were manufactured in quantity, those of the Hult Brothers Rotary Steam Engine Company of Stockholm, Sweden, and the spherical engine of Beauchamp Tower are notable. Tower's engines were used by the Great Eastern Railway to drive lighting dynamos on their locomotives, and by the Admiralty for driving dynamos on board the ships of the Royal Navy. They were eventually replaced in these niche applications by steam turbines.


=== Rocket type ===

The aeolipile represents the use of steam by the rocket-reaction principle, although not for direct propulsion.In more modern times there has been limited use of steam for rocketry – particularly for rocket cars. Steam rocketry works by filling a pressure vessel with hot water at high pressure and opening a valve leading to a suitable nozzle. The drop in pressure immediately boils some of the water and the steam leaves through a nozzle, creating a propulsive force.Ferdinand Verbiest's carriage was powered by an aeolipile in 1679.


== Safety ==
Steam engines possess boilers and other components that are pressure vessels that contain a great deal of potential energy. Steam escapes and boiler explosions (typically BLEVEs) can and have in the past caused great loss of life. While variations in standards may exist in different countries, stringent legal, testing, training, care with manufacture, operation and certification is applied to ensure safety.Failure modes may include:

over-pressurisation of the boiler
insufficient water in the boiler causing overheating and vessel failure
buildup of sediment and scale which cause local hot spots, especially in riverboats using dirty feed water
pressure vessel failure of the boiler due to inadequate construction or maintenance.
escape of steam from pipework/boiler causing scaldingSteam engines frequently possess two independent mechanisms for ensuring that the pressure in the boiler does not go too high; one may be adjusted by the user, the second is typically designed as an ultimate fail-safe. Such safety valves traditionally used a simple lever to restrain a plug valve in the top of a boiler. One end of the lever carried a weight or spring that restrained the valve against steam pressure. Early valves could be adjusted by engine drivers, leading to many accidents when a driver fastened the valve down to allow greater steam pressure and more power from the engine. The more recent type of safety valve uses an adjustable spring-loaded valve, which is locked such that operators may not tamper with its adjustment unless a seal is illegally broken. This arrangement is considerably safer.Lead fusible plugs may be present in the crown of the boiler's firebox. If the water level drops, such that the temperature of the firebox crown increases significantly, the lead melts and the steam escapes, warning the operators, who may then manually suppress the fire. Except in the smallest of boilers the steam escape has little effect on dampening the fire. The plugs are also too small in area to lower steam pressure significantly, depressurizing the boiler. If they were any larger, the volume of escaping steam would itself endanger the crew.


== Steam cycle ==

The Rankine cycle is the fundamental thermodynamic underpinning of the steam engine. The cycle is an arrangement of components as is typically used for simple power production, and utilizes the phase change of water (boiling water producing steam, condensing exhaust steam, producing liquid water)) to provide a practical heat/power conversion system. The heat is supplied externally to a closed loop with some of the heat added being converted to work and the waste heat being removed in a condenser. The Rankine cycle is used in virtually all steam power production applications. In the 1990s, Rankine steam cycles generated about 90% of all electric power used throughout the world, including virtually all solar, biomass, coal and nuclear power plants. It is named after William John Macquorn Rankine, a Scottish polymath.The Rankine cycle is sometimes referred to as a practical Carnot cycle because, when an efficient turbine is used, the TS diagram begins to resemble the Carnot cycle. The main difference is that heat addition (in the boiler) and rejection (in the condenser) are isobaric (constant pressure) processes in the Rankine cycle and isothermal (constant temperature) processes in the theoretical Carnot cycle. In this cycle, a pump is used to pressurize the working fluid which is received from the condenser as a liquid not as a gas. Pumping the working fluid in liquid form during the cycle requires a small fraction of the energy to transport it compared to the energy needed to compress the working fluid in gaseous form in a compressor (as in the Carnot cycle). The cycle of a reciprocating steam engine differs from that of turbines because of condensation and re-evaporation occurring in the cylinder or in the steam inlet passages.The working fluid in a Rankine cycle can operate as a closed loop system, where the working fluid is recycled continuously, or may be an ""open loop"" system, where the exhaust steam is directly released to the atmosphere, and a separate source of water feeding the boiler is supplied. Normally water is the fluid of choice due to its favourable properties, such as non-toxic and unreactive chemistry, abundance, low cost, and its thermodynamic properties. Mercury is the working fluid in the mercury vapor turbine. Low boiling hydrocarbons can be used in a binary cycle.The steam engine contributed much to the development of thermodynamic theory; however, the only applications of scientific theory that influenced the steam engine were the original concepts of harnessing the power of steam and atmospheric pressure and knowledge of properties of heat and steam. The experimental measurements made by Watt on a model steam engine led to the development of the separate condenser. Watt independently discovered latent heat, which was confirmed by the original discoverer Joseph Black, who also advised Watt on experimental procedures. Watt was also aware of the change in the boiling point of water with pressure. Otherwise, the improvements to the engine itself were more mechanical in nature. The thermodynamic concepts of the Rankine cycle did give engineers the understanding needed to calculate efficiency which aided the development of modern high-pressure and -temperature boilers and the steam turbine.


== Efficiency ==

The efficiency of an engine cycle can be calculated by dividing the energy output of mechanical work that the engine produces by the energy put into the engine by the burning fuel.The historical measure of a steam engine's energy efficiency was its ""duty"". The concept of duty was first introduced by Watt in order to illustrate how much more efficient his engines were over the earlier Newcomen designs. Duty is the number of foot-pounds of work delivered by burning one bushel (94 pounds) of coal. The best examples of Newcomen designs had a duty of about 7 million, but most were closer to 5 million. Watt's original low-pressure designs were able to deliver duty as high as 25 million, but averaged about 17. This was a three-fold improvement over the average Newcomen design. Early Watt engines equipped with high-pressure steam improved this to 65 million.No heat engine can be more efficient than the Carnot cycle, in which heat is moved from a high-temperature reservoir to one at a low temperature, and the efficiency depends on the temperature difference. For the greatest efficiency, steam engines should be operated at the highest steam temperature possible (superheated steam), and release the waste heat at the lowest temperature possible.The efficiency of a Rankine cycle is usually limited by the working fluid. Without the pressure reaching supercritical levels for the working fluid, the temperature range over which the cycle can operate is small; in steam turbines, turbine entry temperatures are typically 565 °C (the creep limit of stainless steel) and condenser temperatures are around 30 °C. This gives a theoretical Carnot efficiency of about 63% compared with an actual efficiency of 42% for a modern coal-fired power station. This low turbine entry temperature (compared with a gas turbine) is why the Rankine cycle is often used as a bottoming cycle in combined-cycle gas turbine power stations.One principal advantage the Rankine cycle holds over others is that during the compression stage relatively little work is required to drive the pump, the working fluid being in its liquid phase at this point. By condensing the fluid, the work required by the pump consumes only 1% to 3% of the turbine (or reciprocating engine) power and contributes to a much higher efficiency for a real cycle. The benefit of this is lost somewhat due to the lower heat addition temperature. Gas turbines, for instance, have turbine entry temperatures approaching 1500 °C. Nonetheless, the efficiencies of actual large steam cycles and large modern simple cycle gas turbines are fairly well matched.In practice, a reciprocating steam engine cycle exhausting the steam to atmosphere will typically have an efficiency (including the boiler) in the range of 1–10%, but with the addition of a condenser, Corliss valves, multiple expansion, and high steam pressure/temperature, it may be greatly improved, historically into the range of 10–20%, and very rarely slightly higher.A modern, large electrical power station (producing several hundred megawatts of electrical output) with steam reheat, economizer etc. will achieve efficiency in the mid 40% range, with the most efficient units approaching 50% thermal efficiency.It is also possible to capture the waste heat using cogeneration in which the waste heat is used for heating a lower boiling point working fluid or as a heat source for district heating via saturated low-pressure steam.

		
		


== See also ==


== Notes ==


== References ==


== References ==


== Further reading ==
Thurston, Robert Henry (1878). A History of the Growth of the Steam-engine. The International Scientific Series. New York: D. Appleton and Company. OCLC 16507415.


== External links ==
Animated engines – Illustrates a variety of engines
Howstuffworks – ""How Steam Engines Work""
Video of the 1900 steam engine aboard paddle steamer Unterwalden"
"The diesel engine, named after Rudolf Diesel, is an internal combustion engine in which ignition of the fuel is caused by the elevated temperature of the air in the cylinder due to the mechanical compression (adiabatic compression); thus, the diesel engine is a so-called compression-ignition engine (CI engine). This contrasts with engines using spark plug-ignition of the air-fuel mixture, such as a petrol engine (gasoline engine) or a gas engine (using a gaseous fuel like natural gas or liquefied petroleum gas).
Diesel engines work by compressing only the air. This increases the air temperature inside the cylinder to such a high degree that atomised diesel fuel injected into the combustion chamber ignites spontaneously. With the fuel being injected into the air just before combustion, the dispersion of the fuel is uneven; this is called a heterogeneous air-fuel mixture. The torque a diesel engine produces is controlled by manipulating the air-fuel ratio (λ); instead of throttling the intake air, the diesel engine relies on altering the amount of fuel that is injected, and the air-fuel ratio is usually high.
The diesel engine has the highest thermal efficiency (engine efficiency) of any practical internal or external combustion engine due to its very high expansion ratio and inherent lean burn which enables heat dissipation by the excess air. A small efficiency loss is also avoided compared with non-direct-injection gasoline engines since unburned fuel is not present during valve overlap and therefore no fuel goes directly from the intake/injection to the exhaust. Low-speed diesel engines (as used in ships and other applications where overall engine weight is relatively unimportant) can reach effective efficiencies of up to 55%.Diesel engines may be designed as either two-stroke or four-stroke cycles. They were originally used as a more efficient replacement for stationary steam engines. Since the 1910s, they have been used in submarines and ships. Use in locomotives, trucks, heavy equipment and electricity generation plants followed later. In the 1930s, they slowly began to be used in a few automobiles. Since the 1970s, the use of diesel engines in larger on-road and off-road vehicles in the US has increased. According to Konrad Reif, the EU average for diesel cars accounts for half of newly registered cars.The world's largest diesel engines put in service are 14-cylinder, two-stroke watercraft diesel engines; they produce a peak power of almost 100 MW each.


== History ==


=== Diesel's idea ===

In 1878, Rudolf Diesel, who was a student at the ""Polytechnikum"" in Munich, attended the lectures of Carl von Linde. Linde explained that steam engines are capable of converting just 6–10% of the heat energy into work, but that the Carnot cycle allows conversion of much more of the heat energy into work by means of isothermal change in condition. According to Diesel, this ignited the idea of creating a highly efficient engine that could work on the Carnot cycle. Diesel was also exposed to a fire piston, a traditional fire starter using rapid adiabatic compression principles which Linde had acquired from Southeast Asia. After several years of working on his ideas, Diesel published them in 1893 in the essay Theory and Construction of a Rational Heat Motor.Diesel was heavily criticised for his essay, but only few found the mistake that he made; his rational heat motor was supposed to utilise a constant temperature cycle (with isothermal compression) that would require a much higher level of compression than that needed for compression ignition. Diesel's idea was to compress the air so tightly that the temperature of the air would exceed that of combustion. However, such an engine could never perform any usable work. In his 1892 US patent (granted in 1895) #542846 Diesel describes the compression required for his cycle:

""pure atmospheric air is compressed, according to curve 1 2, to such a degree that, before ignition or combustion takes place, the highest pressure of the diagram and the highest temperature are obtained-that is to say, the temperature at which the subsequent combustion has to take place, not the burning or igniting point. To make this more clear, let it be assumed that the subsequent combustion shall take place at a temperature of 700°. Then in that case the initial pressure must be sixty-four atmospheres, or for 800° centigrade the pressure must be ninety atmospheres, and so on. Into the air thus compressed is then gradually introduced from the exterior finely divided fuel, which ignites on introduction, since the air is at a temperature far above the igniting-point of the fuel. The characteristic features of the cycle according to my present invention are therefore, increase of pressure and temperature up to the maximum, not by combustion, but prior to combustion by mechanical compression of air, and there upon the subsequent performance of work without increase of pressure and temperature by gradual combustion during a prescribed part of the stroke determined by the cut-oil"".By June 1893, Diesel had realised his original cycle would not work and he adopted the constant pressure cycle. Diesel describes the cycle in his 1895 patent application. Notice that there is no longer a mention of compression temperatures exceeding the temperature of combustion. Now it is simply stated that the compression must be sufficient to trigger ignition.

""1. In an internal-combustion engine, the combination of a cylinder and piston constructed and arranged to compress air to a degree producing a temperature above the igniting-point of the fuel, a supply for compressed air or gas; a fuel-supply; a distributing-valve for fuel, a passage from the air supply to the cylinder in communication with the fuel-distributing valve, an inlet to the cylinder in communication with the air-supply and with the fuel-valve, and a cut-oil, substantially as described."" See US patent # 608845 filed 1895 / granted 1898In 1892, Diesel received patents in Germany, Switzerland, the United Kingdom and the United States for ""Method of and Apparatus for Converting Heat into Work"". In 1894 and 1895, he filed patents and addenda in various countries for his engine; the first patents were issued in Spain (No. 16,654), France (No. 243,531) and Belgium (No. 113,139) in December 1894, and in Germany (No. 86,633) in 1895 and the United States (No. 608,845) in 1898.Diesel was attacked and criticised over a time period of several years. Critics have claimed that Diesel never invented a new motor and that the invention of the diesel engine is fraud. Otto Köhler and Emil Capitaine were two of the most prominent critics of Diesel's time. Köhler had published an essay in 1887, in which he describes an engine similar to the engine Diesel describes in his 1893 essay. Köhler figured that such an engine could not perform any work. Emil Capitaine had built a petroleum engine with glow-tube ignition in the early 1890s; he claimed against his own better judgement, that his glow-tube ignition engine worked the same way Diesel's engine did. His claims were unfounded and he lost a patent lawsuit against Diesel. Other engines, such as the Akroyd engine and the Brayton engine, also use an operating cycle that is different from the diesel engine cycle. Friedrich Sass says that the diesel engine is Diesel's ""very own work"" and that any ""Diesel myth"" is ""falsification of history"".


=== The first diesel engine ===
Diesel sought out firms and factories that would build his engine. With the help of Moritz Schröter and Max Gutermuth, he succeeded in convincing both Krupp in Essen and the Maschinenfabrik Augsburg. Contracts were signed in April 1893, and in early summer 1893, Diesel's first prototype engine was built in Augsburg. On 10 August 1893, the first ignition took place, the fuel used was petrol. In winter 1893/1894, Diesel redesigned the existing engine, and by 18 January 1894, his mechanics had converted it into the second prototype. On February 17, 1894, the redesigned engine ran for 88 revolutions – one minute; with this news, Maschinenfabrik Augsburg's stock rose by 30%, indicative of the tremendous anticipated demands for a more efficient engine. On 26 June 1895 the engine achieved an effective efficiency of 16.6% and had a fuel consumption of 519 g·kW−1·h−1.
 However, despite proving the concept, the engine caused problems, and Diesel could not achieve any substantial progress. Therefore, Krupp considered rescinding the contract they had made with Diesel. Diesel was forced to improve the design of his engine and rushed to construct a third prototype engine. Between 8 November and 20 December 1895, the second prototype had successfully covered over 111 hours on the test bench. In the January 1896 report, this was considered a success.In February 1896, Diesel considered supercharging the third prototype. Imanuel Lauster, who was ordered to draw the third prototype, had finished the drawings by 30 April 1896. During summer that year the engine was built, it was completed on 6 October 1896. Tests were conducted until early 1897. First public tests began on 1 February 1897. Moritz Schröter's test on 17 February 1897 was the main test of Diesel's engine. The engine was rated 13.1 kW with a specific fuel consumption of 324 g·kW−1·h−1, resulting in an effective efficiency of 26.2%. By 1898, Diesel had become a millionaire.


=== Timeline ===


==== 1890s ====
1893: Rudolf Diesel's essay titled Theory and Construction of a Rational Heat Motor appears.
1893: February 21, Diesel and the Maschinenfabrik Augsburg sign a contract that allows Diesel to build a prototype engine.
1893: February 23, Diesel obtains a patent (RP 67207) titled ""Arbeitsverfahren und Ausführungsart für Verbrennungsmaschinen"" (Working Methods and Techniques for Internal Combustion Engines).
1893: April 10, Diesel and Krupp sign a contract that allows Diesel to build a prototype engine.
1893: April 24, both Krupp and the Maschinenfabrik Augsburg decide to collaborate and build just a single prototype in Augsburg.
1893: July, the first prototype is completed.
1893: August 10, Diesel injects fuel (petrol) for the first time, resulting in combustion, destroying the indicator.
1893: November 30, Diesel applies for a patent (RP 82168) for a modified combustion process. He obtains it on 12 July 1895.
1894: January 18, after the first prototype had been modified to become the second prototype, testing with the second prototype begins.
1894: February 17, The second prototype runs for the first time.
1895: March 30, Diesel applies for a patent (RP 86633) for a starting process with compressed air.
1895: June 26, the second prototype passes brake testing for the first time.
1895: Diesel applies for a second patent US Patent # 608845
1895: November 8 – December 20, a series of tests with the second prototype is conducted. In total, 111 operating hours are recorded.
1896: October 6, the third and final prototype engine is completed.
1897: February 1, after 4 years Diesel's prototype engine is running and finally ready for efficiency testing and production.
1897: October 9, Adolphus Busch licenses rights to the diesel engine for the US and Canada.
1897: 29 October, Rudolf Diesel obtains a patent (DRP 95680) on supercharging the diesel engine.
1898: February 1, the Diesel Motoren-Fabrik Actien-Gesellschaft is registered.
1898: March, the first commercial diesel engine, rated 2×30 PS (2×22 kW), is installed in the Kempten plant of the Vereinigte Zündholzfabriken A.G.
1898: September 17, the Allgemeine Gesellschaft für Dieselmotoren A.-G. is founded.
1899: The first two-stroke diesel engine, invented by Hugo Güldner, is built.


==== 1900s ====

1901: Imanuel Lauster designs the first trunk piston diesel engine (DM 70).
1901: By 1901, MAN had produced 77 diesel engine cylinders for commercial use.
1903: Two first diesel-powered ships are launched, both for river and canal operations: The Vandal naphtha tanker and the Sarmat.
1904: The French launch the first diesel submarine, the Aigrette.
1905: January 14: Diesel applies for a patent on unit injection (L20510I/46a).
1905: The first diesel engine turbochargers and intercoolers are manufactured by Büchi.
1906: The Diesel Motoren-Fabrik Actien-Gesellschaft is dissolved.
1908: Diesel's patents expire.
1908: The first lorry (truck) with a diesel engine appears.
1909: March 14, Prosper L'Orange applies for a patent on precombustion chamber injection.  He later builds the first diesel engine with this system.


==== 1910s ====
1910: MAN starts making two-stroke diesel engines.
1910: November 26, James McKechnie applies for a patent on unit injection. Unlike Diesel, he managed to successfully build working unit injectors.
1911: November 27, the Allgemeine Gesellschaft für Dieselmotoren A.-G. is dissolved.
1911: The Germania shipyard in Kiel builds 850 PS (625 kW) diesel engines for German submarines. These engines are installed in 1914.
1912: MAN builds the first double-acting piston two-stroke diesel engine.
1912: The first locomotive with a diesel engine is used on the Swiss Winterthur-Romanshorn railroad.
1912: The Selandia is the first ocean-going ship with diesel engines.
1913: NELSECO diesels are installed on commercial ships and US Navy submarines.
1913: September 29, Rudolf Diesel dies mysteriously when crossing the English Channel on the SS Dresden.
1914: MAN builds 900 PS (662 kW) two-stroke engines for Dutch submarines.
1919: Prosper L'Orange obtains a patent on a Precombustion chamber insert incorporating a needle injection nozzle. First diesel engine from Cummins.


==== 1920s ====

1923: At the Königsberg DLG exhibition, the first agricultural tractor with a diesel engine, the prototype Benz-Sendling S6, is presented.
1923: December 15, the first lorry with a direct-injected diesel engine is tested by MAN. The same year, Benz builds a lorry with a pre-combustion chamber injected diesel engine.
1923: The first two-stroke diesel engine with counterflow scavenging appears.
1924: Fairbanks-Morse introduces the two-stroke Y-VA (later renamed to Model 32).
1925: Sendling starts mass-producing a diesel-powered agricultural tractor.
1927: Bosch introduces the first inline injection pump for motor vehicle diesel engines.
1929: The first passenger car with a diesel engine appears. Its engine is an Otto engine modified to use the diesel principle and Bosch's injection pump. Several other diesel car prototypes follow.


==== 1930s ====
1933: Junkers Motorenwerke in Germany start production of the most successful mass-produced aviation diesel engine of all time, the Jumo 205. By the outbreak of World War II, over 900 examples are produced. Its rated take-off power is 645 kW.
1933: General Motors uses its new roots-blown, unit-injected two-stroke Winton 201A diesel engine to power its automotive assembly exhibit at the Chicago World's Fair (A Century of Progress). The engine is offered in several versions ranging from 600–900 hp (447–671 kW).
1934: The Budd Company builds the first diesel-electric passenger train in the US, the Pioneer Zephyr 9900, using a Winton engine.
1935: The Citroën Rosalie is fitted with an early swirl chamber injected diesel engine for testing purposes. Daimler-Benz starts manufacturing the Mercedes-Benz OM 138, the first mass-produced diesel engine for passenger cars, and one of the few marketable passenger car diesel engines of its time. It is rated 45 PS (33 kW).
1936: March 4, the airship LZ 129 Hindenburg, the biggest aircraft ever made, takes off for the first time. She is powered by four V16 Daimler-Benz LOF 6 diesel engines, rated 1200 PS (883 kW) each.
1936: Manufacture of the first mass-produced passenger car with a diesel engine (Mercedes-Benz 260 D) begins.
1937: Konstantin Fyodorovich Chelpan develops the V-2 diesel engine, later used in the Soviet T-34 tanks, widely regarded as the best tank chassis of World War II.
1938: General Motors forms the GM Diesel Division, later to become Detroit Diesel, and introduces the Series 71 inline high-speed medium-horsepower two stroke engine, suitable for road vehicles and marine use.


==== 1940s ====
1946: Clessie Cummins obtains a patent on a fuel feeding and injection apparatus for oil-burning engines that incorporates separate components for generating injection pressure and injection timing.
1946: Klöckner-Humboldt-Deutz (KHD) introduces an air-cooled mass-production diesel engine to the market.


==== 1950s ====

1950s: KHD becomes the air-cooled diesel engine global market leader.
1951: J. Siegfried Meurer obtains a patent on the M-System, a design that incorporates a central sphere combustion chamber in the piston (DBP 865683).
1953: First mass-produced swirl chamber injected passenger car diesel engine (Borgward/Fiat).
1954: Daimler-Benz introduces the Mercedes-Benz OM 312 A, a 4.6 litre straight-6 series-production industrial diesel engine with a turbocharger, rated 115 PS (85 kW). It proves to be unreliable.
1954: Volvo produces a small batch series of 200 units of a turbocharged version of the TD 96 engine. This 9.6 litre engine is rated 136 kW.
1955: Turbocharging for MAN two-stroke marine diesel engines becomes standard.
1959: The Peugeot 403 becomes the first mass-produced passenger sedan/saloon manufactured outside West Germany to be offered with a diesel engine option.


==== 1960s ====

1964: Summer, Daimler-Benz switches from precombustion chamber injection to helix-controlled direct injection.
1962–65: A diesel compression braking system, eventually to be manufactured by the Jacobs Manufacturing Company and nicknamed the ""Jake Brake"", is invented and patented by Clessie Cummins.


==== 1970s ====
1972: KHD introduces the AD-System, Allstoff-Direkteinspritzung, (anyfuel direct-injection), for its diesel engines. AD-diesels can operate on virtually any kind of liquid fuel, but they are fitted with an auxiliary spark plug that fires if the ignition quality of the fuel is too low.
1976: Development of the common rail injection begins at the ETH Zürich.
1976: The Volkswagen Golf becomes the first compact passenger sedan/saloon to be offered with a diesel engine option.
1978: Daimler-Benz produces the first passenger car diesel engine with a turbocharger (Mercedes-Benz OM 617).
1979: First prototype of a low-speed two-stroke crosshead engine with common rail injection.


==== 1980s ====

1981/82: Uniflow scavenging for two-stroke marine diesel engines becomes standard.
1985: December, road testing of a common rail injection system for lorries using a modified 6VD 12,5/12 GRF-E engine in an IFA W50 takes place.
1986: The BMW E28 524td is the world's first passenger car equipped with an electronically controlled injection pump (developed by Bosch).
1987: Daimler-Benz introduces the electronically controlled injection pump for lorry diesel engines.
1988: The Fiat Croma becomes the first mass-produced passenger car in the world to have a direct injected diesel engine.
1989: The Audi 100 is the first passenger car in the world with a turbocharged, direct injected, and electronically controlled diesel engine.


==== 1990s ====
1992: 1 July, the Euro 1 emission standard comes into effect.
1993: First passenger car diesel engine with four valves per cylinder, the Mercedes-Benz OM 604.
1994: Unit injector system by Bosch for lorry diesel engines.
1996: First diesel engine with direct injection and four valves per cylinder, used in the Opel Vectra.
1996: First radial piston distributor injection pump by Bosch.
1997: First mass-produced common rail diesel engine for a passenger car, the Fiat 1.9 JTD.
1998: BMW wins the 24 Hours Nürburgring race with a modified BMW E36. The car, called 320d, is powered by a 2-litre, straight-four diesel engine with direct injection and a helix-controlled distributor injection pump (Bosch VP 44), producing 180 kW. The fuel consumption is 23 l/100 km, only half the fuel consumption of a similar Otto-powered car.
1998: Volkswagen introduces the VW EA188 Pumpe-Düse engine (1.9 TDI), with Bosch-developed electronically controlled unit injectors.
1999: Daimler-Chrysler presents the first common rail three-cylinder diesel engine used in a passenger car (the Smart City Coupé).


==== 2000s ====

2000: Peugeot introduces the diesel particulate filter for passenger cars.
2002: Piezoelectric injector technology by Siemens.
2003: Piezoelectric injector technology by Bosch, and Delphi.
2004: BMW introduces dual-stage turbocharging with the BMW M57 engine.
2006: The world's most powerful diesel engine, the Wärtsilä RT-flex96C, is produced. It is rated 80,080 kW.
2006: Audi R10 TDI, equipped with a 5.5-litre V12-TDI engine, rated 476 kW, wins the 2006 24 Hours of Le Mans.
2006: Daimler-Chrysler launches the first series-production passenger car engine with selective catalytic reduction exhaust gas treatment, the Mercedes-Benz OM 642. It is fully complying with the Tier2Bin8 emission standard.
2008: Volkswagen introduces the LNT catalyst for passenger car diesel engines with the VW 2.0 TDI engine.
2008: Volkswagen starts series production of the biggest passenger car diesel engine, the Audi 6-litre V12 TDI.
2008: Subaru introduces the first horizontally opposed diesel engine to be fitted to a passenger car. It is a 2-litre common rail engine, rated 110 kW.


==== 2010s ====
2010: Mitsubishi developed and started mass production of its 4N13 1.8 L DOHC I4, the world's first passenger car diesel engine that features a variable valve timing system.
2012: BMW introduces dual-stage turbocharging with three turbochargers for the BMW N57 engine.
2015: Common rail systems working with pressures of 2,500 bar launched.
2015: In the Volkswagen emissions scandal, the US EPA issued a notice of violation of the Clean Air Act to Volkswagen Group after it was found that Volkswagen had intentionally programmed turbocharged direct injection (TDI) diesel engines to activate certain emissions controls only during laboratory emissions testing.


== Operating principle ==


=== Characteristics ===
The characteristics of a diesel engine are
Compression ignition: Due to almost adiabatic compression, the fuel ignites without any ignition-initiating apparatus such as spark plugs.
Mixture formation inside the combustion chamber: Air and fuel are mixed in the combustion chamber and not in the inlet manifold.
Engine speed adjustment solely by mixture quality: Instead of throttling the air-fuel mixture, the amount of torque produced (resulting in crankshaft rotational speed differences) is set solely by the mass of injected fuel, always mixed with as much air as possible.
Heterogeneous air-fuel mixture: The dispersion of air and fuel in the combustion chamber is uneven.
High air ratio: Due to always running on as much air as possible and not depending on exact mixture of air and fuel, diesel engines have an air-fuel ratio leaner than stochiometric (
  
    
      
        
          λ
          
            v
          
        
        ≥
        
          λ
          
            m
            i
            n
          
        
        >
        1
      
    
    {\displaystyle \lambda _{v}\geq \lambda _{min}>1}
  ).
Diffusion flame: At combustion, oxygen first has to diffuse into the flame, rather than having oxygen and fuel already mixed before combustion, which would result in a premixed flame.
Fuel with high ignition performance: As diesel engines solely rely on compression ignition, fuel with high ignition performance (cetane rating) is ideal for proper engine operation, fuel with a good knocking resistance (octane rating), e.g. petrol, is suboptimal for diesel engines.


=== Cycle of the diesel engine ===

The diesel internal combustion engine differs from the gasoline powered Otto cycle by using highly compressed hot air to ignite the fuel rather than using a spark plug (compression ignition rather than spark ignition).
In the diesel engine, only air is initially introduced into the combustion chamber. The air is then compressed with a compression ratio typically between 15:1 and 23:1. This high compression causes the temperature of the air to rise. At about the top of the compression stroke, fuel is injected directly into the compressed air in the combustion chamber. This may be into a (typically toroidal) void in the top of the piston or a pre-chamber depending upon the design of the engine. The fuel injector ensures that the fuel is broken down into small droplets, and that the fuel is distributed evenly. The heat of the compressed air vaporises fuel from the surface of the droplets. The vapour is then ignited by the heat from the compressed air in the combustion chamber, the droplets continue to vaporise from their surfaces and burn, getting smaller, until all the fuel in the droplets has been burnt. Combustion occurs at a substantially constant pressure during the initial part of the power stroke. The start of vaporisation causes a delay before ignition and the characteristic diesel knocking sound as the vapour reaches ignition temperature and causes an abrupt increase in pressure above the piston (not shown on the P-V indicator diagram). When combustion is complete the combustion gases expand as the piston descends further; the high pressure in the cylinder drives the piston downward, supplying power to the crankshaft.
As well as the high level of compression allowing combustion to take place without a separate ignition system, a high compression ratio greatly increases the engine's efficiency. Increasing the compression ratio in a spark-ignition engine where fuel and air are mixed before entry to the cylinder is limited by the need to prevent pre-ignition, which would cause engine damage. Since only air is compressed in a diesel engine, and fuel is not introduced into the cylinder until shortly before top dead centre (TDC), premature detonation is not a problem and compression ratios are much higher.
The p–V diagram is a simplified and idealised representation of the events involved in a diesel engine cycle, arranged to illustrate the similarity with a Carnot cycle. Starting at 1, the piston is at bottom dead centre and both valves are closed at the start of the compression stroke; the cylinder contains air at atmospheric pressure. Between 1 and 2 the air is compressed adiabatically – that is without heat transfer to or from the environment – by the rising piston. (This is only approximately true since there will be some heat exchange with the cylinder walls.) During this compression, the volume is reduced, the pressure and temperature both rise. At or slightly before 2 (TDC) fuel is injected and burns in the compressed hot air. Chemical energy is released and this constitutes an injection of thermal energy (heat) into the compressed gas. Combustion and heating occur between 2 and 3. In this interval the pressure remains constant since the piston descends, and the volume increases; the temperature rises as a consequence of the energy of combustion. At 3 fuel injection and combustion are complete, and the cylinder contains gas at a higher temperature than at 2. Between 3 and 4 this hot gas expands, again approximately adiabatically. Work is done on the system to which the engine is connected. During this expansion phase the volume of the gas rises, and its temperature and pressure both fall. At 4 the exhaust valve opens, and the pressure falls abruptly to atmospheric (approximately). This is unresisted expansion and no useful work is done by it. Ideally the adiabatic expansion should continue, extending the line 3–4 to the right until the pressure falls to that of the surrounding air, but the loss of efficiency caused by this unresisted expansion is justified by the practical difficulties involved in recovering it (the engine would have to be much larger). After the opening of the exhaust valve, the exhaust stroke follows, but this (and the following induction stroke) are not shown on the diagram. If shown, they would be represented by a low-pressure loop at the bottom of the diagram. At 1 it is assumed that the exhaust and induction strokes have been completed, and the cylinder is again filled with air. The piston-cylinder system absorbs energy between 1 and 2 – this is the work needed to compress the air in the cylinder, and is provided by mechanical kinetic energy stored in the flywheel of the engine. Work output is done by the piston-cylinder combination between 2 and 4. The difference between these two increments of work is the indicated work output per cycle, and is represented by the area enclosed by the p–V loop. The adiabatic expansion is in a higher pressure range than that of the compression because the gas in the cylinder is hotter during expansion than during compression. It is for this reason that the loop has a finite area, and the net output of work during a cycle is positive.


=== Efficiency ===
Due to its high compression ratio, the diesel engine has a high efficiency, and the lack of a throttle valve means that the charge-exchange losses are fairly low, resulting in a low specific fuel consumption, especially in medium and low load situations. This makes the diesel engine very economical. Even though diesel engines have a theoretical efficiency of 75%, in practice it is much lower. In his 1893 essay Theory and Construction of a Rational Heat Motor, Rudolf Diesel describes that the effective efficiency of the diesel engine would be in between 43.2% and 50.4% , or maybe even greater. Modern passenger car diesel engines may have an effective efficiency of up to 43%, whilst engines in large diesel trucks, and buses can achieve peak efficiencies around 45%.  However, average efficiency over a driving cycle is lower than peak efficiency. For example, it might be 37% for an engine with a peak efficiency of 44%. The highest diesel engine efficiency of up to 55% is achieved by large two-stroke watercraft diesel engines.


=== Major advantages ===
Diesel engines have several advantages over engines operating on other principles:

The diesel engine has the highest effective efficiency of all combustion engines.Diesel engines inject the fuel directly into the combustion chamber, have no intake air restrictions apart from air filters and intake plumbing and have no intake manifold vacuum to add parasitic load and pumping losses resulting from the pistons being pulled downward against intake system vacuum. Cylinder filling with atmospheric air is aided and volumetric efficiency is increased for the same reason.
Although the fuel efficiency (mass burned per energy produced) of a diesel engine drops at lower loads, it doesn't drop quite as fast as that of a typical petrol or turbine engine.
 Diesel engines can combust a huge variety of fuels, including several fuel oils, that have advantages over fuels such as petrol. These advantages include:
Low fuel costs, as fuel oils are relatively cheap
Good lubrication properties
High energy density
Low risk of catching fire, as they do not form a flammable vapour
Biodiesel is an easily synthesised, non-petroleum-based fuel (through transesterification) which can run directly in many diesel engines, while gasoline engines either need adaptation to run synthetic fuels or else use them as an additive to gasoline (e.g., ethanol added to gasohol).
Diesel engines have a very good exhaust-emission behaviour. The exhaust contains minimal amounts of carbon monoxide and hydrocarbons. Direct injected diesel engines emit approximately as much nitrogen oxide as Otto cycle engines. Swirl chamber and precombustion chamber injected engines, however, emit approximately 50% less nitrogen oxide than Otto cycle engines when running under full load. Compared with Otto cycle engines, diesel engines emit 10 times less pollutants and also less carbon dioxide (comparing the raw emissions without exhaust gas treatment).
They have no high voltage electrical ignition system, resulting in high reliability and easy adaptation to damp environments. The absence of coils, spark plug wires, etc., also eliminates a source of radio frequency emissions which can interfere with navigation and communication equipment, which is especially important in marine and aircraft applications, and for preventing interference with radio telescopes. (For this reason, only diesel-powered vehicles are allowed in parts of the American National Radio Quiet Zone.)
Diesel engines can accept super- or turbocharging pressure without any natural limit, constrained only by the design and operating limits of engine components, such as pressure, speed and load. This is unlike petrol engines, which inevitably suffer detonation at higher pressure if engine tuning and/or fuel octane adjustments are not made to compensate.


== Fuel injection ==
Diesel engines rely on the air/fuel mixing being done in the cylinder, which means they need a fuel injection system. The fuel is injected directly into the combustion chamber, which can be either a segmented combustion chamber, known as indirect injection (IDI), or an unsegmented combustion chamber, known as direct injection (DI). The definition of the diesel engine is specific in requiring that the fuel be introduced directly into the combustion, or pre-combustion chamber, rather than initially into an external manifold. For creating the fuel pressure, diesel engines usually have an injection pump. There are several different types of injection pumps and methods for creating a fine air-fuel mixture. Over the years many different injection methods have been used. These can be described as the following:

Air blast, where the fuel is blown into the cylinder by a blast of air.
Solid fuel / hydraulic injection, where the fuel is pushed through a spring loaded valve / injector to produce a combustible mist.
Mechanical unit injector, where the injector is directly operated by a cam and fuel quantity is controlled by a rack or lever.
Mechanical electronic unit injector, where the injector is operated by a cam and fuel quantity is controlled electronically.
Common rail mechanical injection, where fuel is at high pressure in a common rail and controlled by mechanical means.
Common rail electronic injection, where fuel is at high pressure in a common rail and controlled electronically.


=== Torque controlling ===
A necessary component of all diesel engines is a mechanical or electronic governor which regulates the torque of the engine and thus idling speed and maximum speed by controlling the rate of fuel delivery. This means a change of 
  
    
      
        
          λ
          
            v
          
        
      
    
    {\displaystyle \lambda _{v}}
  . Unlike Otto-cycle engines, incoming air is not throttled. Mechanically-governed fuel injection systems are driven by the engine's accessory gear train or serpentine belt. These systems use a combination of springs and weights to control fuel delivery relative to both load and speed. Modern electronically controlled diesel engines control fuel delivery by use of an electronic control module (ECM) or electronic control unit (ECU). The ECM/ECU receives an engine speed signal, as well as other operating parameters such as intake manifold pressure and fuel temperature, from a sensor and controls the amount of fuel and start of injection timing through actuators to maximise power and efficiency and minimise emissions. Controlling the timing of the start of injection of fuel into the cylinder is a key to minimizing emissions, and maximizing fuel economy (efficiency), of the engine. The timing is measured in degrees of crank angle of the piston before top dead centre. For example, if the ECM/ECU initiates fuel injection when the piston is 10° before TDC, the start of injection, or timing, is said to be 10° before TDC. Optimal timing will depend on the engine design as well as its speed and load.


=== Types of fuel injection ===


==== Air-blast injection ====

Diesel's original engine injected fuel with the assistance of compressed air, which atomised the fuel and forced it into the engine through a nozzle (a similar principle to an aerosol spray). The nozzle opening was closed by a pin valve lifted by the camshaft to initiate the fuel injection before top dead centre (TDC). This is called an air-blast injection. Driving the compressor used some power but the efficiency was better than the efficiency of any other combustion engine at that time. Also, air-blast injection made engines very heavy and did not allow for quick load changes making it unsuitable for road vehicles.


==== Indirect injection ====

An indirect diesel injection system (IDI) engine delivers fuel into a small chamber called a swirl chamber, precombustion chamber, pre chamber or ante-chamber, which is connected to the cylinder by a narrow air passage. Generally the goal of the pre chamber is to create increased turbulence for better air / fuel mixing. This system also allows for a smoother, quieter running engine, and because fuel mixing is assisted by turbulence, injector pressures can be lower. Most IDI systems use a single orifice injector. The pre-chamber has the disadvantage of lowering efficiency due to increased heat loss to the engine's cooling system, restricting the combustion burn, thus reducing the efficiency by 5–10%. IDI engines are also more difficult to start and usually require the use of glow plugs. IDI engines may be cheaper to build but generally require a higher compression ratio than the DI counterpart. IDI also makes it easier to produce smooth, quieter running engines with a simple mechanical injection system since exact injection timing is not as critical. Most modern automotive engines are DI which have the benefits of greater efficiency and easier starting; however, IDI engines can still be found in the many ATV and small diesel applications. Indirect injected diesel engines use pintle-type fuel injectiors.


==== Helix-controlled direct injection ====

Direct injection Diesel engines inject fuel directly into the cylinder. Usually there is a combustion cup in the top of the piston where the fuel is sprayed. Many different methods of injection can be used. Usually, an engine with helix-controlled mechanic direct injection has either an inline or a distributor injection pump. For each engine cylinder, the corresponding plunger in the fuel pump measures out the correct amount of fuel and determines the timing of each injection. These engines use injectors that are very precise spring-loaded valves that open and close at a specific fuel pressure. Separate high-pressure fuel lines connect the fuel pump with each cylinder. Fuel volume for each single combustion is controlled by a slanted groove in the plunger which rotates only a few degrees releasing the pressure and is controlled by a mechanical governor, consisting of weights rotating at engine speed constrained by springs and a lever. The injectors are held open by the fuel pressure. On high-speed engines the plunger pumps are together in one unit. The length of fuel lines from the pump to each injector is normally the same for each cylinder in order to obtain the same pressure delay. Direct injected diesel engines usually use orifice-type fuel injectors.Electronic control of the fuel injection transformed the direct injection engine by allowing much greater control over the combustion.


==== Unit direct injection ====

Unit direct injection, also known as Pumpe-Düse (pump-nozzle), is a high pressure fuel injection system that injects fuel directly into the cylinder of the engine. In this system the injector and the pump are combined into one unit positioned over each cylinder controlled by the camshaft. Each cylinder has its own unit eliminating the high-pressure fuel lines, achieving a more consistent injection. Under full load, the injection pressure can reach up to 220 MPa. Unit injection systems used to dominate the commercial diesel engine market, but due to higher requirements of the flexibility of the injection system, they have been rendered obsolete by the more advanced common-rail-system.


==== Common rail direct injection ====

Common rail (CR) direct injection systems do not have the fuel metering, pressure-raising and delivery functions in a single unit, as in the case of a Bosch distributor-type pump, for example. A high-pressure pump supplies the CR. The requirements of each cylinder injector are supplied from this common high pressure reservoir of fuel. An Electronic Diesel Control (EDC) controls both rail pressure and injections depending on engine operating conditions. The injectors of older CR systems have solenoid-driven plungers for lifting the injection needle, whilst newer CR injectors use plungers driven by piezoelectric actuators, that have fewer moving mass and therefore allow even more injections in a very short period of time. The injection pressure of modern CR systems ranges from 140 MPa to 270 MPa.


== Types ==
There are several different ways of categorising diesel engines, based on different design characteristics:


=== By power output ===
Small <188 kW (252 hp)
Medium 188–750 kW
Large >750 kWSource


=== By cylinder bore ===
Passenger car engines: 75...100 mm
Lorry and commercial vehicle engines: 90...170 mm
High-performance high-speed engines: 165...280 mm
Medium-speed engines: 240...620 mm
Low-speed two-stroke engines: 260...900 mmSource:


=== By number of strokes ===
Four-stroke cycle
Two-stroke cycleSource


=== By piston and connecting rod ===
Crosshead piston
Double-acting piston
Opposed piston
Trunk piston


=== By cylinder arrangement ===
Regular cylinder configurations such as straight (inline), V, and boxer (flat) configurations can be used for diesel engines. The inline-six-cylinder design is the most prolific in light- to medium-duty engines, though inline-four engines are also common. Small-capacity engines (generally considered to be those below five litres in capacity) are generally four- or six-cylinder types, with the four-cylinder being the most common type found in automotive uses. The V configuration used to be common for commercial vehicles, but it has been abandoned in favour of the inline configuration.


=== By engine speeds ===
Günter Mau categorises diesel engines by their rotational speeds into three groups:

High-speed engines (> 1,000 rpm),
Medium-speed engines (300–1,000 rpm), and
Slow-speed engines (< 300 rpm).Source


==== High-speed engines ====
High-speed engines are used to power trucks (lorries), buses, tractors, cars, yachts, compressors, pumps and small electrical generators. As of 2018, most high-speed engines have direct injection. Many modern engines, particularly in on-highway applications, have common rail direct injection. On bigger ships, high-speed diesel engines are often used for powering electric generators. The highest power output of high-speed diesel engines is approximately 5 MW.


==== Medium-speed engines ====

Medium-speed engines are used in large electrical generators, ship propulsion and mechanical drive applications such as large compressors or pumps. Medium speed diesel engines operate on either diesel fuel or heavy fuel oil by direct injection in the same manner as low-speed engines. Usually, they are four-stroke engines with trunk pistons.The power output of medium-speed diesel engines can be as high as 21,870 kW, with the effective efficiency being around 47...48% (1982). Most larger medium-speed engines are started with compressed air direct on pistons, using an air distributor, as opposed to a pneumatic starting motor acting on the flywheel, which tends to be used for smaller engines.Medium-speed engines intended for marine applications are usually used to power (ro-ro) ferries, passenger ships or small freight ships. Using medium-speed engines reduces the cost of smaller ships and increases their transport capacity. In addition to that, a single ship can use two smaller engines instead of one big engine, which increases the ship's safety.


==== Low-speed engines ====

Low-speed diesel engines are usually very large in size and mostly used to power ships. There are two different types of low-speed engines that are commonly used: Two-stroke engines with a crosshead, and four-stroke engines with a regular trunk-piston. Two-stroke engines have a limited rotational frequency and their charge exchange is more difficult, which means that they are usually bigger than four-stroke engines and used to directly power a ship's propeller. Four-stroke engines on ships are usually used to power an electric generator. An electric motor powers the propeller. Both types are usually very undersquare. Low-speed diesel engines (as used in ships and other applications where overall engine weight is relatively unimportant) often have an effective efficiency of up to 55%. Like medium-speed engines, low-speed engines are started with compressed air, and they use heavy oil as their primary fuel.


== Two-stroke engines ==

Two-stroke diesel engines use only two strokes instead of four strokes for a complete engine cycle. Filling the cylinder with air and compressing it takes place in one stroke, and the power and exhaust strokes are combined. The compression in a two-stroke diesel engine is similar to the compression that takes place in a four-stroke diesel engine: As the piston passes through bottom centre and starts upward, compression commences, culminating in fuel injection and ignition. Instead of a full set of valves, two-stroke diesel engines have simple intake ports, and exhaust ports (or exhaust valves). When the piston approaches bottom dead centre, both the intake and the exhaust ports are ""open"", which means that there is atmospheric pressure inside the cylinder. Therefore, some sort of pump is required to blow the air into the cylinder and the combustion gasses into the exhaust. This process is called scavenging. The pressure required is approximately 10 - 30 kPa.
ScavengingIn general, there are three types of scavenging possible:

Uniflow scavenging
Crossflow scavenging
Reverse flow scavengingCrossflow scavenging is incomplete and limits the stroke, yet some manufacturers used it. Reverse flow scavenging is a very simple way of scavenging, and it was popular amongst manufacturers until the early 1980s. Uniflow scavenging is more complicated to make but allows the highest fuel efficiency; since the early 1980s, manufacturers such as MAN and Sulzer have switched to this system. It is standard for modern marine two-stroke diesel engines.


== Dual-fuel diesel engines ==
So-called dual-fuel diesel engines or gas diesel engines burn two different types of fuel simultaneously, for instance, a gaseous fuel and diesel engine fuel. The diesel engine fuel auto-ignites due to compression ignition, and then ignites the gaseous fuel. Such engines do not require any type of spark ignition and operate similar to regular diesel engines.


== Diesel engine particularities ==


=== Torque and power ===
Torque is a force applied to a lever at a right angle multiplied by the lever length. This means that the torque an engine produces depends on the displacement of the engine and the force that the gas pressure inside the cylinder applies to the piston, commonly referred to as effective piston pressure:

  
    
      
        M
        =
        
          p
          
            e
          
        
        ⋅
        
          V
          
            h
          
        
        ⋅
        
          π
          
            −
            1
          
        
        ⋅
        
          i
          
            −
            1
          
        
      
    
    {\displaystyle M=p_{e}\cdot V_{h}\cdot \pi ^{-1}\cdot i^{-1}}
  

  
    
      
        M
      
    
    {\displaystyle M}
   .. Torque [N·m]; 
  
    
      
        
          p
          
            e
          
        
      
    
    {\displaystyle p_{e}}
   .. Effective piston pressure [kN·m−2]; 
  
    
      
        
          V
          
            h
          
        
      
    
    {\displaystyle V_{h}}
   .. Displacement [dm3]; 
  
    
      
        i
      
    
    {\displaystyle i}
   .. Strokes [either 2 or 4]ExampleEngine A: effective piston pressure=570 kN·m−2, displacement= 2.2 dm3, strokes= 4, torque= 100 N·m
  
    
      
        570
        ⋅
        2.2
        ⋅
        
          π
          
            −
            1
          
        
        ⋅
        
          4
          
            −
            1
          
        
        ≈
        100
      
    
    {\displaystyle 570\cdot 2.2\cdot \pi ^{-1}\cdot 4^{-1}\approx 100}
  Power is the quotient of work and time:

  
    
      
        P
        =
        2
        π
        n
        M
      
    
    {\displaystyle P=2\pi nM}
  

  
    
      
        P
      
    
    {\displaystyle P}
   .. Power [W]; 
  
    
      
        M
      
    
    {\displaystyle M}
   .. Torque [N·m]; 
  
    
      
        n
      
    
    {\displaystyle n}
   .. Time (crankshaft speed) [s−1]which means:
  
    
      
        P
        =
        2
        π
        ⋅
        
          n
          
            1
          
        
        ⋅
        M
        ⋅
        
          60
          
            −
            1
          
        
      
    
    {\displaystyle P=2\pi \cdot n_{1}\cdot M\cdot 60^{-1}}
  

  
    
      
        P
      
    
    {\displaystyle P}
   .. Power [W]; 
  
    
      
        M
      
    
    {\displaystyle M}
   .. Torque [N·m]; 
  
    
      
        
          n
          
            1
          
        
      
    
    {\displaystyle n_{1}}
   .. Time (crankshaft speed) [min−1]ExampleEngine A: Power≈ 44,000 W, torque= 100 N·m, time= 4200 min−1
  
    
      
        44
        ,
        000
        ≈
        2
        ⋅
        π
        ⋅
        4200
        ⋅
        100
        ⋅
        
          60
          
            −
            1
          
        
      
    
    {\displaystyle 44,000\approx 2\cdot \pi \cdot 4200\cdot 100\cdot 60^{-1}}
  Engine B: Power≈ 44,000 W, torque= 260 N·m, time= 1600 min−1
  
    
      
        44
        ,
        000
        ≈
        2
        ⋅
        π
        ⋅
        1600
        ⋅
        260
        ⋅
        
          60
          
            −
            1
          
        
      
    
    {\displaystyle 44,000\approx 2\cdot \pi \cdot 1600\cdot 260\cdot 60^{-1}}
  This means, that increasing either torque or time will result in an increase in power. As the maximum rotational frequency of the diesel engine's crankshaft is usually in between 3500...5000 min−1 due to diesel principle limitations, the torque of the diesel engine must be great to achieve a high power, or, in other words, as the diesel engine cannot use a lot of time for achieving a certain amount of power, it has to perform more work (=produce more torque).


=== Mass ===
The average diesel engine has a poorer power-to-mass ratio than the Otto engine. This is because the diesel must operate at lower engine speeds. Due to the higher operating pressure inside the combustion chamber, which increases the forces on the parts due to inertial forces, the diesel engine needs heavier, stronger parts capable of resisting these forces, which results in an overall greater engine mass.


=== Emissions ===

As diesel engines burn a mixture of fuel and air, the exhaust therefore contains substances that consist of the same chemical elements, as fuel and air. The main elements of air are nitrogen (N2) and oxygen (O2), fuel consists of hydrogen (H2) and carbon (C). Burning the fuel will result in the final stage of oxidation. An ideal diesel engine, (a hypothetical model that we use as an example), running on an ideal air-fuel mixture, produces an exhaust that consists of carbon dioxide (CO2), water (H2O), nitrogen (N2), and the remaining oxygen (O2). The combustion process in a real engine differs from an ideal engine's combustion process, and due to incomplete combustion, the exhaust contains additional substances, most notably, carbon monoxide (CO), diesel particulate matter (PM), and due to dissociation, nitrogen oxide (NO x ).When diesel engines burn their fuel with high oxygen levels, this results in high combustion temperatures and higher efficiency, and particulate matter tends to burn, but the amount of NO x  pollution tends to increase. NO x  pollution can be reduced by recirculating a portion of an engine's exhaust gas back to the engine cylinders, which reduces the oxygen quantity, causing a reduction of combustion temperature, and resulting in fewer NO x . To further reduce NO x  emissions, lean NO x  traps (LNTs) and SCR-catalysts can be used. Lean NO x  traps adsorb the nitrogen oxide and ""trap"" it. Once the LNT is full, it has to be ""regenerated"" using hydrocarbons. This is achieved by using a very rich air-fuel mixture, resulting in incomplete combustion. An SCR-catalyst converts nitrogen oxide using urea, which is injected into the exhaust stream, and catalytically converts the NO x  into nitrogen (N2) and water (H2O). Compared with an Otto engine, the diesel engine produces approximately the same amount of NO x , but some older diesel engines may have an exhaust that contains up to 50% less NO x . However, Otto engines, unlike diesel engines, can use a three-way-catalyst, that converts most of the NO x .


=== Noise ===

The distinctive noise of a diesel engine is variably called diesel clatter, diesel nailing, or diesel knock. Diesel clatter is caused largely by the way the fuel ignites; the sudden ignition of the diesel fuel when injected into the combustion chamber causes a pressure wave, resulting in an audible ″knock″. Engine designers can reduce diesel clatter through: indirect injection; pilot or pre-injection; injection timing; injection rate; compression ratio; turbo boost; and exhaust gas recirculation (EGR). Common rail diesel injection systems permit multiple injection events as an aid to noise reduction. Therefore, newer diesel engines do not knock anymore. Diesel fuels with a higher cetane rating are more likely to ignite and hence reduce diesel clatter.


=== Cold weather starting ===
In general, diesel engines do not require any starting aid. In cold weather however, some diesel engines can be difficult to start and may need preheating depending on the combustion chamber design. The minimum starting temperature that allows starting without pre-heating is 40 °C for precombustion chamber engines, 20 °C for swirl chamber engines, and 0 °C for direct injected engines. Smaller engines with a displacement of less than 1 litre per cylinder usually have glowplugs, whilst larger heavy-duty engines have flame-start systems.In the past, a wider variety of cold-start methods were used. Some engines, such as Detroit Diesel engines used a system to introduce small amounts of ether into the inlet manifold to start combustion. Instead of glowplugs, some diesel engines are equipped with starting aid systems that change valve timing. The simplest way this can be done is with a decompression lever. Activating the decompression lever locks the outlet valves in a slight down position, resulting in the engine not having any compression and thus allowing for turning the crankshaft over without resistance. When the crankshaft reaches a higher speed, flipping the decompression lever back into its normal position will abruptly re-activate the outlet valves, resulting in compression − the flywheel's mass moment of inertia then starts the engine. Other diesel engines, such as the precombustion chamber engine XII Jv 170/240 made by Ganz & Co., have a valve timing changing system that is operated by adjusting the inlet valve camshaft, moving it into a slight ""late"" position. This will make the inlet valves open with a delay, forcing the inlet air to heat up when entering the combustion chamber.


=== Supercharging and turbocharging ===

As the diesel engine relies on manipulation of 
  
    
      
        
          λ
          
            v
          
        
      
    
    {\displaystyle \lambda _{v}}
   for torque controlling and speed regulation, the intake air mass does not have to precisely match the injected fuel mass (which would be 
  
    
      
        λ
        =
        1
      
    
    {\displaystyle \lambda =1}
  ). diesel engines are thus ideally suited for supercharging and turbocharging. An additional advantage of the diesel engine is the lack of fuel during the compression stroke. In diesel engines, the fuel is injected near top dead centre (TDC), when the piston is near its highest position. The fuel then ignites due to compression heat. Preignition, caused by the artificial turbocharger compression increase during the compression stroke, cannot occur.Many diesels are therefore turbocharged and some are both turbocharged and supercharged. A turbocharged engine can produce more power than a naturally aspirated engine of the same configuration. A supercharger is powered mechanically by the engine's crankshaft, while a turbocharger is powered by the engine exhaust. Turbocharging can improve the fuel economy of diesel engines by recovering waste heat from the exhaust, increasing the excess air factor, and increasing the ratio of engine output to friction losses. Adding an intercooler to a turbocharged engine further increases engine performance by cooling down the air-mass and thus allowing more air-mass per volume.A two-stroke engine does not have a discrete exhaust and intake stroke and thus is incapable of self-aspiration. Therefore, all two-stroke diesel engines must be fitted with a blower or some form of compressor to charge the cylinders with air and assist in dispersing exhaust gases, a process referred to as scavenging. Roots-type superchargers were used for ship engines until the mid-1950s, since 1955 they have been widely replaced by turbochargers. Usually, a two-stroke ship diesel engine has a single-stage turbocharger with a turbine that has an axial inflow and a radial outflow.


== Fuel and fluid characteristics ==

In diesel engines, a mechanical injector system atomizes the fuel directly into the combustion chamber (as opposed to a Venturi jet in a carburetor, or a fuel injector in a manifold injection system atomizing fuel into the intake manifold or intake runners as in a petrol engine). Because only air is inducted into the cylinder in a diesel engine, the compression ratio can be much higher as there is no risk of pre-ignition provided the injection process is accurately timed. This means that cylinder temperatures are much higher in a diesel engine than a petrol engine, allowing less volatile fuels to be used.

Therefore, diesel engines can operate on a huge variety of different fuels. In general, fuel for diesel engines should have a proper viscosity, so that the injection pump can pump the fuel to the injection nozzles without causing damage to itself or corrosion of the fuel line. At injection, the fuel should form a good fuel spray, and it should not have a coking effect upon the injection nozzles. To ensure proper engine starting and smooth operation, the fuel should be willing to ignite and hence not cause a high ignition delay, (this means that the fuel should have a high cetane number). Diesel fuel should also have a high lower heating value.Inline mechanical injector pumps generally tolerate poor-quality or bio-fuels better than distributor-type pumps. Also, indirect injection engines generally run more satisfactorily on fuels with a high ignition delay (for instance, petrol) than direct injection engines. This is partly because an indirect injection engine has a much greater 'swirl' effect, improving vaporisation and combustion of fuel, and because (in the case of vegetable oil-type fuels) lipid depositions can condense on the cylinder walls of a direct-injection engine if combustion temperatures are too low (such as starting the engine from cold). Direct-injected engines with an MAN centre sphere combustion chamber rely on fuel condensing on the combustion chamber walls. The fuel starts vaporising only after ignition sets in, and it burns relatively smoothly. Therefore, such engines also tolerate fuels with poor ignition delay characteristics, and, in general, they can operate on petrol rated 86 RON.


=== Fuel types ===
In his 1893 work Theory and Construction of a Rational Heat Motor, Rudolf Diesel considers using coal dust as fuel for the diesel engine. However, Diesel just considered using coal dust (as well as liquid fuels and gas); his actual engine was designed to operate on petroleum, which was soon replaced with regular petrol and kerosene for further testing purposes, as petroleum proved to be too viscous. In addition to kerosene and petrol, Diesel's engine could also operate on ligroin.Before diesel engine fuel was standardised, fuels such as petrol, kerosene, gas oil, vegetable oil and mineral oil, as well as mixtures of these fuels, were used. Typical fuels specifically intended to be used for diesel engines were petroleum distillates and coal-tar distillates such as the following; these fuels have specific lower heating values of:

Diesel oil: 10,200 kcal·kg−1 (42.7 MJ·kg−1) up to 10,250 kcal·kg−1 (42.9 MJ·kg−1)
Heating oil: 10,000 kcal·kg−1 (41.8 MJ·kg−1) up to 10,200 kcal·kg−1 (42.7 MJ·kg−1)
Coal-tar creosote: 9,150 kcal·kg−1 (38.3 MJ·kg−1) up to 9,250 kcal·kg−1 (38.7 MJ·kg−1)
Kerosene: up to 10,400 kcal·kg−1 (43.5 MJ·kg−1)Source:The first diesel fuel standards were the DIN 51601, VTL 9140-001, and NATO F 54, which appeared after World War II. The modern European EN 590 diesel fuel standard was established in May 1993; the modern version of the NATO F 54 standard is mostly identical with it. The DIN 51628 biodiesel standard was rendered obsolete by the 2009 version of the EN 590; FAME biodiesel conforms to the EN 14214 standard. Watercraft diesel engines usually operate on diesel engine fuel that conforms to the ISO 8217 standard (Bunker C). Also, some diesel engines can operate on gasses (such as LNG).


=== Modern diesel fuel properties ===


=== Gelling ===
DIN 51601 diesel fuel was prone to waxing or gelling in cold weather; both are terms for the solidification of diesel oil into a partially crystalline state. The crystals build up in the fuel system (especially in fuel filters), eventually starving the engine of fuel and causing it to stop running. Low-output electric heaters in fuel tanks and around fuel lines were used to solve this problem. Also, most engines have a spill return system, by which any excess fuel from the injector pump and injectors is returned to the fuel tank. Once the engine has warmed, returning warm fuel prevents waxing in the tank. Before direct injection diesel engines, some manufacturers, such as BMW, recommended mixing up to 30% petrol in with the diesel by fuelling diesel cars with petrol to prevent the fuel from gelling when the temperatures dropped below −15 °C.


== Safety ==


=== Fuel flammability ===
Diesel fuel is less flammable than petrol, because its flash point is 55 °C, leading to a lower risk of fire caused by fuel in a vehicle equipped with a diesel engine.
Diesel fuel can create an explosive air/vapour mix under the right conditions. However, compared with petrol, it is less prone due to its lower vapour pressure, which is an indication of evaporation rate. The Material Safety Data Sheet for ultra-low sulfur diesel fuel indicates a vapour explosion hazard for diesel fuel indoors, outdoors, or in sewers.


=== Cancer ===
Diesel exhaust has been classified as an IARC Group 1 carcinogen. It causes lung cancer and is associated with an increased risk for bladder cancer.


=== Engine runaway (uncontrollable overspeeding) ===
See diesel engine runaway.


== Applications ==
The characteristics of diesel have different advantages for different applications.


=== Passenger cars ===
Diesel engines have long been popular in bigger cars and have been used in smaller cars such as superminis in Europe since the 1980s. They were popular in larger cars earlier, as the weight and cost penalties were less noticeable. Smooth operation as well as high low end torque are deemed important for passenger cars and small commercial vehicles. The introduction of electronically controlled fuel injection significantly improved the smooth torque generation, and starting in the early 1990s, car manufacturers began offering their high-end luxury vehicles with diesel engines. Passenger car diesel engines usually have between three and ten cylinders, and a displacement ranging from 0.8 to 5.0 litres. Modern powerplants are usually turbocharged and have direct injection.Diesel engines do not suffer from intake-air throttling, resulting in very low fuel consumption especially at low partial load (for instance: driving at city speeds). One fifth of all passenger cars worldwide have diesel engines, with many of them being in Europe, where approximately 47% of all passenger cars are diesel-powered. Daimler-Benz in conjunction with Robert Bosch GmbH produced diesel-powered passenger cars starting in 1936. The popularity of diesel-powered passenger cars in markets such as India, South Korea and Japan is increasing (as of 2018).


=== Commercial vehicles and lorries ===

In 1893, Rudolf Diesel suggested that the diesel engine could possibly power ‘wagons’ (lorries). The first lorries with diesel engines were brought to market in 1924.Modern diesel engines for lorries have to be both extremely reliable and very fuel efficient. Common-rail direct injection, turbocharging and four valves per cylinder are standard. Displacements range from 4.5 to 15.5 litres, with power-to-mass ratios of 2.5–3.5 kg·kW−1 for heavy duty and 2.0–3.0 kg·kW−1 for medium duty engines. V6 and V8 engines used to be common, due to the relatively low engine mass the V configuration provides. Recently, the V configuration has been abandoned in favour of straight engines. These engines are usually straight-6 for heavy and medium duties and straight-4 for medium duty. Their undersquare design causes lower overall piston speeds which results in increased lifespan of up to 1,200,000 kilometres (750,000 mi). Compared with 1970s diesel engines, the expected lifespan of modern lorry diesel engines has more than doubled.


=== Railroad rolling stock ===
Diesel engines for locomotives are built for continuous operation between refuellings and may need to be designed to use poor quality fuel in some circumstances. Some locomotives use two-stroke diesel engines. Diesel engines have replaced steam engines on all non-electrified railroads in the world. The first diesel locomotives appeared in 1913, and diesel multiple units soon after. Most modern diesel locomotives are more correctly known as diesel-electric locomotives because they use an electric transmission: the diesel engine drives an electric generator which powers electric traction motors. While electric locomotives have replaced the diesel locomotive for passenger services in many areas diesel traction is widely used for cargo-hauling freight trains and on tracks where electrification is not economically viable.
In the 1940s, road vehicle diesel engines with power outputs of 150...200 PS (110...147 kW) were considered reasonable for DMUs. Commonly, regular truck powerplants were used. The height of these engines had to be less than 1,000 mm to allow underfloor installation. Usually, the engine was mated with a pneumatically operated mechanical gearbox, due to the low size, mass, and production costs of this design. Some DMUs used hydraulic torque converters instead. Diesel-electric transmission was not suitable for such small engines. In the 1930s, the Deutsche Reichsbahn standardised its first DMU engine. It was a 30.3 litre, 12-cylinder boxer unit, producing 275 PS (202 kW). Several German manufacturers produced engines according to this standard.


=== Watercraft ===

The requirements for marine diesel engines vary, depending on the application. For military use and medium-size boats, medium-speed four-stroke diesel engines are most suitable. These engines usually have up to 24 cylinders and come with power outputs in the one-digit Megawatt region. Small boats may use lorry diesel engines. Large ships use extremely efficient, low-speed two-stroke diesel engines. They can reach efficiencies of up to 55%. Unlike most regular diesel engines, two-stroke watercraft engines use highly viscous fuel oil. Submarines are usually diesel-electric.The first diesel engines for ships were made by A. B. Diesels Motorer Stockholm in 1903. These engines were three-cylinder units of 120 PS (88 kW) and four-cylinder units of 180 PS (132 kW) and used for Russian ships. In World War I, especially submarine diesel engine development advanced quickly. By the end of the War, double acting piston two-stroke engines with up to 12,200 PS (9 MW) had been made for marine use.


=== Aviation ===

Diesel engines had been used in aircraft before World War II, for instance, in the rigid airship LZ 129 Hindenburg, which was powered by four Daimler-Benz DB 602 diesel engines, or in several Junkers aircraft, which had Jumo 205 engines installed. Until the late 1970s, there has not been any applications of the diesel engine in aircraft. In 1978, Karl H. Bergey argued that “the likelihood of a general aviation diesel in the near future is remote.” In recent years (2016), diesel engines have found use in unmanned aircraft (UAV), due to their reliability, durability, and low fuel consumption. In early 2019, AOPA reported, that a diesel engine model for general aviation aircraft is “approaching the finish line.”


=== Non-road diesel engines ===

Non-road diesel engines are commonly used for construction equipment. Fuel efficiency, reliability and ease of maintenance are very important for such engines, whilst high power output and quiet operation are negligible. Therefore, mechanically controlled fuel injection and air-cooling are still very common. The common power outputs of non-road diesel engines vary a lot, with the smallest units starting at 3 kW, and the most powerful engines being heavy duty lorry engines.


=== Stationary diesel engines ===

Stationary diesel engines are commonly used for electricity generation, but also for powering refrigerator compressors, or other types of compressors or pumps. Usually, these engines run permanently, either with mostly partial load, or intermittently, with full load. Stationary diesel engines powering electric generators that put out an alternating current, usually operate with alternating load, but fixed rotational frequency. This is due to the mains' fixed frequency of either 50 Hz (Europe), or 60 Hz (United States). The engine's crankshaft rotational frequency is chosen so that the mains' frequency is a multiple of it. For practical reasons, this results in crankshaft rotational frequencies of either 25 Hz (1500 per minute) or 30 Hz (1800 per minute).


== Low heat rejection engines ==
A special class of prototype internal combustion piston engines has been developed over several decades with the goal of improving efficiency by reducing heat loss. These engines are variously called adiabatic engines; due to better approximation of adiabatic expansion; low heat rejection engines, or high temperature engines. They are generally piston engines with combustion chamber parts lined with ceramic thermal barrier coatings. Some make use of pistons and other parts made of titanium which has a low thermal conductivity and density. Some designs are able to eliminate the use of a cooling system and associated parasitic losses altogether. Developing lubricants able to withstand the higher temperatures involved has been a major barrier to commercialization.


== Future developments ==
In mid-2010s literature, main development goals for future diesel engines are described as improvements of exhaust emissions, reduction of fuel consumption, and increase of lifespan (2014). It is said that the diesel engine, especially the diesel engine for commercial vehicles, will remain the most important vehicle powerplant until the mid-2030s. Editors assume that the complexity of the diesel engine will increase further (2014). Some editors expect a future convergency of diesel and Otto engines' operating principles due to Otto engine development steps made towards homogeneous charge compression ignition (2017).


== See also ==


== References ==


== External links ==
""Diesel Information Hub"". Association for Emissions Control by Catalyst.
The short film The Diesel Story (1952) is available for free download at the Internet Archive
 ""Introduction to Two Stroke Marine Diesel Engine"" on YouTube
 ""The Engine That Powers the World"" BBC Documentary on YouTube


=== Patents ===
Method of and Apparatus for Converting Heat into Work. # 542846 filed 1892
Internal Combustion Engine #608845 filed 1895"
"An internal combustion engine (ICE) is a heat engine in which the combustion of a fuel occurs with an oxidizer (usually air) in a combustion chamber that is an integral part of the working fluid flow circuit. In an internal combustion engine, the expansion of the high-temperature and high-pressure gases produced by combustion applies direct force to some component of the engine. The force is applied typically to pistons, turbine blades, rotor or a nozzle. This force moves the component over a distance, transforming chemical energy into useful work.
The first commercially successful internal combustion engine was created by Étienne Lenoir around 1860 and the first modern internal combustion engine was created in 1876 by Nicolaus Otto (see Otto engine).
The term internal combustion engine usually refers to an engine in which combustion is intermittent, such as the more familiar four-stroke and two-stroke piston engines, along with variants, such as the six-stroke piston engine and the Wankel rotary engine. A second class of internal combustion engines use continuous combustion: gas turbines, jet engines and most rocket engines, each of which are internal combustion engines on the same principle as previously described. Firearms are also a form of internal combustion engine.In contrast, in external combustion engines, such as steam or Stirling engines, energy is delivered to a working fluid not consisting of, mixed with, or contaminated by combustion products. Working fluids can be air, hot water, pressurized water or even liquid sodium, heated in a boiler. ICEs are usually powered by energy-dense fuels such as gasoline or diesel fuel, liquids derived from fossil fuels. While there are many stationary applications, most ICEs are used in mobile applications and are the dominant power supply for vehicles such as cars, aircraft, and boats, known as internal-combustion-engine vehicles (ICEV).
Typically an ICE is fed with fossil fuels like natural gas or petroleum products such as gasoline, diesel fuel or fuel oil. There is a growing usage of renewable fuels like biodiesel for CI (compression ignition) engines and bioethanol or methanol for SI (spark ignition) engines. Hydrogen is sometimes used, and can be obtained from either fossil fuels or renewable energy.


== History ==

Various scientists and engineers contributed to the development of internal combustion engines. In 1791, John Barber developed the gas turbine. In 1794 Thomas Mead patented a gas engine. Also in 1794, Robert Street patented an internal combustion engine, which was also the first to use liquid fuel, and built an engine around that time. In 1798, John Stevens built the first American internal combustion engine. In 1807, French engineers Nicéphore Niépce (who went on to invent photography) and Claude Niépce ran  a prototype internal combustion engine, using controlled dust explosions, the Pyréolophore. This engine powered a boat on the Saône river, France.  The same year,  the Swiss engineer François Isaac de Rivaz built an internal combustion engine ignited by an electric spark. In 1823, Samuel Brown patented the first internal combustion engine to be applied industrially.
In 1854 in the UK, the Italian inventors Eugenio Barsanti and Felice Matteucci obtained the certification: ""Obtaining Motive Power by the Explosion of Gases"". In 1857 the Great Seal Patent Office conceded them patent No.1655 for the invention of an ""Improved Apparatus for Obtaining Motive Power from Gases"". Barsanti and Matteucci obtained other patents for the same invention in France, Belgium and Piedmont between 1857 and 1859. In 1860, Belgian Jean Joseph Etienne Lenoir produced a gas-fired internal combustion engine. In 1864, Nicolaus Otto patented the first atmospheric gas engine. In 1872, American George Brayton invented the first commercial liquid-fuelled internal combustion engine. In 1876, Nicolaus Otto, working with Gottlieb Daimler and Wilhelm Maybach, patented the compressed charge, four-cycle engine. In 1879, Karl Benz patented a reliable two-stroke gasoline engine. Later, in 1886, Benz began the first commercial production of motor vehicles with the internal combustion engine. In 1892, Rudolf Diesel developed the first compressed charge, compression ignition engine. In 1926, Robert Goddard launched the first liquid-fueled rocket. In 1939, the Heinkel He 178 became the world's first jet aircraft.


== Etymology ==
At one time, the word engine (via Old French, from Latin ingenium, ""ability"") meant any piece of machinery—a sense that persists in expressions such as siege engine. A ""motor"" (from Latin motor, ""mover"") is any machine that produces mechanical power. Traditionally, electric motors are not referred to as ""engines""; however, combustion engines are often referred to as ""motors"". (An electric engine refers to a locomotive operated by electricity.)
In boating, an internal combustion engine that is installed in the hull is referred to as an engine, but the engines that sit on the transom are referred to as motors.


== Applications ==

Reciprocating piston engines are by far the most common power source for land and water vehicles, including automobiles, motorcycles, ships and to a lesser extent, locomotives (some are electrical but most use Diesel engines). Rotary engines of the Wankel design are used in some automobiles, aircraft and motorcycles.  These are collectively known as internal-combustion-engine vehicles (ICEV).Where  high power-to-weight ratios are required, internal combustion engines appear in the form of combustion turbines or Wankel engines. Powered aircraft typically uses an ICE which may be a reciprocating engine. Airplanes can instead use jet engines and helicopters can instead employ turboshafts; both of which are types of turbines. In addition to providing propulsion, airliners may employ a separate ICE as an auxiliary power unit. Wankel engines are fitted to many unmanned aerial vehicles.
ICEs drive large electric generators that power electrical grids. They are found in the form of combustion turbines with a typical electrical output in the range of some 100 MW. Combined cycle power plants use the high temperature exhaust to boil and superheat water steam to run a steam turbine. Thus, the efficiency is higher because more energy is extracted from the fuel than what could be extracted by the combustion engine alone. 
Combined cycle power plants achieve efficiencies in the range of 50% to 60%. In a smaller scale, stationary engines like Gas engine or Diesel generators are used for backup or for providing electrical power to areas not connected to an electric grid.
Small engines (usually 2‐stroke gasoline engines) are a common power source for lawnmowers, string trimmers, chain saws, leafblowers, pressure washers, snowmobiles, jet skis, outboard motors, mopeds, and motorcycles.


== Classification ==
There are several possible ways to classify internal combustion engines.


=== Reciprocating ===
By number of strokes:

Two-stroke engine
Clerk cycle
Day cycle
Four-stroke engine (Otto cycle)
Six-stroke engineBy type of ignition:

Compression-ignition engine
Spark-ignition engine (commonly found as gasoline engines)By mechanical/thermodynamic cycle (these 2 cycles do not encompass all reciprocating engines, and are infrequently used):

Atkinson cycle
Miller cycle


=== Rotary ===

Wankel engine


=== Continuous combustion ===
Gas turbine engine
Turbojet, through a propelling nozzle
Turbofan, through a duct-fan
Turboprop, through an unducted propeller, usually with variable pitch
Turboshaft, a gas turbine optimized for producing mechanical torque instead of thrust
Ramjet , similar to a turbojet but uses vehicle speed to compress (ram) the air instead of a compressor.
Scramjet, a variant of the ramjet that uses supersonic combustion.
Rocket engine


== Reciprocating engines ==


=== Structure ===

The base of a reciprocating internal combustion engine is the engine block, which is typically made of cast iron or aluminium. The engine block contains the cylinders. In engines with more than one cylinder they are usually arranged either in 1 row (straight engine) or 2 rows (boxer engine or V engine); 3 rows are occasionally used (W engine) in contemporary engines, and other engine configurations are possible and have been used. Single cylinder engines are common for motorcycles and in small engines of machinery. Water-cooled engines contain passages in the engine block where cooling fluid circulates (the water jacket). Some small engines are air-cooled, and instead of having a water jacket the cylinder block has fins protruding away from it to cool by directly transferring heat to the air. The cylinder walls are usually finished by honing to obtain a cross hatch, which is better able to retain the oil. A too rough surface would quickly harm the engine by excessive wear on the piston.
The pistons are short cylindrical parts which seal one end of the cylinder from the high pressure of the compressed air and combustion products and slide continuously within it while the engine is in operation. The top wall of the piston is termed its crown and is typically flat or concave. Some two-stroke engines use pistons with a deflector head. Pistons are open at the bottom and hollow except for an integral reinforcement structure (the piston web). When an engine is working, the gas pressure in the combustion chamber exerts a force on the piston crown which is transferred through its web to a gudgeon pin. Each piston has rings fitted around its circumference that mostly prevent the gases from leaking into the crankcase or the oil into the combustion chamber. A ventilation system drives the small amount of gas that escapes past the pistons during normal operation (the blow-by gases) out of the crankcase so that it does not accumulate contaminating the oil and creating corrosion. In two-stroke gasoline engines the crankcase is part of the air–fuel path and due to the continuous flow of it they do not need a separate crankcase ventilation system.

The cylinder head is attached to the engine block by numerous bolts or studs. It has several functions. The cylinder head seals the cylinders on the side opposite to the pistons; it contains short ducts (the ports) for intake and exhaust and the associated intake valves that open to let the cylinder be filled with fresh air and exhaust valves that open to allow the combustion gases to escape. However, 2-stroke crankcase scavenged engines connect the gas ports directly to the cylinder wall without poppet valves; the piston controls their opening and occlusion instead. The cylinder head also holds the spark plug in the case of spark ignition engines and the injector for engines that use direct injection. All CI engines use fuel injection, usually direct injection but some engines instead use indirect injection. SI engines can use a carburetor or fuel injection as port injection or direct injection. Most SI engines have a single spark plug per cylinder but some have 2. A head gasket prevents the gas from leaking between the cylinder head and the engine block. The opening and closing of the valves is controlled by one or several camshafts and springs—or in some engines—a desmodromic mechanism that uses no springs. The camshaft may press directly the stem of the valve or may act upon a rocker arm, again, either directly or through a pushrod.

The crankcase is sealed at the bottom with a sump that collects the falling oil during normal operation to be cycled again. The cavity created between the cylinder block and the sump houses a crankshaft that converts the reciprocating motion of the pistons to rotational motion. The crankshaft is held in place relative to the engine block by main bearings, which allow it to rotate. Bulkheads in the crankcase form a half of every main bearing; the other half is a detachable cap. In some cases a single main bearing deck is used rather than several smaller caps. A connecting rod is connected to offset sections of the crankshaft (the crankpins) in one end and to the piston in the other end through the gudgeon pin and thus transfers the force and translates the reciprocating motion of the pistons to the circular motion of the crankshaft. The end of the connecting rod attached to the gudgeon pin is called its small end, and the other end, where it is connected to the crankshaft, the big end. The big end has a detachable half to allow assembly around the crankshaft. It is kept together to the connecting rod by removable bolts.
The cylinder head has an intake manifold and an exhaust manifold attached to the corresponding ports. The intake manifold connects to the air filter directly, or to a carburetor when one is present, which is then connected to the air filter. It distributes the air incoming from these devices to the individual cylinders. The exhaust manifold is the first component in the exhaust system. It collects the exhaust gases from the cylinders and drives it to the following component in the path. The exhaust system of an ICE may also include a catalytic converter and muffler. The final section in the path of the exhaust gases is the tailpipe.


=== 4-stroke engines ===

The top dead center (TDC) of a piston is the position where it is nearest to the valves; bottom dead center (BDC) is the opposite position where it is furthest from them. A stroke is the movement of a piston from TDC to BDC or vice versa, together with the associated process. While an engine is in operation, the crankshaft rotates continuously at a nearly constant speed. In a 4-stroke ICE, each piston experiences 2 strokes per crankshaft revolution in the following order. Starting the description at TDC, these are:
Intake, induction or suction: The intake valves are open as a result of the cam lobe pressing down on the valve stem. The piston moves downward increasing the volume of the combustion chamber and allowing air to enter in the case of a CI engine or an air fuel mix in the case of SI engines that do not use direct injection. The air or air-fuel mixture is called the charge in any case.
Compression: In this stroke, both valves are closed and the piston moves upward reducing the combustion chamber volume which reaches its minimum when the piston is at TDC. The piston performs work on the charge as it is being compressed; as a result its pressure, temperature and density increase; an approximation to this behavior is provided by the ideal gas law. Just before the piston reaches TDC, ignition begins. In the case of a SI engine, the spark plug receives a high voltage pulse that generates the spark which gives it its name and ignites the charge. In the case of a CI engine the fuel injector quickly injects fuel into the combustion chamber as a spray; the fuel ignites due to the high temperature.
Power or working stroke: The pressure of the combustion gases pushes the piston downward, generating more work than it required to compress the charge. Complementary to the compression stroke, the combustion gases expand and as a result their temperature, pressure and density decreases. When the piston is near to BDC the exhaust valve opens. The combustion gases expand irreversibly due to the leftover pressure—in excess of back pressure, the gauge pressure on the exhaust port—; this is called the blowdown.
Exhaust: The exhaust valve remains open while the piston moves upward expelling the combustion gases. For naturally aspirated engines a small part of the combustion gases may remain in the cylinder during normal operation because the piston does not close the combustion chamber completely; these gases dissolve in the next charge. At the end of this stroke, the exhaust valve closes, the intake valve opens, and the sequence repeats in the next cycle. The intake valve may open before the exhaust valve closes to allow better scavenging.


=== 2-stroke engines ===

The defining characteristic of this kind of engine is that each piston completes a cycle every crankshaft revolution. The 4 processes of intake, compression, power and exhaust take place in only 2 strokes so that it is not possible to dedicate a stroke exclusively for each of them. Starting at TDC the cycle consist of:

Power: While the piston is descending the combustion gases perform work on it, as in a 4-stroke engine. The same thermodynamic considerations about the expansion apply.
Scavenging: Around 75° of crankshaft rotation before BDC the exhaust valve or port opens, and blowdown occurs. Shortly thereafter the intake valve or transfer port opens.  The incoming charge displaces the remaining combustion gases to the exhaust system and a part of the charge may enter the exhaust system as well. The piston reaches BDC and reverses direction. After the piston has traveled a short distance upwards into the cylinder the exhaust valve or port closes; shortly the intake valve or transfer port closes as well.
Compression: With both intake and exhaust closed the piston continues moving upwards compressing the charge and performing a work on it. As in the case of a 4-stroke engine, ignition starts just before the piston reaches TDC and the same consideration on the thermodynamics of the compression on the charge.While a 4-stroke engine uses the piston as a positive displacement pump to accomplish scavenging taking 2 of the 4 strokes, a 2-stroke engine uses the last part of the power stroke and the first part of the compression stroke for combined intake and exhaust. The work required to displace the charge and exhaust gases comes from either the crankcase or a separate blower. For scavenging, expulsion of burned gas and entry of fresh mix, two main approaches are described: Loop scavenging, and Uniflow scavenging, SAE news published in the 2010s that 'Loop Scavenging' is better under any circumstance than Uniflow Scavenging.


==== Crankcase scavenged ====

Some SI engines are crankcase scavenged and do not use poppet valves. Instead the crankcase and the part of the cylinder below the piston is used as a pump. The intake port is connected to the crankcase through a reed valve or a rotary disk valve driven by the engine. For each cylinder a transfer port connects in one end to the crankcase and in the other end to the cylinder wall. The exhaust port is connected directly to the cylinder wall. The transfer and exhaust port are opened and closed by the piston. The reed valve opens when the crankcase pressure is slightly below intake pressure, to let it be filled with a new charge; this happens when the piston is moving upwards. When the piston is moving downwards the pressure in the crankcase increases and the reed valve closes promptly, then the charge in the crankcase is compressed. When the piston is moving upwards, it uncovers the exhaust port and the transfer port and the higher pressure of the charge in the crankcase makes it enter the cylinder through the transfer port, blowing the exhaust gases. Lubrication is accomplished by adding 2-stroke oil to the fuel in small ratios. Petroil refers to the mix of gasoline with the aforesaid oil. This kind of 2-stroke engines has a lower efficiency than comparable 4-strokes engines and release a more polluting exhaust gases for the following conditions:

They use a total-loss lubrication system: all the lubricating oil is eventually burned along with the fuel.
There are conflicting requirements for scavenging: On one side, enough fresh charge needs to be introduced in each cycle to displace almost all the combustion gases but introducing too much of it means that a part of it gets in the exhaust.
They must use the transfer port(s) as a carefully designed and placed nozzle so that a gas current is created in a way that it sweeps the whole cylinder before reaching the exhaust port so as to expel the combustion gases, but minimize the amount of charge exhausted. 4-stroke engines have the benefit of forcibly expelling almost all of the combustion gases because during exhaust the combustion chamber is reduced to its minimum volume. In crankcase scavenged 2-stroke engines, exhaust and intake are performed mostly simultaneously and with the combustion chamber at its maximum volume.The main advantage of 2-stroke engines of this type is mechanical simplicity and a higher power-to-weight ratio than their 4-stroke counterparts. Despite having twice as many power strokes per cycle, less than twice the power of a comparable 4-stroke engine is attainable in practice.
In the US, 2-stroke engines were banned for road vehicles due to the pollution. Off-road only motorcycles are still often 2-stroke but are rarely road legal. However, many thousands of 2-stroke lawn maintenance engines are in use.


==== Blower scavenged ====

Using a separate blower avoids many of the shortcomings of crankcase scavenging, at the expense of increased complexity which means a higher cost and an increase in maintenance requirement. An engine of this type uses ports or valves for intake and valves for exhaust, except opposed piston engines, which may also use ports for exhaust. The blower is usually of the Roots-type but other types have been used too. This design is commonplace in CI engines, and has been occasionally used in SI engines.
CI engines that use a blower typically use uniflow scavenging. In this design the cylinder wall contains several intake ports placed uniformly spaced along the circumference just above the position that the piston crown reaches when at BDC. An exhaust valve or several like that of 4-stroke engines is used. The final part of the intake manifold is an air sleeve which feeds the intake ports. The intake ports are placed at a horizontal angle to the cylinder wall (I.e: they are in plane of the piston crown) to give a swirl to the incoming charge to improve combustion. The largest reciprocating IC are low speed CI engines of this type; they are used for marine propulsion (see marine diesel engine) or electric power generation and achieve the highest thermal efficiencies among internal combustion engines of any kind. Some Diesel-electric locomotive engines operate on the 2-stroke cycle. The most powerful of them have a brake power of around 4.5 MW or 6,000 HP. The EMD SD90MAC class of locomotives are an example of such. The comparable class GE AC6000CW whose prime mover has almost the same brake power uses a 4-stroke engine.
An example of this type of engine is the Wärtsilä-Sulzer RT-flex96-C turbocharged 2-stroke Diesel, used in large container ships. It is the most efficient and powerful reciprocating internal combustion engine in the world with a thermal efficiency over 50%. For comparison, the most efficient small four-stroke engines are around 43% thermally-efficient (SAE 900648); size is an advantage for efficiency due to the increase in the ratio of volume to surface area.
See the external links for a in-cylinder combustion video in a 2-stroke, optically accessible motorcycle engine.


==== Historical design ====
Dugald Clerk developed the first two cycle engine in 1879. It used a separate cylinder which functioned as a pump in order to transfer the fuel mixture to the cylinder.In 1899 John Day simplified Clerk's design into the type of 2 cycle engine that is very widely used today.
Day cycle engines are crankcase scavenged and port timed. The crankcase and the part of the cylinder below the exhaust port is used as a pump. The operation of the Day cycle engine begins when the crankshaft is turned so that the piston moves from BDC upward (toward the head) creating a vacuum in the crankcase/cylinder area. The carburetor then feeds the fuel mixture into the crankcase through a reed valve or a rotary disk valve (driven by the engine). There are cast in ducts from the crankcase to the port in the cylinder to provide for intake and another from the exhaust port to the exhaust pipe.  The height of the port in relationship to the length of the cylinder is called the ""port timing"".
On the first upstroke of the engine there would be no fuel inducted into the cylinder as the crankcase was empty. On the downstroke, the piston now compresses the fuel mix, which has lubricated the piston in the cylinder and the bearings due to the fuel mix having oil added to it. As the piston moves downward is first uncovers the exhaust, but on the first stroke there is no burnt fuel to exhaust. As the piston moves downward further, it uncovers the intake port which has a duct that runs to the crankcase. Since the fuel mix in the crankcase is under pressure, the mix moves through the duct and into the cylinder.
Because there is no obstruction in the cylinder of the fuel to move directly out of the exhaust port prior to the piston rising far enough to close the port, early engines used a high domed piston to slow down the flow of fuel. Later the fuel was ""resonated"" back into the cylinder using an expansion chamber design. When the piston rose close to TDC, a spark ignites the fuel. As the piston is driven downward with power, it first uncovers the exhaust port where the burned fuel is expelled under high pressure and then the intake port where the process has been completed and will keep repeating.
Later engines used a type of porting devised by the Deutz company to improve performance. It was called the Schnurle Reverse Flow system. DKW licensed this design for all their motorcycles. Their DKW RT 125 was one of the first motor vehicles to achieve over 100 mpg as a result.


=== Ignition ===
Internal combustion engines require ignition of the mixture, either by spark ignition (SI) or compression ignition (CI). Before the invention of reliable electrical methods, hot tube and flame methods were used. Experimental engines with laser ignition have been built.


==== Spark ignition process ====

The spark ignition engine was a refinement of the early engines which used Hot Tube ignition. When Bosch developed the magneto it became the primary system for producing electricity to energize a spark plug. Many small engines still use magneto ignition. Small engines are started by hand cranking using a recoil starter or hand crank. Prior to Charles F. Kettering of Delco's development of the automotive starter all gasoline engined automobiles used a hand crank.Larger engines typically power their starting motors and ignition systems using the electrical energy stored in a lead–acid battery.  The battery's charged state is maintained by an automotive alternator or (previously) a generator which uses engine power to create electrical energy storage.
The battery supplies electrical power for starting when the engine has a starting motor system, and supplies electrical power when the engine is off. The battery also supplies electrical power during rare run conditions where the alternator cannot maintain more than 13.8 volts (for a common 12V automotive electrical system). As alternator voltage falls below 13.8 volts, the lead-acid storage battery increasingly picks up electrical load. During virtually all running conditions, including normal idle conditions, the alternator supplies primary electrical power.
Some systems disable alternator field (rotor) power during wide open throttle conditions. Disabling the field reduces alternator pulley mechanical loading to nearly zero, maximizing crankshaft power. In this case, the battery supplies all primary electrical power.
Gasoline engines take in a mixture of air and gasoline and compress it by the movement of the piston from bottom dead center to top dead center when the fuel is at maximum compression. The reduction in the size of the swept area of the cylinder and taking into account the volume of the combustion chamber is described by a ratio. Early engines had compression ratios of 6 to 1. As compression ratios were increased, the efficiency of the engine increased as well.
With early induction and ignition systems the compression ratios had to be kept low. With advances in fuel technology and combustion management, high performance engines can run reliably at 12:1 ratio. With low octane fuel, a problem would occur as the compression ratio increased as the fuel was igniting due to the rise in temperature that resulted. Charles Kettering developed a lead additive which allowed higher compression ratios, which was progressively abandoned for automotive use from the 1970s onward, partly due to lead poisoning concerns.
The fuel mixture is ignited at difference progressions of the piston in the cylinder. At low rpm, the spark is timed to occur close to the piston achieving top dead center. In order to produce more power, as rpm rises the spark is advanced sooner during piston movement. The spark occurs while the fuel is still being compressed progressively more as rpm rises.The necessary high voltage, typically 10,000 volts, is supplied by an induction coil or transformer. The induction coil is a fly-back system, using interruption of electrical primary system current through some type of synchronized interrupter. The interrupter can be either contact points or a power transistor. The problem with this type of ignition is that as RPM increases the availability of electrical energy decreases. This is especially a problem, since the amount of energy needed to ignite a more dense fuel mixture is higher. The result was often a high RPM misfire.
Capacitor discharge ignition was developed. It produces a rising voltage that is sent to the spark plug. CD system voltages can reach 60,000 volts. CD ignitions use step-up transformers. The step-up transformer uses energy stored in a capacitance to generate electric spark. With either system, a mechanical or electrical control system provides a carefully timed high-voltage to the proper cylinder. This spark, via the spark plug, ignites the air-fuel mixture in the engine's cylinders.
While gasoline internal combustion engines are much easier to start in cold weather than diesel engines, they can still have cold weather starting problems under extreme conditions. For years, the solution was to park the car in heated areas. In some parts of the world, the oil was actually drained and heated over night and returned to the engine for cold starts. In the early 1950s, the gasoline Gasifier unit was developed, where, on cold weather starts, raw gasoline was diverted to the unit where part of the fuel was burned causing the other part to become a hot vapor sent directly to the intake valve manifold.  This unit was quite popular until electric engine block heaters became standard on gasoline engines sold in cold climates.


==== Compression ignition process ====

Diesel, PPC and HCCI engines, rely solely on heat and pressure created by the engine in its compression process for ignition. The compression level that occurs is usually twice or more than a gasoline engine. Diesel engines take in air only, and shortly before peak compression, spray a small quantity of diesel fuel into the cylinder via a fuel injector that allows the fuel to instantly ignite. HCCI type engines take in both air and fuel, but continue to rely on an unaided auto-combustion process, due to higher pressures and heat. This is also why diesel and HCCI engines are more susceptible to cold-starting issues, although they run just as well in cold weather once started. Light duty diesel engines with indirect injection in automobiles and light trucks employ glowplugs (or other pre-heating: see Cummins ISB#6BT) that pre-heat the combustion chamber just before starting to reduce no-start conditions in cold weather. Most diesels also have a battery and charging system; nevertheless, this system is secondary and is added by manufacturers as a luxury for the ease of starting, turning fuel on and off (which can also be done via a switch or mechanical apparatus), and for running auxiliary electrical components and accessories. Most new engines rely on electrical and electronic engine control units (ECU) that also adjust the combustion process to increase efficiency and reduce emissions.
The compression ignition cycle does not always reach self-ignition for some fuels. Sometimes, an additive can help that fuel reach self-ignition (eg adding argon to methane). .


=== Lubrication ===

Surfaces in contact and relative motion to other surfaces require lubrication to reduce wear, noise and increase efficiency by reducing the power wasting in overcoming friction, or to make the mechanism work at all. Also, the lubricant used can reduce excess heat and provide additional cooling to components. At the very least, an engine requires lubrication in the following parts:

Between pistons and cylinders
Small bearings
Big end bearings
Main bearings
Valve gear (The following elements may not be present):
Tappets
Rocker arms
Pushrods
Timing chain or gears. Toothed belts do not require lubrication.In 2-stroke crankcase scavenged engines, the interior of the crankcase, and therefore the crankshaft, connecting rod and bottom of the pistons are sprayed by the 2-stroke oil in the air-fuel-oil mixture which is then burned along with the fuel. The valve train may be contained in a compartment flooded with lubricant so that no oil pump is required.
In a splash lubrication system no oil pump is used. Instead the crankshaft dips into the oil in the sump and due to its high speed, it splashes the crankshaft, connecting rods and bottom of the pistons. The connecting rod big end caps may have an attached scoop to enhance this effect. The valve train may also be sealed in a flooded compartment, or open to the crankshaft in a way that it receives splashed oil and allows it to drain back to the sump. Splash lubrication is common for small 4-stroke engines.
In a forced (also called pressurized) lubrication system, lubrication is accomplished in a closed loop which carries motor oil to the surfaces serviced by the system and then returns the oil to a reservoir. The auxiliary equipment of an engine is typically not serviced by this loop; for instance, an alternator may use ball bearings sealed with their own lubricant. The reservoir for the oil is usually the sump, and when this is the case, it is called a wet sump system. When there is a different oil reservoir the crankcase still catches it, but it is continuously drained by a dedicated pump; this is called a dry sump system.
On its bottom, the sump contains an oil intake covered by a mesh filter which is connected to an oil pump then to an oil filter outside the crankcase, from there it is diverted to the crankshaft main bearings and valve train. The crankcase contains at least one oil gallery (a conduit inside a crankcase wall) to which oil is introduced from the oil filter. The main bearings contain a groove through all or half its circumference; the oil enters to these grooves from channels connected to the oil gallery. The crankshaft has drillings which take oil from these grooves and deliver it to the big end bearings. All big end bearings are lubricated this way. A single main bearing may provide oil for 0, 1 or 2 big end bearings. A similar system may be used to lubricate the piston, its gudgeon pin and the small end of its connecting rod; in this system, the connecting rod big end has a groove around the crankshaft and a drilling connected to the groove which distributes oil from there to the bottom of the piston and from then to the cylinder.
Other systems are also used to lubricate the cylinder and piston. The connecting rod may have a nozzle to throw an oil jet to the cylinder and bottom of the piston. That nozzle is in movement relative to the cylinder it lubricates, but always pointed towards it or the corresponding piston.
Typically a forced lubrication systems have a lubricant flow higher than what is required to lubricate satisfactorily, in order to assist with cooling. Specifically, the lubricant system helps to move heat from the hot engine parts to the cooling liquid (in water-cooled engines) or fins (in air-cooled engines) which then transfer it to the environment. The lubricant must be designed to be chemically stable and maintain suitable viscosities within the temperature range it encounters in the engine.


=== Cylinder configuration ===
Common cylinder configurations include the straight or inline configuration, the more compact V configuration, and the wider but smoother flat or boxer configuration. Aircraft engines can also adopt a radial configuration, which allows more effective cooling. More unusual configurations such as the H, U, X, and W have also been used.

Multiple cylinder engines have their valve train and crankshaft configured so that pistons are at different parts of their cycle. It is desirable to have the pistons' cycles uniformly spaced (this is called even firing) especially in forced induction engines; this reduces torque pulsations and makes inline engines with more than 3 cylinders statically balanced in its primary forces. However, some engine configurations require odd firing to achieve better balance than what is possible with even firing. For instance, a 4-stroke I2 engine has better balance when the angle between the crankpins is 180° because the pistons move in opposite directions and inertial forces partially cancel, but this gives an odd firing pattern where one cylinder fires 180° of crankshaft rotation after the other, then no cylinder fires for 540°. With an even firing pattern, the pistons would move in unison and the associated forces would add.
Multiple crankshaft configurations do not necessarily need a cylinder head at all because they can instead have a piston at each end of the cylinder called an opposed piston design. Because fuel inlets and outlets are positioned at opposed ends of the cylinder, one can achieve uniflow scavenging, which, as in the four-stroke engine is efficient over a wide range of engine speeds. Thermal efficiency is improved because of a lack of cylinder heads. This design was used in the Junkers Jumo 205 diesel aircraft engine, using two crankshafts at either end of a single bank of cylinders, and most remarkably in the Napier Deltic diesel engines. These used three crankshafts to serve three banks of double-ended cylinders arranged in an equilateral triangle with the crankshafts at the corners. It was also used in single-bank locomotive engines, and is still used in marine propulsion engines and marine auxiliary generators.


=== Diesel cycle ===

Most truck and automotive diesel engines use a cycle reminiscent of a four-stroke cycle, but with compression heating causing ignition, rather than needing a separate ignition system. This variation is called the diesel cycle. In the diesel cycle, diesel fuel is injected directly into the cylinder so that combustion occurs at constant pressure, as the piston moves.


=== Otto cycle ===
Otto cycle is the typical cycle for most of the cars internal combustion engines, that work using gasoline as a fuel. Otto cycle is exactly the same one that was described for the four-stroke engine. It consists of the same major steps: Intake, compression, ignition, expansion and exhaust.


=== Five-stroke engine ===
In 1879, Nicolaus Otto manufactured and sold a double expansion engine (the double and triple expansion principles had ample usage in steam engines), with two small cylinders at both sides of a low-pressure larger cylinder, where a second expansion of exhaust stroke gas took place; the owner returned it, alleging poor performance. In 1906, the concept was incorporated in a car built by EHV (Eisenhuth Horseless Vehicle Company); and in the 21st century Ilmor designed and successfully tested a 5-stroke double expansion internal combustion engine, with high power output and low SFC (Specific Fuel Consumption).


=== Six-stroke engine ===
The six-stroke engine was invented in 1883. Four kinds of six-stroke use a regular piston in a regular cylinder (Griffin six-stroke, Bajulaz six-stroke, Velozeta six-stroke and Crower six-stroke), firing every three crankshaft revolutions. These systems capture the wasted heat of the four-stroke Otto cycle with an injection of air or water.
The Beare Head and ""piston charger"" engines operate as opposed-piston engines, two pistons in a single cylinder, firing every two revolutions rather more like a regular four-stroke.


=== Other cycles ===
The very first internal combustion engines did not compress the mixture. The first part of the piston downstroke drew in a fuel-air mixture, then the inlet valve closed and, in the remainder of the down-stroke, the fuel-air mixture fired. The exhaust valve opened for the piston upstroke. These attempts at imitating the principle of a steam engine were very inefficient.
There are a number of variations of these cycles, most notably the Atkinson and Miller cycles. The diesel cycle is somewhat different.
Split-cycle engines separate the four strokes of intake, compression, combustion and exhaust into two separate but paired cylinders. The first cylinder is used for intake and compression. The compressed air is then transferred through a crossover passage from the compression cylinder into the second cylinder, where combustion and exhaust occur. A split-cycle engine is really an air compressor on one side with a combustion chamber on the other.
Previous split-cycle engines have had two major problems—poor breathing (volumetric efficiency) and low thermal efficiency. However, new designs are being introduced that seek to address these problems.
The Scuderi Engine addresses the breathing problem by reducing the clearance between the piston and the cylinder head through various turbo charging techniques. The Scuderi design requires the use of outwardly opening valves that enable the piston to move very close to the cylinder head without the interference of the valves. Scuderi addresses the low thermal efficiency via firing after top dead centre (ATDC).
Firing ATDC can be accomplished by using high-pressure air in the transfer passage to create sonic flow and high turbulence in the power cylinder.


== Combustion turbines ==


=== Jet engine ===

Jet engines use a number of rows of fan blades to compress air which then enters a combustor where it is mixed with fuel (typically JP fuel) and then ignited. The burning of the fuel raises the temperature of the air which is then exhausted out of the engine creating thrust. A modern turbofan engine can operate at as high as 48% efficiency.There are six sections to a turbofan engine:

Fan
Compressor
Combustor
Turbine
Mixer
Nozzle


=== Gas turbines ===

A gas turbine compresses air and uses it to turn a turbine. It is essentially a jet engine which directs its output to a shaft.  There are three stages to a turbine: 1) air is drawn through a compressor where the temperature rises due to compression, 2) fuel is added in the combuster, and 3) hot air is exhausted through turbine blades which rotate a shaft connected to the compressor.
A gas turbine is a rotary machine similar in principle to a steam turbine and it consists of three main components: a compressor, a combustion chamber, and a turbine. The air, after being compressed in the compressor, is heated by burning fuel in it. The heated air and the products of combustion expand in a turbine, producing work output. About ​2⁄3 of the work drives the compressor: the rest (about ​1⁄3) is available as useful work output.Gas Turbines are among the most efficient internal combustion engines. The General Electric 7HA and 9HA turbine combined cycle electrical plants are rated at over 61% efficiency.


=== Brayton cycle ===

A gas turbine is a rotary machine somewhat similar in principle to a steam turbine. It consists of three main components: compressor, combustion chamber, and turbine. The air is compressed by the compressor where a temperature rise occurs. The compressed air is further heated by combustion of injected fuel in the combustion chamber which expands the air. This energy rotates the turbine which powers the compressor via a mechanical coupling. The hot gases are then exhausted to provide thrust.
Gas turbine cycle engines employ a continuous combustion system where compression, combustion, and expansion occur simultaneously at different places in the engine—giving continuous power. Notably, the combustion takes place at constant pressure, rather than with the Otto cycle, constant volume.


== Wankel engines ==

The Wankel engine (rotary engine) does not have piston strokes. It operates with the same separation of phases as the four-stroke engine with the phases taking place in separate locations in the engine. In thermodynamic terms it follows the Otto engine cycle, so may be thought of as a ""four-phase"" engine. While it is true that three power strokes typically occur per rotor revolution, due to the 3:1 revolution ratio of the rotor to the eccentric shaft, only one power stroke per shaft revolution actually occurs. The drive (eccentric) shaft rotates once during every power stroke instead of twice (crankshaft), as in the Otto cycle, giving it a greater power-to-weight ratio than piston engines. This type of engine was most notably used in the Mazda RX-8, the earlier RX-7, and other vehicle models. The engine is also used in unmanned aerial vehicles, where the small size and weight and the high power-to-weight ratio are advantageous.


== Forced induction ==

Forced induction is the process of delivering compressed air to the intake of an internal combustion engine. A forced induction engine uses a gas compressor to increase the pressure, temperature and density of the air. An engine without forced induction is considered a naturally aspirated engine.
Forced induction is used in the automotive and aviation industry to increase engine power and efficiency. It particularly helps aviation engines, as they need to operate at high altitude.
Forced induction is achieved by a supercharger, where the compressor is directly powered from the engine shaft or, in the turbocharger, from a turbine powered by the engine exhaust.


== Fuels and oxidizers ==
All internal combustion engines depend on combustion of a chemical fuel, typically with oxygen from the air (though it is possible to inject nitrous oxide to do more of the same thing and gain a power boost). The combustion process typically results in the production of a great quantity of heat, as well as the production of steam and carbon dioxide and other chemicals at very high temperature; the temperature reached is determined by the chemical make up of the fuel and oxidisers (see stoichiometry), as well as by the compression and other factors.


=== Fuels ===
The most common modern fuels are made up of hydrocarbons and are derived mostly from fossil fuels (petroleum). Fossil fuels include diesel fuel, gasoline and petroleum gas, and the rarer use of propane. Except for the fuel delivery components, most internal combustion engines that are designed for gasoline use can run on natural gas or liquefied petroleum gases without major modifications. Large diesels can run with air mixed with gases  and a pilot diesel fuel ignition injection. Liquid and gaseous biofuels, such as ethanol and biodiesel (a form of diesel fuel that is produced from crops that yield triglycerides such as soybean oil), can also be used. Engines with appropriate modifications can also run on hydrogen gas, wood gas, or charcoal gas, as well as from so-called producer gas made from other convenient biomass. Experiments have also been conducted using powdered solid fuels, such as the magnesium injection cycle.
Presently, fuels used include:

Petroleum:
Petroleum spirit (North American term: gasoline, British term: petrol)
Petroleum diesel.
Autogas (liquified petroleum gas).
Compressed natural gas.
Jet fuel (aviation fuel)
Residual fuel
Coal:
Gasoline can be made from carbon (coal) using  the Fischer-Tropsch process
Diesel fuel can be made from carbon using  the Fischer-Tropsch process
Biofuels and vegetable oils:
Peanut oil and other vegetable oils.
Woodgas, from an onboard wood gasifier using solid wood as a fuel
Biofuels:
Biobutanol (replaces gasoline).
Biodiesel (replaces petrodiesel).
Dimethyl Ether (replaces petrodiesel).
Bioethanol and Biomethanol (wood alcohol) and other biofuels  (see Flexible-fuel vehicle).
Biogas
Hydrogen (mainly spacecraft rocket engines)Even fluidized metal powders and explosives have seen some use. Engines that use gases for fuel are called gas engines and those that use liquid hydrocarbons are called oil engines; however, gasoline engines are also often colloquially referred to as, ""gas engines"" (""petrol engines"" outside North America).
The main limitations on fuels are that it must be easily transportable through the fuel system to the combustion chamber, and that the fuel releases sufficient energy in the form of heat upon combustion to make practical use of the engine.
Diesel engines are generally heavier, noisier, and more powerful at lower speeds than gasoline engines. They are also more fuel-efficient in most circumstances and are used in heavy road vehicles, some automobiles (increasingly so for their increased fuel efficiency over gasoline engines), ships, railway locomotives, and light aircraft. Gasoline engines are used in most other road vehicles including most cars, motorcycles, and mopeds. Note that in Europe, sophisticated diesel-engined cars have taken over about 45% of the market since the 1990s. There are also engines that run on hydrogen, methanol, ethanol, liquefied petroleum gas (LPG), biodiesel, paraffin and tractor vaporizing oil (TVO).


==== Hydrogen ====

Hydrogen could eventually replace conventional fossil fuels in traditional internal combustion engines. Alternatively fuel cell technology may come to deliver its promise and the use of the internal combustion engines could even be phased out.
Although there are multiple ways of producing free hydrogen, those methods require converting combustible molecules into hydrogen or consuming electric energy. Unless that electricity is produced from a renewable source—and is not required for other purposes—hydrogen does not solve any energy crisis. In many situations the disadvantage of hydrogen, relative to carbon fuels, is its storage. Liquid hydrogen has extremely low density (14 times lower than water) and requires extensive insulation—whilst gaseous hydrogen requires heavy tankage. Even when liquefied, hydrogen has a higher specific energy but the volumetric energetic storage is still roughly five times lower than gasoline. However, the energy density of hydrogen is considerably higher than that of electric batteries, making it a serious contender as an energy carrier to replace fossil fuels. The 'Hydrogen on Demand' process (see direct borohydride fuel cell) creates hydrogen as needed, but has other issues, such as the high price of the sodium borohydride that is the raw material.


=== Oxidizers ===

Since air is plentiful at the surface of the earth, the oxidizer is typically atmospheric oxygen, which has the advantage of not being stored within the vehicle. This increases the power-to-weight and power-to-volume ratios. Other materials are used for special purposes, often to increase power output or to allow operation under water or in space.

Compressed air has been commonly used in torpedoes.
Compressed oxygen, as well as some compressed air, was used in the Japanese Type 93 torpedo. Some submarines carry pure oxygen. Rockets very often use liquid oxygen.
Nitromethane is added to some racing and model fuels to increase power and control combustion.
Nitrous oxide has been used—with extra gasoline—in tactical aircraft, and in specially equipped cars to allow short bursts of added power from engines that otherwise run on gasoline and air. It is also used in the Burt Rutan rocket spacecraft.
Hydrogen peroxide power was under development for German World War II submarines. It may have been used in some non-nuclear submarines, and was used on some rocket engines (notably the Black Arrow and the Messerschmitt Me 163 rocket fighter).
Other chemicals such as chlorine or fluorine have been used experimentally, but have not been found practical.


== Cooling ==

Cooling is required to remove excessive heat—over heating can cause engine failure, usually from wear (due to heat-induced failure of lubrication), cracking or warping. Two most common forms of engine cooling are air-cooled and water-cooled. Most modern automotive engines are both water and air-cooled, as the water/liquid-coolant is carried to air-cooled fins and/or fans, whereas larger engines may be singularly water-cooled as they are stationary and have a constant supply of water through water-mains or fresh-water, while most power tool engines and other small engines are air-cooled. Some engines (air or water-cooled) also have an oil cooler. In some engines, especially for turbine engine blade cooling and liquid rocket engine cooling, fuel is used as a coolant, as it is simultaneously preheated before injecting it into a combustion chamber.


== Starting ==

Internal combustion engines must have their cycles started. In reciprocating engines this is accomplished by turning the crankshaft (Wankel Rotor Shaft) which induces the cycles of intake, compression, combustion, and exhaust.  The first engines were started with a turn of their flywheels, while the first vehicle (the Daimler Reitwagen) was started with a hand crank.  All ICE engined automobiles were started with hand cranks until Charles Kettering developed the electric starter for automobiles. This method is now the most widely used, even among non-automobiles.
As diesel engines have become larger and their mechanisms heavier, air starters have come into use. This is due to the lack of torque in electric starters. Air starters work by pumping compressed air into the cylinders of an engine to start it turning.
Two-wheeled vehicles may have their engines started in one of four ways:

By pedaling, as on a bicycle
By pushing the vehicle and then engaging the clutch, known as ""run-and-bump starting""
By kicking downward on a single pedal, known as ""kick starting""
By an electric starter, as in carsThere are also starters where a spring is compressed by a crank motion and then used to start an engine.
Some small engines use a pull-rope mechanism called ""recoil starting"", as the rope rewinds itself after it has been pulled out to start the engine. This method is commonly used in  pushed lawn mowers and other settings where only a small amount of torque is needed to turn an engine over.
Turbine engines are frequently started by an electric motor or by compressed air.


== Measures of engine performance ==
Engine types vary greatly in a number of different ways:

energy efficiency
fuel/propellant consumption (brake specific fuel consumption for shaft engines, thrust specific fuel consumption for jet engines)
power-to-weight ratio
thrust to weight ratio
torque curves (for shaft engines) thrust lapse (jet engines)
compression ratio for piston engines, overall pressure ratio for jet engines and gas turbines


=== Energy efficiency ===
Once ignited and burnt, the combustion products—hot gases—have more available thermal energy than the original compressed fuel-air mixture (which had higher chemical energy). The available energy is manifested as high temperature and pressure that can be translated into work by the engine. In a reciprocating engine, the high-pressure gases inside the cylinders drive the engine's pistons.
Once the available energy has been removed, the remaining hot gases are vented (often by opening a valve or exposing the exhaust outlet) and this allows the piston to return to its previous position (top dead center, or TDC). The piston can then proceed to the next phase of its cycle, which varies between engines. Any heat that is not translated into work is normally considered a waste product and is removed from the engine either by an air or liquid cooling system.
Internal combustion engines are heat engines, and as such their theoretical efficiency can be approximated by idealized thermodynamic cycles. The thermal efficiency of a theoretical cycle cannot exceed that of the Carnot cycle, whose efficiency is determined by the difference between the lower and upper operating temperatures of the engine. The upper operating temperature of an engine is limited by two main factors; the thermal operating limits of the materials, and the auto-ignition resistance of the fuel. All metals and alloys have a thermal operating limit, and there is significant research into ceramic materials that can be made with greater thermal stability and desirable structural properties. Higher thermal stability allows for a greater temperature difference between the lower (ambient) and upper operating temperatures, hence greater thermodynamic efficiency. Also, as the cylinder temperature rises, the engine becomes more prone to auto-ignition. This is caused when the cylinder temperature nears the flash point of the charge. At this point, ignition can spontaneously occur before the spark plug fires, causing excessive cylinder pressures. Auto-ignition can be mitigated by using fuels with high auto-ignition resistance (octane rating), however it still puts an upper bound on the allowable peak cylinder temperature.
The thermodynamic limits assume that the engine is operating under ideal conditions: a frictionless world, ideal gases, perfect insulators, and operation for infinite time. Real world applications introduce complexities that reduce efficiency. For example, a real engine runs best at a specific load, termed its power band. The engine in a car cruising on a highway is usually operating significantly below its ideal load, because it is designed for the higher loads required for rapid acceleration. In addition, factors such as wind resistance reduce overall system efficiency.  Engine fuel economy is measured in miles per gallon or in liters per 100 kilometres. The volume of hydrocarbon assumes a standard energy content.
Most iron engines have a thermodynamic limit of 37%. Even when aided with turbochargers and stock efficiency aids, most engines retain an average efficiency of about 18–20%. However, the latest technologies in Formula One engines have seen a boost in thermal efficiency past 50%.
There are many inventions aimed at increasing the efficiency of IC engines. In general, practical engines are always compromised by trade-offs between different properties such as efficiency, weight, power, heat, response, exhaust emissions, or noise. Sometimes economy also plays a role in not only the cost of manufacturing the engine itself, but also manufacturing and distributing the fuel. Increasing the engine's efficiency brings better fuel economy but only if the fuel cost per energy content is the same.


=== Measures of fuel efficiency and propellant efficiency ===
For stationary and shaft engines including propeller engines, fuel consumption is measured by calculating the brake specific fuel consumption, which measures the mass flow rate of fuel consumption divided by the power produced.
For internal combustion engines in the form of jet engines, the power output varies drastically with airspeed and a less variable measure is used: thrust specific fuel consumption (TSFC), which is the mass of propellant needed to generate impulses that is measured in either pound force-hour or the grams of propellant needed to generate an impulse that measures one kilonewton-second.
For rockets, TSFC can be used, but typically other equivalent measures are traditionally used, such as specific impulse and effective exhaust velocity.


== Air and noise pollution ==


=== Air pollution ===
Internal combustion engines such as reciprocating internal combustion engines produce air pollution emissions, due to incomplete combustion of carbonaceous fuel. The main derivatives of the process are carbon dioxide CO2, water and some soot—also called particulate matter (PM). The effects of inhaling particulate matter have been studied in humans and animals and include asthma, lung cancer, cardiovascular issues, and premature death. There are, however, some additional products of the combustion process that include nitrogen oxides and sulfur and some uncombusted hydrocarbons, depending on the operating conditions and the fuel-air ratio.
Not all of the fuel is completely consumed by the combustion process. A small amount of fuel is present after combustion, and some of it reacts to form oxygenates, such as formaldehyde or acetaldehyde, or hydrocarbons not originally present in the input fuel mixture. Incomplete combustion usually results from insufficient oxygen to achieve the perfect stoichiometric ratio. The flame is ""quenched"" by the relatively cool cylinder walls, leaving behind unreacted fuel that is expelled with the exhaust. When running at lower speeds, quenching is commonly observed in diesel (compression ignition) engines that run on natural gas. Quenching reduces efficiency and increases knocking, sometimes causing the engine to stall. Incomplete combustion also leads to the production of carbon monoxide (CO). Further chemicals released are benzene and 1,3-butadiene that are also hazardous air pollutants.
Increasing the amount of air in the engine reduces emissions of incomplete combustion products, but also promotes reaction between oxygen and nitrogen in the air to produce nitrogen oxides (NO x ). NO x  is hazardous to both plant and animal health, and leads to the production of ozone (O3). Ozone is not emitted directly; rather, it is a secondary air pollutant, produced in the atmosphere by the reaction of NO x  and volatile organic compounds in the presence of sunlight. Ground-level ozone is harmful to human health and the environment. Though the same chemical substance, ground-level ozone should not be confused with stratospheric ozone, or the ozone layer, which protects the earth from harmful ultraviolet rays.
Carbon fuels contain sulfur and impurities that eventually produce sulfur monoxides (SO) and sulfur dioxide (SO2) in the exhaust, which promotes acid rain.
In the United States, nitrogen oxides, PM, carbon monoxide, sulphur dioxide, and ozone, are regulated as criteria air pollutants under the Clean Air Act to levels where human health and welfare are protected. Other pollutants, such as benzene and 1,3-butadiene, are regulated as hazardous air pollutants whose emissions must be lowered as much as possible depending on technological and practical considerations.
NO x , carbon monoxide and other pollutants are frequently controlled via exhaust gas recirculation which returns some of the exhaust back into the engine intake, and catalytic converters, which convert exhaust chemicals to harmless chemicals.


==== Non-road engines ====

The emission standards used by many countries have special requirements for non-road engines which are used by equipment and vehicles that are not operated on the public roadways. The standards are separated from the road vehicles.


=== Noise pollution ===
Significant contributions to noise pollution are made by internal combustion engines. Automobile and truck traffic operating on highways and street systems produce noise, as do aircraft flights due to jet noise, particularly supersonic-capable aircraft. Rocket engines create the most intense noise.


=== Idling ===

Internal combustion engines continue to consume fuel and emit pollutants when idling so it is desirable to keep periods of idling to a minimum. Many bus companies now instruct drivers to switch off the engine when the bus is waiting at a terminal.
In England, the Road Traffic Vehicle Emissions Fixed Penalty Regulations 2002 (Statutory Instrument 2002 No. 1808)  introduced the concept of a ""stationary idling offence"". This means that a driver can be ordered ""by an authorised person ... upon production of evidence of his authorisation, require him to stop the running of the engine of that vehicle"" and a ""person who fails to comply ... shall be guilty of an offence and be liable on summary conviction to a fine not exceeding level 3 on the standard scale"". Only a few local authorities have implemented the regulations, one of them being Oxford City Council.In many European countries, idling is, by default, disabled by stop-start systems.


== See also ==


== References ==


== Bibliography ==
Anyebe, E.A (2009). Combustion Engine and Operations, Automobile Technology Handbook. 2.
Nunney, Malcolm J. (2007). Light and Heavy Vehicle Technology (4th ed.). Elsevier Butterworth-Heinemann. ISBN 978-0-7506-8037-0.CS1 maint: ref=harv (link)
Ricardo, Harry (1931). The High-Speed Internal Combustion Engine.
Singal, R.K. Internal Combustion Engines. New Delhi, India: Kataria Books. ISBN 978-93-5014-214-1.
Stone, Richard (1992). Introduction to Internal Combustion Engines (2nd ed.). Macmillan. ISBN 978-0-333-55083-0.CS1 maint: ref=harv (link)
Patents:
ES 156621 
ES 433850, Ubierna Laciana, ""Perfeccionamientos en Motores de Explosion, con Cinco Tiem-Pos y Doble Expansion"", published 1976-11-01 
ES 230551, Ortuno Garcia Jose, ""Un Nuevo Motor de Explosion"", published 1957-03-01 
ES 249247, Ortuno Garcia Jose, ""Motor de Carreras Distintas"", published 1959-09-01 


== Further reading ==
Singer, Charles Joseph; Raper, Richard (1978).  Charles, Singer;  et al. (eds.). A History of Technology: The Internal Combustion Engine. Clarendon Press. pp. 157–176. ISBN 978-0-19-858155-0.
Setright, LJK (1975). Some unusual engines. London: The Institution of Mechanical Engineers. ISBN 978-0-85298-208-2.
Suzuki, Takashi (1997). The Romance of Engines. US: Society of Automotive Engineers. ISBN 978-1-56091-911-7.
Hardenberg, Horst O. (1999). The Middle Ages of the Internal Combustion Engine. US: Society of Automotive Engineers.
Gunston, Bill (1999). Development of Piston Aero Engines. PSL. ISBN 978-1-85260-619-0.


== External links ==
Combustion video – in-cylinder combustion in an optically accessible, 2-stroke engine
Animated Engines – explains a variety of types
Intro to Car Engines – Cut-away images and a good overview of the internal combustion engine
Walter E. Lay Auto Lab – Research at The University of Michigan
YouTube – Animation of the components and built-up of a 4-cylinder engine
YouTube – Animation of the internal moving parts of a 4-cylinder engine
Next generation engine technologies retrieved May 9, 2009
MIT Overview – Present & Future Internal Combustion Engines: Performance, Efficiency, Emissions, and Fuels
Engine Combustion Network – Open forum for international collaboration among experimental and computational researchers in engine combustion.
Automakers Show Interest in an Unusual Engine Design
How Car Engines Work
A file on unusual engines [1]
Aircraft Engine Historical Society (AEHS) – [2]"
"An aircraft engine, often referred to as an aero engine, is the power component of an aircraft propulsion system. Most aircraft engines are either piston engines or gas turbines, although in recent years many small UAVs have used electric motors.


== Manufacturing industry ==

In commercial aviation the major Western manufacturers of turbofan engines are Pratt & Whitney (a subsidiary of Raytheon Technologies), General Electric, Rolls-Royce, and CFM International (a joint venture of Safran Aircraft Engines and General Electric).[1] Russian manufacturers include the United Engine Corporation, Aviadvigatel and Klimov. Aeroengine Corporation of China was formed in 2016 with the merger of several smaller companies.The largest manufacturer of turboprop engines for general aviation is Pratt & Whitney. General Electric announced in 2015 entrance into the market.


== Development history ==

1848: John Stringfellow made a steam engine for a 10-foot wingspan model aircraft which achieved the first powered flight, albeit with negligible payload.
1903: Charlie Taylor built an inline engine, mostly of aluminum, for the Wright Flyer (12 horsepower).
1903: Manly-Balzer engine sets standards for later radial engines.
1906: Léon Levavasseur produces a successful water-cooled V8 engine for aircraft use.
1908: René Lorin patents a design for the ramjet engine.
1908: Louis Seguin designed the Gnome Omega, the world's first rotary engine to be produced in quantity. In 1909 a Gnome powered Farman III aircraft won the prize for the greatest non-stop distance flown at the Reims Grande Semaine d'Aviation setting a world record for endurance of 180 kilometres (110 mi).
1910: Coandă-1910, an unsuccessful ducted fan aircraft exhibited at Paris Aero Salon, powered by a piston engine. The aircraft never flew, but a patent was filed for routing exhaust gases into the duct to augment thrust.
1914: Auguste Rateau suggests using exhaust-powered compressor – a turbocharger – to improve high-altitude performance; not accepted after the tests
1917-18 - The Idflieg-numbered R.30/16 example of the Imperial German Luftstreitkräfte's Zeppelin-Staaken R.VI heavy bomber becomes the earliest known supercharger-equipped aircraft to fly, with a Mercedes D.II straight-six engine in the central fuselage driving a Brown-Boveri mechanical supercharger for the R.30/16's four Mercedes D.IVa engines.
1918: Sanford Alexander Moss picks up Rateau's idea and creates the first successful turbocharger
1926: Armstrong Siddeley Jaguar IV (S), the first series-produced supercharged engine for aircraft use; two-row radial with a gear-driven centrifugal supercharger.
1930: Frank Whittle submitted his first patent for a turbojet engine.
June 1939: Heinkel He 176 is the first successful aircraft to fly powered solely by a liquid-fueled rocket engine.
August 1939: Heinkel HeS 3 turbojet propels the pioneering German Heinkel He 178 aircraft.
1940: Jendrassik Cs-1, the world's first run of a turboprop engine. It is not put into service.
1943 Daimler-Benz DB 670, first turbofan runs
1944: Messerschmitt Me 163B Komet, the world's first rocket-propelled combat aircraft deployed.
1945: First turboprop-powered aircraft flies, a modified Gloster Meteor with two Rolls-Royce Trent engines.
1947: Bell X-1 rocket-propelled aircraft exceeds the speed of sound.
1948: 100 shp 782, the first turboshaft engine to be applied to aircraft use; in 1950 used to develop the larger 280 shp (210 kW) Turbomeca Artouste.
1949: Leduc 010, the world's first ramjet-powered aircraft flight.
1950: Rolls-Royce Conway, the world's first production turbofan, enters service.
1968: General Electric TF39 high bypass turbofan enters service delivering greater thrust and much better efficiency.
2002: HyShot scramjet flew in dive.
2004: NASA X-43, the first scramjet to maintain altitude.
2020: Pipistrel E-811 is the first electric aircraft engine to be awarded a type certificate by EASA. It powers the Pipistrel Velis Electro, the first fully electric EASA type-certified aeroplane.


== Shaft engines ==


=== Reciprocating (piston) engines ===


==== In-line engine ====

In this entry, for clarity, the term ""inline engine"" refers only to engines with a single row of cylinders, as used in automotive language, but in aviation terms, the phrase ""inline engine"" also covers V-type and opposed engines (as described below), and is not limited to engines with a single row of cylinders. This is typically to differentiate them from radial engines. A straight engine typically has an even number of cylinders, but there are instances of three- and five-cylinder engines. The greatest advantage of an inline engine is that it allows the aircraft to be designed with a low frontal area to minimize drag. If the engine crankshaft is located above the cylinders, it is called an inverted inline engine: this allows the propeller to be mounted high up to increase ground clearance, enabling shorter landing gear. The disadvantages of an inline engine include a poor power-to-weight ratio, because the crankcase and crankshaft are long and thus heavy. An in-line engine may be either air-cooled or liquid-cooled, but liquid-cooling is more common because it is difficult to get enough air-flow to cool the rear cylinders directly. Inline engines were common in early aircraft; one was used in the Wright Flyer, the aircraft that made the first controlled powered flight. However, the inherent disadvantages of the design soon became apparent, and the inline design was abandoned, becoming a rarity in modern aviation.
For other configurations of aviation inline engine, such as X-engines, U-engines, H-engines, etc., see Inline engine (aeronautics).


==== V-type engine ====

Cylinders in this engine are arranged in two in-line banks, typically tilted 60–90 degrees apart from each other and driving a common crankshaft. The vast majority of V engines are water-cooled. The V design provides a higher power-to-weight ratio than an inline engine, while still providing a small frontal area. Perhaps the most famous example of this design is the legendary Rolls-Royce Merlin engine, a 27-litre (1649 in3) 60° V12 engine used in, among others, the Spitfires that played a major role in the Battle of Britain.


==== Horizontally opposed engine ====

A horizontally opposed engine, also called a flat or boxer engine, has two banks of cylinders on opposite sides of a centrally located crankcase. The engine is either air-cooled or liquid-cooled, but air-cooled versions predominate. Opposed engines are mounted with the crankshaft horizontal in airplanes, but may be mounted with the crankshaft vertical in helicopters. Due to the cylinder layout, reciprocating forces tend to cancel, resulting in a smooth running engine. Opposed-type engines have high power-to-weight ratios because they have a comparatively small, lightweight crankcase. In addition, the compact cylinder arrangement reduces the engine's frontal area and allows a streamlined installation that minimizes aerodynamic drag. These engines always have an even number of cylinders, since a cylinder on one side of the crankcase “opposes” a cylinder on the other side.
Opposed, air-cooled four- and six-cylinder piston engines are by far the most common engines used in small general aviation aircraft requiring up to 400 horsepower (300 kW) per engine. Aircraft that require more than 400 horsepower (300 kW) per engine tend to be powered by turbine engines.


==== H configuration engine ====

An H configuration engine is essentially a pair of horizontally opposed engines placed together, with the two crankshafts geared together.


==== Radial engine ====

This type of engine has one or more rows of cylinders arranged around a centrally located crankcase. Each row generally has an odd number of cylinders to produce smooth operation. A radial engine has only one crank throw per row and a relatively small crankcase, resulting in a favorable power-to-weight ratio. Because the cylinder arrangement exposes a large amount of the engine's heat-radiating surfaces to the air and tends to cancel reciprocating forces, radials tend to cool evenly and run smoothly.  The lower cylinders, which are under the crankcase, may collect oil when the engine has been stopped for an extended period. If this oil is not cleared from the cylinders prior to starting the engine, serious damage due to hydrostatic lock may occur.
Most radial engines have the cylinders arranged evenly around the crankshaft, although some early engines, sometimes called semi-radials or fan configuration engines, had an uneven arrangement.  The best known engine of this type is the Anzani engine, which was fitted to the Bleriot XI used for the first flight across the English Channel in 1909.  This arrangement had the drawback of needing a heavy counterbalance for the crankshaft, but was used to avoid the spark plugs oiling up.
In military aircraft designs, the large frontal area of the engine acted as an extra layer of armor for the pilot.  Also air-cooled engines, without vulnerable radiators, are slightly less prone to battle damage, and on occasion would continue running even with one or more cylinders shot away. However, the large frontal area also resulted in an aircraft with an aerodynamically inefficient increased frontal area.


==== Rotary engine ====

Rotary engines have the cylinders in a circle around the crankcase, as in a radial engine, (see above), but the crankshaft is fixed to the airframe and the propeller is fixed to the engine case, so that the crankcase and cylinders rotate.  The advantage of this arrangement is that a satisfactory flow of cooling air is maintained even at low airspeeds, retaining the weight advantage and simplicity of a conventional air-cooled engine without one of their major drawbacks.
The first practical rotary engine was the Gnome Omega designed by the Seguin brothers and first flown in 1909.  Its relative reliability and good power to weight ratio changed aviation dramatically.   Before the first World War most speed records were gained using Gnome-engined aircraft, and in the early years of the war rotary engines were dominant in aircraft types for which speed and agility were paramount. To increase power, engines with two rows of cylinders were built.
However, the gyroscopic effects of the heavy rotating engine produced handling problems in aircraft and the engines also consumed large amounts of oil since they used total loss lubrication, the oil being mixed with the fuel and ejected with the exhaust gases. Castor oil was used for lubrication, since it is not soluble in petrol, and the resultant fumes were nauseating to the pilots.  Engine designers had always been aware of the many limitations of the rotary engine so when the static style engines became more reliable and gave better specific weights and fuel consumption, the days of the rotary engine were numbered.


==== Wankel engine ====

The Wankel is a type of rotary engine. The Wankel engine is about one half the weight and size of a traditional four-stroke cycle piston engine of equal power output, and much lower in complexity.  In an aircraft application, the power-to-weight ratio is very important, making the Wankel engine a good choice. Because the engine is typically constructed with an aluminium housing and a steel rotor, and aluminium expands more than steel when heated,  a Wankel engine does not seize when overheated, unlike a piston engine.  This is an important safety factor for aeronautical use. Considerable development of these designs started after World War II, but at the time the aircraft industry favored the use of turbine engines. It was believed that turbojet or turboprop engines could power all aircraft, from the largest to smallest designs. The Wankel engine did not find many applications in aircraft, but was used by Mazda in a popular line of sports cars. The French company Citroën had developed Wankel powered RE-2 helicopter in 1970's.In modern times the Wankel engine has been used in motor gliders where the compactness, light weight, and smoothness are crucially important.The now-defunct Staverton-based firm MidWest designed and produced single- and twin-rotor aero engines, the MidWest AE series.  These engines were developed from the motor in the Norton Classic motorcycle.  The twin-rotor version was fitted into ARV Super2s and the Rutan Quickie. The single-rotor engine was put into a Chevvron motor glider and into the Schleicher ASH motor-gliders.  After the demise of MidWest, all rights were sold to Diamond of Austria, who have since developed a MkII version of the engine.
As a cost-effective alternative to certified aircraft engines some Wankel engines, removed from automobiles and converted to aviation use, have been fitted in homebuilt experimental aircraft.  Mazda units with outputs ranging from 100 horsepower (75 kW) to 300 horsepower (220 kW) can be a fraction of the cost of traditional engines. Such conversions first took place in the early 1970s; and as of 10 December 2006 the National Transportation Safety Board has only seven reports of incidents involving aircraft with Mazda engines, and none of these is of a failure due to design or manufacturing flaws.


==== Combustion cycles ====
The commonest combustion cycle for aero engines is the four-stroke with spark ignition. Two-stroke spark ignition has also been used for small engines, while the compression-ignition Diesel engine is seldom used.
Starting in the 1930s attempts were made to produce a practical Aircraft diesel engine. In general, Diesel engines are more reliable and much better suited to running for long periods of time at medium power settings. The lightweight alloys of the 1930s were not up to the task of handling the much higher compression ratios of diesel engines, so they generally had poor power-to-weight ratios and were uncommon for that reason, although the Clerget 14F Diesel radial engine (1939) has the same power to weight ratio as a gasoline radial. Improvements in Diesel technology in automobiles (leading to much better power-weight ratios), the Diesel's much better fuel efficiency and the high relative taxation of AVGAS compared to Jet A1 in Europe have all seen a revival of interest in the use of diesels for aircraft. Thielert Aircraft Engines converted Mercedes Diesel automotive engines, certified them for aircraft use, and became an OEM provider to Diamond Aviation for their light twin. Financial problems have plagued Thielert, so Diamond's affiliate — Austro Engine — developed the new AE300 turbodiesel, also based on a Mercedes engine. Competing new Diesel engines may bring fuel efficiency and lead-free emissions to small aircraft, representing the biggest change in light aircraft engines in decades.


=== Power turbines ===


==== Turboprop ====

While military fighters require very high speeds, many civil airplanes do not. Yet, civil aircraft designers wanted to benefit from the high power and low maintenance that a gas turbine engine offered. Thus was born the idea to mate a turbine engine to a traditional propeller. Because gas turbines optimally spin at high speed, a turboprop features a gearbox to lower the speed of the shaft so that the propeller tips don't reach supersonic speeds. Often the turbines that drive the propeller are separate from the rest of the rotating components so that they can rotate at their own best speed (referred to as a free-turbine engine). A turboprop is very efficient when operated within the realm of cruise speeds it was designed for, which is typically 200 to 400 mph (320 to 640 km/h).


==== Turboshaft ====

Turboshaft engines are used primarily for helicopters and auxiliary power units. A turboshaft engine is similar to a turboprop in principle, but in a turboprop the propeller is supported by the engine and the engine is bolted to the airframe: in a turboshaft, the engine does not provide any direct physical support to the helicopter's rotors. The rotor is connected to a transmission which is bolted to the airframe, and the turboshaft engine drives the transmission. The distinction is seen by some as slim, as in some cases aircraft companies make both turboprop and turboshaft engines based on the same design.


=== Electric power ===
A number of electrically powered aircraft, such as the QinetiQ Zephyr, have been designed since the 1960s. Some are used as military drones. In France in late 2007, a conventional light aircraft powered by an 18 kW electric motor using lithium polymer batteries was flown, covering more than 50 kilometers (31 mi), the first electric airplane to receive a certificate of airworthiness.On 18 May 2020, the Pipistrel E-811 was the first electric aircraft engine to be awarded a type certificate by EASA for use in general aviation. The E-811 powers the Pipistrel Velis Electro.Limited experiments with solar electric propulsion have been performed, notably the manned Solar Challenger and Solar Impulse and the unmanned NASA Pathfinder aircraft.
Many big companies, such as Siemens, are developing high performance electric engines for aircraft use, also, SAE shows new developments in elements as pure Copper core electric motors with a better efficiency. A hybrid system as emergency back-up and for added power in take-off is offered for sale by Axter Aerospace, Madrid, Spain. [2]
Small multicopter UAVs are almost always powered by electric motors.


== Reaction engines ==

Reaction engines generate the thrust to propel an aircraft by ejecting the exhaust gases at high velocity from the engine, the resultant reaction of forces driving the aircraft forwards.  The most common reaction propulsion engines flown are turbojets, turbofans and rockets. Other types such as pulsejets, ramjets, scramjets and pulse detonation engines have also flown.  In jet engines the oxygen necessary for fuel combustion comes from the air, while rockets carry oxygen in some form as part of the fuel load, permitting their use in space.


=== Jet turbines ===


==== Turbojet ====

A turbojet is a type of gas turbine engine that was originally developed for military fighters during World War II. A turbojet is the simplest of all aircraft gas turbines. It consists of a compressor to draw air in and compress it, a combustion section where fuel is added and ignited, one or more turbines that extract power from the expanding exhaust gases to drive the compressor, and an exhaust nozzle that accelerates the exhaust gases out the back of the engine to create thrust. When turbojets were introduced, the top speed of fighter aircraft equipped with them was at least 100 miles per hour faster than competing piston-driven aircraft. In the years after the war, the drawbacks of the turbojet gradually became apparent. Below about Mach 2, turbojets are very fuel inefficient and create tremendous amounts of noise. Early designs also respond very slowly to power changes, a fact that killed many experienced pilots when they attempted the transition to jets. These drawbacks eventually led to the downfall of the pure turbojet, and only a handful of types are still in production. The last airliner that used turbojets was the Concorde, whose Mach 2 airspeed permitted the engine to be highly efficient.


==== Turbofan ====

A turbofan engine is much the same as a turbojet, but with an enlarged fan at the front that provides thrust in much the same way as a ducted propeller, resulting in improved fuel efficiency. Though the fan creates thrust like a propeller, the surrounding duct frees it from many of the restrictions that limit propeller performance. This operation is a more efficient way to provide thrust than simply using the jet nozzle alone, and turbofans are more efficient than propellers in the transsonic range of aircraft speeds and can operate in the supersonic realm. A turbofan typically has extra turbine stages to turn the fan. Turbofans were among the first engines to use multiple spools—concentric shafts that are free to rotate at their own speed—to let the engine react more quickly to changing power requirements. Turbofans are coarsely split into low-bypass and high-bypass categories. Bypass air flows through the fan, but around the jet core, not mixing with fuel and burning. The ratio of this air to the amount of air flowing through the engine core is the bypass ratio. Low-bypass engines are preferred for military applications such as fighters due to high thrust-to-weight ratio, while high-bypass engines are preferred for civil use for good fuel efficiency and low noise. High-bypass turbofans are usually most efficient when the aircraft is traveling at 500 to 550 miles per hour (800 to 885 km/h), the cruise speed of most large airliners. Low-bypass turbofans can reach supersonic speeds, though normally only when fitted with afterburners.


=== Pulse jets ===

Pulse jets are mechanically simple devices that—in a repeating cycle—draw air through a no-return valve at the front of the engine into a combustion chamber and ignite it. The combustion forces the exhaust gases out the back of the engine.  It produces power as a series of pulses rather than as a steady output, hence the name. The only application of this type of engine was the German unmanned V1 flying bomb of World War II. Though the same engines were also used experimentally for ersatz fighter aircraft, the extremely loud noise generated by the engines caused mechanical damage to the airframe that was sufficient to make the idea unworkable.


=== Rocket ===

A few aircraft have used rocket engines for main thrust or attitude control, notably the Bell X-1 and North American X-15.
Rocket engines are not used for most aircraft as the energy and propellant efficiency is very poor, but have been employed for short bursts of speed and takeoff.  Where fuel/propellant efficiency is of lesser concern, rocket engines can be useful because they produce very large amounts of thrust and weigh very little.


=== Precooled jet engines ===

For very high supersonic/low hypersonic flight speeds, inserting a cooling system into the air duct of a hydrogen jet engine permits greater fuel injection at high speed and obviates the need for the duct to be made of refractory or actively cooled materials. This greatly improves the thrust/weight ratio of the engine at high speed.
It is thought that this design of engine could permit sufficient performance for antipodal flight at Mach 5, or even permit a single stage to orbit vehicle to be practical. The hybrid air-breathing SABRE rocket engine is a pre-cooled engine under development.


=== Piston-turbofan hybrid ===
At the April 2018 ILA Berlin Air Show, Munich-based research institute de:Bauhaus Luftfahrt presented a high-efficiency composite cycle engine for 2050, combining a geared turbofan with a piston engine core.
The 2.87 m diameter, 16-blade fan gives a 33.7 ultra-high bypass ratio, driven by a geared low-pressure turbine but the high-pressure compressor drive comes from a piston-engine with two 10 piston banks without a high-pressure turbine, increasing efficiency with non-stationary isochoric-isobaric combustion for higher peak pressures and temperatures.
The 11,200 lb (49.7 kN) engine could power a 50-seat regional jet.Its cruise TSFC would be 11.5 g/kN/s (0.406 lb/lbf/hr) for an overall engine efficiency of 48.2%, for a burner temperature of 1,700 K (1,430 °C), an overall pressure ratio of 38 and a peak pressure of 30 MPa (300 bar).
Although engine weight increases by 30%, aircraft fuel consumption is reduced by 15%.
Sponsored by the European Commission under Framework 7 project LEMCOTEC, Bauhaus Luftfahrt, MTU Aero Engines and GKN Aerospace presented the concept in 2015, raising the overall engine pressure ratio to over 100 for a 15.2% fuel burn reduction compared to 2025 engines.


== Engine position numbering ==

On multi-engine aircraft, engine positions are numbered from left to right from the point of view of the pilot looking forward, so for example on a four-engine aircraft such as the Boeing 747, engine No. 1 is on the left side, farthest from the fuselage, while engine No. 3 is on the right side nearest to the fuselage.In the case of the twin-engine English Electric Lightning, which has two fuselage-mounted jet engines one above the other, engine No. 1 is below and to the front of engine No. 2, which is above and behind.In the Cessna 337 Skymaster, a push-pull twin-engine airplane, engine No. 1 is the one at the front of the fuselage, while engine No. 2 is aft of the cabin.


== Fuel ==
Aircraft reciprocating (piston) engines are typically designed to run on aviation gasoline. Avgas has a higher octane rating than automotive gasoline to allow higher compression ratios, power output, and efficiency at higher altitudes. Currently the most common Avgas is 100LL. This refers to the octane rating (100 octane) and the lead content (LL = low lead, relative to the historic levels of lead in pre-regulation Avgas).Refineries blend Avgas with tetraethyllead (TEL) to achieve these high octane ratings, a practice that governments no longer permit for gasoline intended for road vehicles. The shrinking supply of TEL and the possibility of environmental legislation banning its use have made a search for replacement fuels for general aviation aircraft a priority for pilots’ organizations.Turbine engines and aircraft diesel engines burn various grades of jet fuel. Jet fuel is a relatively less volatile petroleum derivative based on kerosene, but certified to strict aviation standards, with additional additives.Model aircraft typically use nitro engines (also known as ""glow engines"" due to the use of a glow plug) powered by glow fuel, a mixture of methanol, nitromethane, and lubricant. Electrically powered model airplanes and helicopters are also commercially available. Small multicopter UAVs are almost always powered by electricity, but larger gasoline-powered designs are under development.


== See also ==


== Notes ==


== References ==


== External links ==
Aircraft Engines and Aircraft Engine Theory (includes links to diagrams)
The Aircraft Engine Historical Society
Jet Engine Specification Database
Aircraft Engine Efficiency: Comparison of Counter-rotating and Axial Aircraft LP Turbines
The History of Aircraft Power Plants Briefly Reviewed : From the "" 7 lb. per h.p"" Days to the "" 1 lb. per h.p"" of To-day
""The Quest for Power"" a 1954 Flight article by Bill Gunston
""Engine Directory"". Flight International. 24 September 1997."
"""Engine Engine #9"" is a song written and recorded by American country music artist Roger Miller. It was released in May 1965 as the lead single from the album, The 3rd Time Around. The song peaked at number 2 on the U.S. country singles chart.The song was most famously quoted in rap duo Black Sheep's song ""The Choice Is Yours (Revisited)"", an extended version of another song, ""The Choice Is Yours"".  This quote refers to the MTA NYC # 9 subway line that used to exist.


== Chart performance ==


== References =="
"A game engine, also known as a game architecture, game framework or gameframe, is a software-development environment designed for people to build video games. Developers use game engines to construct games for consoles, mobile devices, and personal computers. The core functionality typically provided by a game engine includes a rendering engine (""renderer"") for 2D or 3D graphics, a physics engine or collision detection (and collision response), sound, scripting, animation, artificial intelligence, networking, streaming, memory management, threading, localization support, scene graph, and may include video support for  cinematics. Implementers often economize on the process of game development by reusing/adapting, in large part, the same game engine to produce different games
or to aid in porting games to multiple platforms.


== Purpose ==
In many cases, game engines provide a suite of visual development tools in addition to reusable software components. These tools are generally provided in an integrated development environment to enable simplified, rapid development of games in a data-driven manner. Game-engine developers attempt to ""pre-invent the wheel"" by developing robust software suites which include many elements a game developer may need to build a game. Most game-engine suites provide facilities that ease development, such as graphics, sound, physics and artificial-intelligence (AI) functions. These game engines are sometimes called ""middleware"" because, as with the  business sense of the term, they provide a flexible and reusable software platform which provides all the core functionality needed, right  out of the box, to develop a game application while reducing costs, complexities, and time-to-market — all critical factors in the highly competitive video-game industry. As of 2001, Gamebryo, JMonkeyEngine and RenderWare were widely-used middleware programs of this type.Like other types of middleware, game engines usually provide  platform  abstraction, allowing the same game to run on various platforms (including game consoles and personal computers) with few, if any, changes made to the game source-code. Often, programmers design game engines  with a  component-based architecture that allows specific systems in the engine to be replaced or extended with more specialized (and often more expensive) game-middleware components. Some game engines comprise a series of loosely connected game middleware components that can be selectively combined to create a custom engine, instead of the more common approach of extending or customizing a flexible integrated product. However achieved, extensibility remains a high priority for game engines due to the wide variety of uses for which they are applied. Despite the specificity of the name ""game engine"", end-users often re-purpose game engines for other kinds of interactive applications with  real-time graphical requirements - such as  marketing demos, architectural visualizations, training simulations, and  modeling environments.Some game engines only provide  real-time 3D rendering capabilities instead of the wide range of functionality needed by games. These engines rely upon the game developer to implement the rest of this functionality or to assemble it from other game-middleware components. These types of engines are generally referred to as a ""graphics engine"", ""rendering engine"", or ""3D engine"" instead of the more encompassing term ""game engine"". This terminology is inconsistently used, as many full-featured 3D game engines are referred to simply as ""3D engines"". Examples of graphics engines include: Crystal Space, Genesis3D,  Irrlicht, OGRE, RealmForge, Truevision3D, and Vision Engine. Modern game- or graphics-engines generally provide a scene graph - an object-oriented representation of the 3D game-world which often simplifies game design and can be used for more efficient rendering of vast virtual worlds.
As technology ages, the components of an engine may become outdated or insufficient for the requirements of a given project. Since the complexity of programming an entirely new engine may result in unwanted delays (or necessitate that a project re-start from the beginning), an engine-development team may elect to update their existing engine with newer functionality or components.


== Components ==
Such a framework is composed of a multitude of very different components.


=== Main game program ===
The actual game logic has to be implemented by some algorithms. It is distinct from any rendering.


=== Rendering engine ===
The rendering engine generates animated 3D graphics by any of a number of methods (rasterization, ray-tracing etc.).
Instead of being programmed and compiled to be executed on the CPU or GPU directly, most often rendering engines are built upon one or multiple rendering application programming interfaces (APIs), such as Direct3D, OpenGL, or Vulkan which provide a software abstraction of the graphics processing unit (GPU). Low-level libraries such as DirectX, Simple DirectMedia Layer (SDL), and GLFW are also commonly used in games as they provide platform-independent access to the windowing system and allow the application to allocate a surface on a computer screen where the graphics will be displayed, this is commonly referred to as graphical context creation. These libraries usually also provide access to other computer hardware such as input devices (mouse, keyboard, and joystick), network cards, and sound cards. Before hardware-accelerated 3D graphics, software renderers had been used. Software rendering is still used in some modeling tools or for still-rendered images when visual accuracy is valued over real-time performance (frames-per-second) or when the computer hardware does not meet needs such as shader support.
With the advent of hardware accelerated physics processing, various physics APIs such as PAL and the physics extensions of COLLADA became available to provide a software abstraction of the physics processing unit of different middleware providers and console platforms.
Game engines can be written in any programming language like C++, C or Java, though each language is structurally different and may provide different levels of access to specific functions. Often a Scripting Language like Javascript / ECMAScript gets added as the second layer to speed up the development.


=== Audio engine ===
The audio engine is the component which consists of algorithms related to the loading, modifying and output of sound through the client's speaker system. At a minimum it must be able to load, decompress and play sound files. More advanced audio engines can calculate and produce such things as Doppler effects, echoes, pitch/amplitude adjustments, oscillation, etc.  It can perform calculations on the CPU, or on a dedicated ASIC. Abstraction APIs, such as OpenAL, SDL audio, XAudio 2, Web Audio, etc. are available.


=== Physics engine ===

The physics engine is responsible for simulating the laws of physics realistically within the application. Specifically, it provides a set of functions for simulating physical forces and collisions, acting on the various objects within the game at run time.


=== Artificial intelligence ===
The AI is usually outsourced from the main game program into a special module to be designed and written by software engineers with specialist knowledge. Most games will implement very different AI systems, and thus, AI is considered to be specific to the particular game for which it is created. Many modern game engines come packaged with search algorithms such as A-star and subroutines for baking level geometry into a Navmesh which can help speed up the process of scripting AI behavior.


== History ==

Before game engines, games were typically written as singular entities: a game for the Atari 2600, for example, had to be designed from the bottom up to make optimal use of the display hardware—this core display routine is today called the kernel by retro developers. Other platforms had more leeway, but even when the display was not a concern, memory constraints usually sabotaged attempts to create the data-heavy design that an engine needs. Even on more accommodating platforms, very little could be reused between games. The rapid advance of arcade hardware—which was the leading edge of the market at the time—meant that most of the code would have to be thrown out afterwards anyway, as later generations of games would use completely different game designs that took advantage of extra resources. Thus most game designs through the 1980s were designed through a hard-coded ruleset with a small number of levels and graphics data. Since the golden age of arcade video games, it became common for video game companies to develop in-house game engines for use with first party software.
While third-party game engines were not common up until the rise of 3D computer graphics in the 1990s, there were several 2D game creation systems produced in the 1980s for independent video game development. These include Pinball Construction Set (1983), ASCII's War Game Construction Kit (1983), Thunder Force Construction (1984), Adventure Construction Set (1984), Garry Kitchen's GameMaker (1985), Wargame Construction Set (1986), Shoot-'Em-Up Construction Kit (1987), Arcade Game Construction Kit (1988), and most popularly ASCII's RPG Maker engines from 1998 onwards. Klik & Play (1994) is another legacy offering that's still available.
The term ""game engine"" arose in the mid-1990s, especially in connection with 3D games such as first-person shooters (FPS). (See also: first-person shooter engine.) Such was the popularity of Id Software's Doom and Quake games that, rather than work from scratch, other developers licensed the core portions of the software and designed their own graphics, characters, weapons and levels—the ""game content"" or ""game assets"". Separation of game-specific rules and data from basic concepts like collision detection and game entity meant that teams could grow and specialize.
Later games, such as id Software's Quake III Arena and Epic Games's 1998 Unreal were designed with this approach in mind, with the engine and content developed separately. The practice of licensing such technology has proved to be a useful auxiliary revenue stream for some game developers, as one license for a high-end commercial game engine can range from US$10,000 to millions of dollars, and the number of licensees can reach several dozen companies, as seen with the Unreal Engine. At the very least, reusable engines make developing game sequels faster and easier, which is a valuable advantage in the competitive video game industry. While there was a strong rivalry between Epic and id around 2000, since then Epic's Unreal Engine has been far more popular than id Tech 4 and its successor id Tech 5.Modern game engines are some of the most complex applications written, often featuring dozens of finely tuned systems interacting to ensure a precisely controlled user experience. The continued evolution of game engines has created a strong separation between rendering, scripting, artwork, and level design. It is now common, for example, for a typical game development team to have several times as many artists as actual programmers.First-person shooter games remain the predominant users of third-party game engines, but they are now also being used in other genres. For example, the role-playing video game The Elder Scrolls III: Morrowind and the MMORPG Dark Age of Camelot are based on the Gamebryo engine, and the MMORPG Lineage II is based on the Unreal Engine. Game engines are used for games originally developed for home consoles as well; for example, the RenderWare engine is used in the Grand Theft Auto and Burnout franchises.
Threading is taking on more importance due to modern multi-core systems (e.g. Cell) and increased demands in realism. Typical threads involve rendering, streaming, audio, and physics. Racing games have typically been at the forefront of threading with the physics engine running in a separate thread long before other core subsystems were moved, partly because rendering and related tasks need updating at only 30–60 Hz. For example, on PlayStation 3, physics ran in Need For Speed at 100 Hz versus Forza Motorsport 2 at 360 Hz.
Although the term was first used in the 1990s, there are a few earlier systems in the 1980s that are also considered to be game engines, such as Sierra's Adventure Game Interpreter (AGI) and SCI systems, LucasArts' SCUMM system and Incentive Software's Freescape engine (in 1986). Unlike most modern game engines, these game engines were never used in any third-party products (except for the SCUMM system which was licensed to and used by Humongous Entertainment).
As game engine technology matures and becomes more user-friendly, the application of game engines has broadened in scope. They are now being used for serious games: visualization, training, medical, and military simulation applications, with the CryEngine being one example. To facilitate this accessibility, new hardware platforms are now being targeted by game engines, including mobile phones (e.g. Android phones, iPhone) and web browsers (e.g. WebGL, Shockwave, Flash, Trinigy's WebVision, Silverlight, Unity Web Player, O3D and pure DHTML).Additionally, more game engines are being built upon higher level languages such as Java and C#/.NET (e.g. TorqueX, and Visual3D.NET), Python (Panda3D), or Lua Script (Leadwerks). As most 3D rich games are now mostly GPU-limited (i.e. limited by the power of the graphics card), the potential slowdown due to translation overheads of higher level languages becomes negligible, while the productivity gains offered by these languages work to the game engine developers' benefit. These recent trends are being propelled by companies such as Microsoft to support Indie game development. Microsoft developed XNA as the SDK of choice for all video games released on Xbox and related products. This includes the Xbox Live Indie Games channel designed specifically for smaller developers who don't have the extensive resources necessary to box games for sale on retail shelves. It is becoming easier and cheaper than ever to develop game engines for platforms that support managed frameworks.


== Game engines as an industry ==
Producers of game engines decide how they allow users to utilize their products. Just as gaming is an industry, so are the engines they are built off. The major game engines come at varying prices, whether it be in the form of subscription fees or license payments.Unreal Engine 4, one of the major game engines and used to create several notable games such as Fortnite, PlayerUnknown's Battlegrounds, and Life Is Strange 2, adopted a free-to-use structure with a royalty on all game sales using this engine. Although the differences among the different game engines blur as they are built upon during the game creation process, different game developers may either be too used to a system to change, or attracted by the huge benefits of such engines regardless of pay-walls.
Another game engine currently bringing in a notable income is the Unity engine, utilizing a similar pay module to the Unreal Engine. This engine is behind games such as Rust, Subnautica, and Life Is Strange: Before the Storm.


== Game middleware ==
In the broader sense of the term, game engines themselves can be described as middleware. In the context of video games, however, the term ""middleware"" is often used to refer to subsystems of functionality within a game engine. Some game middleware does only one thing but does it more convincingly or more efficiently than general purpose middleware. For example, SpeedTree was used to render the realistic trees and vegetation in the role-playing video game The Elder Scrolls IV: Oblivion and Fork Particle was used to simulate and render real time particle system visual effects or particle effects in Sid Meier's Civilization V.The four most widely used middleware packages that provide subsystems of functionality include RAD Game Tools' Bink, Firelight FMOD, Havok, and Scaleform GFx. RAD Game Tools develops Bink for basic video rendering, along with Miles audio, and Granny 3D rendering. Firelight FMOD is a low cost robust audio library and toolset. Havok provides a robust physics simulation system, along with a suite of animation and behavior applications. Scaleform provides GFx for high performance Flash UI and high-quality video playback, and an Input Method Editor (IME) add-on for in-game Asian chat support.
Other middleware is used for performance optimisation - for example 'Simplygon' helps to optimise and generate level of detail meshes, and 'Umbra' adds occlusion culling optimisations to 3d graphics.
Some middleware contains full source code, others just provide an API reference for a compiled binary library. Some middleware programs can be licensed either way, usually for a higher fee for full source code.


== First-person shooter engines ==

A subset of game engines are 3D first-person shooter (FPS) game engines. Groundbreaking development in terms of visual quality is done in order to get FPS games to its current standard. The level of visual details emphasized in these games have become increasingly precise, something that engines focused on flight and driving simulators and real-time strategy (RTS) games don't contain.
The development of the FPS graphic engines that appear in games can be characterized by a steady increase in technologies, with some breakthroughs. Attempts at defining distinct generations lead to arbitrary choices of what constitutes a highly modified version of an ""old engine"" and what is a brand-new engine.The classification is complicated as game engines blend old and new technologies. Features that were considered advanced in a new game one year become the expected standard the next year. Games with a mix of older generation and newer feature are the norm.


== See also ==
List of game engines
List of first-person shooter engines
3D computer graphics
List of game middleware
Authoring system


== References =="
"Search engine optimization (SEO) is the process of growing the quality and quantity of website traffic by increasing the visibility of a website or a web page to users of a web search engine. SEO refers to the improvement of unpaid results (known as ""natural"" or ""organic"" results) and excludes direct traffic and the purchase of paid placement. Additionally, it may target different kinds of searches, including image search, video search, academic search, news search, and industry-specific vertical search engines. Promoting a site to increase the number of backlinks, or inbound links, is another SEO tactic. By May 2015, mobile search had surpassed desktop search.As an Internet marketing strategy, SEO considers how search engines work, the computer-programmed algorithms that dictate search engine behavior, what people search for, the actual search terms or keywords typed into search engines, and which search engines are preferred by their targeted audience. SEO is performed because a website will receive more visitors from a search engine when websites rank higher in the search engine results page (SERP). These visitors can then potentially be converted into customers.SEO differs from local search engine optimization in that the latter is focused on optimizing a business' online presence so that its web pages will be displayed by search engines when a user enters a local search for its products or services. The former instead is more focused on national or international searches.


== History ==
Webmasters and content providers began optimizing websites for search engines in the mid-1990s, as the first search engines were cataloging the early Web. Initially, all webmasters only needed to submit the address of a page, or URL, to the various engines which would send a web crawler to crawl that page, extract links to other pages from it, and return information found on the page to be indexed. The process involves a search engine spider downloading a page and storing it on the search engine's own server. A second program, known as an indexer, extracts information about the page, such as the words it contains, where they are located, and any weight for specific words, as well as all links the page contains. All of this information is then placed into a scheduler for crawling at a later date.
Website owners recognized the value of a high ranking and visibility in search engine results, creating an opportunity for both white hat and black hat SEO practitioners. According to industry analyst Danny Sullivan, the phrase ""search engine optimization"" probably came into use in 1997. Sullivan credits Bruce Clay as one of the first people to popularize the term. On May 2, 2007, Jason Gambert attempted to trademark the term SEO by convincing the Trademark Office in Arizona that SEO is a ""process"" involving manipulation of keywords and not a ""marketing service.""
Early versions of search algorithms relied on webmaster-provided information such as the keyword meta tag or index files in engines like ALIWEB. Meta tags provide a guide to each page's content. Using metadata to index pages was found to be less than reliable, however, because the webmaster's choice of keywords in the meta tag could potentially be an inaccurate representation of the site's actual content. Inaccurate, incomplete, and inconsistent data in meta tags could and did cause pages to rank for irrelevant searches. Web content providers also manipulated some attributes within the HTML source of a page in an attempt to rank well in search engines. By 1997, search engine designers recognized that webmasters were making efforts to rank well in their search engine, and that some webmasters were even manipulating their rankings in search results by stuffing pages with excessive or irrelevant keywords. Early search engines, such as Altavista and Infoseek, adjusted their algorithms to prevent webmasters from manipulating rankings.By heavily relying on factors such as keyword density, which were exclusively within a webmaster's control, early search engines suffered from abuse and ranking manipulation. To provide better results to their users, search engines had to adapt to ensure their results pages showed the most relevant search results, rather than unrelated pages stuffed with numerous keywords by unscrupulous webmasters. This meant moving away from heavy reliance on term density to a more holistic process for scoring semantic signals. Since the success and popularity of a search engine is determined by its ability to produce the most relevant results to any given search, poor quality or irrelevant search results could lead users to find other search sources. Search engines responded by developing more complex ranking algorithms, taking into account additional factors that were more difficult for webmasters to manipulate. In 2005, an annual conference, AIRWeb (Adversarial Information Retrieval on the Web), was created to bring together practitioners and researchers concerned with search engine optimization and related topics.Companies that employ overly aggressive techniques can get their client websites banned from the search results. In 2005, the Wall Street Journal reported on a company, Traffic Power, which allegedly used high-risk techniques and failed to disclose those risks to its clients. Wired magazine reported that the same company sued blogger and SEO Aaron Wall for writing about the ban. Google's Matt Cutts later confirmed that Google did in fact ban Traffic Power and some of its clients.Some search engines have also reached out to the SEO industry, and are frequent sponsors and guests at SEO conferences, webchats, and seminars. Major search engines provide information and guidelines to help with website optimization. Google has a Sitemaps program to help webmasters learn if Google is having any problems indexing their website and also provides data on Google traffic to the website. Bing Webmaster Tools provides a way for webmasters to submit a sitemap and web feeds, allows users to determine the ""crawl rate"", and track the web pages index status.
In 2015, it was reported that Google was developing and promoting mobile search as a key feature within future products. In response, many brands began to take a different approach to their Internet marketing strategies.


=== Relationship with Google ===
In 1998, two graduate students at Stanford University, Larry Page and Sergey Brin, developed ""Backrub"", a search engine that relied on a mathematical algorithm to rate the prominence of web pages. The number calculated by the algorithm, PageRank, is a function of the quantity and strength of inbound links. PageRank estimates the likelihood that a given page will be reached by a web user who randomly surfs the web, and follows links from one page to another. In effect, this means that some links are stronger than others, as a higher PageRank page is more likely to be reached by the random web surfer.
Page and Brin founded Google in 1998. Google attracted a loyal following among the growing number of Internet users, who liked its simple design. Off-page factors (such as PageRank and hyperlink analysis) were considered as well as on-page factors (such as keyword frequency, meta tags, headings, links and site structure) to enable Google to avoid the kind of manipulation seen in search engines that only considered on-page factors for their rankings. Although PageRank was more difficult to game, webmasters had already developed link building tools and schemes to influence the Inktomi search engine, and these methods proved similarly applicable to gaming PageRank. Many sites focused on exchanging, buying, and selling links, often on a massive scale. Some of these schemes, or link farms, involved the creation of thousands of sites for the sole purpose of link spamming.By 2004, search engines had incorporated a wide range of undisclosed factors in their ranking algorithms to reduce the impact of link manipulation. In June 2007, The New York Times' Saul Hansell stated Google ranks sites using more than 200 different signals. The leading search engines, Google, Bing, and Yahoo, do not disclose the algorithms they use to rank pages. Some SEO practitioners have studied different approaches to search engine optimization, and have shared their personal opinions. Patents related to search engines can provide information to better understand search engines. In 2005, Google began personalizing search results for each user. Depending on their history of previous searches, Google crafted results for logged in users.In 2007, Google announced a campaign against paid links that transfer PageRank. On June 15, 2009, Google disclosed that they had taken measures to mitigate the effects of PageRank sculpting by use of the nofollow attribute on links. Matt Cutts, a well-known software engineer at Google, announced that Google Bot would no longer treat any nofollow links, in the same way, to prevent SEO service providers from using nofollow for PageRank sculpting. As a result of this change the usage of nofollow led to evaporation of PageRank. In order to avoid the above, SEO engineers developed alternative techniques that replace nofollowed tags with obfuscated JavaScript and thus permit PageRank sculpting. Additionally several solutions have been suggested that include the usage of iframes, Flash and JavaScript.In December 2009, Google announced it would be using the web search history of all its users in order to populate search results. On June 8, 2010 a new web indexing system called Google Caffeine was announced. Designed to allow users to find news results, forum posts and other content much sooner after publishing than before, Google Caffeine was a change to the way Google updated its index in order to make things show up quicker on Google than before. According to Carrie Grimes, the software engineer who announced Caffeine for Google, ""Caffeine provides 50 percent fresher results for web searches than our last index..."" Google Instant, real-time-search, was introduced in late 2010 in an attempt to make search results more timely and relevant. Historically site administrators have spent months or even years optimizing a website to increase search rankings. With the growth in popularity of social media sites and blogs the leading engines made changes to their algorithms to allow fresh content to rank quickly within the search results.In February 2011, Google announced the Panda update, which penalizes websites containing content duplicated from other websites and sources. Historically websites have copied content from one another and benefited in search engine rankings by engaging in this practice. However, Google implemented a new system which punishes sites whose content is not unique. The 2012 Google Penguin attempted to penalize websites that used manipulative techniques to improve their rankings on the search engine. Although Google Penguin has been presented as an algorithm aimed at fighting web spam, it really focuses on spammy links by gauging the quality of the sites the links are coming from. The 2013 Google Hummingbird update featured an algorithm change designed to improve Google's natural language processing and semantic understanding of web pages. Hummingbird's language processing system falls under the newly recognized term of ""conversational search"" where the system pays more attention to each word in the query in order to better match the pages to the meaning of the query rather than a few words. With regards to the changes made to search engine optimization, for content publishers and writers, Hummingbird is intended to resolve issues by getting rid of irrelevant content and spam, allowing Google to produce high-quality content and rely on them to be 'trusted' authors.
In October 2019, Google announced they would start applying BERT models for English language search queries in the US. Bidirectional Encoder Representations from Transformers (BERT) was another attempt by Google to improve their natural language processing but this time in order to better understand the search queries of their users. In terms of search engine optimization, BERT intended to connect users more easily to relevant content and increase the quality of traffic coming to websites that are ranking in the Search Engine Results Page.


== Methods ==


=== Getting indexed ===

The leading search engines, such as Google, Bing and Yahoo!, use crawlers to find pages for their algorithmic search results. Pages that are linked from other search engine indexed pages do not need to be submitted because they are found automatically. The Yahoo! Directory and DMOZ, two major directories which closed in 2014 and 2017 respectively, both required manual submission and human editorial review. Google offers Google Search Console, for which an XML Sitemap feed can be created and submitted for free to ensure that all pages are found, especially pages that are not discoverable by automatically following links in addition to their URL submission console. Yahoo! formerly operated a paid submission service that guaranteed crawling for a cost per click; however, this practice was discontinued in 2009.
Search engine crawlers may look at a number of different factors when crawling a site. Not every page is indexed by the search engines. The distance of pages from the root directory of a site may also be a factor in whether or not pages get crawled.Today, most people are searching on Google using a mobile device. In November 2016, Google announced a major change to the way crawling websites and started to make their index mobile-first, which means the mobile version of a given website becomes the starting point for what Google includes in their index. In May 2019, Google updated the rendering engine of their crawler to be the latest version of Chromium (74 at the time of the announcement).  Google indicated that they would regularly update the Chromium rendering engine to the latest version.  In December 2019, Google began updating the User-Agent string of their crawler to reflect the latest Chrome version used by their rendering service.  The delay was to allow webmasters time to update their code that responded to particular bot User-Agent strings.  Google ran evaluations and felt confident the impact would be minor.


=== Preventing crawling ===

To avoid undesirable content in the search indexes, webmasters can instruct spiders not to crawl certain files or directories through the standard robots.txt file in the root directory of the domain. Additionally, a page can be explicitly excluded from a search engine's database by using a meta tag specific to robots (usually <meta name=""robots"" content=""noindex""> ). When a search engine visits a site, the robots.txt located in the root directory is the first file crawled. The robots.txt file is then parsed and will instruct the robot as to which pages are not to be crawled. As a search engine crawler may keep a cached copy of this file, it may on occasion crawl pages a webmaster does not wish crawled. Pages typically prevented from being crawled include login specific pages such as shopping carts and user-specific content such as search results from internal searches. In March 2007, Google warned webmasters that they should prevent indexing of internal search results because those pages are considered search spam.


=== Increasing prominence ===
A variety of methods can increase the prominence of a webpage within the search results. Cross linking between pages of the same website to provide more links to important pages may improve its visibility.
Writing content that includes frequently searched keyword phrase, so as to be relevant to a wide variety of search queries will tend to increase traffic. Updating content so as to keep search engines crawling back frequently can give additional weight to a site. Adding relevant keywords to a web page's metadata, including the title tag and meta description, will tend to improve the relevancy of a site's search listings, thus increasing traffic. URL canonicalization of web pages accessible via multiple URLs, using the canonical link element or via 301 redirects can help make sure links to different versions of the URL all count towards the page's link popularity score. 


=== White hat versus black hat techniques ===
SEO techniques can be classified into two broad categories: techniques that search engine companies recommend as part of good design (""white hat""), and those techniques of which search engines do not approve (""black hat""). The search engines attempt to minimize the effect of the latter, among them spamdexing. Industry commentators have classified these methods, and the practitioners who employ them, as either white hat SEO, or black hat SEO. White hats tend to produce results that last a long time, whereas black hats anticipate that their sites may eventually be banned either temporarily or permanently once the search engines discover what they are doing.An SEO technique is considered white hat if it conforms to the search engines' guidelines and involves no deception. As the search engine guidelines are not written as a series of rules or commandments, this is an important distinction to note. White hat SEO is not just about following guidelines but is about ensuring that the content a search engine indexes and subsequently ranks is the same content a user will see. White hat advice is generally summed up as creating content for users, not for search engines, and then making that content easily accessible to the online ""spider"" algorithms, rather than attempting to trick the algorithm from its intended purpose. White hat SEO is in many ways similar to web development that promotes accessibility, although the two are not identical.
Black hat SEO attempts to improve rankings in ways that are disapproved of by the search engines, or involve deception. One black hat technique uses hidden text, either as text colored similar to the background, in an invisible div, or positioned off screen. Another method gives a different page depending on whether the page is being requested by a human visitor or a search engine, a technique known as cloaking. Another category sometimes used is grey hat SEO. This is in between black hat and white hat approaches, where the methods employed avoid the site being penalized but do not act in producing the best content for users. Grey hat SEO is entirely focused on improving search engine rankings.
Search engines may penalize sites they discover using black or grey hat methods, either by reducing their rankings or eliminating their listings from their databases altogether. Such penalties can be applied either automatically by the search engines' algorithms, or by a manual site review. One example was the February 2006 Google removal of both BMW Germany and Ricoh Germany for use of deceptive practices. Both companies, however, quickly apologized, fixed the offending pages, and were restored to Google's search engine results page.


== As marketing strategy ==
SEO is not an appropriate strategy for every website, and other Internet marketing strategies can be more effective, such as paid advertising through pay per click (PPC) campaigns, depending on the site operator's goals. Search engine marketing (SEM) is the practice of designing, running and optimizing search engine ad campaigns. Its difference from SEO is most simply depicted as the difference between paid and unpaid priority ranking in search results. SEM focuses on prominence more so than relevance; website developers should regard SEM with the utmost importance with consideration to visibility as most navigate to the primary listings of their search. A successful Internet marketing campaign may also depend upon building high-quality web pages to engage and persuade internet users, setting up analytics programs to enable site owners to measure results, and improving a site's conversion rate. In November 2015, Google released a full 160-page version of its Search Quality Rating Guidelines to the public, which revealed a shift in their focus towards ""usefulness"" and mobile search. In recent years the mobile market has exploded, overtaking the use of desktops, as shown in by StatCounter in October 2016 where they analyzed 2.5 million websites and found that 51.3% of the pages were loaded by a mobile device. Google has been one of the companies that are utilizing the popularity of mobile usage by encouraging websites to use their Google Search Console, the Mobile-Friendly Test, which allows companies to measure up their website to the search engine results and determine how user-friendly their websites are. 
SEO may generate an adequate return on investment. However, search engines are not paid for organic search traffic, their algorithms change, and there are no guarantees of continued referrals. Due to this lack of guarantee and the uncertainty, a business that relies heavily on search engine traffic can suffer major losses if the search engines stop sending visitors. Search engines can change their algorithms, impacting a website's search engine ranking, possibly resulting in a serious loss of traffic. According to Google's CEO, Eric Schmidt, in 2010, Google made over 500 algorithm changes – almost 1.5 per day. It is considered a wise business practice for website operators to liberate themselves from dependence on search engine traffic. In addition to accessibility in terms of web crawlers (addressed above), user web accessibility has become increasingly important for SEO.


== International markets ==
Optimization techniques are highly tuned to the dominant search engines in the target market.
The search engines' market shares vary from market to market, as does competition.
In 2003, Danny Sullivan stated that Google represented about 75% of all searches. In markets outside the United States, Google's share is often larger, and Google remains the dominant search engine worldwide as of 2007. As of 2006, Google had an 85–90% market share in Germany. While there were hundreds of SEO firms in the US at that time, there were only about five in Germany. As of June 2008, the market share of Google in the UK was close to 90% according to Hitwise. That market share is achieved in a number of countries.
As of 2009, there are only a few large markets where Google is not the leading search engine. In most cases, when Google is not leading in a given market, it is lagging behind a local player. The most notable example markets are China, Japan, South Korea, Russia and the Czech Republic where respectively Baidu, Yahoo! Japan, Naver, Yandex and Seznam are market leaders.
Successful search optimization for international markets may require professional translation of web pages, registration of a domain name with a top level domain in the target market, and web hosting that provides a local IP address. Otherwise, the fundamental elements of search optimization are essentially the same, regardless of language.


== Legal precedents ==
On October 17, 2002, SearchKing filed suit in the United States District Court, Western District of Oklahoma, against the search engine Google. SearchKing's claim was that Google's tactics to prevent spamdexing constituted a tortious interference with contractual relations.  On May 27, 2003, the court granted Google's motion to dismiss the complaint because SearchKing ""failed to state a claim upon which relief may be granted.""In March 2006, KinderStart filed a lawsuit against Google over search engine rankings. KinderStart's website was removed from Google's index prior to the lawsuit, and the amount of traffic to the site dropped by 70%. On March 16, 2007, the United States District Court for the Northern District of California (San Jose Division) dismissed KinderStart's complaint without leave to amend, and partially granted Google's motion for Rule 11 sanctions against KinderStart's attorney, requiring him to pay part of Google's legal expenses.


== See also ==


== Notes ==


== External links ==

Web Development Promotion at Curlie
Google Webmaster Guidelines
Google Search Quality Evaluators Guidelines, July 20, 2018 (PDF)
Yahoo! Webmaster Guidelines
Bing Webmaster Guidelines
""The Dirty Little Secrets of Search"", article in The New York Times (February 12, 2011)
Google I/O 2010 – SEO site advice from the experts on YouTube – Technical tutorial on search engine optimization, given at Google I/O 2010."
"The Unreal Engine is a game engine developed by Epic Games, first showcased in the 1998 first-person shooter game Unreal. Although initially developed for first-person shooters, it has been used in a variety of other genres, including platformers, fighting games, MMORPGs, and other RPGs. Written in C++, the Unreal Engine features a high degree of portability, supporting a wide range of platforms.
The latest release is Unreal Engine 4, which launched in 2014 under a subscription model. Since 2015, it can be downloaded for free, with its source code available on GitHub. Epic allows for its use in commercial products based on a royalty model, typically asking developers for 5% of revenues from sales, though with the success of Fortnite, which has become a testbed for Unreal Engine for Epic, Epic waives this fee for developers that publish their games through the Epic Games Store. On May 13th, 2020, Epic announced that their portion of royalties for games developed in Unreal Engine are waived until developers have earned their first US$1 million in revenue, retroactively applying to January 1st, 2020. Unreal Engine 5 is scheduled for release by late 2021.


== History ==


=== First generation ===

The first-generation Unreal Engine was developed by Tim Sweeney, the founder of Epic Games. Having created editing tools for the shareware games ZZT (1991) and Jill of the Jungle (1992), Sweeney began writing the engine in 1995 for the production of a game that would later become a first-person shooter known as Unreal. After years in development, it debuted with the game's release in 1998, although MicroProse and Legend Entertainment had access to the technology much earlier, licensing it in 1996. According to an interview, Sweeney ""wrote 90 percent of the code in the engine."" As with ZZT, he used the IBM Model M keyboard while programming.Among its features were collision detection, colored lighting, and a limited form of texture filtering. The engine also integrated a level editor, UnrealEd, that had support for real-time constructive solid geometry operations as early as 1996, allowing mappers to change the level layout on the fly. Even though Unreal was designed to compete with id Software, developers of Doom and Quake, John Carmack complimented the game for the use of 16-bit color while remarking its implementation of visual effects such as volumetric fog. ""I doubt any important game will be designed with 8-bit color in mind from now on. Unreal has done an important thing in pushing toward direct color, and this gives the artists a lot more freedom,"" he said in an article written by Geoff Keighley for GameSpot. ""Light blooms [the spheres of light], fog volumes, and composite skies were steps I was planning on taking, but Epic got there first with Unreal,"" he said, adding: ""The Unreal engine has raised the bar on what action gamers expect from future products. The visual effects first seen in the game will become expected from future games.""At first, the engine relied completely on software rendering, meaning the graphics calculations were handled by the CPU. However, over time, it was able to take advantage of the capabilities provided by graphics cards, focusing on the Glide API, specially designed for 3dfx accelerators. While supported, OpenGL and Direct3D reported a slower performance compared to Glide due to their deficiency in texture management. According to Sweeney, the hardest part of the engine to program was the renderer, as he had to rewrite it several times during development, though he found less ""glamorous"" the infrastructure connecting all the subsystems. With regard to audio, Epic employed the Galaxy Sound System, a software programmed in assembly language that integrated both EAX and Aureal technologies, and allowed the use of tracker music, which gave level designers flexibility in how the soundtrack was played at a specific point.

Unreal was noted for its graphical innovations, but Sweeney recognized in an interview with Eurogamer that many aspects of the game were unpolished, citing complaints about its high system requirements and online gameplay issues. The development of Unreal Tournament enabled Epic to address these points, incorporating several enhancements in the engine intended to optimize performance on low-end machines and improve the networking code, while refining the artificial intelligence for bots to display coordination in team-based environments. In addition to being available on Microsoft Windows, Linux, Mac and Unix, the engine was ported through Unreal Tournament to the PlayStation 2 and, with the help of Secret Level, to the Dreamcast.By late 1999, The New York Times indicated that there had been sixteen external projects using Epic's technology, including Deus Ex, The Wheel of Time, and Duke Nukem Forever, the latter of which was originally based on the Quake II engine. Unlike id Software, whose engine business only offered the source code, Epic provided support for licensees and met with them to discuss improvements to its game development system. While it cost around $3 million to produce and licenses for up to $350,000, Epic gave players the ability to modify its games with the incorporation of UnrealEd and a scripting language called UnrealScript, sparking a community of enthusiasts around a game engine built to be extensible over multiple generations of games.
The big goal with the Unreal technology all long was to build up a base of code that could be extended and improved through many generations of games. Meeting that goal required keeping the technology quite general-purpose, writing clean code, and designing the engine to be very extensible. The early plans to design an extensible multi-generational engine happened to give us a great advantage in licensing the technology as it reached completion. After we did a couple of licensing deals, we realised it was a legitimate business. Since then, it has become a major component of our strategy.


=== Unreal Engine 2 ===

In October 1998, IGN reported, based on an interview with affiliate Voodoo Extreme, that Sweeney was doing research for his next-generation engine. With development starting a year later, the second version made its debut in 2002 with America's Army, a free multiplayer shooter developed by the U.S. Army as a recruitment device. Soon after, Epic would release Unreal Championship on the Xbox, with it being one of the first games to utilize Microsoft's Xbox Live.Though based on its predecessor, this generation saw a notable advance in rendering terms as well as new improvements to the tool set. Capable of running levels nearly 100 times more detailed than those found in Unreal, the engine integrated a variety of features, including a cinematic editing tool, particle systems, export plug-ins for 3D Studio Max and Maya, and a skeletal animation system first showcased in the PlayStation 2 version of Unreal Tournament. In addition, the user interface for UnrealEd was rewritten in C++ using the wxWidgets toolkit, which Sweeney said was the ""best thing available"" at the time.Physical simulations, such as ragdoll player collisions and arbitrary rigid body dynamics, were powered by the Karma physics engine. With Unreal Tournament 2004, vehicle-based gameplay was successfully implemented, enabling large-scale combat. While Unreal Tournament 2003 had support for vehicle physics through the Karma engine, as demonstrated by a testmap with a ""hastily-constructed vehicle"", it wasn't until Psyonix created a modification out of Epic's base code that the game received fully coded vehicles. Impressed by their efforts, Epic decided to include it in its successor as a new game mode under the name of Onslaught by hiring Psyonix as a contractor. Psyonix would later develop Rocket League before being acquired by Epic in 2019.A specialized version of UE2 called UE2X was designed for Unreal Championship 2: The Liandri Conflict on the original Xbox platform, featuring optimizations specific to that console. In March 2011, Ubisoft Montreal revealed that UE2 was successfully running on the Nintendo 3DS via Tom Clancy's Splinter Cell 3D. ""The 3DS is powerful, and we are able to run the Unreal Engine on this console, which is pretty impressive for a handheld machine, and the 3D doesn't affect the performance (thanks to my amazing programmers),"" said Ubisoft's Fabrice Cuny.


=== Unreal Engine 3 ===
Screenshots of Unreal Engine 3 were presented in 2004, at which point the engine had already been in development for over 18 months. The engine was based on the first-generation, but contained new features. ""The basic architectural decisions visible to programmers of an object-oriented design, a data-driven scripting approach, and a fairly modular approach to subsystems still remain [from Unreal Engine 1]. But the parts of the game that are really visible to gamers –the renderer, the physics system, the sound system, and the tools– are all visibly new and dramatically more powerful,"" said Sweeney. Unlike Unreal Engine 2, which still supported a fixed-function pipeline, Unreal Engine 3 was designed to take advantage of fully programmable shader hardware. All lighting and shadowing calculations were done per-pixel, instead of per-vertex. On the rendering side, Unreal Engine 3 provided support for a gamma-correct high-dynamic range renderer. The first games released using Unreal Engine 3 were Gears of War for Xbox 360, and RoboBlitz for Windows, which were both released on November 7, 2006.

Initially, Unreal Engine 3 only supported Windows, PlayStation 3, and Xbox 360 platforms, while iOS (first demonstrated with Epic Citadel) and Android were added later in 2010, with Infinity Blade being the first iOS title and Dungeon Defenders the first Android title. In 2011, it was announced that the engine would support Adobe Flash Player 11 through the Stage 3D hardware-accelerated APIs and that it was being used in two Wii U games, Batman: Arkham City and Aliens: Colonial Marines. In 2013, Epic teamed-up with Mozilla to bring Unreal Engine 3 to the web; using the asm.js sublanguage and Emscripten compiler, they were able to port the engine in four days.Throughout the lifetime of UE3, significant updates were incorporated, including improved destructible environments, soft body dynamics, large crowd simulation, iOS functionality, Steamworks integration, a real-time global illumination solution, and stereoscopic 3D on Xbox 360 via TriOviz for Games Technology. DirectX 11 support was demonstrated with the Samaritan demo, which was unveiled at the 2011 Game Developers Conference and built by Epic Games in a close partnership with NVIDIA, with engineers working around the country to push real-time graphics to a new high point.


==== Unreal Development Kit ====
While Unreal Engine 3 was quite open for modders to work with, the ability to publish and sell games meant using UE3 was restricted to licensees of the engine. However, in November 2009, Epic released a free version of UE3's SDK, called the Unreal Development Kit (UDK), that is available to the general public.In December 2010, the kit was updated to include support for creating iOS games and apps. OS X compatibility followed in the September 2011 release.


=== Unreal Engine 4 ===

Development on Unreal Engine 4 began in 2003, according to Mark Rein, the vice-president of Epic Games. In early 2008, Sweeney revealed in an interview that he was basically the only person working on the engine, although he stated the research and development team would expand over time, designing the engine in parallel with the efforts by the UE3 team. In February 2012, Rein said ""people are going to be shocked later this year when they see Unreal Engine 4""; Epic unveiled UE4 to limited attendees at the 2012 Game Developers Conference, and a video of the engine being demonstrated by technical artist Alan Willard was released to the public on June 7, 2012, via GameTrailers TV.One of the major features planned for UE4 was real-time global illumination using voxel cone tracing, eliminating pre-computed lighting. However, this feature, called Sparse Voxel Octree Global Illumination (SVOGI), has been replaced with a similar but less computationally expensive algorithm due to performance concerns. UE4 also includes the new ""Blueprints"" visual scripting system (a successor to UE3's ""Kismet""), which allows for rapid development of game logic without using code, resulting in less of a divide between technical artists, designers, and programmers.
I could say: 'I'm going to convert this pillar into a blueprint [in the Engine] and add some sort of trap to it.' It means I can really go in and start enhancing my world with interaction that just would not have been possible without a technical artist, a designer and a programmer and now any one of those three can do all of it, provided they have the assets handy. The fact that I can just go in and say, 'If you're within X distance of this thing, start to glow and take my distance to it, normalize it zero to one and then just lerp [oscillate] between two different brightness values, so as I reach for something it gets hot'...that would have been something do-able but very difficult for anybody except a gameplay programmer. And he wouldn't have known how to set up the assets, but now any one of the three could do it.
On March 19, 2014, at the Game Developers Conference (GDC), Epic Games released Unreal Engine 4 through a new licensing model. For a monthly subscription at US$19, developers were given access to the full version of the engine, including the C++ source code, which could be downloaded via GitHub. Any released product was charged with a 5% royalty of gross revenues. The first game released using Unreal Engine 4 was Daylight, developed with early access to the engine and released on April 29, 2014.On September 4, 2014, Epic released Unreal Engine 4 to schools and universities for free, including personal copies for students enrolled in accredited video game development, computer science, art, architecture, simulation, and visualization programs. On February 19, 2015, Epic launched Unreal Dev Grants, a $5 million development fund aiming to provide grants to creative projects using Unreal Engine 4.

In March 2015, Epic released Unreal Engine 4, along with all future updates, for free for all users. In exchange, Epic established a selective royalty schedule, asking for 5% of revenue for products that make more than $3,000 per quarter. Sweeney stated that when they moved to the subscription model in 2014, use of Unreal grew by 10 times and through many smaller developers, and believed that they would draw even more uses through this new pricing scheme.In an attempt to attract Unreal Engine developers, Oculus VR announced in October 2016 that it will pay royalty fees for all Unreal-powered Oculus Rift titles published on their store for up to the first $5 million of gross revenue per game.To prepare for the release of its free-to-play battle royale mode in Fortnite in September 2017, Epic had to make a number of Unreal Engine modifications that helped it to handle a large number (up to 100) of connections to the same server while still retaining high bandwidth, and to improve the rendering of a large open in-game world. Epic said it would incorporate these changes into future updates of the Unreal Engine.With the opening of the Epic Games Store in December 2018, Epic will not charge the 5% revenue fee on games that use the Unreal Engine and released through the Epic Games Stores, absorbing that cost as part of the base 12% cut Epic is taking to cover other costs.Effective May 13, 2020, and retroactive to January 1, 2020, the royalty exemption amount is increased to $1,000,000 USD in lifetime gross revenue per title.


==== Supported platforms ====


=== Unreal Engine 5 ===

Unreal Engine 5 was revealed on May 13, 2020 with expected launch in late-2021, supporting all existing systems including the next-generation consoles PlayStation 5 and Xbox Series X. Work on the engine started about two years prior to its announcement. Among its major features include Nanite, an engine that allows for high-detailed photographic source material to be imported into games. The Nanite virtualized geometry technology allows Epic to take advantage of its past acquisition of Quixel, the world's largest photogrammetry library in 2019. The goal of Unreal Engine 5 was to make it as easy as possible for developers to create detailed game worlds without having to spend excessive time on creating new detailed assets, allowing the engine software to handle these factors. Nanite can import nearly any other pre-existing three-dimension representation of objects and environments, including ZBrush and CAD models, allowing the use of film-quality assets. Nanite automatically handles the levels of detail (LODs) of these imported objects appropriate to the target platform and draw distance, a task that an artist would have had to perform otherwise. Lumen is another component described as a ""fully dynamic global illumination solution that immediately reacts to scene and light changes"". Lumen eliminates the need for artists and developers to craft a lightmap for a given scene, but instead calculates light reflections and shadows on the fly, thus allowing for real-time behavior of light sources. Additional components include Niagara for fluid and particle dynamics and Chaos for a physics engine.With potentially tens of billions of polygons present on a single screen at 4k resolution, Epic also developed the Unreal Engine 5 to take advantage of the upcoming high-speed storage solutions with the next-generation console hardware that will use a mix of RAM and custom solid-state drives. Epic had worked closely with Sony in optimizing Unreal Engine 5 for the PlayStation 5, with Epic helping Sony with the console's storage architecture, which Sweeney said is ""far ahead of anything you can buy on anything on PC for any amount of money right now.""  To demonstrate the ease of creating a detailed world with minimal effort, the May 2020 reveal of the engine showcased a demo called ""Lumen in the Land of Nanite"" running on a PlayStation 5 that was built by mostly pulling assets from the Quixel library and using the Nanite, Lumen, and other Unreal Engine 5 components to create a seemingly-realistic cave setting that could be explored. Epic affirmed that Unreal Engine 5 would be fully supported on the Xbox Series X as well, but had been focused on the PlayStation 5 during the announcement as a result of their work with Sony in the years prior. Epic plans to use Fortnite as a testbed for Unreal Engine 5 to showcase what the engine can do to the industry, with the game expected to use the engine by mid-2021. Ninja Theory's Senua's Saga: Hellblade II will also be one of the first games to use Unreal Engine 5.Unreal Engine 5 will retain the current royalty model, with developers returning 5% of gross revenues to Epic Games, though this fee is forgiven for those that release their games on the Epic Games Store. Further, Epic announced alongside Unreal Engine 5 that they will not take any fee from games using any version of Unreal Engine for the first US$1 million in gross revenue, retroactive to January 1, 2020.


== UnrealScript ==
UnrealScript (often abbreviated to UScript) was Unreal Engine's native scripting language used for authoring game code and gameplay events before the release of Unreal Engine 4. The language was designed for simple, high-level game programming. The UnrealScript interpreter was programmed by Sweeney, who also created an earlier game scripting language, ZZT-oop.Similar to Java, UnrealScript was object-oriented without multiple inheritance (classes all inherit from a common Object class), and classes were defined in individual files named for the class they define. Unlike Java, UnrealScript did not have object wrappers for primitive types. Interfaces were only supported in Unreal Engine generation 3 and a few Unreal Engine 2 games. UnrealScript supported operator overloading, but not method overloading, except for optional parameters.
At the 2012 Game Developers Conference, Epic announced that UnrealScript was being removed from Unreal Engine 4 in favor of C++. Visual scripting would be supported by the Blueprints Visual Scripting system, a replacement for the earlier Kismet visual scripting system.
One of the key moments in Unreal Engine 4's development was, we had a series of debates about UnrealScript – the scripting language I'd built that we'd carried through three generations. And what we needed to do to make it competitive in the future. And we kept going through bigger and bigger feature lists of what we needed to do to upgrade it, and who could possibly do the work, and it was getting really, really unwieldy. And there was this massive meeting to try and sort it out, and try to cut things and decide what to keep, and plan and...there was this point where I looked at that and said 'you know, everything you're proposing to add to UnrealScript is already in C++. Why don't we just kill UnrealScript and move to pure C++? You know, maximum performance and maximum debuggability. It gives us all these advantages.'


== Marketplace ==
With Unreal Engine 4, Epic opened the Unreal Engine Marketplace in September 2014. The Marketplace is a digital storefront that allows content creators and developers to provide art assets, models, sounds, environments, code snippets, and other features that others could purchase, along with tutorials and other guides. Some content is provided for free by Epic, including previously offered Unreal assets and tutorials. Prior to July 2018, Epic took a 30% share of the sales but due to the success of Unreal and Fortnite Battle Royale, Epic retroactively reduced its take to 12%.


== Use in film making ==
The Unreal Engine has found use in film making, such as in the production of television series like with The Mandalorian and Westworld. In these series, virtual sets can be created within Unreal, and then rendered to large LED projection screens and atmospheric lighting systems that track with a camera's motion around actors and objects. The overall appearance was recognized to appear more natural than typical chromakey effects, and allows for real-time composition of shots, immediate editing of the virtual sets as needed, and the ability to shoot multiple scenes within a short period by just changing the virtual world behind the actors. Jon Favreau and Lucasarts' Industrial Light & Magic division had worked with Epic in developing their StageCraft technology for The Mandalorian, based on a similar approach Favreau had used in The Lion King. Favreau shared this technology approach with Jonathan Nolan and Lisa Joy, the producers for Westworld. The show had already looked at the use of virtual sets before and had some technology established, but integrated the use of Unreal Engine as with StageCraft for the third season of the show.Orca Studios, a Spanish-based company, has been working with Epic to establish multiple studios for virtual filming similar to the StageCraft approach with the Unreal Engine providing the virtual sets, particularly during the 2019–20 COVID-19 pandemic which had restricted travel.


== Awards ==
Technology & Engineering Emmy Award from the National Academy of Television Arts and Sciences for ""3D Engine Software for the Production of Animation"" in 2018
Game Developer Magazine Front Line Award for Best Game Engine for 2004, 2005, 2006, 2007, 2009, 2010, 2011, and 2012
Develop Industry Excellence Award for Best Engine for 2009, 2010, 2011 2013, 2016, 2017, and 2018
Guinness World Record for most successful video game engine


== See also ==
List of Unreal Engine games
3D computer graphics


== References ==


== Further reading ==


== External links ==
Official website"
"A web search engine or Internet search engine is a software system that is designed to carry out web search (Internet search), which means to search the World Wide Web in a systematic way for particular information specified in a textual web search query. The search results are generally presented in a line of results, often referred to as search engine results pages (SERPs). The information may be a mix of links to web pages, images, videos, infographics, articles, research papers, and other types of files. Some search engines also mine data available in databases or open directories. Unlike web directories, which are maintained only by human editors, search engines also maintain real-time information by running an algorithm on a web crawler.
Internet content that is not capable of being searched by a web search engine is generally described as the deep web.


== History ==

The thought for indexing information began as far back as 1945 in Vannevar Bush's The Atlantic Monthly article ""As We May Think"". Vannevar expressed the emphasis on information in the future and the need for scientists to design a way to incorporate information found in journals. He suggested a memory device called the Memex, used to compress and store information which could then be retrieved with speed and flexibility. Internet search engines themselves predate the debut of the Web in December 1990. The Who is user search dates back to 1982 and the Knowbot Information Service multi-network user search was first implemented in 1989. The first well documented search engine that searched content files, namely FTP files, was Archie, which debuted on 10 September 1990.Prior to September 1993, the World Wide Web was entirely indexed by hand. There was a list of webservers edited by Tim Berners-Lee and hosted on the CERN webserver. One snapshot of the list in 1992 remains, but as more and more web servers went online the central list could no longer keep up. On the NCSA site, new servers were announced under the title ""What's New!""The first tool used for searching content (as opposed to users) on the Internet was Archie. The name stands for ""archive"" without the ""v"". It was created by Alan Emtage, Bill Heelan and J. Peter Deutsch, computer science students at McGill University in Montreal, Quebec, Canada. The program downloaded the directory listings of all the files located on public anonymous FTP (File Transfer Protocol) sites, creating a searchable database of file names; however, Archie Search Engine did not index the contents of these sites since the amount of data was so limited it could be readily searched manually.
The rise of Gopher (created in 1991 by Mark McCahill at the University of Minnesota) led to two new search programs, Veronica and Jughead. Like Archie, they searched the file names and titles stored in Gopher index systems. Veronica (Very Easy Rodent-Oriented Net-wide Index to Computerized Archives) provided a keyword search of most Gopher menu titles in the entire Gopher listings. Jughead (Jonzy's Universal Gopher Hierarchy Excavation And Display) was a tool for obtaining menu information from specific Gopher servers. While the name of the search engine ""Archie Search Engine"" was not a reference to the Archie comic book series, ""Veronica"" and ""Jughead"" are characters in the series, thus referencing their predecessor.
In the summer of 1993, no search engine existed for the web, though numerous specialized catalogues were maintained by hand. Oscar Nierstrasz at the University of Geneva wrote a series of Perl scripts that periodically mirrored these pages and rewrote them into a standard format. This formed the basis for W3Catalog, the web's first primitive search engine, released on September 2, 1993.In June 1993, Matthew Gray, then at MIT, produced what was probably the first web robot, the Perl-based World Wide Web Wanderer, and used it to generate an index called ""Wandex"". The purpose of the Wanderer was to measure the size of the World Wide Web, which it did until late 1995. The web's second search engine Aliweb appeared in November 1993. Aliweb did not use a web robot, but instead depended on being notified by website administrators of the existence at each site of an index file in a particular format.
JumpStation (created in December 1993 by Jonathon Fletcher) used a web robot to find web pages and to build its index, and used a web form as the interface to its query program. It was thus the first WWW resource-discovery tool to combine the three essential features of a web search engine (crawling, indexing, and searching) as described below. Because of the limited resources available on the platform it ran on, its indexing and hence searching were limited to the titles and headings found in the web pages the crawler encountered.
One of the first ""all text"" crawler-based search engines was WebCrawler, which came out in 1994. Unlike its predecessors, it allowed users to search for any word in any webpage, which has become the standard for all major search engines since. It was also the search engine that was widely known by the public. Also in 1994, Lycos (which started at Carnegie Mellon University) was launched and became a major commercial endeavor.
The first popular search engine on the Web was Yahoo! Search. The first product from Yahoo!, founded by Jerry Yang and David Filo in January 1994, was a Web directory called Yahoo! Directory. In 1995, a search function was added, allowing users to search Yahoo! Directory! It became one of the most popular ways for people to find web pages of interest, but its search function operated on its web directory, rather than its full-text copies of web pages.
Soon after, a number of search engines appeared and vied for popularity. These included Magellan, Excite, Infoseek, Inktomi, Northern Light, and AltaVista. Information seekers could also browse the directory instead of doing a keyword-based search.
In 1996, Robin Li developed the RankDex site-scoring algorithm for search engines results page ranking and received a US patent for the technology. It was the first search engine that used hyperlinks to measure the quality of websites it was indexing, predating the very similar algorithm patent filed by Google two years later in 1998. Larry Page referenced Li's work in some of his U.S. patents for PageRank. Li later used his Rankdex technology for the Baidu search engine, which was founded by Robin Li in China and launched in 2000.
In 1996, Netscape was looking to give a single search engine an exclusive deal as the featured search engine on Netscape's web browser. There was so much interest that instead Netscape struck deals with five of the major search engines: for $5 million a year, each search engine would be in rotation on the Netscape search engine page. The five engines were Yahoo!, Magellan, Lycos, Infoseek, and Excite.Google adopted the idea of selling search terms in 1998, from a small search engine company named goto.com. This move had a significant effect on the SE business, which went from struggling to one of the most profitable businesses in the Internet.Search engines were also known as some of the brightest stars in the Internet investing frenzy that occurred in the late 1990s. Several companies entered the market spectacularly, receiving record gains during their initial public offerings. Some have taken down their public search engine, and are marketing enterprise-only editions, such as Northern Light. Many search engine companies were caught up in the dot-com bubble, a speculation-driven market boom that peaked in 1999 and ended in 2001.
Around 2000, Google's search engine rose to prominence. The company achieved better results for many searches with an algorithm called PageRank, as was explained in the paper Anatomy of a Search Engine written by Sergey Brin and Larry Page, the later founders of Google. This iterative algorithm ranks web pages based on the number and PageRank of other web sites and pages that link there, on the premise that good or desirable pages are linked to more than others. Larry Page's patent for PageRank cites Robin Li's earlier RankDex patent as an influence. Google also maintained a minimalist interface to its search engine. In contrast, many of its competitors embedded a search engine in a web portal. In fact, Google search engine became so popular that spoof engines emerged such as Mystery Seeker.
By 2000, Yahoo! was providing search services based on Inktomi's search engine. Yahoo! acquired Inktomi in 2002, and Overture (which owned AlltheWeb and AltaVista) in 2003. Yahoo! switched to Google's search engine until 2004, when it launched its own search engine based on the combined technologies of its acquisitions.
Microsoft first launched MSN Search in the fall of 1998 using search results from Inktomi. In early 1999 the site began to display listings from Looksmart, blended with results from Inktomi. For a short time in 1999, MSN Search used results from AltaVista instead. In 2004, Microsoft began a transition to its own search technology, powered by its own web crawler (called msnbot).
Microsoft's rebranded search engine, Bing, was launched on June 1, 2009. On July 29, 2009, Yahoo! and Microsoft finalized a deal in which Yahoo! Search would be powered by Microsoft Bing technology.
As of 2019, active search engine crawlers include those of Google, Sogou, Baidu, Bing, Gigablast, Mojeek, DuckDuckGo and Yandex.


== Approach ==

A search engine maintains the following processes in near real time:

Web crawling
Indexing
SearchingWeb search engines get their information by web crawling from site to site. The ""spider"" checks for the standard filename robots.txt, addressed to it. The robots.txt file contains directives for search spiders, telling it which pages to crawl. After checking for robots.txt and either finding it or not, the spider sends certain information back to be indexed depending on many factors, such as the titles, page content, JavaScript, Cascading Style Sheets (CSS), headings, or its metadata in HTML meta tags. After a certain number of pages crawled, amount of data indexed, or time spent on the website, the spider stops crawling and moves on. ""[N]o web crawler may actually crawl the entire reachable web. Due to infinite websites, spider traps, spam, and other exigencies of the real web, crawlers instead apply a crawl policy to determine when the crawling of a site should be deemed sufficient. Some websites are crawled exhaustively, while others are crawled only partially"".Indexing means associating words and other definable tokens found on web pages to their domain names and HTML-based fields. The associations are made in a public database, made available for web search queries. A query from a user can be a single word, multiple words or a sentence. The index helps find information relating to the query as quickly as possible. Some of the techniques for indexing, and caching are trade secrets, whereas web crawling is a straightforward process of visiting all sites on a systematic basis.
Between visits by the spider, the cached version of page (some or all the content needed to render it) stored in the search engine working memory is quickly sent to an inquirer. If a visit is overdue, the search engine can just act as a web proxy instead. In this case the page may differ from the search terms indexed. The cached page holds the appearance of the version whose words were previously indexed, so a cached version of a page can be useful to the web site when the actual page has been lost, but this problem is also considered a mild form of linkrot.

Typically when a user enters a query into a search engine it is a few keywords. The index already has the names of the sites containing the keywords, and these are instantly obtained from the index. The real processing load is in generating the web pages that are the search results list: Every page in the entire list must be weighted according to information in the indexes. Then the top search result item requires the lookup, reconstruction, and markup of the snippets showing the context of the keywords matched. These are only part of the processing each search results web page requires, and further pages (next to the top) require more of this post processing.
Beyond simple keyword lookups, search engines offer their own GUI- or command-driven operators and search parameters to refine the search results. These provide the necessary controls for the user engaged in the feedback loop users create by filtering and weighting while refining the search results, given the initial pages of the first search results.
For example, from 2007 the Google.com search engine has allowed one to filter by date by clicking ""Show search tools"" in the leftmost column of the initial search results page, and then selecting the desired date range. It's also possible to weight by date because each page has a modification time. Most search engines support the use of the boolean operators AND, OR and NOT to help end users refine the search query. Boolean operators are for literal searches that allow the user to refine and extend the terms of the search. The engine looks for the words or phrases exactly as entered. Some search engines provide an advanced feature called proximity search, which allows users to define the distance between keywords. There is also concept-based searching where the research involves using statistical analysis on pages containing the words or phrases you search for. As well, natural language queries allow the user to type a question in the same form one would ask it to a human. A site like this would be ask.com.The usefulness of a search engine depends on the relevance of the result set it gives back. While there may be millions of web pages that include a particular word or phrase, some pages may be more relevant, popular, or authoritative than others. Most search engines employ methods to rank the results to provide the ""best"" results first. How a search engine decides which pages are the best matches, and what order the results should be shown in, varies widely from one engine to another. The methods also change over time as Internet usage changes and new techniques evolve. There are two main types of search engine that have evolved: one is a system of predefined and hierarchically ordered keywords that humans have programmed extensively. The other is a system that generates an ""inverted index"" by analyzing texts it locates. This first form relies much more heavily on the computer itself to do the bulk of the work.
Most Web search engines are commercial ventures supported by advertising revenue and thus some of them allow advertisers to have their listings ranked higher in search results for a fee. Search engines that do not accept money for their search results make money by running search related ads alongside the regular search engine results. The search engines make money every time someone clicks on one of these ads.


=== Local search ===
Local search is the process that optimizes efforts of local businesses. They focus on change to make sure all searches are consistent. It's important because many people determine where they plan to go and what to buy based on their searches.


== Market share ==
As of September 2019, Google is the world's most used search engine, with a market share of 92.96 percent, and the world's most used search engines are:


=== East Asia and Russia ===
In Russia, Yandex commands a market share of 61.9 percent, compared to Google's 28.3 percent. In China, Baidu is the most popular search engine. South Korea's homegrown search portal, Naver, is used for 70 percent of online searches in the country. Yahoo! Japan and Yahoo! Taiwan are the most popular avenues for Internet searches in Japan and Taiwan, respectively.China is one of the only countries where Google is not in the top 3 for web search engines. Google was a top search engine in China but they had to give up in China due to cyber attack and failed attempt to follow China’s censorship rules. That’s also the reason why Google is not number one in Russia and East Asia countries. These countries all have strict censorship rules. Rules that other search engines can follow better than Google.


=== Europe ===
Most countries' markets in Western Europe are dominated by Google, except for the Czech Republic, where Seznam is a strong competitor.


== Search engine bias ==
Although search engines are programmed to rank websites based on some combination of their popularity and relevancy, empirical studies indicate various political, economic, and social biases in the information they provide and the underlying assumptions about the technology. These biases can be a direct result of economic and commercial processes (e.g., companies that advertise with a search engine can become also more popular in its organic search results), and political processes (e.g., the removal of search results to comply with local laws). For example, Google will not surface certain neo-Nazi websites in France and Germany, where Holocaust denial is illegal.
Biases can also be a result of social processes, as search engine algorithms are frequently designed to exclude non-normative viewpoints in favor of more ""popular"" results. Indexing algorithms of major search engines skew towards coverage of U.S.-based sites, rather than websites from non-U.S. countries.Google Bombing is one example of an attempt to manipulate search results for political, social or commercial reasons.
Several scholars have studied the cultural changes triggered by search engines, and the representation of certain controversial topics in their results, such as terrorism in Ireland, climate change denial, and conspiracy theories.


== Customized results and filter bubbles ==
Many search engines such as Google and Bing provide customized results based on the user's activity history. This leads to an effect that has been called a filter bubble. The term describes a phenomenon in which websites use algorithms to selectively guess what information a user would like to see, based on information about the user (such as location, past click behaviour and search history). As a result, websites tend to show only information that agrees with the user's past viewpoint. This puts the user in a state of intellectual isolation without contrary information. Prime examples are Google's personalized search results and Facebook's personalized news stream. According to Eli Pariser, who coined the term, users get less exposure to conflicting viewpoints and are isolated intellectually in their own informational bubble. Pariser related an example in which one user searched Google for ""BP"" and got investment news about British Petroleum while another searcher got information about the Deepwater Horizon oil spill and that the two search results pages were ""strikingly different"". The bubble effect may have negative implications for civic discourse, according to Pariser. Since this problem has been identified, competing search engines have emerged that seek to avoid this problem by not tracking or ""bubbling"" users, such as DuckDuckGo. Other scholars do not share Pariser's view, finding the evidence in support of his thesis unconvincing.


== Religious search engines ==
The global growth of the Internet and electronic media in the Arab and Muslim World during the last decade has encouraged Islamic adherents in the Middle East and Asian sub-continent, to attempt their own search engines, their own filtered search portals that would enable users to perform safe searches. More than usual safe search filters, these Islamic web portals categorizing websites into being either ""halal"" or ""haram"", based on interpretation of the ""Law of Islam"". ImHalal came online in September 2011. Halalgoogling came online in July 2013. These use haram filters on the collections from Google and Bing (and others).While lack of investment and slow pace in technologies in the Muslim World has hindered progress and thwarted success of an Islamic search engine, targeting as the main consumers Islamic adherents, projects like Muxlim, a Muslim lifestyle site, did receive millions of dollars from investors like Rite Internet Ventures, and it also faltered. Other religion-oriented search engines are Jewogle, the Jewish version of Google, and SeekFind.org, which is Christian. SeekFind filters sites that attack or degrade their faith.


== Search engine submission ==
Web search engine submission is a process in which a webmaster submits a website directly to a search engine. While search engine submission is sometimes presented as a way to promote a website, it generally is not necessary because the major search engines use web crawlers that will eventually find most web sites on the Internet without assistance. They can either submit one web page at a time, or they can submit the entire site using a sitemap, but it is normally only necessary to submit the home page of a web site as search engines are able to crawl a well designed website. There are two remaining reasons to submit a web site or web page to a search engine: to add an entirely new web site without waiting for a search engine to discover it, and to have a web site's record updated after a substantial redesign.
Some search engine submission software not only submits websites to multiple search engines, but also adds links to websites from their own pages. This could appear helpful in increasing a website's ranking, because external links are one of the most important factors determining a website's ranking. However, John Mueller of Google has stated that this ""can lead to a tremendous number of unnatural links for your site"" with a negative impact on site ranking.


== See also ==


== References ==


== Further reading ==
Steve Lawrence; C. Lee Giles (1999). ""Accessibility of information on the web"". Nature. 400 (6740): 107–9. Bibcode:1999Natur.400..107L. doi:10.1038/21987. PMID 10428673.
Bing Liu (2007), Web Data Mining: Exploring Hyperlinks, Contents and Usage Data. Springer,ISBN 3-540-37881-2
Bar-Ilan, J. (2004). The use of Web search engines in information science research. ARIST, 38, 231-288.
Levene, Mark (2005). An Introduction to Search Engines and Web Navigation. Pearson.
Hock, Randolph (2007). The Extreme Searcher's Handbook.ISBN 978-0-910965-76-7
Javed Mostafa (February 2005). ""Seeking Better Web Searches"". Scientific American. 292 (2): 66–73. Bibcode:2005SciAm.292b..66M. doi:10.1038/scientificamerican0205-66.
Ross, Nancy; Wolfram, Dietmar (2000). ""End user searching on the Internet: An analysis of term pair topics submitted to the Excite search engine"". Journal of the American Society for Information Science. 51 (10): 949–958. doi:10.1002/1097-4571(2000)51:10<949::AID-ASI70>3.0.CO;2-5.
Xie, M.;  et al. (1998). ""Quality dimensions of Internet search engines"". Journal of Information Science. 24 (5): 365–372. doi:10.1177/016555159802400509.
Information Retrieval: Implementing and Evaluating Search Engines. MIT Press. 2010.


== External links ==
Search Engines at Curlie"
"A browser engine (also known as a layout engine or rendering engine) is a core software component of every major web browser. The primary job of a browser engine is to transform HTML documents and other resources of a web page into an interactive visual representation on a user's device.


== Name and scope ==
A browser engine is not a stand-alone computer program but a critical piece of a larger program, such as a web browser, from which the term is derived. (The word ""engine"" is an analogy to the engine of a car.)
Besides ""browser engine"", two other terms are in common use regarding related concepts: ""layout engine"" and ""rendering engine"".  In theory, layout and rendering (or ""painting"") could be handled by separate engines.  In practice, however, they are tightly coupled and rarely considered separately.
In addition to layout and rendering, a browser engine enforces the security policy between documents, handles navigation through hyperlinks and data submitted through forms, and implements the Document Object Model (DOM) data structure exposed to page scripts.
Executing JavaScript (JS) code is a separate matter, however, as every major web browser uses a dedicated engine for this. The JS language was originally created for use in browsers, but it is now used elsewhere too, so the implementation of JS engines is decoupled from browser engines. In a web browser, the two engines work in concert via the shared DOM data structure.
Browser engines are used in other types of programs besides web browsers. Email clients need them to display HTML email. The Electron framework, which is powered by the two engines of the Google Chrome browser, has been used to create many applications.


== Layout and rendering ==
The layout of a web page is typically specified by Cascading Style Sheets (CSS). Each style sheet is a series of rules which the browser engine interprets. For example, some rules specify typography details, such as font, color, and text size. The engine combines all relevant CSS rules to calculate precise graphical coordinates for the visual representation it will paint on the screen.Some engines may begin rendering before all of a page's resources are downloaded. This can result in visual changes as more data is received, such as images being gradually filled in or a flash of unstyled content.


== Notable engines ==

Because the Web platform is a set of open standards, there are multiple browser engine implementations.
Gecko is Mozilla's browser engine, used in its Firefox web browser, the Thunderbird email client, and the SeaMonkey internet suite. Goanna is a fork of Gecko used in the Pale Moon browser.Apple created the WebKit engine for its Safari browser by forking the KHTML engine of the KDE project.Google originally used WebKit for its Chrome browser but eventually forked it to create the Blink engine. All Chromium-based browsers use Blink, as do applications built with CEF, Electron, or any other framework that embeds Chromium.
Although Apple permits third-party browsers as alternatives to Safari on iOS devices, all browsers distributed through its App Store must use WebKit as their engine. For example, Opera Mini for iOS uses WebKit, whereas all other Opera variants use Blink. (Opera formerly used its own proprietary Presto engine.)
Microsoft maintains its own proprietary EdgeHTML engine, which is the successor of its Trident engine. However, EdgeHTML is now only used for Universal Windows Platform apps, as the Edge browser has been remade with the Blink engine.


=== Timeline ===


== References =="
"The inline-four engine or straight-four engine is a four-cylinder internal combustion engine in which the cylinders are mounted in a straight line or plane along the crankcase. The single bank of cylinders may be oriented in either a vertical or an inclined plane with all the pistons driving a common crankshaft. Where it is inclined, it is sometimes called a slant-four. In a specification chart or when an abbreviation is used, an inline-four engine is listed either as I4 or L4 (for longitudinal, to avoid confusion between the digit 1 and the letter I).
The inline-four layout is in perfect primary balance and confers a degree of mechanical simplicity that makes it popular for economy cars. However, it suffers from a secondary imbalance that causes minor vibrations in smaller engines, and more powerful vibrations as engine size and power increase. So, the more powerful engines used in larger cars are generally more complex designs with more than four cylinders.
Today almost all manufacturers of four-cylinder automobile engines produce the inline-four layout, with Subaru and Porsche 718 flat-four engines being notable exceptions, and so four-cylinder is usually synonymous with and a more widely used term than inline-four. The inline-four is the most common engine configuration in modern cars, with the V6 engine the second most popular. In the late 2000s (decade), due to stringent government regulations mandating reduced vehicle emissions and increased fuel efficiency, the proportion of new vehicles sold in the U.S. with four-cylinder engines (largely of the inline-four type) rose from 30 percent to 47 percent between 2005 and 2008, particularly in mid-size vehicles where a decreasing number of buyers have chosen the V6 performance option.


== Displacement ==
This configuration is most commonly used for petrol engine displacements up to 3.0 L. Porsche, for instance, used a 3.0 L four in its 944 S2 and 968 sports cars. Production cars with inline-fours larger than 3.0 L have included the 1927 Model A Ford (3.3 L (201 cu in)), the 1965-1980 International Harvester Scout (3.2 L (195 cu in)), the 1961-1963 Pontiac Tempest (3.2 L (195 cu in) Pontiac Trophy 4 engine) and, in smaller quantities, the 1927-1931 Bentley 4½ Litre. A few very early vehicles had inline-four engines with much larger displacements, including the 1910 Blitzen Benz (21.5 L (1,312 cu in)) and the 1911 Fiat S76 Record (28.4 L (1,733 cu in)).
Inline-four diesel engines, which are lower revving than gasoline engines, often exceed 3.0 L. Mitsubishi still employs a 3.2 L inline-four turbodiesel in its Pajero (called the Shogun or Montero in certain markets), and several manufacturers of light commercial vehicles and large four-wheel drive vehicles, such as Fiat Powertrain Technologies, Isuzu, Nissan, Tata Motors, and Toyota employ a 3.0 L inline-four diesel.
Larger inline-four engines are used in industrial applications, such as in small trucks and tractors, are often found with displacements up to about 5 L. Diesel engines for stationary, marine and locomotive use (which run at low speeds) are made in much larger sizes.
Generally, European and Asian manufacturers of trucks with a gross vehicle weight rating between 7.5 and 18 tonnes use inline four-cylinder diesel engines with displacements around 5 L. The MAN D0834 engine is a 4.6 L inline-4 with 220 hp (164 kW) and 627 lb⋅ft (850 N⋅m), which is available for the MAN TGL light-duty truck and VARIOmobil motorhomes. The Isuzu Forward is a medium-duty truck which is available with a 5.2 L inline-four engine that delivers 210 hp (157 kW) and 470 lb⋅ft (640 N⋅m). The Hino Ranger is a medium-duty truck which is available with a 5.1 L inline-four engine that delivers 175 hp (130 kW) and 465 lb⋅ft (630 N⋅m). The earlier Hino Ranger even had a 5.3 L inline-four engine.The Kubota M135X is a tractor with a 6.1 L inline-four. This turbo-diesel engine has a bore of 118 mm (4.6 in) and a relatively long stroke of 140 mm (5.5 in).One of the strongest Powerboat-4-cylinders is the Volvo Penta D4-300 turbodiesel. This is a 3.7 L-inline-4 with 300 hp (224 kW) and 516 lb⋅ft (700 N⋅m).Brunswick Marine built a 127 kW (170 bhp) 3.7 L 4-cylinder gasoline engine (designated as the ""470"") for their Mercruiser Inboard/outboard line. The block was formed from one half of a Ford 460 cubic inch V8 engine. This engine was produced in the 1970s and 1980s.One of the largest inline-four engines is the MAN B&W 4K90 marine engine. This two-stroke turbo-diesel has a giant displacement of 6,489 L. This results from a massive 0.9 meter bore and 2.5 meter stroke. The 4K90 engine develops 18,280 kW (24,854 PS; 24,514 hp) at 94 rpm and weighs 787 tons.The largest on-road inline-4 cylinder turbo-diesel engine is the Detroit Diesel Series 50, with a displacement of 8.5 L. It is widely used in various applications such as buses, trucks, and more. Power ratings varied from 250 hp to 350 hp. It was manufactured from 1994, until 2005. The Series 50 was also marketed as the Series 50G, for its CNG and LNG versions.
Displacement can also be very small, as found in kei cars sold in Japan, such as the Subaru EN series; engines that started out at 550 cc and are currently at 660 cc, with variable valve timing, DOHC and superchargers resulting in engines that often claim the legal maximum of 64 PS (47 kW; 63 bhp). The 1.2 L, turbocharged, direct-injected, Toyota 8NR-FTS engine has a maximum power output of 114 hp (85 kW) and a maximum torque of 190 Nm (140 lbft) at a low rpm (1500 rpm).


== Balance and smoothness ==

The inline-four engine is much smoother than one- or two-cylinder engines, and this has resulted in it becoming the engine of choice for most economy cars for many years. Its prominent advantage is the lack of rocking vibration, and the lack of need for heavy counterweights makes it easier to be sporty (quick revving up and down). However, it tends to show secondary imbalance at high rpm because two pistons always move together, making the imbalance twice as strong as other configurations without them.


=== Piston speed ===
An even-firing inline-four engine is in primary balance because the pistons are moving in pairs, and one pair of pistons is always moving up at the same time as the other pair is moving down. However, piston acceleration and deceleration is greater in the top half of the crankshaft rotation than in the bottom half, because the connecting rods are not infinitely long, resulting in a non-sinusoidal motion. As a result, two pistons are always accelerating faster in one direction, while the other two are accelerating more slowly in the other direction, which leads to a secondary dynamic imbalance that causes an up-and-down vibration at twice crankshaft speed. This imbalance is common among all piston engines, but the effect is particularly strong on inline-four because of the two pistons always moving together.
The reason for the piston's higher speed during the 180° rotation from mid-stroke through top-dead-centre, and back to mid-stroke, is that the minor contribution to the piston's up/down movement from the connecting rod's change of angle here has the same direction as the major contribution to the piston's up/down movement from the up/down movement of the crank pin. By contrast, during the 180° rotation from mid-stroke through bottom-dead-centre and back to mid-stroke, the minor contribution to the piston's up/down movement from the connecting rod's change of angle has the opposite direction of the major contribution to the piston's up/down movement from the up/down movement of the crank pin.
The strength of this imbalance is determined by 1. Reciprocating mass, 2. Ratio of connecting rod length to stroke, and 3. Acceleration of piston movement. So small displacement engines with light pistons show little effect, and racing engines use long connecting rods. However, the effect grows exponentially with crankshaft rotational speed. See crossplane article for unusual inline-four configurations.


=== Balance shaft use ===
Most inline-four engines below 2.0 L in displacement rely on the damping effect of their engine mounts to reduce the vibrations to acceptable levels. Above 2.0 L, most now use balance shafts to eliminate the secondary vibrations. In a system invented by Dr. Frederick W. Lanchester in 1911, an inline-four engine uses two balance shafts, rotating in opposite directions at twice the crankshaft's speed, to offset the differences in piston speed. In the 1970s, Mitsubishi Motors patented the placement of the balancer shafts at different heights to counteract the second order rolling couple (i.e. about the crankshaft axis) due to the torque exerted by the inertia of the four pistons moving and stopping together. Porsche, Fiat, Saab, and Chrysler were among the companies who licensed this technology from Mitsubishi.There have been numerous examples of larger inline-fours without balance shafts, such as the Citroën DS 23 2,347 cc engine that was a derivative of the Traction Avant engine, the 1948 Austin 2,660 cc engine used in the Austin-Healey 100 and Austin Atlantic, the 3.3 L flathead engine used in the Ford Model A (1927), and the 2.5 L GM Iron Duke engine used in a number of American cars and trucks. Soviet/Russian GAZ Volga cars and UAZ SUVs, vans and light trucks used aluminium big-bore inline-four engines (2.5 or later 2.9 L) with no balance shafts from the 1950s-1990s. These engines were generally the result of a long incremental evolution process and their power was kept low compared to their capacity. However, the forces increase with the square of the engine speed — that is, doubling the speed makes the vibration four times more forceful — so some modern high-speed inline-fours, generally those with a displacement greater than 2.0 litres, have more need to use balance shafts to offset the vibration.


=== Non-overlapping power strokes ===

Four-cylinder engines also have a smoothness problem in that the power strokes of the pistons do not overlap. With four cylinders and four strokes to complete in the four-stroke cycle, each piston completes its power stroke before the next piston starts a new power stroke, resulting in a pause between each power stroke and a pulsating delivery of power. In engines with more cylinders, the power strokes overlap, which gives them a smoother delivery of power and less torsional vibration than a four can achieve. As a result, five-, six-, eight-, ten- and twelve-cylinder engines are generally used in more luxurious and expensive cars.


=== Advantages ===
Four-cylinder engines, often derided as ""four-bangers"", do offer some advantages: an alloy block inline-four is usually small, compact and lightweight, which decreases overall vehicle mass, usually resulting in an increase in fuel efficiency in the urban cycle. The light weight of the inline-four also allows for ease of removal and installation when maintenance or overhaul are necessary.
When compared to a V6 or V8, an inline-four will generally have somewhat lower frictional losses at a comparable engine speed due to having fewer pistons, connecting rods and bearings, although the lower frictional loss is offset by the inline-four's need to turn faster than a larger engine in order to produce equivalent power. In a diesel engine, this is less of a problem, and so inline-4 engines can be scaled up to 5 litres in commercial vehicle use.
An inline-4 engine using the 4-stroke ""Otto"" cycle will always have one cylinder on the power stroke, a major advantage over a 1, 2, or 3 cylinder engine when no power stroke occurs at certain times. An inline-4 has only one cylinder head, a major advantage over servicing and maintenance compared to Vee angled engine with 2 cylinder heads, and consequently an inline-4 has less probability of reliability issues as there is less frictional loss which can cause problems such as overheating and head gasket problems (see above). A V6 engine has poor primary and secondary balance, and requires extensive use of balance shafts and harmonic damping which sap ultimate engine power.
A small capacity 2 litre turbocharged 4 cylinder engine running at 2.0 bar boost has effectively the same power output as a normally aspirated 4 litre V8, albeit with a massive mid range torque advantage (because a turbo car is less dependent on air for its mid range power unlike an atmo engine) and a clear power advantage at high altitude running. It was for this reason that Lotus and Ford-Cosworth developed high revving small capacity 2 litre turbocharged units with great success in motor sport. Lotus won the 1992 IMSA Bridgestone Supercar Championship its 350+ BHP Esprit X180R (Type 106) driven by Doc Bundy, beating its Corvette, Porsche, Mazda and Nissan rivals with a combination of its nimble lightweight chassis and torquey forced induction 4 cylinder engine. Ford-Cosworth developed the Sierra RS Cosworth for competition with its powerful but lightweight 2 litre inline 4 with turbochargers and intercoolers, it won Touring Car Championships in the UK, Australia, Germany, Japan and New Zealand. The Cosworth inline 4 YB produced around 500 BHP at around 10,000–11,000 RPM and took victories at the Spa 24 Hours, Bathurst and RAC Tourist Trophy amongst others, defeating its V6, V8 and inline 6 cylinder engine rivals mainly because its small light 2 litre block could be mounted further back behind the front axle line in the Sierra chassis, giving it effectively a mid engine configuration with the resultant better centre of gravity and a corresponding centre of pressure (aero balance) which gave a more equal balance of downforce between the front and rear axles.  
A notable inline-four is the BMW Megatron M12 1.5-litre Formula 1 engine, which won the 1983 World Drivers Championship installed in the Brabham BT52 chassis driven by Nelson Piquet. In the second half of the 1983 Formula 1 season, the BMW was capable of over 800 BHP in qualifying, and in race trim usually had an output of between 640 BHP to 700 BHP, depending on how much boost the drivers used.


== Automobile use ==


=== Notable production inline-four engines ===

The smallest automobile production inline-four engine powered the 1962–1970 Mazda P360 Carol kei car. Displacing just 358 cc, the Mazda DA was a conventional but tiny pushrod engine. Honda produced, from 1963 to 1967, a 356 cc (21.7 cu in) inline-four engine for the T360 truck. Inline-four motorcycle engines are built down to 250 cc, e.g. in the Honda CBR250.
Most inline-four engines, however, have been over 700 cc (43 cu in) displacement. A practical upper limit could be placed in the 2.5 L range for contemporary production cars. Larger engines (up to 6.1 L) have been seen in tractors (Kubota M135X) and medium duty truck use (Isuzu Forward, Hino Ranger), especially using diesel fuel (one of the strongest is the MAN D0834 engine with 220 hp (164 kW) and 627 lb⋅ft (850 N⋅m)). The use of balance shafts allowed Porsche to use a 3.0 L (2,990 cc) inline-four engine on road cars first in the 944 S2, but the largest modern non-diesel was the 3,186 cc (194.4 cu in) Pontiac inline-4 produced from one half of the Division's 6,373 cc (388.9 cu in) V8 for the debut of its 1961 Tempest.
The largest mass-produced inline-four engine in a car has currently the Mitsubishi Pajero 3.2 DI-D, which has a 3,200 cc inline-four with 165 hp (123 kW) at 3,500 rpm (in Europe, 200 hp) and 381 N⋅m (281 lb⋅ft) at 2,000 rpm. The Engine has a bore of 98.5 mm (3.9 in) and a stroke of 105 mm (4.1 in).Currently, one of the largest straight-4 engines in production is General Motors' Vortec 2900 installed in the GMC Canyon and Chevrolet Colorado small pickup trucks. It shares the same 95.5 mm (3.8 in) bore and 102 mm (4.0 in) stroke as the larger inline-five Vortec 3700. The latest version of the Vortec 2900, the LLV, displaces 2.9 L (2921 cc, 178 in³) and produces 185 hp (138 kW) at 5,600 rpm and 195 lb⋅ft (264 N⋅m) at 2,800 rpm. Engine redline is 6,300 rpm. Another example of a large inline-four engine is the Russian 2.89 L UMZ 421 series UMZ engine.
In the early 20th century, bigger engines existed, both in road cars and sports cars. Due to the absence of displacement limit regulations, manufacturers took increasing liberties with engine size. In order to achieve power over 100 hp (75 kW), most engine builders simply increased displacement, which could sometimes achieve over 10.0 L. The biggest inline-four ever made was the 28.3 L engine used in the 1911 Fiat S76 racing car. These engines ran at very low rpm, often less than 1,500 rpm maximum, and had a specific output of about 10 hp/L. The US tractor industry both farm and industrial relied on large four-cylinder power units until the early 1960s, when six-cylinder designs came into favour. International Harvester built a large 5.7-litre (350 CID) four-cylinder for their WD-9 series tractors.
Other technologically or historically notable engines using this configuration include:

Alfa Romeo Twin Cam engine - one of the first mass-produced twin cam engines produced from 1954. Also first engine in production car with variable valve timing.
BMC A-Series engine - the first engine to be used in a transverse drive train powering the front wheels of a mass-produced automobile (Mini).
Chevrolet Cosworth Twin-Cam Vega - 2.0 L all aluminum (block & head), DOHC, 16 valves, electronic fuel injection, stainless steel header.
Dodge A853 - intercooled turbo engine from the SRT-4, set the land speed record for 4-cylinder production cars at the Bonneville Salt Flats.
Fiat Twin Cam engine - One of the first mass-produced twincam engines, produced from 1959.
Ford Model T engine - one of the most widely produced engines in the world.
GM Quad-4 engine - twin-cam Oldsmobile engine offered in GM small, sporty cars.
Honda ED engine - first use of Honda's CVCC technology.
Honda F20C engine - its 250 PS (180 kW; 250 hp) from 2.0 L was the highest specific output of its time, particularly noteworthy in that it achieved this without forced induction.
Mitsubishi Sirius engine - includes the 4G63, which has the highest specific output of a turbocharged production engine in the world with the Lancer Evolution FQ-400 available in the United Kingdom (202.9 hp/L)
Triumph Slant-4 engine - the first mass-produced multi-valve engine for Triumph and an early turbo engine for Saab.
Willys L-134 engine - nicknamed the Go Devil engine. Powered the World War II Jeep and post-war models. Notably undersquare, with 3.125 in (79.4 mm) bore and 4.375 in (111.1 mm) stroke.In the late 2000s (decade), with auto manufacturers making efforts to increase fuel efficiency and reduce emissions, due to the high price of oil and the economic recession, the proportion of new vehicles with inline-four engines have increased considerably at the expense of V6 and V8 engines. This is particularly evident in mid-size vehicles where a decreasing number of buyers have chosen the V6 performance options.


=== Racing use ===

1913 saw a Peugeot driven by Jules Goux winning the Indianapolis 500. This car was powered by an inline-four engine designed by Ernest Henry. This design was very influential for racing engines as it had, for the first time, dual overhead camshafts (DOHC) and four valves per cylinder, a layout that would become the standard until today for racing inline-four engines.This Peugeot was sold to the American driver ""Wild Bob"" Burman who broke the engine in 1915. As Peugeot couldn't deliver a new engine during World War I, Burman asked Harry Arminius Miller to build a new engine. With John Edward and Fred Offenhauser, Miller created a Peugeot-inspired inline-four engine. This was the first version of the engine that would dominate the Indianapolis 500 until 1976 under the brand Miller and later Offenhauser. The Offenhausers won five straight victories at Indianapolis from 1971 to 1976, and it was not until 1981 that they were eliminated as competitors by engines such as the Cosworth V8 engine.Many cars produced for the pre-WWII voiturette Grand Prix motor racing category used inline-four engine designs. 1.5 L supercharged engines found their way into cars such as the Maserati 4CL and various English Racing Automobiles (ERA) models. These were resurrected after the war, and formed the foundation of what was later to become Formula One, although the straight-eight supercharged Alfettas would dominate the early years of F1.
Another engine that played an important role in racing history is the inline-four Ferrari engine designed by Aurelio Lampredi. This engine was originally designed as a 2 L Formula 2 engine for the Ferrari 500, but evolved to 2.5 L to compete in Formula One in the Ferrari 625. For sports car racing, capacity was increased up to 3.4 L for the Ferrari 860 Monza.
Yet another very successful engine was the Coventry Climax inline-four originally designed by Walter Hassan as a 1.5 L Formula 2 engine. Enlarged to 2.0 L for Formula One in 1958, it evolved into the large 2,495 cc FPF that won the Formula One championship in Cooper's chassis in 1959 and 1960.In Formula One, the 1980s were dominated by the 1,500 cc turbocharged cars. The BMW model M12/13 turbo was notable for the era for its high boost pressures and performance. The cast iron block 4-cylinder turbocharged Formula One motor, based on the standard BMW M10 engine introduced in 1961, powered the F1 cars of Brabham, Arrows and Benetton and won the world championship in 1983. In the years 1986 and 1987, the version M12/13/1 was tilted sideways by 72° for use in the extremely low Brabham BT55. Unfortunately, the design was not successful, probably due to cooling issues in the tight compartment. The 1986 engine was said to produce about 1,300 hp (969 kW) in qualifying.From 2010 to 2012, the GP3 Series used a 2.0 L (122 cu in) turbocharged inline-four engine developed by Renault Sport with a maximum power of 280 hp.
Inline-four engines are also used in MotoGP by the Suzuki (since 2015) and Yamaha (since 2002) teams. In 2010, when the four-stroke Moto2 class was introduced, the engines for the class were a 600 cc (36.6 cu in) inline-four engine made by Honda based on the CBR600RR with a maximum power output of 110 kW (150 hp). Starting in 2019, the engines were replaced by a Triumph 765 cc (46.7 cu in) triple engine.
In 2019, the Deutsche Tourenwagen Masters (DTM) switched to using 2.0 L (122 cu in) turbocharged inline-four engines.


== Motorcycle use ==

Belgian arms manufacturer FN Herstal, which had been making motorcycles since 1901, began producing the first motorcycles with inline-fours in 1905. The FN Four had its engine mounted upright with the crankshaft longitudinal. Other manufacturers that used this layout included Pierce, Henderson, Ace, Cleveland, and Indian in the United States, Nimbus in Denmark, Windhoff in Germany, and Wilkinson in the United Kingdom.The first across-the-frame 4-cylinder motorcycle was the 1939 racer Gilera 500 Rondine, it also had double-over-head camshafts, forced-inducting supercharger and was liquid-cooled. Modern inline-four motorcycle engines first became popular with Honda's SOHC CB750 introduced in 1969, and others followed in the 1970s. Since then, the inline-four has become one of the most common engine configurations in street bikes. Outside of the cruiser category, the inline-four is the most common configuration because of its relatively high performance-to-cost ratio. All major Japanese motorcycle manufacturers offer motorcycles with inline-four engines, as do MV Agusta and BMW. BMW's earlier inline-four motorcycles were mounted horizontally along the frame, but all current four-cylinder BMW motorcycles have transverse engines. The modern Triumph company has offered inline-four-powered motorcycles, though they were discontinued in favour of triples.
The 2009 Yamaha R1 has an inline-four engine that does not fire at even intervals of 180°. Instead, it uses a crossplane crankshaft that prevents the pistons from simultaneously reaching top dead centre. This results in better secondary balance, which is particularly beneficial in the higher rpm range, and ""big-bang firing order"" theory says the irregular delivery of torque to the rear tire makes sliding in the corners at racing speeds easier to control.


== Notes ==


== References ==


== Sources =="
"Petrol engine (British English) or gasoline engine (American English) is an internal combustion engine with spark-ignition, designed to run on petrol (gasoline) and similar volatile fuels.
In most petrol engines, the fuel and air are usually pre-mixed before compression (although some modern petrol engines now use cylinder-direct petrol injection). The pre-mixing was formerly done in a carburetor, but now it is done by electronically controlled fuel injection, except in small engines where the cost/complication of electronics does not justify the added engine efficiency. The process differs from a diesel engine in the method of mixing the fuel and air, and in using spark plugs to initiate the combustion process. In a diesel engine, only air is compressed (and therefore heated), and the fuel is injected into very hot air at the end of the compression stroke, and self-ignites.


== History ==

The first practical petrol engine was built in 1876 in Germany by Nicolaus August Otto, although there had been earlier attempts by Étienne Lenoir, Siegfried Marcus, Julius Hock and George Brayton.


== Compression ratio ==

With both air and fuel in a closed cylinder, compressing the mixture too much poses the danger of auto-ignition — or behaving like a compression-ignition engine. Because of the difference in burn rates between the two different fuels, petrol engines are mechanically designed with different timing than diesels, so to auto-ignite a petrol engine causes the expansion of gas inside the cylinder to reach its greatest point before the cylinder has reached the top dead center (TDC) position. Spark plugs are typically set statically or at idle at a minimum of 10 degrees or so of crankshaft rotation before the piston reaches TDC, but at much higher values at higher engine speeds to allow time for the fuel-air charge to substantially complete combustion before too much expansion has occurred - gas expansion occurring with the piston moving down in the power stroke. Higher octane petrol burns slower, therefore it has a lower propensity to auto-ignite and its rate of expansion is lower. Thus, engines designed to run high-octane fuel exclusively can achieve higher compression ratios (CRs).
Most modern automobile petrol engines generally have a compression ratio of 10.0:1 to 13.5:1. Engines with a knock sensor can and usually have CR higher than 11.1:1 and approaches 14.0:1 (for high octane fuel and usually with direct fuel injection) and engines without a knock sensor generally have CR of 8.0:1 to 10.5:1.


== Speed and efficiency ==
Petrol engines run at higher rotation speeds than diesels, partially due to their lighter pistons, connecting rods and crankshaft (a design efficiency made possible by lower compression ratios) and due to petrol burning more quickly than diesel.
Because pistons in petrol engines tend to have much shorter strokes than pistons in diesel engines, typically it takes less time for a piston in a petrol engine to complete its stroke than a piston in a diesel engine. However, the lower compression ratios of petrol engines give petrol engines lower efficiency than diesel engines.
Typically, most petrol engines have approximately 20%(avg.) thermal efficiency, which is nearly half of diesel engines. However some newer engines are reported to be much more efficient (thermal efficiency up to 38%) than previous spark-ignition engines.


== Applications ==


=== Current ===
Petrol engines have many applications, including:

Automobiles
Motorcycles
Aircraft
Motorboats
Small engines, such as lawn mowers, chainsaws and portable engine-generators


=== Historical ===
Before the use of diesel engines became widespread, petrol engines were used in buses, lorries (trucks) and a few railway locomotives. Examples:

Bedford OB bus
Bedford M series lorry
GE 57-ton gas-electric boxcab locomotive


== Design ==


=== Working cycles ===

Petrol engines may run on the four-stroke cycle or the two-stroke cycle.  For details of working cycles see:

Four-stroke cycle
Two-stroke cycle
Wankel engine


=== Cylinder arrangement ===
Common cylinder arrangements are from 1 to 6 cylinders in-line or from 2 to 12 cylinders in V-formation. Flat engines – like a V design flattened out – are common in small airplanes and motorcycles and were a hallmark of Volkswagen automobiles into the 1990s. Flat 6s are still used in many modern Porsches, as well as Subarus. Many flat engines are air-cooled. Less common, but notable in vehicles designed for high speeds is the W formation, similar to having 2 V engines side by side. Alternatives include rotary and radial engines the latter typically have 7 or 9 cylinders in a single ring, or 10 or 14 cylinders in two rings.


=== Cooling ===
Petrol engines may be air-cooled, with fins (to increase the surface area on the cylinders and cylinder head); or liquid-cooled, by a water jacket and radiator.  The coolant was formerly water, but is now usually a mixture of water and either ethylene glycol or propylene glycol.  These mixtures have lower freezing points and higher boiling points than pure water and also prevent corrosion, with modern antifreezes also containing lubricants and other additives to protect water pump seals and bearings.  The cooling system is usually slightly pressurized to further raise the boiling point of the coolant.


=== Ignition ===

Petrol engines use spark ignition and high voltage current for the spark may be provided by a magneto or an ignition coil.  In modern car engines the ignition timing is managed by an electronic Engine Control Unit.


=== Power measurement ===
The most common way of engine rating is what is known as the brake power, measured at the flywheel, and given in metric horsepower or kilowatts (metric), or in horsepower (Imperial/USA).  This is the actual mechanical power output of the engine in a usable and complete form.  The term ""brake"" comes from the use of a brake in a dynamometer test to load the engine.  For accuracy, it is important to understand what is meant by usable and complete. For example, for a car engine, apart from friction and thermodynamic losses inside the engine, power is absorbed by the water pump, alternator, and radiator fan, thus reducing the power available at the flywheel to move the car along.  Power is also absorbed by the power steering pump and air conditioner's compressor (if fitted), but these are not installed during a power output test or calculation. Power output varies slightly according to the energy value of the fuel, the ambient air temperature and humidity, and the altitude. Therefore, there are agreed standards in the USA and Europe on the fuel to use when testing, and engines are rated at 25 ⁰C (Europe), and 64 ⁰F (USA) at sea level, 50% humidity. Marine engines, as supplied, usually have no radiator fan, and often no alternator. In such cases the quoted power rating does not allow for losses in the radiator fan and alternator. The Society of Automotive Engineers (SAE) in the US, and the International Organization for Standardization (ISO) in Europe, publish standards on exact procedures, and how to apply corrections for non-standard conditions such as altitude above sea level.
Car testers are most familiar with the chassis dynamometer or ""rolling road"" installed in many workshops. This measures drive wheel brake horsepower, which is generally 15-20% less than the brake horsepower measured at the crankshaft or flywheel on an engine dynamometer. The measured power curve in kW is shown at 3:39 in the video.


== See also ==
Bore
Gasoline direct injection
Otto engine


== References =="
"The SpaceX Raptor is a full-flow staged combustion, methane-fueled rocket engine manufactured by SpaceX. The engine is powered by cryogenic liquid methane and liquid oxygen (LOX), rather than the RP-1 kerosene and LOX used in SpaceX's prior Merlin and Kestrel rocket engines. The earliest concepts for Raptor considered liquid hydrogen (LH2) as fuel rather than methane. The Raptor engine has more than two times the thrust of the Merlin 1D engine that powers the current Falcon 9 launch vehicle.
Raptor will be used in both stages of the two-stage-to-orbit, super heavy-lift launch vehicle Starship.The Raptor engine is a highly reusable methalox staged combustion engine that will power the next generation of SpaceX launch vehicles designed to replace all existing SpaceX vehicles, including the Falcon 9 and Falcon Heavy launch vehicles and the SpaceX Dragon 2. Raptor engines are expected to be used in various applications, including existing Earth-orbit satellite delivery market, the exploration and colonization of Mars.Raptor engines began flight testing on the Starhopper in July 2019 and became the first full-flow staged combustion rocket engine ever flown. Currently, Raptor is the rocket engine having the highest combustion chamber pressure ever reached by any rocket engines.


== Description ==

The Raptor engine is powered by subcooled liquid methane and subcooled liquid oxygen using a more efficient staged combustion cycle, a departure from the simpler ""open-cycle"" gas generator system and lox/kerosene propellants that current Merlin engines use. The RS-25, with hydrolox propellant also used a staged combustion process, as do several Russian rocket engines, including the RD-180 and the 25.74 MPa (3,733 psi) chamber pressure RD-191. The stated design size for the Raptor engine varied widely during 2012–2017 as detailed design continued, from a high target of 8,200 kN (1,800,000 lbf) of vacuum thrust to a more recent, much lower target of 1,900 kN (430,000 lbf). In its 2017 iteration, the operational engine is expected to have a vacuum Isp = 382 s (3,750 m/s) and a sea-level Isp = 334 s (3,280 m/s).The Raptor engine is designed for the use of deep cryogenic methalox propellants—fluids cooled to near their freezing points, rather than nearer their boiling points, which is more typical for cryogenic rocket engines. The use of subcooled propellants increases propellant density to allow more propellant mass in tanks; the engine performance is also improved with subcooled propellants. Specific impulse is increased, and the risk of cavitation at inputs to the turbopumps is reduced due to the higher mass flow rate per unit power generated. Engine ignition for all Raptor engines, both on the pad and in the air, will be by spark ignition, which will eliminate the pyrophoric mixture of triethylaluminum-triethylborane (TEA-TEB) used for engine ignition on the Falcon 9 and Falcon Heavy.Raptor has been claimed to be able to deliver ""long life ... and more benign turbine environments"". Specifically, Raptor utilizes a full-flow staged combustion cycle, where all the oxidizer—with a low-fuel ratio—will power the oxygen turbine pump, and all the fuel—with a low-oxygen ratio—will power the methane turbine pump.  Both streams—oxidizer and fuel—will be mixed completely in the gas phase before they enter the combustion chamber.  Prior to 2014, only two full-flow staged-combustion rocket engines had ever progressed sufficiently to be tested on test stands: the Soviet RD-270 project in the 1960s and the Aerojet Rocketdyne Integrated Powerhead Demonstrator in the mid-2000s.Additional characteristics of the full-flow design, projected to further increase performance or reliability include:
eliminating the fuel–oxidizer turbine interseal, which is a potential point of failure in more traditional engine designs;
lower pressures are required through the pumping system, increasing life span and further reducing risk of catastrophic failure;
ability to increase the combustion-chamber pressure, thereby either increasing overall performance or ""by using cooler gases, providing the same performance as a standard staged combustion engine but with much less stress on materials, thus significantly reducing material fatigue or [engine] weight"".SpaceX aims at a lifetime of 1000 flights for Raptor.The turbopump and many of the critical parts of the injectors for the initial engine development testing were, as of 2015, manufactured by using 3D printing, which increases the speed of development and iterative testing. The 2016 1 MN (220,000 lbf) test-stand engine had 40% (by mass) of its parts manufactured by 3D printing.The Raptor engine uses a large number of coaxial swirl injectors to admit propellants to the combustion chamber, rather than pintle injectors used on the previous Merlin rocket engines that SpaceX mass-produced for its Falcon family of launch vehicles.
Raptor uses ""dual redundant torch igniters"".


== History ==
The engine development from 2009 to 2015 was funded exclusively through private investment by SpaceX, and not as a result of any funding from the US government. In January 2016, SpaceX did agree with the US Air Force to take US$33.6 million in defense department funding in order to develop a particular Raptor model: a prototype of a new upper-stage variant of the Raptor engine designed for potential use as an upper stage on Falcon 9 and Falcon Heavy, with SpaceX agreeing to fund at least US$67.3 million on the same upper-stage development project, on a minimum 2:1 private-to-government funding basis.


=== Initial concept ===
An advanced rocket engine design project named Raptor—then a hydrolox engine—was first publicly discussed by SpaceX's Max Vozoff at the American Institute of Aeronautics and Astronautics Commercial Crew/Cargo symposium in 2009. As of April 2011, SpaceX had a small number of staff working on the Raptor upper-stage engine, then still a LH2/LOX concept, at a low level of priority. Further mention of the development program occurred in 2011. In March 2012, news accounts asserted that the Raptor upper-stage engine development program was underway, but that details were not being publicly released.In October 2012, SpaceX publicly announced concept work on a rocket engine that would be ""several times as powerful as the Merlin 1 series of engines, and won't use Merlin's RP-1 fuel"", but declined to specify which fuel would be used. They indicated that details on a new SpaceX rocket would be forthcoming in ""one to three years"" and that the large engine was intended for the next-generation launch vehicle using multiple of these large engines, that would be expected to launch payload masses of the order of 150 to 200 tonnes (150,000 to 200,000 kg; 330,000 to 440,000 lb) to low Earth orbit, exceeding the payload mass capability of the NASA Space Launch System.


=== Methane engine announcement and component development ===
In November 2012, Musk announced a new direction for the propulsion division of SpaceX: developing methane-fueled rocket engines. He further indicated that the engine concept, codenamed Raptor, would now become a methane-based design, and that methane would be the fuel of choice for SpaceX's plans for Mars colonization.

Because of the presence of water underground and carbon dioxide in the atmosphere of Mars, methane, a simple hydrocarbon, can easily be synthesized on Mars using the Sabatier reaction. In-situ resource production on Mars has been examined by NASA and found to be viable for oxygen, water, and methane production. According to a study published by researchers from the Colorado School of Mines, in-situ resource utilization such as methane from Mars makes space missions more feasible technically and economically and enables reusability.When first mentioned by SpaceX in 2009, the term ""Raptor"" was applied exclusively to an upper-stage engine concept—and 2012 pronouncements indicated that it was then still a concept for an upper stage engine—but in early 2014 SpaceX confirmed that Raptor would be used both on a new second stage, as well as for the large (then, nominally a 10-meter-diameter) core of the Mars Colonial Transporter (subsequently, in 2016, on both stages of the Interplanetary Transport System and then, in 2017 on the Big Falcon Rocket).The earliest public hints that a staged-combustion methane engine was under consideration at SpaceX were given in May 2011 when SpaceX asked if the Air Force was interested in a methane-fueled engine as an option to compete with the mainline kerosene-fueled engine that had been requested in the USAF Reusable Booster System High Thrust Main Engine solicitation.Public information released in November 2012 indicated that SpaceX might have a family of Raptor-designated rocket engines in mind; this was confirmed by SpaceX in October 2013. However, in March 2014 SpaceX COO Gwynne Shotwell clarified that the focus of the new engine development program is exclusively on the full-size Raptor engine; smaller subscale methalox engines were not planned on the development path to the very large Raptor engine.In October 2013, SpaceX announced that they would be performing methane engine tests of Raptor engine components at the John C. Stennis Space Center in Hancock County, Mississippi, and that SpaceX would add equipment to the existing test stand infrastructure in order to support liquid methane and hot gaseous methane engine component testing. In April 2014, SpaceX completed the requisite upgrades and maintenance to the Stennis test stand to prepare for testing of Raptor components, and the engine component testing program began in earnest, focusing on the development of robust startup and shutdown procedures, something that is typically quite difficult to do for full-flow staged combustion cycle engines.  Component testing at Stennis also allowed hardware characterization and verification of proprietary analytical software models that SpaceX developed to push the technology on this engine cycle that had little prior development work in the West.October 2013 was the first time SpaceX disclosed a nominal design thrust of the Raptor engine—2,900 kN (661,000 lbf)—although early in 2014 they announced a Raptor engine with greater thrust, and in 2015, one with lower thrust that might better optimize thrust-to-weight.
In February 2014, Tom Mueller, the head of rocket engine development at SpaceX, revealed in a speech that Raptor was being designed for use on a vehicle where nine engines would ""put over 100 tons of cargo up to Mars"" and that the rocket would be more powerful than previously released publicly, producing greater than 4,400 kN (1,000,000 lbf). A June 2014 talk by Mueller provided more specific engine performance target specifications indicating 6,900 kN (1,600,000 lbf) of sea-level thrust, 8,200 kN (1,800,000 lbf) of vacuum thrust, and a specific impulse (Isp) of 380 s (3,700 m/s) for a vacuum version. Earlier information had estimated the design Isp under vacuum conditions as only 363 s (3,560 m/s). Jeff Thornburg, who led development of the Raptor engine at SpaceX 2011–2015, noted that methane rocket engines have higher performance than kerosene/RP-1 and lower than hydrogen, with significantly fewer problems for long-term, multi-start engine designs than kerosene—methane is cleaner burning—and significantly lower cost than hydrogen, coupled with the ability to ""live off the land"" and produce methane directly from extraterrestrial sources.SpaceX successfully began development testing of injectors in 2014 and completed a full-power test of a full-scale oxygen preburner in 2015.  76 hot fire tests of the preburner, totaling some 400 seconds of test time, were executed from April–August 2015.  SpaceX completed its planned testing using NASA Stennis facilities in 2014 and 2015.In January 2015, Elon Musk stated that the thrust they were currently targeting was around 230 tonnes-force (2,300 kN; 510,000 lbf), much lower than older statements had mentioned. By August 2015, an Elon Musk statement surfaced that indicated the oxidizer to fuel ratio of the Mars-bound engine would be approximately 3.8 to 1.In January 2016, the US Air Force awarded a US$33.6 million development contract to SpaceX to develop a prototype version of its methane-fueled reusable Raptor engine for use on the upper stage of the Falcon 9 and Falcon Heavy launch vehicles, which required double-matching funding by SpaceX of at least US$67.3 million. Work under the contract was expected to be completed in 2018, with engine performance testing to be done at NASA's John C. Stennis Space Center in Mississippi and Los Angeles Air Force Base, California.


=== Engine development and testing ===

Initial development testing of Raptor methane engine components was done at the Stennis Space Center in Hancock County, Mississippi, where SpaceX added equipment to the existing infrastructure in order to support liquid methane engine testing. Initial testing was limited to components of the Raptor engine, since the 440 kN (100,000 lbf) test stands at the E-2 complex at Stennis were not large enough to test the full Raptor engine. The development Raptor engine discussed in the October 2013 time frame relative to Stennis testing was designed to generate more than 2,900 kN (661,000 lbf) vacuum thrust. A revised, higher-thrust, specification was discussed by the company in February 2014, but it was unclear whether that higher thrust was something that would be achieved with the initial development engines.
Raptor engine component testing began in May 2014 at the E-2 test complex which SpaceX modified to support methane engine tests. The first items tested were single Raptor injector elements, various designs of high-volume gas injectors.
The modifications to the test stands made by SpaceX are now a part of the Stennis test infrastructure and are available to other users of the test facility after the SpaceX facility lease was completed.
SpaceX successfully completed a ""round of main injector testing in late 2014"" and a ""full-power test of the oxygen preburner component"" for Raptor by June 2015.  Tests continued at least into September 2015.By early 2016, SpaceX had constructed a new engine test stand at their site of McGregor in central Texas that can handle the larger thrust of the full Raptor engine.By August 2016, the first integrated Raptor rocket engine, manufactured at the SpaceX Hawthorne facility in California, shipped to the McGregor rocket engine test facility in Texas for development testing. The engine had 1 MN (220,000 lbf) thrust, which makes it approximately one-third the size of the full-scale Raptor engine planned for flight tests in 2019/2020 timeframe. It is the first full-flow staged-combustion methalox engine ever to reach a test stand. This 2016 development engine had ""an expansion ratio of just 150, the maximum possible within Earth’s atmosphere"" to prevent flow separation problems. It performed an initial 9-second firing test on 26 September 2016, the day before Musk's talk at the International Aeronautical Congress.
On 26 September 2016, Elon Musk tweeted two images of the first test firing of an integrated Raptor in SpaceX's McGregor test complex. On the same day Musk revealed that their target performance for Raptor was a vacuum specific impulse of 382 s (3,750 m/s), with a thrust of 3 MN (670,000 lbf), a chamber pressure of 300 bar (30 MPa; 4,400 psi), and an expansion ratio of 150 for an altitude optimized version. When asked if the nozzle diameter for such version was 14 ft (4.3 m), he stated that it was pretty close to that dimension. He also disclosed that it used multi-stage turbopumps. On the 27th he clarified that 150 expansion ratio was for the development version, that the production vacuum version would have an expansion ratio of 200.
Substantial additional technical details of the ITS propulsion were summarized in a technical article on the Raptor engine published the next week.By September 2017, the development Raptor engine—with 200 bars (20 MPa; 2,900 psi) chamber pressure—had undergone 1200 seconds of test fire testing in ground-test stands across 42 main engine tests, with the longest test being 100 seconds (which is limited by the capacity of the ground-test propellant tanks). As of September 2017, the first version of the flight engine is intended to operate at a chamber pressure of 250 bars (25 MPa; 3,600 psi), with the intent to raise it to 300 bars (30 MPa; 4,400 psi) at a later time.By September 2017, the 200 bars (20 MPa; 2,900 psi) sub-scale test engine, with a thrust of 1 meganewton (220,000 lbf) and ""a new alloy to help its oxygen-rich turbopump resist oxidization, ... had completed 1200 seconds of firings across 42 tests."" This alloy is known as SX500 which is used to contain hot oxygen gas in the engine at up to 12000 psi. SX500 was created by the SpaceX metallurgy team.While plans for Raptor flight testing have consistently been on the new-generation fiber-composite-material construction flight vehicles since 2016, the specific vehicle was not clarified until October 2017, when it was indicated that initial suborbital test flights would occur with a Big Falcon Ship.
In November 2016, the first flight tests of the Raptor engine were projected to be on the Interplanetary Transport System, no earlier than the early 2020s.
By July 2017, the plan had been modified to do flight testing on a much smaller launch vehicle and spacecraft, and the new system architecture had ""evolved quite a bit"" since the ITS concept from 2016. A key driver of the 2017 architecture was to make the new system useful for substantial Earth-orbit and Cislunar launches so that the new system might pay for itself, in part, through economic spaceflight activities in the near-Earth space zone.Elon Musk announced in September 2017 that the initial flight platform for any Raptor engine would be some part of the Big Falcon Rocket. BFR was a 9 m (30 ft)-diameter launch vehicle.
In October 2017, Musk clarified that ""[initial flight testing will be with] a full-scale 9-meter-diameter ship doing short hops of a few hundred kilometers altitude and lateral distance ... [projected to be] fairly easy on the vehicle, as no heat shield is needed, we can have a large amount of reserve propellant and don’t need the high area ratio, deep-space Raptor engines.""Notably, Musk also announced that the new Raptor-powered BFR launch vehicle was planned to entirely replace both Falcon 9 and Falcon Heavy launch vehicles as well as the SpaceX Dragon 2 in the existing operational SpaceX fleet in the early 2020s, initially aiming at the Earth-orbit market, but SpaceX is explicitly designing in substantial capability to the spacecraft vehicles to support long-duration spaceflight in the cislunar and Mars mission environment as well. SpaceX intends this approach to bring significant cost savings which will help the company justify the development expense of designing and building the new launch vehicle design. In addition to orbital spaceflight missions, BFR is being considered for the point-to-point Earth transportation market, with ~30–60-minute flights to nearly anywhere on the planet.The first flight version of the Raptor engine arrived in McGregor, Texas in late January 2019.On 3 February 2019, SpaceX performed the first test of a flight version engine. The test lasted two seconds with the engine operating at 60 percent of rated thrust at a chamber pressure of 170 bars (17,000 kPa).
Just four days later, the test engine achieved the power levels needed for use in SpaceX Starship. The engine reached 172 tonnes-force (1,690 kN; 380,000 lbf) thrust with a chamber pressure of 257 bars (25.7 MPa). The test was conducted using warm propellant, with expectations of a 10% to 20% increase in performance when switching to deep cryogenic temperatures for the propellant.
On 10 February 2019, Musk announced on Twitter that the flight version engine had attained the chamber combustion pressure of 268.9 bars (26.89 MPa) on a test stand. On 19 June 2020, Musk announced that the Raptor engine tests achieved the expected chamber combustion pressure of 300 bars (30 MPa) on a test stand.By March, serial number 2 (SN2) of the flight version Raptor engine had been delivered to the SpaceX South Texas Launch Site east of Brownsville, Texas for system integration testing on the Starhopper, the first test article of Starship, approximately one year ahead of schedule. SN2 was used for two tethered integration tests of the flight test ""hopper"" in early April.  Serial numbers 3, 4, 5 and 6 had all made it to the test stand by early July, but the first three had issues of various sorts and SpaceX did not try any flight tests of the Starhopper test vehicle.  SN6 was still under test on the ground test stand as of 8 July 2019.The first flight test of a Raptor engine occurred on 25 July 2019 at the SpaceX South Texas Launch Site. Unusually, for initial flight tests of orbital-class rocket engines, this was not a full-duration burn but just a 22-second test. SpaceX is developing their next-generation rocket to be reusable from the beginning, just like an aircraft, and thus needs to start with narrow flight test objectives, while still aiming to land the rocket successfully to be used subsequently in further tests to expand the flight envelope.Another flight test of a Raptor engine (probably SN6) occurred on 27 August 2019 from Boca Chica, Texas, test facility. The Starhopper reached an estimated altitude of 150 m (FAA approved). A side step and a perfect landing on a nearby landing pad terminated the roughly 1 minute flight.
On August 4, 2020 a single Raptor engine (SN27) propelled a Starship prototype (SN5) to an altitude of 150 m (FAA approved) at the Boca Chica, Texas, test facility. The Raptor engine was mounted off center and controlled the Starship during lift off, a traverse of approximately 100 meters, and landing on a secondary pad.  The total flight time was approximately 50 seconds.In August 2020, a ground stand test of a Raptor achieved 330 bar (33,000 kPa) chamber pressure, producing ~225 tf (2,210 kN; 500,000 lbf) of thrust. This achievement surpassed RD-701 engine and set a new world record of the highest pressure ever reached in a rocket engine's combustion chamber. Tests have also shown that the engine—designed to be throttleable from the outset—can throttle engine thrust down to 40 percent of maximum output.  The current limitation to decreasing thrust even further is raptor preburner flameout.


== Versions ==
The Raptor methalox engine for SpaceX next-generation launch vehicles have gone through a number of design concepts for engine  thrust, specific impulse, and sea-level-nozzle/vacuum-nozzle sizings, depending on the vehicle design concept SpaceX was working on at the time, and subscale versions of Raptor engines were also built for early testing on ground test stands.  After 2013, all engine design concepts were methalox using the full-flow staged combustion (FFSC) cycle.  In addition, in 2016–2018, a custom prototype upper-stage methalox FFSC Raptor engine was designed and tested for the Falcon 9 and Falcon Heavy launch vehicles, strictly for the US Air Force to meet US military space readiness objectives.  SpaceX never implemented plans to switch the F9/FH upper stage to methalox propellants. 


=== SpaceX next-generation launch vehicle ===
In September 2016 at the IAC meetings, Musk mentioned several Raptor engine designs that could be used on the Interplanetary Transport System by late in the decade.  In addition, a much smaller subscale engine had already been built for test and validation of the new full-flow staged-combustion cycle engine.  At that time, this first subscale Raptor development engine had recently been tested on a ground test stand, but for only one brief firing.The ""Raptor subscale development engine"" had approximately 1,000 kN (220,000 lbf) thrust. In order to eliminate flow separation problems while being tested in Earth's atmosphere, the test nozzle expansion ratio had been limited to only 150. The engine began testing in September 2016 on aground test stand. Sources differed on the performance of the test engine. In reporting during the two weeks following the Musk ITS launch vehicle reveal on 27 September, NASASpaceFlight.com indicated that the development engine was only one-third the size of any of the several larger engine designs that were discussed for the later flight vehicles.For the flight vehicles, Elon Musk discussed two engines: both a low-expansion ratio (ER40) for the first stage, or ITS booster and a higher-expansion ratio (200) to obtain higher performance with the second stage.  42 of these ER40 engines were envisioned in the high-level design of the first stage, with 3,050 kN (690,000 lbf) of thrust at sea level, and 3,285 kN (738,000 lbf) in vacuum. In addition, three gimbaled short-nozzle ER40 engines were to be used for maneuvering the 2016-design ITS second-stage; and these engines were also expected to be used for retropropulsive landings on Mars (with mean atmospheric pressure on the Martian surface of 600 Pa (0.0060 bar; 0.087 psi),).  The higher-efficiency engine for in-space flight in vacuum conditions was envisioned then to target a specific impulse of 382s, using a much larger nozzle giving an expansion ratio of 200. Six of these non-gimbaled engines were planned to provide primary propulsion for the 2016 designs of the Interplanetary Spaceship and the Earth-orbit ITS tanker. As designed, both of those vehicles were to play a short-term role as second stages on launches to Earth orbit, as well as provide high-Isp efficiency on transfer from geocentric to heliocentric orbit for transport to beyond-Earth-orbit celestial bodies. 3,500 kN (790,000 lbf) thrust at vacuum, the only conditions under which the six ER200 engines were expected to be fired.A year later, at the IAC meetings in September 2017, and following a year of testing and iterative development by the propulsion team, Musk said that a smaller Raptor engine—with slightly over half as much thrust as the previous concept designs for the ITS—would be used on the next-generation rocket, now a 9 m (30 ft)-diameter launch vehicle and publicly referred to as Big Falcon Rocket (BFR). With the much smaller launch vehicle, fewer Raptor engines would be used on each stage. BFR was then slated to have 31 Raptors on the first stage and 6 on the second stage.  By mid-2018, SpaceX was publicly stating that the sea-level flight version Raptor engine design, with a nozzle exit diameter of 1.3 m (4.3 ft), was expected to have 1,700 kN (380,000 lbf) thrust at sea level with an Isp of 330 s (3,200 m/s) increasing to an Isp of 356 s (3,490 m/s) in vacuum. The vacuum flight version, with a nozzle exit diameter of 2.4 m (7.9 ft), was expected to exert 1,900 kN (430,000 lbf) force with an Isp of 375 s (3,680 m/s).  The earliest versions of the flight engine is designed to operate at 250 bars (25,000 kPa; 3,600 psi) chamber pressure; but SpaceX expects to increase this to 300 bar (30,000 kPa; 4,400 psi) in later iterations. The flight engine is designed for extreme reliability, aiming to support the airline-level of safety required by the point-to-point Earth transportation market.In the BFR update given in September 2018, Musk showed video of a 71-second hot fire test of a Raptor engine, and stated that ""this is the Raptor engine that will power BFR, both the ship and the booster; it's the same engine. ...  approximately a 200 tonne engine aiming for roughly 300 bar chamber pressure. ... If you had it at a high expansion ratio, has the potential to have a specific impulse of 380.""


==== Raptor vac ====
The Raptor vac engine is a methalox full-flow staged combustion (FFSC) engine but is optimized for higher performance under vacuum conditions, most notably, optimized for highest specific impulse given other engine requirements like reusability, reliability, and so forth.
While the optimized Raptor vac engine is aiming for an Isp of ~380 s (3,700 m/s), the v1.0 Raptor vac design to support early Starship development has been made more conservative and is projecting an Isp of only 365–370 s (3,580–3,630 m/s), intentionally decreasing engine performance to obtain having test engines sooner. In addition, Raptor vac v1 will have a smaller engine nozzle in order to avoid flow separation when the engine is fired at sea-level atmospheric pressure.


=== Upper stage engine prototype for Falcon 9 ===
In January 2016, the US Air Force (USAF) awarded a US$33.6 million development contract to SpaceX to develop a prototype version of its methane-fueled reusable Raptor engine for use on the upper stage of the Falcon 9 and Falcon Heavy launch vehicles. The contract required double-matching funding by SpaceX of at least US$67.3 million.
Work under the contract was expected to be completed no later than December 2018, and engine performance testing was planned to be completed at NASA's Stennis Space Center in Mississippi under US Air Force supervision.
The USAF contract called only for the development and build of a single prototype engine with a series of ground tests, with no upper stage launch vehicle design funded by the contract. The Air Force was working with the US Congress in February 2016 to pursue new launch systems.""In October 2017 the US Air Force (USAF) awarded a US$40.8 million modification for the development of the Raptor rocket propulsion system prototype for the Evolved Expendable Launch Vehicle program, with work under that contract expected to be completed by April 2018.Little technical detail was ever publicly released about the USAF second stage engine, as is typical for defense contracts. The prototype however was to be designed:
to serve the theoretical purpose of servicing an upper stage that could be used on the existing SpaceX Falcon 9 (7,600 kN (1,700,000 lbf)-class) and the existing Falcon Heavy (23,000 kN (5,200,000 lbf)-class) first-stage sea-level thrust launch vehicles.
with propellants: liquid methane and liquid oxygen (LOX),
with the Raptor full-flow staged combustion engine cycle,
explicitly to be a reusable engineThe USAF contract called only for the development and build of a prototype, to be demonstrated in a USAF-supervised set of tests. No upper stage vehicle design/redesign was funded by the contract.  Neither the Air Force nor SpaceX subsequently published any results of this non-Starship oriented rocket engine contract.


== Comparison to other engines ==


== Applications ==
As of September 2016, the Raptor engine was slated to be used in three spaceflight vehicles making up the two launch stages of an ITS stack.  The first stage would always be ITS booster while the second stage may be either an Interplanetary Spaceship (for beyond-Earth-orbit missions) or an ITS tanker (for on-orbit propellant transfer operations nearer to Earth).
The SpaceX 2016-design of the Interplanetary booster was announced with 42 sea-level optimized Raptors in the first stage of the ITS with a total of 128 MN (29,000,000 lbf) of thrust. The SpaceX Interplanetary Spaceship—which made up the second stage of the ITS on Earth launches was also an interplanetary spacecraft carrying cargo and passengers to beyond-Earth-orbit destinations after on-orbit refueling—was slated in the 2016 design to use six vacuum-optimized Raptors for primary propulsion plus three Raptors with sea-level nozzles for maneuvering.The SpaceX design after late 2017 is for a much smaller launch vehicle, 9 meters in diameter rather than 12 meters for the ITS, and is now known as Starship. The Starship first stage (now known as Super Heavy) was slated to have 31 sea-level optimized Raptors in the initial design concept, with a total of 48 MN (11,000,000 lbf) of thrust. The Starship will use three vacuum-optimized Raptors for primary propulsion plus three sea-level Raptors for maneuvering.
SpaceX is building the Starship vehicles at the SpaceX South Texas Launch Site.


== See also ==
BE-4 – comparable methane-fuel engine from Blue Origin
RD-191 – modern Russian kerosene-fuel engine of comparable size
SpaceX Merlin – current kerosene-fueled rocket engine made by SpaceX
SpaceX rocket engines – overview of all rocket engines made by SpaceX
Comparison of orbital rocket engines – overview of known rocket engines


== References ==


== External links ==
SpaceX Raptor Engine Test on 25 September 2016, SciNews, video, September 2016.
GPUs to Mars:  Full-scale Simulation of SpaceX's Mars Rocket Engine, Adam Lichtl and Steven Jones, GPU Technology Conference, spring 2015."
"A jet engine is a type of reaction engine discharging a fast-moving jet that generates thrust by jet propulsion. While this broad definition can include rocket, water jet, and hybrid propulsion, the term jet engine typically refers to an airbreathing jet engine such as a turbojet, turbofan, ramjet, or pulse jet. In general, jet engines are combustion engines.
Airbreathing jet engines typically feature a rotating air compressor powered by a turbine, with the leftover power providing thrust through the propelling nozzle—this process is known as the Brayton thermodynamic cycle. Jet aircraft use such engines for long-distance travel. Early jet aircraft used turbojet engines that were relatively inefficient for subsonic flight. Most modern subsonic jet aircraft use more complex high-bypass turbofan engines.  They give higher speed and greater fuel efficiency than piston and propeller aeroengines over long distances. A few air-breathing engines made for high speed applications (ramjets and scramjets) use the ram effect of the vehicle's speed instead of a mechanical compressor.
The thrust of a typical jetliner engine went from 5,000 lbf (22,000 N) (de Havilland Ghost turbojet) in the 1950s to 115,000 lbf (510,000 N) (General Electric GE90 turbofan) in the 1990s, and their reliability went from 40 in-flight shutdowns per 100,000 engine flight hours to less than 1 per 100,000 in the late 1990s. This, combined with greatly decreased fuel consumption, permitted routine transatlantic flight by twin-engined airliners by the turn of the century, where previously a similar journey would have required multiple fuel stops.


== History ==

A rudimentary form of jet power dates back to the aeolipile, a device described by Hero of Alexandria in 1st-century Roman Egypt. This device directed steam power through two nozzles to cause a sphere to spin rapidly on its axis.  It was seen as a curiosity.
The first practical applications of jet propulsion appeared with the invention of the gunpowder-powered rocket by the Chinese in the 13th century. It was initially a type of firework, and gradually progressed to propel formidable weaponry. The principles used by the Chinese to send their rockets and fireworks was similar to that of a jet engine.In 1551, Taqi ad-Din Muhammad ibn Ma'ruf in Ottoman Egypt invented a steam jack, driven by a steam turbine, describing a method for rotating a spit by means of a jet of steam playing on rotary vanes around the periphery of a wheel. It was the first practical steam jet device. A similar device was later described by John Wilkins in 1648.The earliest report of an attempted jet flight also dates back to the Ottoman Empire. In 1633, the Ottoman soldier Lagâri Hasan Çelebi reportedly used a cone-shaped rocket.The earliest attempts at airbreathing jet engines were hybrid designs in which an external power source first compressed air, which was then mixed with fuel and burned for jet thrust.  The Caproni Campini N.1, and the Japanese Tsu-11 engine intended to power Ohka kamikaze planes towards the end of World War II were unsuccessful. 

Even before the start of World War II, engineers were beginning to realize that engines driving propellers were approaching limits due to issues related to propeller efficiency, which declined as blade tips approached the speed of sound.  If aircraft performance were to increase beyond such a barrier, a different propulsion mechanism was necessary. This was the motivation behind the development of the gas turbine engine, the most common form of jet engine.
The key to a practical jet engine was the gas turbine, extracting power from the engine itself to drive the compressor.  The gas turbine was not a new idea: the patent for a stationary turbine was granted to John Barber in England in 1791. The first gas turbine to successfully run self-sustaining was built in 1903 by Norwegian engineer Ægidius Elling.  Such engines did not reach manufacture due to issues of safety, reliability, weight and, especially, sustained operation.
The first patent for using a gas turbine to power an aircraft was filed in 1921 by Maxime Guillaume. His engine was an axial-flow turbojet, but was never constructed, as it would have required considerable advances over the state of the art in compressors. Alan Arnold Griffith published An Aerodynamic Theory of Turbine Design in 1926 leading to experimental work at the RAE.

In 1928, RAF College Cranwell cadet Frank Whittle formally submitted his ideas for a turbojet to his superiors. In October 1929, he developed his ideas further. On 16 January 1930, in England, Whittle submitted his first patent (granted in 1932). The patent showed a two-stage axial compressor feeding a single-sided centrifugal compressor. Practical axial compressors were made possible by ideas from A.A.Griffith in a seminal paper in 1926 (""An Aerodynamic Theory of Turbine Design""). Whittle would later concentrate on the simpler centrifugal compressor only.  Whittle was unable to interest the government in his invention, and development continued at a slow pace.

In 1935, Hans von Ohain started work on a similar design in Germany, both compressor and turbine being radial, on opposite sides of the same disc, initially unaware of Whittle's work. Von Ohain's first device was strictly experimental and could run only under external power, but he was able to demonstrate the basic concept. Ohain was then introduced to Ernst Heinkel, one of the larger aircraft industrialists of the day, who immediately saw the promise of the design. Heinkel had recently purchased the Hirth engine company, and Ohain and his master machinist Max Hahn were set up there as a new division of the Hirth company. They had their first HeS 1 centrifugal engine running by September 1937. Unlike Whittle's design, Ohain used hydrogen as fuel, supplied under external pressure. Their subsequent designs culminated in the gasoline-fuelled HeS 3 of 5 kN (1,100 lbf), which was fitted to Heinkel's simple and compact He 178 airframe and flown by Erich Warsitz in the early morning of August 27, 1939, from Rostock-Marienehe aerodrome, an impressively short time for development. The He 178 was the world's first jet plane. Heinkel applied for a US patent covering the Aircraft Power Plant by Hans Joachim Pabst von Ohain in May 31, 1939; patent number US2256198, with M Hahn referenced as inventor.

Austrian Anselm Franz of Junkers' engine division (Junkers Motoren or ""Jumo"") introduced the axial-flow compressor in their jet engine. Jumo was assigned the next engine number in the RLM 109-0xx numbering sequence for gas turbine aircraft powerplants, ""004"", and the result was the Jumo 004 engine. After many lesser technical difficulties were solved, mass production of this engine started in 1944 as a powerplant for the world's first jet-fighter aircraft, the Messerschmitt Me 262 (and later the world's first jet-bomber aircraft, the Arado Ar 234). A variety of reasons conspired to delay the engine's availability, causing the fighter to arrive too late to improve Germany's position in World War II, however this was the first jet engine to be used in service.

Meanwhile, in Britain the Gloster E28/39 had its maiden flight on 15 May 1941 and the Gloster Meteor finally entered service with the RAF in July 1944. These were powered by turbojet engines from Power Jets Ltd., set up by Frank Whittle. The first two operational turbojet aircraft, the Messerschmitt Me 262 and then the Gloster Meteor entered service within three months of each other in 1944.
Following the end of the war the German jet aircraft and jet engines were extensively studied by the victorious allies and contributed to work on early Soviet and US jet fighters. The legacy of the axial-flow engine is seen in the fact that practically all jet engines on fixed-wing aircraft have had some inspiration from this design.
By the 1950s, the jet engine was almost universal in combat aircraft, with the exception of cargo, liaison and other specialty types. By this point, some of the British designs were already cleared for civilian use, and had appeared on early models like the de Havilland Comet and Avro Canada Jetliner. By the 1960s, all large civilian aircraft were also jet powered, leaving the piston engine in low-cost niche roles such as cargo flights.
The efficiency of turbojet engines was still rather worse than piston engines, but by the 1970s, with the advent of high-bypass turbofan jet engines (an innovation not foreseen by the early commentators such as Edgar Buckingham, at high speeds and high altitudes that seemed absurd to them), fuel efficiency was about the same as the best piston and propeller engines.


== Uses ==

Jet engines power jet aircraft, cruise missiles and unmanned aerial vehicles. In the form of rocket engines they power fireworks, model rocketry, spaceflight, and military missiles.
Jet engines have propelled high speed cars, particularly drag racers, with the all-time record held by a rocket car. A turbofan powered car, ThrustSSC, currently holds the land speed record.
Jet engine designs are frequently modified for non-aircraft applications, as industrial gas turbines or marine powerplants. These are used in electrical power generation, for powering water, natural gas, or oil pumps, and providing propulsion for ships and locomotives. Industrial gas turbines can create up to 50,000 shaft horsepower. Many of these engines are derived from older military turbojets such as the Pratt & Whitney J57 and J75 models. There is also a derivative of the P&W JT8D low-bypass turbofan that creates up to 35,000 HP.
Jet engines are also sometimes developed into, or share certain components such as engine cores, with turboshaft and turboprop engines, which are forms of gas turbine engines that are typically used to power helicopters and some propeller-driven aircraft.


== Types of jet engine ==
There are a large number of different types of jet engines, all of which achieve forward thrust from the principle of jet propulsion.


=== Airbreathing ===

Commonly aircraft are propelled by airbreathing jet engines. Most airbreathing jet engines that are in use are turbofan jet engines, which give good efficiency at speeds just below the speed of sound.


==== Turbine powered ====

Gas turbines are rotary engines that extract energy from a flow of combustion gas. They have an upstream compressor coupled to a downstream turbine with a combustion chamber in-between. In aircraft engines, those three core components are often called the ""gas generator"". There are many different variations of gas turbines, but they all use a gas generator system of some type.


===== Turbojet =====

A turbojet engine is a gas turbine engine that works by compressing air with an inlet and a compressor (axial, centrifugal, or both), mixing fuel with the compressed air, burning the mixture in the combustor, and then passing the hot, high pressure air through a turbine and a nozzle. The compressor is powered by the turbine, which extracts energy from the expanding gas passing through it. The engine converts internal energy in the fuel to kinetic energy in the exhaust, producing thrust. All the air ingested by the inlet is passed through the compressor, combustor, and turbine, unlike the turbofan engine described below.


===== Turbofan =====

Turbofans differ from turbojets in that they have an additional fan at the front of the engine, which accelerates air in a duct bypassing the core gas turbine engine. Turbofans are the dominant engine type for medium and long-range airliners.
Turbofans are usually more efficient than turbojets at subsonic speeds, but at high speeds their large frontal area generates more drag. Therefore, in supersonic flight, and in military and other aircraft where other considerations have a higher priority than fuel efficiency, fans tend to be smaller or absent.
Because of these distinctions, turbofan engine designs are often categorized as low-bypass or high-bypass, depending upon the amount of air which bypasses the core of the engine.  Low-bypass turbofans have a bypass ratio of around 2:1 or less.


==== Ram compression ====

Ram compression jet engines are airbreathing engines similar to gas turbine engines and they both follow the Brayton cycle. Gas turbine and ram powered engines differ, however, in how they compress the incoming airflow. Whereas gas turbine engines use axial or centrifugal compressors to compress incoming air, ram engines rely only on air compressed through the inlet or diffuser. A ram engine thus requires a substantial initial forward airspeed before it can function. Ram powered engines are considered the most simple type of air breathing jet engine because they can contain no moving parts.Ramjets are ram powered jet engines. They are mechanically simple, and operate less efficiently than turbojets except at very high speeds.

Scramjets differ mainly in the fact that the air does not slow to subsonic speeds. Rather, they use supersonic combustion. They are efficient at even higher speed. Very few have been built or flown. 


==== Non-continuous combustion ====


== Other types of jet propulsion ==


=== Rocket ===

The rocket engine uses the same basic physical principles of thrust as a form of reaction engine, but is distinct from the jet engine in that it does not require atmospheric air to provide oxygen; the rocket carries all components of the reaction mass. However some definitions treat it as a form of jet propulsion.Because rockets do not breathe air, this allows them to operate at arbitrary altitudes and in space.This type of engine is used for launching satellites, space exploration and manned access, and permitted landing on the moon in 1969.
Rocket engines are used for high altitude flights, or anywhere where very high accelerations are needed since rocket engines themselves have a very high thrust-to-weight ratio.
However, the high exhaust speed and the heavier, oxidizer-rich propellant results in far more propellant use than turbofans. Even so, at extremely high speeds they become energy-efficient.
An approximate equation for the net thrust of a rocket engine is:

  
    
      
        
          F
          
            N
          
        
        =
        
          
            
              m
              ˙
            
          
        
        
        
          g
          
            0
          
        
        
        
          I
          
            sp,vac
          
        
        −
        
          A
          
            e
          
        
        
        p
        
      
    
    {\displaystyle F_{N}={\dot {m}}\,g_{0}\,I_{\text{sp,vac}}-A_{e}\,p\;}
  Where 
  
    
      
        
          F
          
            N
          
        
      
    
    {\displaystyle F_{N}}
   is the net thrust, 
  
    
      
        
          I
          
            sp,vac
          
        
      
    
    {\displaystyle I_{\text{sp,vac}}}
   is the specific impulse, 
  
    
      
        
          g
          
            0
          
        
      
    
    {\displaystyle g_{0}}
   is a standard gravity, 
  
    
      
        
          
            
              m
              ˙
            
          
        
      
    
    {\displaystyle {\dot {m}}}
   is the propellant flow in kg/s, 
  
    
      
        
          A
          
            e
          
        
      
    
    {\displaystyle A_{e}}
   is the cross-sectional area at the exit of the exhaust nozzle, and 
  
    
      
        p
      
    
    {\displaystyle p}
   is the atmospheric pressure.


=== Hybrid ===
Combined-cycle engines simultaneously use two or more different principles of jet propulsion.


=== Water jet ===

A water jet, or pump-jet, is a marine propulsion system that utilizes a jet of water. The mechanical arrangement may be a ducted propeller with nozzle, or a centrifugal compressor and nozzle. The pump-jet must be driven by a separate engine such as a Diesel or gas turbine.


== General physical principles ==
All jet engines are reaction engines that generate thrust by emitting a jet of fluid rearwards at relatively high speed. The forces on the inside of the engine needed to create this jet give a strong thrust on the engine which pushes the craft forwards.
Jet engines make their jet from propellant stored in tanks that are attached to the engine (as in a 'rocket') as well as in duct engines (those commonly used on aircraft) by ingesting an external fluid (very typically air) and expelling it at higher speed.


=== Propelling nozzle ===

The propelling nozzle is the key component of all jet engines as it creates the exhaust jet. Propelling nozzles turn internal and pressure energy into high velocity kinetic energy. The total pressure and temperature don't change through the nozzle but their static values drop as the gas speeds up.
The velocity of the air entering the nozzle is low, about Mach 0.4, a prerequisite for minimizing pressure losses in the duct leading to the nozzle. The temperature entering the nozzle may be as low as sea level ambient for a fan nozzle in the cold air at cruise altitudes. It may be as high as the 1000K exhaust gas temperature for a supersonic afterburning engine or 2200K with afterburner lit. The pressure entering the nozzle may vary from 1.5 times the pressure outside the nozzle, for a single stage fan, to 30 times for the fastest manned aircraft at mach 3+.Convergent nozzles are only able to accelerate the gas up to local sonic (Mach 1) conditions. To reach high flight speeds, even greater exhaust velocities are required, and so a convergent-divergent nozzle is often used on high-speed aircraft.The nozzle thrust is highest if the static pressure of the gas reaches the ambient value as it leaves the nozzle. This only happens if the nozzle exit area is the correct value for the nozzle pressure ratio (npr). Since the npr changes with engine thrust setting and flight speed this is seldom the case. Also at supersonic speeds the divergent area is less than required to give complete internal expansion to ambient pressure as a trade-off with external body drag. Whitford gives the F-16 as an example. Other underexpanded examples were the XB-70 and SR-71.
The nozzle size, together with the area of the turbine nozzles, determines the operating pressure of the compressor.


=== Thrust ===


=== Energy efficiency relating to aircraft jet engines ===
This overview highlights where energy losses occur in complete jet aircraft powerplants or engine installations.
A jet engine at rest, as on a test stand, sucks in fuel and generates thrust. How well it does this is judged by how much fuel it uses and what force is required to restrain it. This is a measure of its efficiency. If something deteriorates inside the engine (known as performance deterioration) it will be less efficient and this will show when the fuel produces less thrust. If a change is made to an internal part which allows the air/combustion gases to flow more smoothly the engine will be more efficient and use less fuel. A standard definition is used to assess how different things change engine efficiency and also to allow comparisons to be made between different engines. This definition is called specific fuel consumption, or how much fuel is needed to produce one unit of thrust. For example, it will be known for a particular engine design that if some bumps in a bypass duct are smoothed out the air will flow more smoothly giving a pressure loss reduction of x% and y% less fuel will be needed to get the take-off thrust, for example. This understanding comes under the engineering discipline Jet engine performance. How efficiency is affected by forward speed and by supplying energy to aircraft systems is mentioned later.
The efficiency of the engine is controlled primarily by the operating conditions inside the engine which are the pressure produced by the compressor and the temperature of the combustion gases at the first set of rotating turbine blades. The pressure is the highest air pressure in the engine. The turbine rotor temperature is not the highest in the engine but is the highest at which energy transfer takes place ( higher temperatures occur in the combustor). The above pressure and temperature are shown on a Thermodynamic cycle diagram.
The efficiency is further modified by how smoothly the air and the combustion gases flow through the engine, how well the flow is aligned (known as incidence angle) with the moving and stationary passages in the compressors and turbines. Non-optimum angles, as well as non-optimum passage and blade shapes can cause thickening and separation of Boundary layers and formation of Shock waves. It is important to slow the flow (lower speed means less pressure losses or Pressure drop) when it travels through ducts connecting the different parts. How well the individual components contribute to turning fuel into thrust is quantified by measures like efficiencies for the compressors, turbines and combustor and pressure losses for the ducts.  These are shown as lines on a Thermodynamic cycle diagram.
The engine efficiency, or thermal efficiency, known as 
  
    
      
        
          η
          
            t
            h
          
        
      
    
    {\displaystyle \eta _{th}}
  . is dependent on the Thermodynamic cycle parameters, maximum pressure and temperature, and on component efficiencies, 
  
    
      
        
          η
          
            c
            o
            m
            p
            r
            e
            s
            s
            o
            r
          
        
      
    
    {\displaystyle \eta _{compressor}}
  , 
  
    
      
        
          η
          
            c
            o
            m
            b
            u
            s
            t
            i
            o
            n
          
        
      
    
    {\displaystyle \eta _{combustion}}
   and 
  
    
      
        
          η
          
            t
            u
            r
            b
            i
            n
            e
          
        
      
    
    {\displaystyle \eta _{turbine}}
   and duct pressure losses.
The engine needs compressed air for itself just to run successfully. This air comes from its own compressor and is called secondary air. It does not contribute to making thrust so makes the engine less efficient. It is used to preserve the mechanical integrity of the engine, to stop parts overheating and to prevent oil escaping from bearings for example. Only some of this air taken from the compressors returns to the turbine flow to contribute to thrust production. Any reduction in the amount needed improves the engine efficiency. Again, it will be known for a particular engine design that a reduced requirement for cooling flow of x% will reduce the specific fuel consumption by y%. In other words, less fuel will be required to give take-off thrust, for example. The engine is more efficient.
All of the above considerations are basic to the engine running on its own and, at the same time, doing nothing useful, i.e. it is not moving an aircraft or supplying energy for the aircraft's electrical, hydraulic and air systems. In the aircraft the engine gives away some of its thrust-producing potential, or fuel, to power these systems. These requirements, which cause installation losses, reduce its efficiency. It is using some fuel that does not contribute to the engine's thrust.
Finally, when the aircraft is flying the propelling jet itself contains wasted kinetic energy after it has left the engine. This is quantified by the term propulsive, or Froude, efficiency 
  
    
      
        
          η
          
            p
          
        
      
    
    {\displaystyle \eta _{p}}
   and may be reduced by redesigning the engine to give it bypass flow and a lower speed for the propelling jet, for example as a turboprop or turbofan engine. At the same time forward speed increases the 
  
    
      
        
          η
          
            t
            h
          
        
      
    
    {\displaystyle \eta _{th}}
   by increasing the Overall pressure ratio.
The overall efficiency of the engine at flight speed is defined as 
  
    
      
        
          η
          
            o
          
        
        =
        
          η
          
            p
          
        
        
          η
          
            t
            h
          
        
      
    
    {\displaystyle \eta _{o}=\eta _{p}\eta _{th}}
  .The 
  
    
      
        
          η
          
            o
          
        
      
    
    {\displaystyle \eta _{o}}
   at flight speed depends on how well the intake compresses the air before it is handed over to the engine compressors. The intake compression ratio, which can be as high as 32:1 at Mach 3, adds to that of the engine compressor to give the Overall pressure ratio and 
  
    
      
        
          η
          
            t
            h
          
        
      
    
    {\displaystyle \eta _{th}}
   for the Thermodynamic cycle. How well it does this is defined by its pressure recovery or measure of the losses in the intake. Mach 3 manned flight has provided an interesting illustration of how these losses can increase dramatically in an instant. The North American XB-70 Valkyrie and Lockheed SR-71 Blackbird at Mach 3 each had pressure recoveries of about 0.8, due to relatively low losses during the compression process, i.e. through systems of multiple shocks. During an 'unstart' the efficient shock system would be replaced by a very inefficient single shock beyond the inlet and an intake pressure recovery of about 0.3 and a correspondingly low pressure ratio.
The propelling nozzle at speeds above about Mach 2 usually has extra internal thrust losses because the exit area is not big enough as a trade-off with external afterbody drag.Although a bypass engine improves propulsive efficiency it incurs losses of its own inside the engine itself. Machinery has to be added to transfer energy from the gas generator to a bypass airflow. The low loss from the propelling nozzle of a turbojet is added to with extra losses due to inefficiencies in the added turbine and fan. These may be included in a transmission, or transfer, efficiency 
  
    
      
        
          η
          
            T
          
        
      
    
    {\displaystyle \eta _{T}}
  . However, these losses are more than made up by the improvement in propulsive efficiency. There are also extra pressure losses in the bypass duct and an extra propelling nozzle.
With the advent of turbofans with their loss-making machinery what goes on inside the engine has been separated by Bennett, for example, between gas generator and transfer machinery giving 
  
    
      
        
          η
          
            o
          
        
        =
        
          η
          
            p
          
        
        
          η
          
            t
            h
          
        
        
          η
          
            T
          
        
      
    
    {\displaystyle \eta _{o}=\eta _{p}\eta _{th}\eta _{T}}
  .

The energy efficiency (
  
    
      
        
          η
          
            o
          
        
      
    
    {\displaystyle \eta _{o}}
  ) of jet engines installed in vehicles has two main components:

propulsive efficiency (
  
    
      
        
          η
          
            p
          
        
      
    
    {\displaystyle \eta _{p}}
  ): how much of the energy of the jet ends up in the vehicle body rather than being carried away as kinetic energy of the jet.
cycle efficiency (
  
    
      
        
          η
          
            t
            h
          
        
      
    
    {\displaystyle \eta _{th}}
  ): how efficiently the engine can accelerate the jetEven though overall energy efficiency 
  
    
      
        
          η
          
            o
          
        
      
    
    {\displaystyle \eta _{o}}
   is:

  
    
      
        
          η
          
            o
          
        
        =
        
          η
          
            p
          
        
        
          η
          
            t
            h
          
        
      
    
    {\displaystyle \eta _{o}=\eta _{p}\eta _{th}}
  for all jet engines the propulsive efficiency is highest as the exhaust jet velocity gets closer to the vehicle speed as this gives the smallest residual kinetic energy. For an airbreathing engine an exhaust velocity equal to the vehicle velocity, or a 
  
    
      
        
          η
          
            p
          
        
      
    
    {\displaystyle \eta _{p}}
   equal to one, gives zero thrust with no net momentum change. The formula for air-breathing engines moving at speed 
  
    
      
        v
      
    
    {\displaystyle v}
   with an exhaust velocity 
  
    
      
        
          v
          
            e
          
        
      
    
    {\displaystyle v_{e}}
  , and neglecting fuel flow, is:

  
    
      
        
          η
          
            p
          
        
        =
        
          
            2
            
              1
              +
              
                
                  
                    v
                    
                      e
                    
                  
                  v
                
              
            
          
        
      
    
    {\displaystyle \eta _{p}={\frac {2}{1+{\frac {v_{e}}{v}}}}}
  And for a rocket:

  
    
      
        
          η
          
            p
          
        
        =
        
          
            
              2
              
              (
              
                
                  v
                  
                    v
                    
                      e
                    
                  
                
              
              )
            
            
              1
              +
              (
              
                
                  v
                  
                    v
                    
                      e
                    
                  
                
              
              
                )
                
                  2
                
              
            
          
        
      
    
    {\displaystyle \eta _{p}={\frac {2\,({\frac {v}{v_{e}}})}{1+({\frac {v}{v_{e}}})^{2}}}}
  In addition to propulsive efficiency, another factor is cycle efficiency; a jet engine is a form of heat engine. Heat engine efficiency is determined by the ratio of temperatures reached in the engine to that exhausted at the nozzle. This has improved constantly over time as new materials have been introduced to allow higher maximum cycle temperatures. For example, composite materials, combining metals with ceramics, have been developed for HP turbine blades, which run at the maximum cycle temperature. The efficiency is also limited by the overall pressure ratio that can be achieved. Cycle efficiency is highest in rocket engines (~60+%), as they can achieve extremely high combustion temperatures. Cycle efficiency in turbojet and similar is nearer to 30%, due to much lower peak cycle temperatures.

The combustion efficiency of most aircraft gas turbine engines at sea level takeoff conditions
is almost 100%. It decreases nonlinearly to 98% at altitude cruise conditions. Air-fuel ratio ranges from 50:1 to 130:1. For any type of combustion chamber there is a rich and weak limit to the air-fuel ratio, beyond which the flame is extinguished. The range of air-fuel ratio between the rich and weak limits is reduced with an increase of air velocity. If the
increasing air mass flow reduces the fuel ratio below certain value, flame extinction occurs.


=== Consumption of fuel or propellant ===
A closely related (but different) concept to energy efficiency is the rate of consumption of propellant mass. Propellant consumption in jet engines is measured by specific fuel consumption, specific impulse, or effective exhaust velocity. They all measure the same thing. Specific impulse and effective exhaust velocity are strictly proportional, whereas specific fuel consumption is inversely proportional to the others.
For air-breathing engines such as turbojets, energy efficiency and propellant (fuel) efficiency are much the same thing, since the propellant is a fuel and the source of energy. In rocketry, the propellant is also the exhaust, and this means that a high energy propellant gives better propellant efficiency but can in some cases actually give lower energy efficiency.
It can be seen in the table (just below) that the subsonic turbofans such as General Electric's CF6 turbofan use a lot less fuel to generate thrust for a second than did the Concorde's Rolls-Royce/Snecma Olympus 593 turbojet. However, since energy is force times distance and the distance per second was greater for the Concorde, the actual power generated by the engine for the same amount of fuel was higher for the Concorde at Mach 2 than the CF6. Thus, the Concorde's engines were more efficient in terms of energy per mile.


=== Thrust-to-weight ratio ===

The thrust-to-weight ratio of jet engines with similar configurations varies with scale, but is mostly a function of engine construction technology. For a given engine, the lighter the engine, the better the thrust-to-weight is, the less fuel is used to compensate for drag due to the lift needed to carry the engine weight, or to accelerate the mass of the engine.
As can be seen in the following table, rocket engines generally achieve much higher thrust-to-weight ratios than duct engines such as turbojet and turbofan engines. This is primarily because rockets almost universally use dense liquid or solid reaction mass which gives a much smaller volume and hence the pressurization system that supplies the nozzle is much smaller and lighter for the same performance. Duct engines have to deal with air which is two to three orders of magnitude less dense and this gives pressures over much larger areas, which in turn results in more engineering materials being needed to hold the engine together and for the air compressor.


=== Comparison of types ===

Propeller engines handle larger air mass flows, and give them smaller acceleration, than jet engines. Since the increase in air speed is small, at high flight speeds the thrust available to propeller-driven aeroplanes is small. However, at low speeds, these engines benefit from relatively high propulsive efficiency.
On the other hand, turbojets accelerate a much smaller mass flow of intake air and burned fuel, but they then reject it at very high speed. When a de Laval nozzle is used to accelerate a hot engine exhaust, the outlet velocity may be locally supersonic. Turbojets are particularly suitable for aircraft travelling at very high speeds.
Turbofans have a mixed exhaust consisting of the bypass air and the hot combustion product gas from the core engine. The amount of air that bypasses the core engine compared to the amount flowing into the engine determines what is called a turbofan's bypass ratio (BPR).
While a turbojet engine uses all of the engine's output to produce thrust in the form of a hot high-velocity exhaust gas jet, a turbofan's cool low-velocity bypass air yields between 30% and 70% of the total thrust produced by a turbofan system.The net thrust (FN) generated by a turbofan can also be expanded as:

  
    
      
        
          F
          
            N
          
        
        =
        
          
            
              
                m
                ˙
              
            
          
          
            e
          
        
        
          v
          
            h
            e
          
        
        −
        
          
            
              
                m
                ˙
              
            
          
          
            o
          
        
        
          v
          
            o
          
        
        +
        B
        P
        R
        
        (
        
          
            
              
                m
                ˙
              
            
          
          
            c
          
        
        
          v
          
            f
          
        
        )
      
    
    {\displaystyle F_{N}={\dot {m}}_{e}v_{he}-{\dot {m}}_{o}v_{o}+BPR\,({\dot {m}}_{c}v_{f})}
  where:

Rocket engines have extremely high exhaust velocity and thus are best suited for high speeds (hypersonic) and great altitudes. At any given throttle, the thrust and efficiency of a rocket motor improves slightly with increasing altitude (because the back-pressure falls thus increasing net thrust at the nozzle exit plane), whereas with a turbojet (or turbofan) the falling density of the air entering the intake (and the hot gases leaving the nozzle) causes the net thrust to decrease with increasing altitude. Rocket engines are more efficient than even scramjets above roughly Mach 15.


=== Altitude and speed ===
With the exception of scramjets, jet engines, deprived of their inlet systems can only accept air at around half the speed of sound. The inlet system's job for transonic and supersonic aircraft is to slow the air and perform some of the compression.
The limit on maximum altitude for engines is set by flammability – at very high altitudes the air becomes too thin to burn, or after compression, too hot. For turbojet engines altitudes of about 40 km appear to be possible, whereas for ramjet engines 55 km may be achievable. Scramjets may theoretically manage 75 km. Rocket engines of course have no upper limit.
At more modest altitudes, flying faster compresses the air at the front of the engine, and this greatly heats the air. The upper limit is usually thought to be about Mach 5–8, as above about Mach 5.5, the atmospheric nitrogen tends to react due to the high temperatures at the inlet and this consumes significant energy. The exception to this is scramjets which may be able to achieve about Mach 15 or more, as they avoid slowing the air, and rockets again have no particular speed limit.


=== Noise ===
The noise emitted by a jet engine has many sources. These include, in the case of gas turbine engines, the fan, compressor, combustor, turbine and propelling jet/s.The propelling jet produces jet noise which is caused by the violent mixing action of the high speed jet with the surrounding air. In the subsonic case the noise is produced by eddies and in the supersonic case by Mach waves. The sound power radiated from a jet varies with the jet velocity raised to the eighth power for velocities up to 2,000 ft/sec and varies with the velocity cubed above 2,000 ft/sec. Thus, the lower speed exhaust jets emitted from engines such as high bypass turbofans are the quietest, whereas the fastest jets, such as rockets, turbojets, and ramjets, are the loudest. For commercial jet aircraft the jet noise has reduced from the turbojet through bypass engines to turbofans as a result of a progressive reduction in propelling jet velocities. For example, the JT8D, a bypass engine, has a jet velocity of 1450 ft/sec whereas the JT9D, a turbofan, has jet velocities of 885 ft/sec (cold) and 1190 ft/sec (hot).The advent of the turbofan replaced the very distinctive jet noise with another sound known as ""buzz saw"" noise. The origin is the shockwaves originating at the supersonic fan blades at takeoff thrust.


=== Cooling ===
Adequate heat transfer away from the working parts of the jet engine is critical to maintaining strength of engine materials and ensuring long life for the engine.
After 2016, research is ongoing in the development of transpiration cooling techniques to jet engine components.


== Operation ==

In a jet engine, each major rotating section usually has a separate gauge devoted to monitoring its speed of rotation. 
Depending on the make and model, a jet engine may have an N1 gauge that monitors the low-pressure compressor section and/or fan speed in turbofan engines. The gas generator section may be monitored by an N2 gauge, while triple spool engines may have an N3 gauge as well. Each engine section rotates at many thousands RPM. Their gauges therefore are calibrated in percent of a nominal speed rather than actual RPM, for ease of display and interpretation.


== See also ==


== References ==


=== Bibliography ===
Brooks, David S. (1997). Vikings at Waterloo: Wartime Work on the Whittle Jet Engine by the Rover Company. Rolls-Royce Heritage Trust. ISBN 978-1-872922-08-9.
Golley, John (1997). Genesis of the Jet: Frank Whittle and the Invention of the Jet Engine. Crowood Press. ISBN 978-1-85310-860-0.
Hill, Philip; Peterson, Carl (1992), Mechanics and Thermodynamics of Propulsion (2nd ed.), New York: Addison-Wesley, ISBN 978-0-201-14659-2
Kerrebrock, Jack L. (1992). Aircraft Engines and Gas Turbines (2nd ed.). Cambridge, MA: The MIT Press. ISBN 978-0-262-11162-1.


== External links ==
 Media related to Jet engines at Wikimedia Commons
 The dictionary definition of jet engine at Wiktionary
Media about jet engines from Rolls-Royce
How Stuff Works article on how a Gas Turbine Engine works
Influence of the Jet Engine on the Aerospace Industry
An Overview of Military Jet Engine History, Appendix B, pp. 97–120, in Military Jet Engine Acquisition (Rand Corp., 24 pp, PDF)
Basic jet engine tutorial (QuickTime Video)
An article on how reaction engine works"
"The LS based small-block engine is the primary V8 used in General Motors' line of rear-wheel-drive cars and trucks. Introduced in January 1995, it is a ""clean sheet"" design with only rod bearings, lifters, and bore spacing in common with the longstanding Chevrolet small block V8 that preceded it as the basis for GM small-block V8s. The basic LS variations use cast iron blocks, while performance editions are all aluminium with cast iron cylinder liners.
The LS small-block has been manufactured in three Generations – III, IV, and V – with preceding Generations I and II of modular GM small-block engines having been based on the Chevrolet small-block V8 originally released in 1954.  GM recycled the ""LT"" designation beginning with the LS Generation V ""LT1"" in 2014.
Several versions of the LS were used in the Chevrolet Corvette, beginning with the LS1 in 1997 through the LS9 and others in 2013. Variants of the LT version of the GM small-block have been used since. 
Most of the credit for this engine family must go to Ed Koerner, GM's Powertrain vice president of engineering operations at the time. He was a V8 design veteran and former National Hot Rod Association (NHRA) record holder in drag racing. Koerner had been the Chief Engineer for all the existing GM small-block V8 engines, and was put in charge of the ""all new"" Gen III LS1 V-8 development project, which would share no parts with previous engines. Design team members included Alan Hayman, Jim Mazzola, Ron Sperry, Bill Compton, Brian Kaminski, Jon Lewis, Stan Turek, Don Weiderhold, and Dave Wandel. 
The performance improvements in the LS-family V8s over the previous classic small block V8 family are several. The lower section of the block incorporates deep side skirts, along with 6-bolt cross-bolted main bearing caps. This fully boxes the crankshaft, creating a very strong and rigid structure that has been hot-rodded by enthusiasts to over 1,000-HP. 
Although it is the same compact physical size as the classic small block V8, this block can accept a 4-inch stroke as an option in its stock form, due to the cam location being elevated slightly, compared to previous block designs. Also, the cam bearing journals are larger, to allow for a higher cam-lift profile than was previously possible. The stock aluminum heads can provide a high amount of air-flow, which previously could only be found in aftermarket race-performance heads.  
The aluminum heads also incorporate steam vents to prevent gas pockets from building up in critical areas, and this is vital in allowing the coolant to manage heat build-up for high-performance applications. Such design features allow for a higher compression ratio with no fear of detonation. The thermostat has been located at a low position, which eliminates the possibility of a gas pocket preventing the thermostat from properly sensing the heat of the coolant. 
Previous generations incorporated a coolant passage through the intake manifold to warm the incoming fuel-air mixture in very cold climates. However, modern fuel-injection techniques eliminate fuel atomization concerns under all conditions, so the LS family uses a dry intake manifold. This removes a common coolant leakage point, and also allows the incoming air to remain as cool as possible for better power production. 


== Generation III (1997–2007) ==
The GM Generation I and Generation II (LT) engine families are both derived from the longstanding Chevrolet small block V8. The Generation III small-block V8 was a ""clean sheet"" design, which replaced the Gen I and Gen II engine families in 2002 and 1995 respectively.
Like the previous two generations, the Buick and Oldsmobile small blocks, the gen III/IV can be found in many different brands. The engine blocks were cast in aluminium for car applications, and iron for most truck applications (notable exceptions include the Chevrolet TrailBlazer SS, Chevrolet SSR and a limited run of Chevrolet/GMC Extended Cab Standard Box Trucks).
The architecture of the LS series makes for an extremely strong engine block with the aluminium engines being nearly as strong as the iron generation I and II engines. The LS engine also used coil-near-plug style ignition to replace the distributor setup of all previous small-block based engines.
The traditional five-bolt pentagonal cylinder head pattern was replaced with a square four-bolt design (much like the 64-90 Oldsmobile V8), and the pistons are of the flat-topped variety (in the LS1, LS2, LS3, LS6, LS7, LQ9 and L33), while all other variants, including the new LS9 and LQ4 truck engine received a dished version of the GM hypereutectic piston.
The cylinder firing order was changed to 1-8-7-2-6-5-4-3, so that the LS series now corresponds to the firing pattern of other modern V8 engines (for example the Ford Modular V8).


=== 3.898 in. bore blocks (1997–2005) ===
The first of the Generation IIIs, the LS1 was the progenitor of the new architecture design that would transform the entire V8 line and influence the last of the Big Blocks.


==== 5.7L ====

The Generation III 5.7L (LS1 and LS6) engines share little other than similar displacement, external dimensions, and rod bearings, with its predecessor (LT1). It is an all-aluminium 5,665 cc (5.7 L; 345.7 cu in) pushrod engine with a bore and a stroke of 99 mm × 92 mm (3.898 in × 3.622 in).
LS1
When introduced in the 1997 Corvette the LS1 was rated at 345 hp (257 kW) at 5,600 rpm and 350 lb⋅ft (475 N⋅m) at 4,400 rpm.  After improvements to the intake and exhaust manifolds in 2001 the rating improved to 350 hp (261 kW) and 365 lb⋅ft (495 N⋅m). The LS1 was used in the Corvette from 97–04. It was also used in 98-02 GM F-Body (Camaro & Firebird) cars with a rating of over 305–325 bhp (227–242 kW), which was rumored to be conservative. The extra horsepower was claimed to come from the intake ram-air effect available in the SS and WS6 models. In Australia, continuous modifications were made to the LS1 engine throughout its lifetime, reaching 380 hp/365 ft-lb in the HSV's YII series, and a Callaway modified version named ""C4B"" was fitted to HSV GTS models producing 400 bhp (298 kW) and 405 lb⋅ft (549 N⋅m) of torque.

1997–2004 Chevrolet Corvette
1998–2002 Pontiac Firebird Formula, Trans Am
1998–2002 Chevrolet Camaro
1999–2004 Holden Special Vehicles Clubsport (VT, VX, Y Series)
1999–2004 Holden Special Vehicles Clubsport R8 (VT, VX, Y Series)
1999–2004 Holden Special Vehicles Grange (VT, VX, Y Series)
1999–2004 Holden Special Vehicles GTS (VT, VX, Y Series)
1999–2004 Holden Special Vehicles Maloo (VT, VX, Y Series)
1999–2004 Holden Special Vehicles Senator Signature (VT, VX, Y Series)
2000–2005 Holden Ute
1999–2005 Holden Commodore (VT, VX, VY, VZ)
1999–2005 Holden Statesman (WH, WK, WL)
1999–2005 Holden Caprice (WH, WK, WL)
2000–2002 Holden Special Vehicles Senator 300 (VX)
2000–2002 Holden Special Vehicles Coupé GTO (VX)
2000–2002 Holden Special Vehicles Coupé GTS (VX)
2000–2002 Holden Special Vehicles SV300 (VX)
2000–2004 Holden Special Vehicles Maloo R8 (VX, Y Series)
2001 Opel Omega V8 (prototype)
2001–2005 Holden Monaro CV8
2005 Holden Monaro CV8 Z
2001–2005 CSV Mondo
2001–2013 Mosler MT900
2003–2004 Holden Special Vehicles Clubsport SE (Y Series)
2003–2004 Holden Special Vehicles Coupé LE (Y Series)
2003–2004 Holden Special Vehicles Coupé4 AWD (Y Series)
2003–2004 Holden Special Vehicles Avalanche XUV (Y Series)
2003–2004 Holden Special Vehicles Avalanche XUV AWD (Y Series)
2004 Pontiac GTO
2006–present Elfin MS8 Streamliner
2006–present Elfin MS8 Clubman
LS6

The LS6 designation was also used on a 454 CID Chevrolet Big-Block engine of the 1970s, as well as an iteration of the GM Iron Duke engine from the late 1970sThe LS6 is a higher-output version of GM's LS1 engine and retains the same capacity. The initial 2001 LS6 produced 385 bhp (287 kW) and 385 lb⋅ft (522 N⋅m), but the engine was modified for 2002 through 2004 to produce 405 bhp (302 kW) and 400 lb⋅ft (542 N⋅m) of torque. The LS6 was originally only used in the high-performance C5 Corvette Z06 model, with the Cadillac CTS V-Series getting the 400 bhp (298 kW) engine later. The V-Series used the LS6 for two years before being replaced by the LS2 in 2006. For 2006, the Z06 replaced the LS6 with the new LS7.
The LS6 shares its basic block architecture with the GM LS1 engine, but other changes were made to the design such as windows cast into the block between cylinders, improved main web strength and bay to bay breathing, an intake manifold and MAF-sensor with higher flow, a camshaft with higher lift and more duration, a higher compression ratio of 10.5:1, sodium-filled valves, and a revised oiling system better suited to high lateral acceleration.
LS6 intake manifolds were also used on all 2001+ LS1/6 engines.
The casting number, located on the top rear edge of the block, is 12561168.
Applications:

2001-2004 Corvette Z06
2004–2005 Cadillac CTS V-Series
2007 SSC Ultimate Aero TT


=== 3.78 in. bore blocks (1999–2007) ===
The 4.8 L and the 5.3 L are smaller truck versions of the LS1 and were designed to replace the 305 and the 350 in trucks.  The 4.8L and the 5.3L engines share the same Gen III LS-series engine block and heads (upper end) and therefore, some parts interchange freely between these engines and other variants in the LS family.


==== 4.8L LR4 ====
The Vortec 4800 LR4 (VIN code ""V"") is a Generation III small block V8 truck engine. Displacement is 4,806 cc (4.8 L; 293.3 cu in) with a bore and stroke of 96 mm × 83 mm (3.78 in × 3.27 in). It is the smallest of the Generation III Vortec truck engines and was the replacement for the 5.0 L 5000 L30. The LR4 engines in 1999 produced 255 hp (190 kW) while the 2000 and above models made 270–285 hp (201–213 kW) and all have a torque rating between 285–295 lb⋅ft (386–400 N⋅m), depending on the model year and application. The 2005-2006 models made 285 hp (213 kW) and 295 lb⋅ft (400 N⋅m), LR4s are manufactured at St. Catharines, Ontario and Romulus, Michigan. It uses flat top pistons.
LR4 applications:

2003–2006 Chevrolet Express/GMC Savana
1999–2006(2007 Classic) Chevrolet Silverado/GMC Sierra 1500
2000–2006 Chevrolet Tahoe/GMC Yukon


==== 5.3 L ====
The Vortec 5300, or LM7/L59/LM4, is a V8 truck engine. It is a longer-stroked by 9 mm (0.35 in) version of the Vortec 4800 and replaced the L31. L59 denoted a flexible fuel version of the standard fuel LM7 engine. Displacement is 5,327 cc (5.3 L; 325.1 cu in) from a bore and stroke of 96 mm × 92 mm (3.78 in × 3.62 in). Vortec 5300s are built in St. Catharines, Ontario and Romulus, Michigan. Another engine variant, the L33, shares the same displacement, but has an aluminum block with cast in cylinder liners, much like the LS1.


===== LM7 =====
The Vortec 5300 LM7 (VIN code 8th digit ""T"") was introduced in 1999. It has a cast iron block and aluminum heads, and can be considered the ""garden variety"" version of the Generation III V8s.
The 1999 LM7 engine produced 270 hp (201 kW) and 315 lb⋅ft (427 N⋅m) of torque.
The 2000-2003 engines made 285 hp (213 kW) and 325 lb⋅ft (441 N⋅m).
The 2004-2007 engines made 295 hp (220 kW) and 335 lb⋅ft (454 N⋅m) of torque.
The stock cam specs @ .050 lift are: 190/191 duration, .466/.457 lift, 114 LSA, 112/116 Timing


===== L59 =====
The Vortec 5300 L59 (VIN code ""Z"") is a flexible fuel version of the LM7. The 2002-2003 made 285 hp (213 kW) and 320 lb⋅ft (434 N⋅m), while the 2004-2007 L59s made 295 hp (220 kW) and 335 lb⋅ft (454 N⋅m).
L59 applications:

2002–2007 Chevrolet Avalanche Z71 Package
2002–2006 Chevrolet Tahoe/GMC Yukon
2002–2006 Chevrolet Suburban/GMC Yukon XL 1500
2002–2007 GMC Sierra 1500 / Chevrolet Silverado 1500


===== LM4 =====
The Vortec 5300 LM4 (VIN code ""P"") is an aluminum block version of the LM7, and had a short production life. The LM4s made 290 hp (216 kW) and 325 lb⋅ft (441 N⋅m), It should not be confused with the L33 described below.
LM4 applications:

2003–2005 Chevrolet TrailBlazer EXT
2003–2004 Isuzu Ascender
2003-2004 GMC Envoy XL
2003–2004 Chevrolet SSR
2004 Buick Rainier


===== L33 =====
The Vortec 5300 L33 (VIN code ""B"") is an aluminum block version of the LM7, known as the Vortec 5300 HO in marketing materials. The L33 uses flat top pistons from the 4.8L instead of standard dished pistons from the LM7.  It also uses 799 cylinder heads, which are identical to 243 castings found on LS6s and LS2s, lacking only the Corvette spec valve springs and hollow stem exhaust valves on the 2002-2004 LS6. This combination increased the compression from 9.5:1 to 10.0:1. The L33 also had a specific camshaft not shared with any other engine, specs @ .050 duration are: 193 duration, .482 lift, 116 LSA. As a result, power increased by 15 hp (11 kW), to 310 hp (230 kW) and 335 lb·ft (441 N·m). It was only available on extended cab 4WD pickup trucks. Only 25% of trucks made in 2005 had the L33 engine.
L33 applications:

2005–2007 Chevrolet Silverado 1500 4WD
2005–2007 GMC Sierra 1500 4WD


=== 4.00 in. bore blocks (1999–2007) ===
The 6.0 L is a larger version of the LS motor. 6.0 L blocks were cast of iron, designed to bridge the gap between the new small blocks and big blocks in truck applications.  There were two versions of this engine: LQ4, and LQ9, the latter being more performance oriented.


==== 6.0 L ====
The Vortec 6000 is a V8 truck engine. Displacement is 5,967 cc (6.0 L; 364.1 cu in) from a bore and stroke of 101.6 mm × 92 mm (4.00 in × 3.62 in). It is an iron/aluminum (1999 & 2000 model year engines had cast iron heads) design and produces 300 to 345 hp (224 to 257 kW) and 360 to 380 lb⋅ft (488 to 515 N⋅m).


===== LQ4 =====
The Vortec 6000 LQ4, is a V8 truck engine. Displacement is 5,967 cc (6.0 L; 364.1 cu in) from a bore and stroke of 101.6 mm × 92 mm (4.00 in × 3.62 in). It is an iron/aluminum (1999 & 2000 model year engines had cast iron heads) design and produces 300 to 325 hp (224 to 242 kW) and 360 to 370 lb⋅ft (488 to 502 N⋅m). LQ4s are built in Romulus, Michigan and Silao, Mexico.
(VIN U) Applications:

Chevrolet Express/GMC Savana
Chevrolet Silverado 2500 Pickup, 3500 Pickup, Crew Cab, and Chassis Cab/GMC Sierra 2500 HD Pickup and Crew Cab, C3, Denali, and 3500 Pickup and Chassis Cab, 1500HD Crew Cab
Chevrolet Suburban/GMC Yukon XL Denali
Hummer H2 SUT
GMC Yukon Denali


===== LQ9 =====
The Vortec HO 6000 or VortecMAX is a special high-output version of the Vortec 6000 V8 truck engine originally designed for Cadillac in 2002. This engine was renamed as the VortecMAX for 2006. It features high-compression (10:1) flat-top pistons for an extra  10 hp (7 kW) and 10 lb⋅ft (14 N⋅m), bringing output to 345 hp (257 kW) and 380 lb⋅ft (515 N⋅m). LQ9s are built only in Romulus, Michigan.


== Generation IV (2005–2020) ==
In 2004, the Generation III was superseded by the Generation IV. This category of engines has provisions for high-displacement ranges up to 7,441 cc (7.4 L; 454.1 cu in) and power output to 776 bhp (579 kW). Based on the Generation III design, Generation IV was designed with displacement on demand in mind, a technology that allows every other cylinder in the firing order to be deactivated. It can also accommodate variable valve timing.
A 3 valves per cylinder design was originally slated for the LS7, which would have been a first for a GM pushrod engine; but the idea was shelved owing to design complexities and when the same two-valve configuration as the other Generation III and IV engines proved to be sufficient to meet the goals for the LS7.


=== 4.00 in. bore blocks (2005–present) ===
This family of blocks were the first of the generation IV small block with the LS2 being the progenitor of this family and generation.  This family of blocks has seen a wide range of applications from performance vehicles to truck usage.


==== 6.0 L ====
The Generation IV 6000 is a V8 engine that displaces 5,972 cc (6.0 L; 364.4 cu in) from bore and stroke of 101.6 mm × 92.075 mm (4.000 in × 3.625 in). It features either a cast iron or aluminum engine block with cast aluminum heads. Certain versions feature variable cam phasing, Active Fuel Management, and Flex-fuel capability.
LS2

LS2 can also refer to the 1973–1974 Super Duty 455 cu in (7.5 L) Pontiac V8 engine
LS2 can also refer to the 1985 Oldsmobile Diesel V6 engine.The LS2 was introduced as the Corvette's new base engine for the 2005 model year. It also appeared as the standard powerplant for the 2005–2006 GTO. It produces 400 bhp (298 kW) at 6000 rpm and 400 lb⋅ft (542 N⋅m) at 4400 rpm from a slightly larger displacement of 5,967 cc (6.0 L; 364.1 cu in). It is similar to the high-performance LS6, but with improved torque throughout the rpm range. The LS2 uses the ""243"" casting heads used on the LS6 (although without the sodium-filled valves), a smaller camshaft, and an additional 18 cubic inches (290 cc). The compression of the LS2 was also raised to 10.9:1 compared to the LS1s' 10.25:1 and the LS6s' 10.5:1. The LS2 in the E-series HSVs are modified in Australia to produce 412 bhp (307 kW) and 412 lb⋅ft (559 N⋅m) of torque. The LS2 in the Chevrolet Trailblazer SS and the Saab 9-7X Aero are rated at 395 bhp (295 kW) (2006–2007) or 390 bhp (291 kW) (2008–2009) and 400 lb⋅ft (542 N⋅m) of torque due to a different (sometimes referred to as a ""truck"") intake manifold that produces more torque at lower RPMs.
The LS2 is also used as the basis of the NASCAR Specification Engine that is used as an optional engine in NASCAR's Camping World Series East and West divisions starting in 2006, and starting in 2010 may also be used on tracks shorter than two kilometers (1.25 miles) in the Camping World Truck Series.A version of NASCAR V8 cylinder block cast in Compacted Graphite Iron by Grainger & Worrall won the UK's Casting of the Year Award 2010.

L76
The L76 is derived from the LS2, and like the LS2 it features an aluminum engine block. However, the L76 does feature Active fuel management (AFM). While the displacement on demand technology was disabled on Holdens, this feature is enabled on the 2008 Pontiac G8 GT and subsequently refitted in the 2009 model Holdens with AFM enabled, but only on models fitted with the 6L80 Automatic Transmission. The engine also meets Euro III emissions requirements. Output is 348 bhp (260 kW) at 5600 rpm and 376 lb⋅ft (510 N⋅m) at 4400 rpm for the Holden variant, and 361 bhp (269 kW) and 385 lb⋅ft (522 N⋅m)  for the G8 GT.
The Vortec 6000 or new VortecMax version is based on the Holden L76 engine, and features variable cam phasing, along with Active Fuel Management. It can be considered the replacement for the Generation III LQ9 engine. It produces 367 hp (274 kW) at 5400 rpm and 375 lb⋅ft (508 N⋅m) at 4400 rpm. Production of the truck-spec L76 started in late 2006, and it was only available with the new body style Silverado and Sierra. The final year for the truck-spec L76 was 2009 in the Silverado and Sierra; it was replaced by the 6.2L L9H engine for MY 2010.

L98

For the tuned-port Generation I engine of the same RPO, see Chevrolet L98The L98 is a slightly modified version of the L76. Since Holden did not use the displacement on demand technology of the L76, some redundant hardware was removed to form the L98. Power increased to 270 kW (362 bhp) at 5700 rpm and 530 N⋅m (391 lb⋅ft) at 4400 rpm.

L77

L77 can also refer to the 455 Oldsmobile large crank journal engine.L77 engines were released in the Holden Commodore Series II VE range in both manual and automatic transmissions, along with the Chevrolet Caprice PPV (police car). The L77 differs from the L76 with its inclusion of Flex-fuel capability, allowing it to run on E85 ethanol.  The L77 is rated at 270 kW (362 hp) and 530 N⋅m (391 lb⋅ft) of torque in the manual Commodore SS and SS-V, in automatic Commodores it is rated at 260 kW (349 hp) and 517 N⋅m (381 lb⋅ft) of torque.

LY6
The LY6 is a Generation IV small block V8 truck engine with a cast iron block. It shares the same bore and stroke as its LQ4 predecessor. Like other Gen IV engines, it features variable valve timing. It generated 361 hp (269 kW) at 5,600 rpm and 385 lb⋅ft (522 N⋅m) of torque at 4,400 rpm using ""regular"" gas, or ~87 octane. Redline is 6,000 rpm and compression ratio is 9.6:1. This engine uses L92 / LS3 style rectangle port cylinder heads, though without the sodium-filled exhaust valves of the LS3.
Applications:

2007–2009 Chevrolet Silverado HD
2007–2009 GMC Sierra HD
2007–2013 Chevrolet Suburban 3/4 ton
2007–2013 GMC Yukon XL 3/4 tonL96
The L96 is essentially identical to its predecessor, the LY6.  The primary difference is that the L96 is Flex Fuel capable, while the LY6 is not.

LFA
The LFA is a Generation IV small block V8 truck engine. The LFA variant is used in the GM's ""two mode"" hybrid GMT900 trucks and SUVs, and is an all-aluminum design. It has a 10.8:1 compression ratio and produces 332 hp (248 kW) at 5100 rpm and 367 lb⋅ft (498 N⋅m) at 4100 rpm. Engine VIN code of 5.
In 2008 this engine was selected by Wards as one of the 10 best engines in any regular production vehicle.

LZ1
The LZ1 is almost entirely based on its predecessor, the LFA, but with some revisions, such as including up-integrated electronic throttle control, long-life spark plugs, GM's Oil Life System, Active Fuel Management and variable valve timing. It has the same compression ratio, power and torque ratings as its predecessor, the LFA.


=== 3.78 in. bore blocks (2005–present) ===
This family of blocks is just an updated version of its Generation III predecessor with Generation IV updates and capabilities.  Applications of this family were mainly for trucks but did see some mild usage (with some modifications) in front-wheel-drive cars.


==== 4.8 L ====


===== LY2 =====
The Vortec 4800 LY2 (VIN code ""C"") is a Generation IV small block V8 truck engine. Like its LR4 predecessor, it gets its displacement from a bore and stroke of 96 mm × 83 mm (3.78 in × 3.27 in). The smallest member of the Generation IV engine family, it is unique in that it is the only member of that family that is used in trucks that does not feature variable valve timing. It has a cast iron block. Power output is  260–295 hp (194–220 kW) and torque is 295–305 lb⋅ft (400–414 N⋅m).
LY2 applications:

2008–2009 Chevrolet Express/GMC Savana
2007–2009 Chevrolet Silverado
2007–2009 Chevrolet Tahoe
2007–2009 GMC Sierra
2007–2009 GMC Yukon


===== L20 =====
The Vortec 4800 L20 makes more power and features variable valve timing. The system adjusts both intake and exhaust timing, but does not come with Active Fuel Management. The L20 has a cast iron block and power output is 260–302 hp (194–225 kW) while torque is 295–305 lb⋅ft (400–414 N⋅m). The Vortec 4800 base engines were dropped from the Chevrolet Tahoe and GMC Yukon in favor of the 5300 with Active Fuel Management.
L20 applications:

2010–2017 Chevrolet Express/GMC Savana
2010–2013 Chevrolet Silverado
2010–2013 GMC Sierra


==== 5.3 L ====
The Generation IV 5.3L engines share all the improvements and refinements found in other Generation IV engines.  8 versions of the Gen IV 5.3L engine were produced: 3 iron blocks (LY5, LMG, and LMF) and 5 aluminum blocks (LH6, LH8, LH9, LC9, and LS4). All versions featured Active Fuel Management except for the LH8, LH9 and LMF.


===== LMF =====
Introduced in 2010, the LMF is a lower tech version used in the lower volume half ton vehicles cargo vans with AWD that still used the 4 speed automatic, and do not use Active Fuel Management.
LMF applications:

2010-2014 Chevrolet Express 1/2 ton AWD
2010-2014 GMC Savana 1/2 ton AWD


===== LH6 =====
The Vortec 5300 LH6 (VIN code ""M"") with Active Fuel Management replaced the LM4 for 2005, and was the first of the Generation IV small block V8 truck engines to go into production. The LH6 produced 300 to 315 hp (224 to 235 kW) and 330 to 338 lb⋅ft (447 to 458 N⋅m). It is the aluminum block counterpart to the LY5.


===== LY5 =====
Introduced in 2007, the Vortec 5300 LY5 (VIN code ""J"") is the replacement for the LM7 Generation III engine. For SUV applications, it is rated at 320 hp (239 kW) and 340 lb⋅ft (461 N⋅m) of torque; while for pickup truck applications, it is rated at 315–320 hp (235–239 kW) at 5200 rpm and 335–340 lb⋅ft (454–461 N⋅m) at 4000 rpm


===== LMG =====
The Vortec 5300 LMG (VIN code ""0"") is the flexible-fuel version of the LY5. Power and torque ratings for SUV and pickup truck applications are the same as each application's LY5 rating. Variable valve timing was added for the 2010 model year.


===== LC9 =====
The Vortec 5300 LC9 (VIN code ""3"" or ""7"") is the aluminum block Flex-Fuel version of the LH6, and is found in 4WD models. SUV applications are rated at 320 hp (239 kW) at 5400 rpm and 335 lb⋅ft (454 N⋅m) at 4000 rpm. Pickup truck applications are rated at 315 hp (235 kW) at 5300 rpm and 335 lb⋅ft (454 N⋅m) at 4000 rpm. Variable valve timing was added for the 2010 model year.
LC9 applications:

2007–2013 Chevrolet Avalanche
2007–2013 Chevrolet Silverado 1500
2007–2014 Chevrolet Suburban 1/2 ton
2007–2013 GMC Sierra 1500
2007–2014 GMC Yukon XL 1/2 ton


===== LH8 =====
The LH8 was introduced in 2008 as the V8 option for the Hummer H3. It was the most basic engine of its family, it did not use any special technology. Also known as the Vortec 5300, the LH8 was available in the H3 and GM mid-size pickups through 2009.
The LH8 is a variant of the 5.3 L Gen IV small block V8 modified to fit in the engine bay of the GMT 345 SUV and GMT 355 trucks. It produces 300 hp (224 kW) at 5200 rpm and 320 lb⋅ft (434 N⋅m) at 4000 rpm. It has a displacement of 5,327 cc (5.3 L; 325.1 cu in) and a compression ratio of 9.9:1.LH8 applications:

2008–2009 Hummer H3 Alpha
2009 Chevrolet Colorado/GMC Canyon


===== LH9 =====
In 2010, the LH8 was replaced by the LH9. The LH9 was upgraded with Variable Valve Timing (VVT) and flex fuel capability. The Vortec 5300 LH9 produces 300 hp (224 kW) at 5200 rpm and 320 lb⋅ft (434 N⋅m) at 4000 rpm. It has a displacement of 5,327 cc (5.3 L; 325.1 cu in). The compression ratio was 9.9:1 for 2010, but was reduced to 9.7:1 for the remaining two years of production.LH9 applications:

2010 Hummer H3 Alpha
2010–2012 Chevrolet Colorado/GMC


===== LS4 =====

LS4 can also refer to a 454 cu in (7.4 L) Chevrolet Big-Block engine of the 1970sThe LS4 is a 5,327 cc (5.3 L; 325.1 cu in) version of the Generation IV block. Though it has the same displacement as the Vortec 5300 LY5, it features an aluminum block instead of iron, and it uses the same cylinder head casting as the Generation III LS6 engine. The bellhousing bolt pattern differs from the rear-wheel drive blocks.
This engine is adapted for transverse front-wheel drive applications. According to GM, ""The crankshaft is shortened 13–3 mm (0.51–0.12 in) at the flywheel end and 10 mm (0.39 in) at the accessory drive end – to reduce the length of the engine compared to the 6.0 L. All accessories are driven by a single serpentine belt to save space. The water pump is mounted remotely with an elongated pump manifold that connects it to the coolant passages. Revised oil pan baffles, or windage trays, are incorporated into the LS4 to ensure that the oil sump stays loaded during high-g cornering."" Active Fuel Management is also used. Output of this version is 303 hp (226 kW)/300 hp on LaCrosse Super and 323 lb⋅ft (438 N⋅m).
Applications:

2005–2008 Pontiac Grand Prix GXP
2006–2009 Chevrolet Impala SS
2006–2007 Chevrolet Monte Carlo SS
2008–2009 Buick LaCrosse Super


=== 4.125 in. bore blocks (2006–present) ===
Inspired by the LS1.R in size and performance goals, this family of blocks was designed for race oriented performance.  The only engine with this bore size that was used in a production vehicle is the LS7 with the LSX being only for aftermarket use.  One unique feature of this family is that the cylinders are siamesed, no water passages between neighboring cylinders.  This was done to increase both bore size and block strength.


==== 7.0 L ====
LS7

LS7 can also refer to a 454 over the counter 460+ hp high compression engine Chevrolet Big-Block engine of the 1970sThe LS7 is a 7,011 cc (7.0 L; 427.8 cu in) engine, based on the Gen IV architecture. The block is changed, with sleeved cylinders in an aluminum block with a larger bore 4.125 in (104.8 mm) and longer stroke 4 in (101.6 mm) than the LS2. The small-block's 4.4 in (110 mm) bore spacing is retained, requiring pressed-in cylinder liners. The crankshaft and main bearing caps are forged steel for durability, the connecting rods are forged titanium, and the pistons are hypereutectic. The two-valve arrangement is retained, though the titanium intake valves by Del West have grown to 2.2 in (56 mm) and sodium-filled exhaust valves are up to 1.61 in (41 mm).
Peak output is 505 bhp (512 PS; 377 kW) at 6300 rpm and 470 lb⋅ft (637 N⋅m) of torque at 4800 rpm with a 7000 rpm redline. During GM's reliability testing of this engine in its prototype phase, the LS7 was remarked to have been repeatedly tested to be 8000 rpm capable, although power was not recorded at that rpm level, due to the constraints of the camshaft's hydraulic lifters and the intake manifold ability to flow required air at that engine speed.
The LS7 is hand-built by the General Motors Performance Build Center in Wixom, Michigan. Most of these engines are installed in the Z06, some are also sold to individuals by GM as a crate engine. While it has the same displacement the Hennessey Venom GT utilizes an iron block LSX, not an LS7. The 2014 and 2015 z28 were the only Camaros to receive the 427 LS7.
After an extensive engineering process over several years, Holden Special Vehicles fitted the LS7 to a special edition model: the W427. The HSV-tuned engine produced 375 kW (510 PS; 503 bhp) at 6500 rpm and 640 N⋅m (472 lb⋅ft) at 5000 rpm of torque. It was unveiled at the Melbourne International Motor Show on February 29, 2008 and went on sale in August 2008. The first Australian car to be fitted with this engine, however, was the CSV GTS of 2007, which was claimed to have a power output of 400 kW (536 hp) and 600 N⋅m (443 lb⋅ft).


=== 4.06 in. bore blocks (2007–present) ===
This family was designed as a replacement for the LS2 but enlarged to better accommodate variable valve timing and Active Fuel Management while still generating good performance.  This family of engines has mainly seen duty in performance cars and high-end SUVs.


==== 6.2 L ====
L92
The 2007 Cadillac Escalade has a 6,162 cc (6.2 L; 376.0 cu in) Vortec 6200 (RPO L92) engine. It is an all-aluminum design which, while still a pushrod engine, boasts variable valve timing. The system adjusts both intake and exhaust timing between two settings. This engine produces 403 hp (301 kW) and 417 lb⋅ft (565 N⋅m) in the GMC Yukon Denali/XL Denali, GMC Sierra Denali, Hummer H2, and briefly in the Chevrolet Tahoe LTZ (midway through MY 2008 through MY 2009) and rated at 403 hp (301 kW) and 415 lb⋅ft (563 N⋅m). Starting in 2009, it was also available in the Chevrolet Silverado and GMC Sierra, as the L9H, with power ratings of 403 hp (301 kW) and 417 lb⋅ft (565 N⋅m).  Engines built prior to April 1, 2006 contained AFM components, but the software was not present in the PCM and thus the system was not functional.  Engines built after this date did not have any AFM components, and instead used a valley cover plate similar to the L20, save for the L94 variants mentioned below.
The 2009 L92 was modified with Flex Fuel capability, becoming the L9H.
In 2010, the L9H was further modified with Active Fuel Management, becoming the L94 (in the Cadillac Escalade and GMC Yukon Denali).

LS3

LS3 can also refer to a 402 cu in (6.6 L) Chevrolet Big-Block engine of the 1970sThe LS3 was introduced as the Corvette's new base engine for the 2008 model year. It produces 430 bhp (321 kW; 436 PS) at 5900 rpm and 424 lb⋅ft (575 N⋅m) at 4600 rpm without the optional Corvette exhaust and is SAE certified. The block is an updated version of the LS2 casting featuring a larger bore of 103.25 mm (4.065 in) creating a displacement of 6,162 cc (6.2 L; 376.0 cu in). It also features higher flowing cylinder heads sourced from the L92, a more aggressive camshaft with 0.551 in (14 mm) lift, a 10.7:1 compression ratio, a revised valvetrain with 0.236 in (6 mm) offset intake rocker arms, a high-flow intake manifold and 47 lb (21 kg)/hr fuel injectors from the LS7 engine.
The L76/L92/LS3 cylinder heads use 2.165 in (55 mm) intake valves, and 1.59 in (40 mm) exhaust valves. Improved manufacturing efficiency makes these heads cheaper than the outgoing LS6 heads, and severely undercuts aftermarket heads. The large valves, however, limit maximum rpm - 6000 in the L76 (with AFM), and 6600 in the LS3 (with hollow stem valves).
In addition to the above, a dual-mode exhaust package with a bypass on acceleration was available on C6 Corvettes. The dual-mode exhaust uses vacuum-actuated outlet valves, which control engine noise during low-load operation, but open for maximum performance during high-load operation. The system is similar to the C6 Z06, but uses a 2.5 in (64 mm) diameter exhaust compared to the Z06's 3 in (76.2 mm). Power is boosted to 436 hp (325 kW) and  428 lb⋅ft (580 N⋅m) with this option. A similar system was optional on later model 5th generation Chevrolet Camaros and standard on the 2016-2017 Chevrolet SS, but no horsepower or torque increases were advertised on those vehicles.
From April 2008, Australian performance car manufacturer HSV adopted the LS3 as its standard V8 throughout the range, replacing the LS2. The LS3 received modifications for its application to HSV E Series models, producing 425 bhp (317 kW). The LS3 engine in the E Series II GTS (released September 2009) was upgraded to produce 436 bhp (325 kW). All HSV MY12.5 excluding the base Maloo and Clubsport variants have been upgraded to produce 436 bhp (325 kW).
From September 2015 Holden introduced the LS3 in all V8 models of the VF II Commodore and WN II Caprice-V, replacing the 6.0L L77.

L99

For the 4.3 L (260 cu in) Generation II engine of the same RPO, see GM LT EngineThe L99 is derived from the LS3 with reduced output but adds Active Fuel Management (formerly called Displacement on Demand) and variable valve timing, which allows it to run on only four cylinders during light load conditions.
Applications:

2010–2015 Chevrolet Camaro SS (Automatic Transmission)LS9
The Gen IV LS9 is a supercharged 6,162 cc (6.2 L; 376.0 cu in) engine, based on the LS3; the LS7 block was not used due to the higher cylinder pressures created by the supercharger requiring the thicker cylinder walls of the LS3. Cylinder dimensions are now bore and stroke of 103.25 mm × 92 mm (4.065 in × 3.622 in). It is equipped with an Eaton four-lobe Roots type supercharger and has a compression ratio of 9.1:1. Power output is rated 638 bhp (647 PS; 476 kW) at 6500 rpm and 604 lb⋅ft (819 N⋅m) at 3800 rpm of torque. Note: GM previously used the LS9 RPO code on 1969 and later Chevrolet trucks (both 2WD and 4WD) including Blazers, Jimmys, Suburbans, as well as car carriers. The original LS9 was a 350 cu in (5.7 L) V8, developing 160 hp (119 kW) and 245 lb⋅ft (332 N⋅m) of torque.
Applications:

2009–2013 Chevrolet Corvette ZR1
2017 HSV GTSR W1
Equus Bass 770LSA
The supercharged 6.2L LSA is similar to the LS9 and debuted in the 2009 CTS-V. The LSA has been SAE certified at 556 bhp (415 kW) at 6100 rpm and 551 lb⋅ft (747 N⋅m) at 3800 rpm. GM labeled it ""the most powerful ever offered in Cadillac's nearly 106-year history"". The LSA features a smaller 1.9 L (120 cu in) capacity supercharger rather than the 2.3 L (140 cu in) variant of the LS9. Other differences include a slightly lower 9.0:1 compression ratio, single unit heat exchanger and cast pistons.
A 580 bhp (433 kW) and 556 lb⋅ft (754 N⋅m) version of the LSA engine is used in the 2012 Camaro ZL1. On May 15, 2013, Holden Special Vehicles announced that this version of the LSA engine will also be used in the GEN-F GTS.


== Generation V (2013–present) ==
In 2007, wardsauto.com reported that the LS3 (used by 2008 Chevrolet Corvette) and Vortec 6000 LFA (used by 2008 Chevrolet Tahoe Hybrid) engines would be the final two designs in the Generation IV small-block engine family, and the future designs would be part of the Generation V engine family. An experimental engine was built based on L92 engine from Cadillac Escalade, GMC Yukon Denali and Hummer H2, and reported to generate 450 bhp (336 kW) on gasoline via direct fuel injection, increased compression ratio to 11.5:1, and a modified engine controller. The first Gen V LT engine was the LT1, announced in 2012 as the initial powerplant for the redesigned Corvette C7, succeeding the LS engine family. The new logo formally adopts the Small Block name for the engines.
The fifth generation of the iconic GM small block engine family features the same cam-in-block architecture and 4.4 in (110 mm) bore centers (the distance between the centers of each cylinder) that were born with the original small block in 1954. Structurally, the Gen-V small-block is similar to the Gen III/IV engines, including a deep-skirt cylinder block. Refinements and new or revised components are used throughout, including a revised cooling system and all-new cylinder heads. Because the positions of the intake and exhaust valves are flipped from where they would be in an LS engine, as well as the need for an addition to the camshaft to drive the high pressure fuel pump for the direct fuel injection, there is very little interchange with the Gen III/IV engines.
All Gen V engines are aluminum blocks (except for the L8T) with aluminum cylinder heads, and include direct injection, piston cooling jets, active fuel management, variable displacement oil pump, and continuously variable valve timing. However, they all retain their ancestors' two-valve pushrod valvetrain.


=== 4.06 in. bore blocks (2014–present) ===
This family of blocks were the first of the generation V small block with the LT1 being the progenitor of this family and generation. This family of blocks has seen a wide range of applications from performance vehicles to truck usage.


==== 6.2 L ====


===== LT1 =====
For the 5.7 L (350 cu in) Generation II engine of the same RPO, see GM LT EngineThe 6.2 L; 376.0 cu in (6,162 cc) LT1 engine debuted in the 2014 Chevrolet Corvette Stingray and is the first Generation V small block engine. Like its LS3 predecessor, it gets its displacement from a bore and stroke of 103.25 mm × 92 mm (4.065 in × 3.622 in) with a compression ratio of 11.5 to 1.
Applications:


===== LT2 =====
The LT2 engine debuted in the 2020 Corvette Stingray as the successor to the LT1. It was designed specifically with mid-engine placement and dry-sump lubrication in mind.
Applications:


===== L86/L87 =====
The 6.2 L; 376.0 cu in (6,162 cc) EcoTec3 is a Generation V small block V8 truck engine (VIN Code ""J""). The L86 is an LT1 engine modified for truck use with a compression ratio of 11.5 to 1. In 2019, GM introduced the L87 as the successor to the L86. Power and Torque remains the same, but whereas the L86's 'Active Fuel Management' alternates between V4 & V8 modes, the L87's 'Dynamic Fuel Management' can alternate between any of 17 different firing orders which vary both how many and which cylinder[s] are actually firing based on demand calculated every 125 milliseconds.
Applications:


===== L8T =====
The L8T is the first iron block member of the Gen V family. It shares its 103.25 mm (4.065 in) bore with the L86, but with a longer stroke of 98 mm (3.9 in) to displace 6.6 liters. It is rated for 401 hp (299 kW)} at 5,200 rpm and 464 lb⋅ft (629 N⋅m) of torque at 4,000 rpm. The compression ratio is 10.8:1. The longer stroke yields little additional peak torque output compared to the L86, but only requires 87 Octane. The stroke is also shorter than the LS7's 101.6 mm (4.00 in), to optimize rod ratio for reliability.
Rather than allow a ""high-strung"" small block to fail the HD truck market, the iron block, lack of both stop-start and cylinder deactivation, longer stroke and rod ratio, lower compression, mere 87 Octane requirement, and greater displacement all suggest that the L8T was designed specifically to assuage the HD truck market's concerns.Applications:


===== LT4 =====
For the 5.7 L (350 cu in) Generation II engine of the same RPO, see GM LT EngineThe 6.2 L; 376.0 cu in (6,162 cc) LT4 engine builds on the design strengths of the previous LS9 supercharged engine used in the sixth-generation Corvette ZR1 and leverages the technologies introduced on the seventh-generation Corvette Stingray, including direct injection, cylinder deactivation and continuously variable valve timing, to take Corvette performance to an all-new level. The LT4 engine is based on the same Gen 5 small block foundation as the Corvette Stingray's LT1 6.2 L naturally aspirated engine, incorporating several unique features designed to support its higher output and the greater cylinder pressures created by forced induction, including: Rotocast A356T6 aluminum cylinder heads that are stronger and handle heat better than conventional aluminum heads, lightweight titanium intake valves, forged powder metal steel connecting rods which are highly machined to an optimized geometry for increased strength while eliminating unnecessary reciprocating mass, 10.0:1 compression ratio, high for a forced-induction engine, enhances performance and efficiency and is enabled by direct injection, forged aluminum pistons with unique, stronger structure to ensure strength under high cylinder pressures, stainless steel exhaust manifolds for structure at higher temperatures, aluminum balancer for reduced mass, and standard dry-sump oiling system with a dual-pressure-control oil pump. The engine uses a 1.7 L (103.7 cu in) Eaton TVS Supercharger. Although smaller than the previous 2.3 L (140.4 cu in) supercharger used on the sixth-gen ZR1, it spins to 5000 rpm faster thus generating boost quicker while making only slightly less total boost than the LS9 engine.Applications:


===== LT5 =====
The 6.2 L; 376.0 cu in (6,162 cc) LT5 engine debuted in the seventh-generation Corvette ZR1 at the 2017 Dubai Motor Show. It draws its name from the 5.7 L LT5 from the C4 manufactured from 1989–1995. The original LT5 is rarely known as a Chevy small block V8, as it was designed and built with Lotus, and implements a DOHC 32 valve multi-port injection system, instead of the push-rod design. The new (and unrelated) LT5, however, has increased its displacement from 5.7 to 6.2 L (350 to 380 cu in), retains the Gen V OHV valvetrain, and is topped with a 2.6 L (158.7 cu in) Eaton TVS supercharger and an improved intercooler. It simultaneously couples the standard direct injection system found on Gen 5 engines with port fuel injection. Power output is 755 hp (765 PS; 563 kW) at 6400 rpm and 715 lb⋅ft (969 N⋅m) of torque at 3600 rpm.
Applications:


=== 3.78 in. bore blocks (2014–present) ===
Unlike the previous Generation III/IV 3.78 in (96 mm) bore block families, there is no 4.8 L (290 cu in) displacement variant (having been 'replaced' by GM's 5th Generation LT V8-based V6, the 4.3 L (260 cu in) LV3).


==== 5.3 L ====


===== L83 =====
Dubbed EcoTec3 5.3 L (320 cu in) is a Generation V small block V8 truck engine (VIN Code ""C""). Like its Vortec 5300 Generation IV predecessor, it gets its displacement from a bore and stroke of 96 mm × 92 mm (3.78 in × 3.62 in) with a compression ratio of 11.0 to 1.
Applications:


===== L8B =====
The L8B is an eAssist mild hybrid version of the L83 featuring a .45-KWH lithium ion battery pack. This setup can improve fuel efficiency by about 13%. This adds about 100 lb (45 kg) to the total weight of the truck but provides an additional 13 hp (10 kW) and 44 lb⋅ft (60 N⋅m).Applications:


===== L82 =====
The L82 is one of two 5.3 liter V8s available in the 4th generation Chevrolet Silverado and GMC Sierra. The L82 uses Active Fuel Management instead of the L84's Dynamic Fuel Management system, and is only available on lower trim trucks.


===== L84 =====
The L84 is one of two 5.3 liter V8s available in the 4th generation Chevrolet Silverado and GMC Sierra. The L84 is distinguished from the L82 by the presence of the Dynamic Fuel Management System, and is either available or standard on mid- to high-level trims.


=== 3.921 in. bore blocks (2014–present) ===
These V6 engines are based on the V8 version of the Gen V family, but with two fewer cylinders - a design lineage that dates back to the previous 4.3 L V6, which was itself a Gen I small block with a pair of cylinders removed.
Of special note, there were no V6 engines based on Generation II, III, or IV small block V8s.


==== 4.3 L ====


===== LV3 =====
Dubbed EcoTec3 4.3 L (260 cu in) is a Generation V small block V6 truck engine. It gets its displacement from bore and stroke of 99.6 mm × 92 mm (3.921 in × 3.622 in) with a compression ratio of 11.0 to 1. Firing order is 1-6-5-4-3-2.
This engine replaces the unrelated 4.3 L V6 whose lineage dates back to 1978.
Applications:


== Engine table ==
The 8th character in the VIN or the RPO code from the glove box sticker can be used to identify which type of LS engine a vehicle has. 
Note 1: depending upon vehicle application (truck, suv, car); horsepower, torque, and fuel requirements will vary. VIN code indicating engine RPO is usually not consistent between vehicle types (cars or trucks) or years. with few exceptions, RPM redline is generally 6000 or higherNote 2: block features are generally dependent upon the Generation but are not always built-in. typical features are AFM (Advanced Fuel Management), VVT (Variable Valve Train), Front Wheel Drive (FWD) and other improvements. features marked with an * indicate that only certain model years have that feature


== Problems ==
In the early production run of the LS-series engine, some engines encountered 'piston slap' during the first few minutes after a cold engine start; this sound is caused by the pistons rocking slightly in the cylinder until they reach operating temperature/size. 'Piston slap' sometimes sounds more like a knock or the sound of a diesel engine running. It is typically only present when the engine is cold and disappears as the engine reaches operating temperature. The noise of 'piston slap' often is louder when listening for it below the oil pan.
Another common problem with the 2001-2006 5.3L engines was cracking cylinder heads. This is commonly called the 'Castech Head' failure on the internet. GM issued a TSB on this failure to help service techs identify the problem. The head casting number (which can be viewed from the passenger side of the vehicle just in front of the valve cover) was 706. Some heads with this casting number would fail (but not all of them) as GM had different suppliers for the same head. The failure was due to undetected porosity around the oil drains in the head.


== Build-your-own program ==
In 2011, Chevrolet Performance began to offer the build your own engine program for LS7 (part number 19259944) or LS9 (part number 19259945) crate engines. It also provides customers the experience of visiting GM's unique Performance Build Center in Wixom, Michigan, where they will join a specially trained engine builder to assist in the start-to-finish assembly of the engine they purchased – from installing the crankshaft in the cylinder block to topping off the engine with its intake system. In the case of the LS9, it also means installing the supercharger assembly. Upon completion, a personalized nameplate is added to the engine.The build-your-own engine program associated with the V8 engines, available for buyers of Chevrolet Corvette, Cadillac XLR and certain top-spec Chevrolet Camaro models, were temporarily halted after the closure of GM Performance Build Center in Wixom, Michigan. The program's venue was reported to be relocated to the Corvette assembly plant in Bowling Green, Kentucky.


== Aftermarket ==
LS7.R
The LS7.R engine is a variation of the LS7 used in the highly successful C6.R American Le Mans Series racecar. It was crowned as Global Motorsport Engine of the year by a jury of 50 race engine engineers on the Professional Motorsport World Expo 2006 in Cologne, Germany.
LSX
LSx is also used to denote any LS engine.

At the 2006 SEMA show, GM Performance Parts introduced the LSX engine, an all-new cast-iron racing block based on the LS7 engine. It was designed with help from drag racing legend Warren Johnson. It offers displacements ranging from 364 to 511 cu in (6.0 to 8.4 L) with a bore x stroke of 4 1⁄4 in × 4 1⁄2 in (108.0 mm × 114.3 mm) and is capable of withstanding 2,500 bhp (1,864 kW). This block incorporates two extra rows of head-bolt holes per bank for increased clamping capacity. The six bolt steel main caps are the same ones used on the LS7 engine. The engine debuted at the auto show in a customized 1969 Camaro owned by Reggie Jackson. The LSX will be available starting the second quarter of 2007, set to be available in authorized dealerships and retailers on March 31, 2007. The Hennessey Venom GT also uses the LSX engine based on LS7.Chevrolet Performance LSX Bowtie block includes LSX specific six-bolts-per-cylinder head bolt pattern, billet-steel six-bolt dowel-located main bearing caps, extra-thick deck for maximum clamping force, extra-thick cylinder walls allow increased bore capacity (maximum 4.2 in (106.7 mm) bore still allows 0.2 in (5.1 mm) minimum wall thickness), true priority main oiling system, main web bay-to-bay breathing holes reduce crank windage, orange powder coat finish, machined bore at 3.88 in (98.6 mm) is ready for final boring/honing.
A 396 cu in (6.5 L) version is used in NASCAR for the Gander Outdoors Truck Series and the ARCA Racing Series as an option engine.  Most teams in both series (known as ""NT1"" in the Truck Series and the ""ARCA 396"" in ARCA) have switched to the engine because of cost savings.
LSX376
Chevrolet Performance LSX376 crate engines are updated versions of LSX crate engine family designed to support up to 1,000 hp (746 kW). All models use Chevrolet Performance LSX Bowtie block.
LSX376-B15 (part number 19299306) includes forged steel crankshaft, forged powdered metal I-beam rods (both the crankshaft and rods from LSA engine) and forged aluminum pistons (9.0:1 compression), high-flow rectangular-port six-bolt LSX-LS3 heads for supercharged and turbocharged combinations producing up to 15 psi (1.0 bar) of boost and up to about 1,000 hp (746 kW).
LSX376-B8 (part number 19171049) is a more economical version that is capable of approximately 8 psi (0.55 bar), for engine producing approximately 600 hp (447 kW). It is designed for production-style supercharger and turbo systems used without enhancements or modifications.LS Edge
Noonan Race Engineering developed two billet aluminium blocks based on the LS engine. Bores sizes up to 4.185 in and strokes up to 4.5 in are available, making a 495 cu in displacement possible. The billet construction provides added block integrity suited to high horsepower applications.
The block design incorporates turbocharger pressure feed lines in the front of the valley and oil dump ports in the side of the block to return oil to the sump.
In addition to the solid block, a waterjacketed version was also designed to provide better cooling options for street or endurance purposes.


== See also ==
General Motors 90° V6 engine
GM engines
Vortec


== References ==


== External links ==
Gen 5 press kit
Gen 3 History of its development"
"Cheat Engine (CE) is a free and open-source memory scanner/debugger created by Eric Heijnen (""Dark Byte"") for the Windows operating system. Cheat Engine is mostly used for cheating in computer games and is sometimes modified and recompiled to evade detection. The program resembles L. Spiro's Memory Hacking Software, TSearch, and ArtMoney. It searches for values input by the user with a wide variety of options that allow the user to find and sort through the computer's memory. Cheat Engine can also create standalone trainers that can operate independently of Cheat Engine, often found on user forums or at the request of another user.


== Features ==
Cheat Engine can view the disassembled memory of a process and allow the addition and/or alteration of game states to give the user advantages such as infinite health, time, or ammunition. It also has some Direct3D manipulation tools, allowing vision through walls ""Wallhacking"" and zooming in/out ""FOV changes"", and with some advanced configuration, Cheat Engine can move the mouse to get a certain texture into the center of the screen. This is commonly used to create aimbots. However, the main use for Cheat Engine is in single player aspect of games, and its use in multiplayer games is discouraged.Cheat Engine can inject code into other processes, and as such, most antivirus programs mistake it for a virus. There are versions that avoid this false identification at the cost of many features (those which rely upon code injection). The most common reason for these false identifications is that Cheat Engine makes use of some techniques also used in Trojan rootkits to gain access to parts of the system and therefore gets flagged as suspicious, especially if heuristic scanning is enabled in the antivirus program's settings. Newer versions of Cheat Engine are less likely to be blocked by antivirus programs, so features like code injection can be used without problems.
As of version 6.1, Cheat Engine can produce game trainers from the tables. While trainers generated in this way are typically very large for their intended purpose, generally used for testing purposes, some have been released by trainers groups as ""final"" versions, and even some popular sites are fully based on CE trainers due to the ease of trainer creation with CE. However, despite their popularity, CE trainer maker has not been updated since its implementation in version 6.1—it is largely unsupported, and emphasis is given on using Lua to generate trainers. Even the trainer maker itself uses Lua scripts to generate trainers.


== Implementations ==
Two branches of Cheat Engine exist, Cheat Engine Delphi and Cheat Engine Lazarus. Cheat Engine Delphi is primarily for 32-bit versions of Windows XP. Cheat Engine Lazarus is designed for 32 and 64-bit versions of Windows 7. Cheat Engine is, with the exception of the kernel module, written in Object Pascal.
Cheat Engine exposes an interface to its device driver with dbk32.dll, a wrapper that handles both loading and initializing the Cheat Engine driver and calling alternative Windows kernel functions. Due to a programming bug in Lazarus pertaining to the use of try and except blocks, Cheat Engine Lazarus had to remove the use of dbk32.dll and incorporate the driver functions in the main executable.
The kernel module, while not essential to normal CE use, can be used to set hardware breakpoints and bypass hooked API in Ring 3, even some in Ring 0. The module is compiled with the Windows Driver development kit and is written in C.Cheat Engine also has a plugin architecture for those who do not wish to share their source code with the community. They are more commonly used for game specific features, as Cheat Engine's stated intent is to be a generic cheating tool. These plugins can be found in several locations on the Cheat Engine website as well as other gaming sites.Cheat Engine Lazarus has the ability to load its unsigned 64-bit device driver on Windows Vista and later x64 bit versions of Windows, by using DBVM, a virtual machine by the same developers that allows access to kernel space from user mode. It is used to allocate nonpaged memory in kernel mode, manually loading the executable image, and creating a system thread at Driver Entry. However, since the Driver Entry parameters are not actually valid, the driver must be modified for DBVM.


== Cheat Tables ==
Cheat Engine allows its users to share their addresses and code locations with other users of the community by making use of cheat tables. ""Cheat Tables"" is a file format used by Cheat Engine to store data such as cheat addresses, scripts including Lua scripts and code locations, usually carrying the file extension .CT. Using a Cheat Table is straightforward and involves simply opening the Cheat Table through Cheat Engine and enabling/ticking the cheats stored within it. The ability to save and share Cheat Tables has resulted in a large online community for sharing cheats through the Cheat Engine Forums. Popular Cheat Tables are hosted on the Fearless Revolution website.In addition to simple memory addresses, cheat tables can extend the functionality of Cheat Engine using the Lua scripting language. Almost all of Cheat Engine's features are scriptable, and it is even possible to design custom dialogs to interact with scripts.


== Controversy ==
In 2017, the Entertainment Software Association (ESA) sent a copyright infringement notice asking Dark Byte to cease and desist. The notice claimed Cheat Engine allowed evading anti-cheat technologies, accessing in-game DLC items/microtransaction items that could only be bought with real money. Dark Byte responded by shutting down the cheat tables section to the public, asking them to be hosted off-site and coming to an agreement with ESA. The Cheat Engine community was not happy with the steps taken, and prominent members moved to a new community website called Fearless Revolution where old cheat tables have been uploaded and new ones are being posted. The Cheat Engine website and forums only focus on development of the tool itself now, and cheat tables have moved to Fearless Revolution forums.


== References ==


== External links ==
Official website"
"Engine displacement is the measure of the cylinder volume swept by all of the pistons of a piston engine, excluding the combustion chambers. It is commonly used as an expression of an engine's size, and by extension as a loose indicator of the power an engine might be capable of producing and the amount of fuel it should be expected to consume. For this reason displacement is one of the measures often used in advertising, as well as regulating, motor vehicles.
It is usually expressed using the metric units of cubic centimetres (cc or cm3, equivalent to millilitres) or litres (l or L), or – particularly in the United States  – cubic inches (CID, cu in, or in3).


== Definition ==
The overall displacement for a typical reciprocating piston engine is calculated by multiplying together three values; the distance travelled by the piston (the stroke length), the circular area of the cylinder (the bore), and the number of cylinders that comprise the whole engine. 
The formula is:

  
    
      
        
          Displacement
        
        =
        
          stroke length
        
        ×
        
          π
        
        ×
        (
        
          
            
              1
              2
            
          
        
        ×
        
          bore
        
        
          )
          
            2
          
        
        ×
        
          number of cylinders
        
      
    
    {\displaystyle {\text{Displacement}}={\text{stroke length}}\times {\pi }\times ({\tfrac {1}{2}}\times {\text{bore}})^{2}\times {\text{number of cylinders}}}
  Using this formula for non-typical types of engine, such as the Wankel design and the oval-piston type used in Honda NR motorcycles, can sometimes yield misleading results when attempting to compare engines. Manufacturers and regulators may develop and use specialised formulae to determine a comparative nominal displacement for variant engine types.


== Governmental regulations ==

In several countries fees and taxes levied on road vehicles by transport authorities are scaled in proportion to engine displacement. In countries where this is practised, vehicle manufacturers often seek to increase power output through higher-revving engines or turbocharging, instead of increasing the displacement.
Examples of countries where the road taxes are based upon engine displacement:

In some European countries, and which predates the EU, there is one charge for engines over 1.0 litre, and another at the level of about 1.6 litres.
In the United Kingdom, cars registered after 1 March 2001 are taxed based on the exhaust emissions. However, cars registered before this date are taxed based on engine displacement. Cars under 1549 cm3 qualify for a lower tax rate.
In Japan, the engine displacement is one of the factors (along with overall vehicle size and power output) used to determine the vehicle size class and therefore the cost of road tax for the vehicle
In France and some other EU countries, mopeds with a displacement of less than 50 cc (3.1 cu in) can be driven with minimum qualifications. This led to all light motorbikes having a displacement of about 49.9 cm3.
In many areas of the United States, Canada (except Quebec), Australia and New Zealand, the road taxes are not based on engine displacement. However, the engine displacement is often used in low-powered scooters or mopeds to determine whether a licence is required to operate the vehicle. A common threshold is 50 cc (3.1 cu in).Wankel engines are able to produce higher power levels for a given displacement. Therefore, they are generally taxed as 1.5 times their stated physical displacement (1.3 litres becomes effectively 2.0, 2.0 becomes effectively 3.0), although actual power outputs can be higher than suggested by this conversion factor.


== Automotive model names ==
Historically, many car model names have included their engine displacement. Examples include the 1923–1930 Cadillac Series 353 (powered by a 353 Cubic inch/5.8-litre engine), and the 1963–1968 BMW 1800 (a 1.8-litre engine).
However, trends towards turbocharging and hybrid/electric drivetrains since 2010 have resulted in far fewer model names being based on the engine displacement.


== See also ==
Active Fuel Management
Bore (engine)
Compression ratio
Stroke (engine)
Variable displacement


== References =="
"The Honda K-series engine is a line of four-cylinder four-stroke car engine introduced in 2001. The K-series engines are equipped with DOHC valvetrains and use roller rockers to reduce friction. The engines use a coil-on-plug, distributorless ignition system with a coil for each spark plug. This system forgoes the use of a conventional distributor-based ignition timing system in favor of a computer-controlled system that allows the ECU to control ignition timings based on various sensor inputs. The cylinders have cast iron sleeves similar to the B- and F-series engines, as opposed to the FRM cylinders found in the H- and newer F-series engines found only in the Honda S2000.
Similar to B series, the K-series car engines have two short blocks with the same design; the only difference between them being the deck height. K20 uses the short block with a deck height of 212mm where K23 and K24 block has a deck height of 231.5mm.Two versions of the Honda i-VTEC system can be found on a K-series engine, and both versions can come with variable timing control (VTC) on the intake cam. The VTEC system on engines like the K20A3 only operate on the intake cam; at low rpm only one intake valve is fully opened, the other opening just slightly to create a swirl effect in the combustion chamber for improved fuel atomization. At high rpm, both intake valves open fully to improve engine breathing. In engines such as the K20A2 found in the Acura RSX Type-S, the VTEC system operates on both the intake and exhaust valves, allowing both to benefit from multiple cam profiles. A modified K20C engine is used in motorsport, as the Sports Car Club of America Formula 3 and 4 series that run in North America both use a K20C engine, with the Formula 4 engine not having a turbocharger.


== K20 ==


=== K20A ===
Applications
Additional notes
K20A Spec R engine (FD2 Civic Type R)

Chromoly flywheel, higher-tensile strength connecting rods, high-compression pistons, stiffer valve springs, higher-lift hollow camshafts with more duration, and 2007–2011 cylinder-head intake-port and exhaust-port surface polishing used in NSX-R. The JDM K20A type-R engine block would be removed from production assembly line by an experienced Honda engine technician to torque the connecting rod bolts to factory specification by hand using micrometer to measure connecting rod bolt stretching. Then the JDM K20A type-R engine block would be returned to the production assembly line to complete the engine building process.


=== K20A (Eco Engine) ===
Similar to K20A3 and K20A1

Found in (Japan models only):
2002-2005 Honda Integra-(Type S)
2000-2005 Honda Stream S (RN3) (front drive)
2000-2005 Honda Stream S (RN4) (all-wheel drive)
2005-2010 Honda Edix (front drive and all-wheel drive)
2005-2008 Honda Accord Sedan (front drive and all-wheel drive)
2005-2008 Honda Accord Wagon  (front drive only)
2006-2010 Honda Civic Sedan (GL)
DOHC i-VTEC
Power and Torque may vary by the Compression Ratio, Intake manifold, and Exhaust manifold
Power: 155 hp@6500rpm; 158 hp@6500rpm
Torque: 138 lb-ft@4000rpm; 140 lb-ft@4000rpm
Redline 6800rpm
Compression: 9.7:1; 9.8:1
Bore X Stroke: 86mm x 86mm
Displacement: 1998cc
K20A9 used in 2004-2008 Europe Honda FR-V (110Kw)


=== K20B ===
Injection Pressure: 10 megapascals (99 atm)
Center Fuel Injection with swirl guide
Air-Fuel Ratio:
Normal driving cycle: 65:1 (ultra-lean combustion)
Acceleration/High load driving cycle: 14.7:1 (Stoichiometric)
Deep Piston Cavity formed in top of Pistons
Application: 2004–2006 Honda Stream Absolute


=== K20C ===
Applications
Additional notesEarth Dreams Technology
K20C1: First Honda Type R engine to be built in the US at the Honda Anna Engine Plant in Anna, Ohio.
The 3rd generation Acura RDX (2019–present) uses the K20C4 motor found in the 10th generation Honda Accord, but with different tuning and other small modifications compared to that of the Accord. This modified version produces 272 hp and 280 lb-ft of torque.


=== K20Z ===
Applications

Additional notes
K20Z3 (as fitted to Ariel's Atom 3.5)

It has an aluminum block with an aluminum head. The K20Z3 has Honda's traditional performance VTEC (as found on previous generation of engines) on the intake and the exhaust cams. Variable cam timing technology is included on the intake but not the exhaust cams. The added timing control corresponds to the added ""i"" in i-VTEC.


== K23 ==


=== K23A1 ===
Additional notes
This version of the K engine uses a Mitsubishi TD04HL-15T turbocharger with a dual path turbine housing, optimizing low end response while allowing better high end flow. Maximum boost pressure is 13.5psi. The engine includes i-VTEC and VTC technologies and comes mated to a version of Honda's 5-speed automatic with SH-AWD (note: SH-AWD was standard from 2007-2009 and optional from 2010-2012).Applications


== K24 ==


=== K24A ===
Applications

Additional notes
K24A2 and K24A3 (2006-2008 Acura TSX)
Increased intake flow:
Intake valve + 1 mm oversize (Intake valve head measures 36mm, but valve seat still measures 35mm)
Intake cam High lift lobe with 0.9 mm more lift and 12 degrees more duration
Throttle body increased from 60–64 mm
Radius on some intake pipes increased from 70–80 mm
Increased exhaust flow
Exhaust Head pipe increased from 60–65 mm
Higher flow catalytic converter
Main (single) exhaust pipe increased from 54–57 mm
Rear (twin) pipes increased in diameter from 42.5 to 45 mm
Block improvements:
Additional air passages in crankcase for reduced pumping losses
Others
Stronger connecting rods
New crankshaft with more counterbalance weight
Revised pistons with more valve-piston clearance
Under-piston oil squirters


=== K24W (Earth Dreams) ===

Direct Injection, iVTEC (intake camshaft & valvetrain)
[Please add accurate technical specifications] This section previously inaccurately suggested that the 2016-2017+ Acura ILX engine K24V7 and the K24W7 of the Acura TLX are the same engine, and although they may be very closely related, even sharing identical internal architecture and components, they actually are different engines with different Honda internal engine code designations. This may be strictly due to different transmissions, as the 2016-2017+ ILX uses its own specific 8-speed dual-clutch auto with a torque converter, as well as different exhaust, intake, and accessory packaging due to their differing chassis [the ILX sharing its basic architecture with the 2013 - 2016 generation Civic].

Applications


=== K24Y ===
Applications


=== K24Z ===
Applications


== References ==


== External links ==
Honda engine pages: i-VTEC DOHC, 2.0L DOHC i-VTEC
K Series VTEC Breakdown: K Series VTEC Breakdown"
"Cosworth is a British automotive engineering company founded in London in 1958, specialising in high-performance internal combustion engines, powertrain, and electronics; for automobile racing (motorsport) and mainstream automotive industries.  Cosworth is based in Northampton, England, with American facilities in Indianapolis, Shelby Charter Township, Michigan and Mooresville, North Carolina.
Cosworth has collected 176 wins in Formula One (F1) as engine supplier, ranking third with most wins, behind Ferrari and Mercedes.


== Corporate history ==
The company was founded as a British racing internal combustion engine maker in 1958 by Mike Costin and Keith Duckworth. Its company name, ""Cosworth"", was derived as a portmanteau of the surnames of its two founders (Costin and Duckworth).
Both of the co-founders were former employees of Lotus Engineering Ltd., and Cosworth initially maintained a strong relationship with Colin Chapman; and initial revenues of the company came almost exclusively from Lotus. When the company was founded in 1958, Duckworth left Lotus, leaving Costin (who had signed a term-employment contract with Chapman) at the company. Until 1962, Costin worked on Cosworth projects in his private time, while being active as a key Lotus engineer on the development of Lotus 15 through 26 (Elan), as well as leading the Team Lotus contingent at foreign races, as evidenced by the 1962 Le Mans Lotus scandal.

Initial series production engines (Mk.II, Mk.V, Mk.VIII, and Mk.XIV) were sold to Lotus exclusively, and many of the other racing engines up to Mk.XII were delivered to Team Lotus. The success of Formula Junior engines (Mk.III, IV, XI, and XVII) started bringing in non-Lotus revenues, and the establishment of Formula B by the Sports Car Club of America (SCCA) allowed the financial foundation of Cosworth to be secured by the increased sales of Mk.XIII, a pure racing engine based on Lotus TwinCam, through its domination of the class. This newly found security enabled the company to distance itself from the Lotus Mk.VII and Elan optional road engine assembly business, and allowed its resources to be concentrated on racing engine development.
The first Cosworth-designed cylinder head was for SCA series; with a single overhead camshaft (SOHC) reverse-flow configuration, similar to the Coventry Climax FWE engine. A real success was achieved with the next gear-driven double overhead camshaft (DOHC) four-valve FVA in 1966, when Cosworth, with a help from Chapman, convinced Ford to purchase the rights to the design, and sign a development contract – including an eight-cylinder version. This resulted in the DFV, which dominated Formula One for many years.
From this time on, Cosworth was supported by Ford for many years, and many of the Cosworth designs were owned by Ford and named as Ford engines under similar contracts. Another success by the BD series in the 1970s put Cosworth on a growing track.Cosworth then went through a number of ownership changes. After Duckworth decided he did not want to be involved with the day-to-day business of running a growing company, he sold out the ownership to United Engineering Industries (UEI) in 1980, retaining his life presidency and day-to-day technical involvement with Cosworth, and becoming a UEI board director; UEI was a group of small- to medium-sized technology companies, which was taken over by Carlton Communications in 1988 – Carlton was primarily interested in some of the audio-visual companies in the UEI portfolio, and Cosworth was a poor fit with these; a new buyer for the company in the engineering/automotive sector was sought, and the traditional engineering company Vickers plc bought Cosworth in 1990.In September 1998, Vickers sold Cosworth to Audi. Audi kept the engineering, manufacturing and casting unit which it called Cosworth Technology and sold the race engine division, Cosworth Racing, and its electronics division, Pi Research, to Ford. In December 2004, Audi announced that it sold Cosworth Technology to Mahle GmbH. Cosworth Technology was then renamed as MAHLE Powertrain on 1 July 2005.On 15 November 2004 Ford sold Cosworth Racing to Champ Car World Series owners Gerald Forsythe and Kevin Kalkhoven, In December 2004, Ford also sold Pi Research to Kalkhoven and Forsythe, creating the current Cosworth Group.Since 2006, Cosworth has diversified to provide engineering consultancy, high performance electronics, and component manufacture services outside of its classic motorsport customer base. Current publicised projects range from an 80 cubic centimetres (4.9 cu in) diesel engine for unmanned aerial vehicles, through to an engineering partnership on some of the world's most powerful normally aspirated road car engines, including upcoming Aston Martin Valkyrie 1000+bhp V12.
Cosworth supplied its last premier class racing engines to one F1 team in 2013, the Marussia F1 Team.


== Internal combustion engines ==


=== Early types ===
The following is the list of initial products, with cylinder heads modified, but not originally designed by Cosworth, on Ford Kent engine cylinder blocks.  The exceptions were Mk.XVII and MAE (modified Anglia engine), which had intake port sleeves for downdraft carburetors brazed into the stock cast iron cylinder head, in place of the normal side draft ports, thus could be considered Cosworth designs.

In addition to the above, Cosworth designed and provided the assembly work for Lotus Elan Special Equipment optional road engines with special camshafts and high compression pistons.
The final model of the above initial series was the MAE in 1965, when new rules were introduced in Formula 3 allowing up to 1,000 cubic centimetres (61.0 cu in) engines with 36 mm intake restrictor plates.  MAE used one barrel of a two barrel Weber IDA downdraft carburetor with the other barrel blanked off.  The domination of this engine was absolute as long as these regulations lasted until 1968. As Cosworth had a serious difficulty meeting the demand, the MAE was mainly sold as a kit.  This experience led to the later FVA/DFV contract to be drawn where the responsibility of development rested with Cosworth, and the manufacturing right and responsibility rested with Ford.  There also were some specially cast iron heads with similar dimensions to these brazed heads with titanium alloy valve spring retainers called the ""screamer head"" for MAE in later years.


=== The SCA series ===
A year before the introduction of the MAE, the single overhead cam two valve SCA was introduced. It was a 997 cc engine based on Ford Cortina 116E block that was designed for Formula 2, and featured the first totally Cosworth-designed head, Laystall forged crankshaft, steel main bearing caps and pistons with only one compression ring and one oil scraper ring each.  Cylinder head to block sealing was by a head gasket incorporating Cooper Rings.  The basic configuration was quite similar to Coventry Climax FWE on Lotus Elite including its SOHC reverse-flow design, except for a series of seven spur gears (one on the crank, two intermediary gears on two fixed shafts mounted on the front cover back plate, one on the 116E camshaft used as a jackshaft, two on a common fixed shaft in the head, and one on the camshaft) driving a five-bearing camshaft and the Ford five main bearing iron block.  The intake ports and the oil scavenge pickup for dry sump lubrication were canted 25 degrees, so they faced straight up and down, respectively, when the engine was mounted 25 degrees from vertical to the right for a lower centre of gravity.
The SCA initially had two 40DCM2 Weber twin-choke downdraft sand-cast carburetors mounted on top to produce 115 hp, which was replaced by Lucas fuel injection in 1966, eventually reaching 140 hp.

The longer stroke SCB was built to compare against the 1,498 cc Mk.XVI, and upon proving its superior power against the Mundy-designed tw0-valve crossflow DOHC head, it acted as the benchmark for the development of FVA to measure the benefits and shortcomings of a four valve crossflow DOHC design.  It was the results of this four valve development work that formed the basis for many of the Cosworth engines that followed.
A larger 85 mm bore SCC with the same short-stroke five-bearing crankshaft as the SCA was built and sold for SCCA 1.1 litre sports car class.


=== The FVA series ===
The Cortina Crossflow block was also the basis for the FVA (four valve Type A), an F2 engine introduced in 1966, and developed under the same contract as the DFV, for the new 1.6-litre engine rules. This engine featured 16 valves operated by twin overhead camshafts driven by a train of 9 gears.  The metering unit for the Lucas mechanical fuel injection was rotated by a toothed belt from the gear-driven inlet cam, while the exhaust cam directly drove an alternator on the rear of the head.  It produced 225 bhp (168 kW) at 9000 rpm.  This engine dominated the category until 1971, and was also used in sports car racing in 1.8 Litre form as the ""FVC"".
The cylinder head on the FVA pioneered many of Duckworth's ideas that would be used on the DFV and a mule for the eight-cylinder engine development, FVB, was built.  However, the distance between the two camshafts and the valve inclination angle were larger than on DFV for the series.
The larger displacement FVD was designed and released for endurance racing in 1975, that displaced 1,975 cc (120.5 cu in) on the aluminium block developed for BDG.  The FVD produced only 275 bhp (205 kW), down from the 325 hp (242 kW) that other twin-cam four cylinders such as the Hart 420S produced but was more reliable.  One was campaigned in the CanAm series in 1978 in the Osprey SR-1, built and driven by Dan Hartill.


=== The DFV (Double Four Valve) ===

In 1966, Colin Chapman (Lotus Cars founder and principal of Team Lotus) persuaded Ford to bankroll Keith Duckworth's design for a new lightweight 3,000-cubic-centimetre (183.1 cu in) Formula One engine. Cosworth received the order along with the £100,000 that Ford felt it adequate to spend on such an objective.  The contract stipulated that a four-cylinder Ford-based F2 engine would be developed as proof of concept (see the FVA above) and that a pure Cosworth V8 would be built based on this.
The DFV design used a similar cylinder head to the one Duckworth had prototyped on the four-cylinder FVB unit on a custom Cosworth cylinder block and crankcase, forming a single 90° V8 engine, thus creating a legend in its own right, the DFV – literally meaning ""Double Four Valve"".  This engine and its derivatives were used for a quarter of a century, and it was the most successful in the history of Formula One / Grand Prix motor racing.  Winning 167 races in a career lasting over 20 years, it was the product that put Cosworth Engineering on the map.  Although originally designed for Formula One, the engine has been modified to be used in a range of categories.
The DFV won on its first outing, at the 1967 Dutch Grand Prix in the hands of Jim Clark, fitted to a Lotus 49, and from 1968 was available for purchase to any F1 team that wished it.  During the 1970s, it was common for almost the entire field (with the notable exception of Ferrari) to use one of these engines – this at a time when independent wealthy individuals could buy exactly the same engine off the shelf that was also being used by McLaren et al.  Most teams just built a tub around a Cosworth DFV and a Hewland gearbox.  It won a record 155 World Championship races, the last being Detroit in 1983, powering a Tyrrell driven by Michele Alboreto.
Although the DFV (bore: 3.373 inches (85.67 mm), stroke: 2.555 inches (64.90 mm), displacement: 2,992.98 cc (182.6 cu in)) with 410 bhp (306 kW; 416 PS) at 9,000 rpm did not produce as much power as some of its rival 12-cylinder engines, it was lighter, resulting in a better power to weight ratio.  In addition to being lighter, it was also made a structural part of the car itself, by placing load bearing arms to stress the block.  These design aspects appealed tremendously to the genius of Colin Chapman who used them to the fullest extent.
The DFY, introduced in 1982 was a further evolution of the DFV for Formula One, with a shorter stroke and a DFL bore (bore: 3.543 inches (89.99 mm), stroke: 2.316 inches (58.83 mm), displacement 2,993.38 cc (182.7 cu in)) with 520 bhp (388 kW; 527 PS) at 11,000 rpm, thereby producing more power, but still unable to fight against the turbocharged cars of the day. It was the advent of turbocharged engines in Formula One which sounded the death knell for the venerable DFV, and in 1986 Cosworth returned to the lower formulae preparing the DFV for the newly created Formula 3000, with the installation of a compulsory 9,000 rpm rev limiter, which scaled power back from 500 to 420 bhp (313 kW; 426 PS); the DFV remained in this class until 1992.  The final F3000 engines gave 500 bhp (373 kW; 507 PS), almost equalling the 1983 DFV which gave 510 bhp (380 kW; 517 PS) at 11,200 rpm.
In Formula One, a new DFV-based design was introduced for the new 3,500 cc (213.6 cu in) normally aspirated rules in 1987.  The DFZ was produced as an interim model, but in 1988 Cosworth created the DFV's final evolution, the DFR, which soldiered on in F1 with smaller teams until 1991, scoring its last points – including a pair of second places by Jean Alesi – with Tyrrell in 1990.
The DFV has recently been given a new lease of life as a result of interest in Classic F1 racing, which was given a World Championship status by the FIA in 2004.


==== DFV variants ====
The DFV spawned a number of derivations.  In 1968; Cosworth created the DFV's first derivation, a 2,500 cubic centimetres (152.6 cu in) version for the Tasman Series, the DFW.  DFV to DFW conversion simply involved substitution of a short-stroke crank and longer connecting rods.

One of the most successful and longest-lived projects of Cosworth has been its CART / Champ Car engine program.  In 1975; Cosworth developed the DFX, by destroking the engine to 2,650 cc (161.7 cu in) and adding a turbocharger, the DFX became the standard engine to run in IndyCar racing, ending the reign of the Offenhauser, and maintaining that position until the late 1980s.  Ford backed Cosworth with creating a new interim design for IndyCar racing in the late 1980s, the DFS, which merged DFR technology into the ageing DFX design, but it was eventually rendered obsolete by advancing technology.
While designed as an F1 engine, the DFV was also used as in endurance racing, although its flat-plane crank design led to destructive vibrations putting stress on devices surrounding the engine, especially the exhaust system.  The first sports car to use a DFV, the Ford P68, failed to finish a single race because of repeated mechanical and electrical failures.  Despite this handicap the DFV won the 24 hours of Le Mans twice in its original 3.0 Litre form for Mirage and Rondeau, who were able to attain sufficient reliability by de-tuning the motor.
The DFL for endurance racing was developed for the 1982 season to replace the DFV.  It came in two versions: one with 3,298 cc (201.3 cu in) and the other with 3,955 cc (241.3 cu in).  While neither competed well in the Group C (C1 Class) the former was adapted to the C2 Class (700 kg minimum weight, 55 Litres fuel, 5 refuelings/1000 km) starting in 1984.  During the latter half of the 1980s it was the most  popular motor for that class, with successful championship campaigns and five class wins at the 24 Hours of Le Mans.  The latter version's severe lack of reliability caused it to fall out of use by 1985.


=== The BDA series ===

Cosworth solidified its association with Ford in 1969, by developing a double overhead camshaft (DOHC) 16-valve inline four-cylinder engine for road use in the Ford Escort.  As Keith Duckworth was busy designing and developing the DFV, the project was assigned to Mike Hall, who created the 1601 cc BDA on the Kent block for homologation purposes.  The camshafts were driven by a toothed belt developed for Fiat 124, hence the name BDA, literally meaning ""Belt Drive, A type"".  It was designed for FIA Group 2 and Group 4 on either rallying or touring car racing purpose.  The nominal homologation at 1601 cc capacity meant that BDA-engined cars competed in what was usually the top class (1600 cc and up) so were eligible for overall victories rather than class wins.
In 1970, the 1701 cc BDB was created for the Escort RS1600, and this engine received fuel injection for the first time in the series as 1701 cc BDC.  Two years later, the BDA series was adopted for Formula 2; first came the 1790 cc BDE, then the 1927 cc BDF eventually reaching a maximum of 1975 cc BDG in 1973.  As the bore size reached ever closer to the bore center distance, leaving little space in between cylinders, the all three types had brazed-in cylinder liners to the block. As a departure from the Ford iron block, the BDG received a new aluminium block (originally designed by Brian Hart in 1971 and re-engineered by Cosworth) soon after, and this cylinder block was used as a replacement part in rebuilding many other BD series engines as well as some Mk.XIII engines.
The iron block was also used for smaller displacements; starting with the very successful 1599 cc Formula Atlantic BDD in 1970, followed by the 1098 cc BDJ and 1300 cc BDH variants for SCCA Formula C and sports car racing, respectively. There was even a one-off 785 cc version built by Cosworth employees Paul Squires and Phil Kidsley; fitted with a Lysholm supercharger it was installed in a Brabham BT28 Formula 3 chassis and competed in the British Hill Climb Championship as the Brabham-Lysholm.In 1970, Ford asked Weslake and Co of Rye to build the BDD for them, and by the end of 1970, the production line was installed at Rye and production was under way.  These engines were often called the 'BDA', but were 1599 cc BDDs eligible for under 1.6 Litre class.
The 1599 cc BDD engine won a number of championships around the world in Formula Atlantic and Formula Pacific during the 1980s.
In 1975, 1599 cc big valve BDM (225 bhp) was developed with fuel injection for Formula Atlantic, and a 'sealed engine' version BDN (1599 cc, 210 bhp) followed in 1977 for Canadian Formula Atlantic series.
Largely known as 'Cosworth BDA', BDD and BDM were also very successful in Formula Pacific and Formula Mondial racing in Australia and New Zealand. In open wheel racing, Cosworth powered cars (Ralt RT4 and Tiga's) won Australian Drivers' Championship in 1982–1986 as well as winning the Australian Grand Prix in 1981–1984 (including wins by Alain Prost and Roberto Moreno) before the race became part of the Formula One World Championship in 1985, and won the New Zealand Grand Prix each year from 1982 to 1988. BDD and BDM engines were also prominent in the Australian Sports Car Championship during the 1980s, winning the 1987 championship.

The turbo charged 1778 cc BDT was created in 1981, which powered the never-raced RWD Escort RS1700T. In 1984, 4WD Ford RS200 debuted with a 1803 cc version of BDT, which was created for Group B rallying. Between 1984 and 1986 the BDT engine was used in Group C endurance racing by Roy Baker, in class C2 using the Tiga GC284, GC285 and GC286. Later in 1986, a 2137 cc version was created by Brian Hart using a bespoke aluminium block and a large intercooler for RS200 Evolution, just as Group B was cancelled by the FIA.  This BDT-E ('E' for Evolution) produced over 600 bhp (447 kW; 608 PS) in Group B 'rallycross' boost level, normally producing  530–550 bhp (395–410 kW; 537–558 PS) on a lower but sustainable boost.
In 1983, the BD series saw its second road engine incarnation (the first being the original BDA and BDB), the BDR, which was a BDA or BDB sold in kit form for the Caterham Super Seven in 1601 cc (120 bhp) and in 1701 cc (130 bhp) formats.
The Hart 420R and the Zakspeed F1 engines owe much to the BDA series, being essentially an aluminium-block derivative using similar heads.


=== The GA/GAA V6 ===

A fuel-injected belt-driven DOHC GA (also called the GAA) was based on the 60 degree V6 block of Ford Essex, and was used for the Ford Capris raced in Group 2 in the early 1970s. This had a capacity of 3,412 cc (208.2 cu in), and was highly competitive against the BMW straight-sixes. The GA was also used in the later years of Formula 5000 in Europe.
The GA or GAA was commissioned by Ford in May 1972, when Ford realised that the Cologne V6 based Weslake OHV V6 engines used in their Capris which competed in the European Touring Car Championship had been modified to the point that no more performance could be extracted from them. Mike Hall, who had already designed the highly successful Cosworth DFV and BDA engines, took on the task of developing a whole new engine based on the 3-Litre Essex V6 block.
The new engine was radically different from the previously-used Weslake unit in that it featured twin overhead camshaft aluminium alloy cylinder heads, 4 valves per cylinder, a Lucas mechanical fuel injection system, dry sump oiling system, a steel crankshaft, and enlarged displacement of 3412cc, compared with the 2.9  litres of the previously used Cologne V6 based Weslake V6.
Ford expected a minimum of 400 Hp from the new Cosworth engine; that figure was exceeded, with the engine producing 420 Hp in the first test run. In race tune they finally produced around 462 bhp (345 kW; 468 PS) at 9000 rpm and 300 ft-lb of torque (407 Nm). This meant that the new engine proved highly successful at competing against BMW in the 1973 Season of the European Touring Car Championship where the engine was installed in Ford's newly homologated Capri RS 3100.
Ford Motorsport also sold 100 Cosworth GA V6 engines, most of them ending up in Formula 5000 cars.
The GA/GAA V6 is a very rare, and extremely expensive engine, with rebuilt units fetching around £50.000.


=== The FBA and FBC V6 ===

The FBA and FBC engines were found in the Ford Granada and Ford Scorpio Ultima. The FBA came first in 1991 and was also known as the 'BOA'; it was based on the Ford Cologne V6 used in the Ford Sierra and Ford Capri and other models and was a twin overhead camshaft 24valve conversion for more power, producing 195 metric horsepower (143 kW; 192 bhp) and better idle quality.

In 1995, with a new version of the Scorpio, it was upgraded with a wider torque spread and higher power – to 204 PS (150 kW; 201 hp), from a variable intake system and reprofiled cams.  The NVH was improved with a change from a single chain to drive all four camshafts – to one chain to drive one bank of cams and a second for the other bank; this engine was known as the 'BOB'.
A racing version was also available for a short time – FBE – with an individual throttle butterfly for each cylinder.
FBB and FBD engines existed as development engines but these were never released.
The two production engines were always mated to an automatic gearbox but have become popular in the custom car scene where they have been mated to the 4x4 manual transmission and the rear-wheel-drive manual transmission from the Ford Sierra XR4 and XR4x4. There are also companies that offer twin and single turbo conversions, and other modifications to increase power to usually around 400 bhp (300 kW). These engines can be bought relatively cheaply and, providing they are well serviced, engines have been known to cover over 200,000 miles without major work being required.


=== The YB series ===

The YB series of 1,993 cc (121.6 cu in) engines are based on the older Pinto engine block, and were introduced in the road-going Ford Sierra RS Cosworth in 1986 with 204 PS (150 kW; 201 bhp). With 5,000 units built for homologation purposes in Group A, both for rallies and touring cars. Racing versions of the RS Cosworth were developing around 370 hp (276 kW; 375 PS), but with the small Garrett T3 turbo on the cars reliability was a problem. A limited edition evolution model was introduced in mid-1987, the Sierra RS500 which included a bigger T4 turbo, with power initially at around the 470 hp (350 kW; 477 PS) mark in 1987, but in later years climbing to close to some 550 hp (410 kW; 558 PS) in full racing trim.
The RS500 came to dominate touring car racing in its heyday from 1987 to 1992, winning multiple championships and major races in Europe including the ETCC, Britain and DTM (German), as well as Japan, Australia and New Zealand. This included wins in the five major races, the Spa 24 Hours held at Spa-Francorchamps in Belgium, the Bathurst 1000 at Mount Panorama in Australia, the RAC Tourist Trophy at Silverstone in England, the Wellington 500 street race in New Zealand, and the InterTEC 500 at Fuji in Japan. The only car to truly challenge the Sierra's dominance towards the end of the Group A era in 1990–1992 was the 640 hp (477 kW; 649 PS), 4WD twin turbo Nissan Skyline R32 GT-R.
At the end of its life in Group A in 1992, the Australian Sierra teams were reportedly getting around 600 bhp (447 kW; 608 PS) from the 2.0L turbocharged YB engines. For his pole position lap at the 1992 Bathurst 1000, Australian driver Dick Johnson (whose team since 1988 had a reputation for having the fastest Sierra's in Group A racing anywhere in the world) was reportedly running a special qualifying engine that was producing close to 680 hp (507 kW; 689 PS) in his RS500.
The various colour cam covers that distinguished each version were as follows: Red: YBB (Sierra Cosworth 2wd, both 3-door and Sapphire), YBD (Sierra RS500), YBJ (Sierra Sapphire 4wd, non cat); Green: YBG (catalyst equipped 4x4 Sierra Sapphire Cosworth); Blue: YBT (large-turbo Escort Cosworth); Silver: YBP (small-turbo Escort Cosworth).
Further evolutions of the YB included a reduced-emissions road version, as well as the block used in the Escort RS Cosworth (which used the Sierra floorpan). The engine stopped being used on new cars in 1997, with the Focus WRC and road-going Focus RS instead relying on Zetec designs.


=== The GBA V6 ===
Cosworth experimented with turbocharged BD derivatives, before settling on an all-new turbocharged 1,500 cc (91.5 cu in) V6 engine to be badged as the Ford TEC (internally it was known as the GB-series). This had a long development history dating back to the 1984 British Grand Prix at Brands Hatch where Cosworth and Ford's competition department agreed to build a new turbo engine to replace the outdated DFV / DFY series. The TEC raced only briefly, in 1986, with the Haas Lola team and in 1987 with the Benetton team. The development of the GBA engine at Cosworth became the subject of a British TV documentary in Channel Four's Equinox series, broadcast in 1986.

The GBA was designed by Keith Duckworth, though many in Formula One doubted his ability to design another truly competitive engine due to his known distaste for turbocharging in general. Rather than design an entirely new engine, Duckworth instead chose to originally try and develop an old, modified 4 cylinder BDA sports car engine as he believed 4 cylinder engines were more compact and economical than a V6 (Cosworth's chief race engine designer Geoff Goddard was against the idea of the straight 4, but reluctantly let Duckworth go down that path). However, after numerous failures of the test engines on the dynamometer which were eventually traced to an incurable vibration at the crankshaft, Duckworth designed an all new 120° V6 engine instead, the same configuration as the Ferrari V6 turbo engine used from 1981 to 1986. The BDA engine was originally limited to 10,000 RPM in sports car racing, but with a turbo its failures generally happened at around 11,000 RPM. The first 4-cylinder test engine was so badly damaged that it actually changed the shape of the engine block to the point where the crankshaft would not move. As around 4 months had been lost in trying to get the 4 cylinder engine to work, Ford and Cosworth's plan for the engine to debut with Haas Lola in 1985 was pushed back to the 1986 season.
The GBA engine was first road tested by Haas Lola's lead driver, 1980 World Champion Alan Jones in the new Lola THL2 at the Boreham Circuit in Essex just north-east of London on 21 February 1986. In freezing, snowy conditions (−6° Celsius) at approximately 10 AM, the V6 turbo, running a conservative 2.5 BAR boost setting, ran cleanly although the engine management electronics developed by Motorola in the United States and Cosworth had not yet been finalised and the engine ran with the same electronics that were used on the dynamometer. Also present at the test were Duckworth, Goddard, the THL2's designer Neil Oatley, the teams #2 driver Patrick Tambay and other staff from both Haas Lola, Ford and Cosworth.
The engine made its Formula One debut with Jones driving the Lola THL2 at the 1986 San Marino Grand Prix, the third round of the 1986 season (for the opening two races in Brazil and Spain, the team used their 1985 car, the Hart 415-T turbo powered Lola THL1, while Tambay also drove the THL1 at Imola). Jones qualified in 21st place and retired after 28 of the races 60 laps due to overheating. Jones also recorded the engine's first finish when he placed 11th in the Belgian Grand Prix. Jones and teammate Patrick Tambay captured the Ford V6 turbo's first ever points when they finished 4th and 5th respectively in the Austrian Grand Prix, with Jones backing up in the next race in Italy with a 6th-placed finish, the final points the engine would gain in 1986.
Producing approximately 900 bhp (671 kW; 912 PS), the turbocharged V6 is the most powerful Formula One engine designed and built by Cosworth. With Haas Lola not competing in 1987, Benetton, having lost the use of the 4 cylinder BMW engines when the German giant pulled out of Formula One, signed with Ford to race their V6 for the season. While in 1986 turbo boost had been unrestricted by the rules, 1987 saw the FIA introduce the pop-off valve to the turbocharged engines in a two-year plan to outlaw the turbos and make all Formula One engines 3.5 litres and naturally aspirated by the start of the 1989 season. While Cosworth adapted the TEC to 1987's 4.0 Bar turbo limit and the new 195 litre fuel limit, development of the V6 turbo engine which would be obsolete in less than two years virtually stopped. Cosworth instead worked on the DFR V8 that was introduced with Benetton in 1988.
With the reduction in turbo boost limit not affecting the Ford V6 as much as others such as Honda, BMW and Ferrari which had more horsepower to lose, the turbo engine would be more competitive with Benetton in 1987, with Teo Fabi taking the engine's first podium with third in Austria, followed by its last podium when Thierry Boutsen also scored third in the last race of the season in Australia.


=== The HB V8 ===
DFV/DFZ/DFR replacement was designed by Geoff Goddard to result in 3,498 cc (213.5 cu in) (96 mm x 60.4 mm) HB V8, which was introduced with the Benetton team midway through 1989 making its debut at the French Grand Prix, and won the Japanese Grand Prix that year (Benetton used both the original HBA1 and the development HBA4 in 1989). As Ford's de facto works team, Benetton maintained exclusivity with this model through the rest of 1989 and 1990. 1991 saw the introduction of customer units, two specifications behind their works equivalents. In 1991, these were supplied to the fledgling Jordan Grand Prix outfit, and for 1992, Lotus. 1993 saw the customer deal extended to McLaren who had lost the use of their Honda V12 engines after 1992. Using the customer HBA7 (and later a customer HBA8), McLaren won five Grands Prix with triple World Champion Ayrton Senna that year.
The HBA1 V8 was introduced in 1989. It exploited a narrower 75° vee-angle rather than the 90° used in the DFV series, and was originally rated at approximately 630 bhp (470 kW; 639 PS). By 1993, the factory HBA8 V8 engine used by Benetton was producing approximately 700 bhp (522 kW; 710 PS) at 13,000 rpm. Although the HB V8 was less powerful than the V10s and V12s used by rivals Renault, Honda, and Ferrari, its advantage was that it was lighter and gave better fuel economy.
A Jaguar-badged version of the HB was developed by Tom Walkinshaw Racing to the tune of 650 bhp at 11,500 rpm for sports car racing, fitted to the extremely successful Jaguar XJR-14.


=== The EC, ECA, ED, EDM and ED 2/4 V8 ===
The HB was developed into 3,498 cc (213.5 cu in) (100 mm x 55.7 mm) EC V8 for the 1994 season. This engine, producing about 740 bhp at 13,800rpm, was badged as Ford Zetec-R, and Michael Schumacher won the Drivers' World Championship with Benetton (his first of a record 7 championships), in 1994. This was the last Ford-powered F1 title.
For the 1995 season, the F1 engine regulation changed to 3 litres, and the EC's bore and stroke were changed to 94mm x 53.9mm, resulting in 2,992 cc (182.6 cu in) ECA, which was introduced at about 600 bhp, and developed to 610 to 630 bhp at 14,000rpm. It was exclusively used by the Sauber team, whose biggest success of the year was Heinz-Harald Frentzen's third place at Monza.
Customer unit Cosworth ED (not badged as Ford Zetec-R) for non-works teams was also made for 1995 with about 580 bhp for Minardi, Simtek (called the EDB), Pacific Racing (EDC) and Forti (EDD) teams.  Minardi realised the power deficiency before the season and asked Magneti Marelli to develop a replacement engine management system, with which the engine was called the EDM. Cosworth later updated the ED to ED 2/4 for Tyrrell and Lola with 2,995 cc (182.8 cu in) (94mm x 53.95mm) displacement for 600 bhp, which was used until the end of 1997 season.


=== The JD, VJ and VJM V10 ===
In order to produce a higher power at higher rpm, a completely new 2,992 cc (182.6 cu in) (89mm x 48.1mm) JD 72° V10 was designed for 1996, which produced about 670 bhp at 15,800rpm, and used by Sauber Formula One team.  This engine was further developed into VJ and VJM with the same V-angle, bore and stroke, reaching 720 bhp for racing, 730 bhp for qualifying, at 16,500rpm. All three of these engines were badged as Ford Zetec-R as well, and used by several teams. In its debut season, the best result was another third place, this time taken by Johnny Herbert at Monaco. This was surpassed one year later by Rubens Barichello's sensational second place, again at Monaco, which was the first points finish for the newly formed Stewart Grand Prix team.


=== Other Formula One engines ===
The Stewart Grand Prix team effectively became the Ford works team, and used Cosworth CR-1 engines from its first season in 1997, which was a much lighter version of VJM, ultimately reaching 770 bhp at 16,500rpm by 2001.  Over the next few years Ford had increased its involvement with the Stewart team, and finally bought the team, renaming it Jaguar Racing for 2000.  Jaguar pulled out of F1 at the end of 2004, but the team (renamed Red Bull Racing) continued to use Cosworth V10 engines until switching to a Ferrari V8 for 2006.  Minardi also used re-badged Cosworth engines until 2005.
Williams began testing the new CA2006 2.4-litre V8 in November 2005, and used the Cosworth V8 engines for the 2006 season.  In the same year, Scuderia Toro Rosso used detuned V10 engines based on the 2005 units.
In 2007, however, the company was left without a partner when Williams chose to switch to Toyota power, and Scuderia Toro Rosso made the switch to Ferrari engines  (as used in 2006 by their mother team Red Bull Racing).
In Max Mosley's letter following the withdrawal of Honda from Formula One in December 2008, it was announced that Cosworth had won the tender to provide a standard engine to any interested participants.  The new engine would become the standard design and manufacturers could opt to use whole units, construct their own from designs provided by Cosworth, or produce their own engine with the caveat that it be limited to the same power as the new ""standard"" engine.
In 2010 Cosworth returned as the engine supplier for Williams and three new teams; Hispania Racing, Lotus Racing and Virgin Racing. The CA2010 is the same 2.4-litre V8 base of the CA2006 used by Williams, but has been re-tuned for the then-mandated 18,000 rpm limit required on all engines, down from its original 20,000 rpm implementation. First units were ready and shipped to teams in mid-January for fitting 2 weeks prior to first track testing for the year.


=== Other IndyCar and Champ Car engines ===

Cosworth designed a series of replacements for the DFS to be used in IndyCar and Champ Car racing: the X-series, beginning in 1992 with the XB.  The XF was developed for the 2000 season to replace the XD, and was chosen as the spec engine for the Champ Car World Series in 2003.  The most recent derivative of the XF, the 2,650 cubic centimetres (161.7 cu in) XFE quad-cam 90° V8 overhead camshaft, continued in that role through the 2007 season.  The Champ Car World Series imposed a rev limit of 12,000 rpm down from the over 15,000 rpm of 2002.  The 2004 model of the XFE had a rated power of nominal 750 horsepower (559 kW; 760 PS) at 1,054 mmHg (intake boost pressure), and a maximum power of 800 bhp (597 kW; 811 PS) at 1130 mmHg (during Push-to-Pass).  The 2004 XFE maximum speed was 12,000 rpm (rev limited) and torque of 490 N⋅m (361 lbf⋅ft).  The aluminium and iron turbo housing ran a boost of 5.9 psi at sea level (= boost of 12 inches of mercury which is 41.5 inches of mercury absolute).  The Methanol-fuelled engine used a steel crankshaft and aluminium alloy pistons.  Weight was 120 kg (264.6 lb) and length was 539 mm (21.2 in).
In 2007, the Ford name was removed from the engine pieces as the manufacturer elected not to continue sponsorship of the series.  Several other engine changes were made, notably the removal of the calibrated ""pop off valve"" designed to limit turbo boost pressure, replaced by engine electronics.  The rated life of the engine was 1,400 miles (2,300 km) between rebuilds.  Engines were sent by the race teams to Cosworth for the rebuild.  In 2007, Champ Car switched to the new Panoz DP01 chassis, which was said to provide better ducting of airflow into the engine.  The Champ Car World Series merged into the Indy Racing League IndyCar Series prior to the 2008 season, and Cosworth does not currently provide engines to any American open wheel racing series.There is evidence that Cosworth was working on a 3,400 cc (207.5 cu in) push-rod V8 along the lines of the Ilmor/Mercedes 500I to exploit the peculiar loophole in the Indianapolis 500 rules on the definition of the word ""pushrod engine"", permitting such engines with extremely short pushrods higher turbocharger boost – this was assigned a project code CD but seemingly never completed.
In mid-2003, Cosworth provided the 3.5 L V8 XG badged as a Chevrolet Gen 4 engine to IRL IndyCar Series teams after the proprietary Chevrolet Gen 3 engine proved inadequate against rival Hondas and Toyotas during the 2003 season.  While many teams left Chevrolet after the 2003 season, those that stayed saw a significant improvement in performance with the new ""Chevworth"" engine compared to their previous units. The XG finished second in its first race at Michigan on July 27, 2003.  Sam Hornish, Jr. went on to win 3 races that season with the new XG.  The XG was reduced in size to 3 L for 2004 season and it won one race in 2005 during Chevrolet's final season in IRL.


=== Other Formula Atlantic engines ===
Currently these are 300 horsepower (224 kW; 304 PS) 2,300 cubic centimetres (140.4 cu in) inline-four engines based on the Mazda MZR engine developed in cooperation with Mazda.  Changes includes a billet crankshaft, barrel throttle bodies, new cylinder head with larger valves, pistons, con rods and camshafts.  A detuned 250 horsepower (190 kW; 250 PS) version, targeting club racers, is sold to the consumer market.  This engine retains the standard crankshaft, and has a different cylinder head.  Both engines are built by Cosworth in Torrance, California, under the guidance of newly appointed technical designer Wayne Merry (formerly of Cosworth in Worcester UK).


=== Other road engines ===
Best known in Europe for its relationship with Ford – in particular because of the Cosworth name in the vehicle title on the high-performance Ford Sierra RS Cosworth and Ford Escort RS Cosworth, but also in the creation of other Ford models; the Escort RS1600, Escort RS1800, RS200, and Scorpio 2.9i 24V.

In the US, the name has also appeared in the title of a road car (well before it did in Europe) as the Cosworth version of the Chevrolet Vega. Only 3,508 1975 and 1976 Cosworth Vegas were produced from March 1975 through 1976. The engine features the Vega sleeveless, aluminium-alloy block fitted with forged components. The twin-cam, 16-valve, aluminium cylinder head design was assisted by Cosworth, but Chevrolet did the development work. The engine features electronic ignition, Bendix electronic fuel injection, and stainless steel headers. The final US emissions standardised version produces 110 bhp. Cosworth's EA racing version was not successful due to engine block structural failures. Chevrolet later produced a heavy-duty 'off-road' block with thicker walls to better withstand the racing application, but by that time Cosworth had moved on. Projected first year sales of the Cosworth Vega had been 5,000. With only 3,508 cars produced and many unsold, the car was discontinued. 1,500 hand-built Cosworth Vega engines were simply scrapped for lack of demand.Other published projects for Adam Opel AG include the Opel Ascona 400 / Manta 400 rally cars and the 2.0L 16V engines in the Opel Kadett, Opel Astra GSi, Opel Vectra and Opel Calibra turbo.Other companies known to have benefitted from the Cosworth engineering input are Mercedes-Benz (with the 190 E 2.3-16), Rolls-Royce, and Audi (notably their RS cars).Cosworth's involvement with Mercedes-Benz came with moves in the mid-1980s from the German manufacturer to re-enter motorsport after retiring from direct factory participation after the tragic 1955 Le Mans crash which killed 80 spectators. Mercedes-Benz was looking to create a Group B rally car out of its new W201 Chassis (190E Model) and turned to the expertise of Cosworth to shorten the development time for this project.

The request was a huge surprise for Cosworth, and the original brief for a 320 bhp engine based on the 136 bhp Mercedes M102 2.3-litre SOHC 4-cylinder engine was duly passed to Mike Hall, who ""drew the famed DFV and BDA engine"". Designed around the existing M102 head bolt pattern, the new twin cam, 16-valve, pentroof head, had its valves set at 45° included angle, rather than the 40° angle of the BDA.  The valves were the biggest that could be fitted into the combustion chamber. Flat top pistons delivered the 10.5:1 compression ratio. The new Cosworth WAA engine also was Cosworth's first one-piece head, i.e. the camshaft carrier was cast integral with the head itself. Again the constraints of the existing head-bolt pattern meant that Hall had to shift the camshaft bearings from outside each pair of camlobes as in the BDA to in between each cylinder's pair of cam lobes. The upside being that this configuration made for less flex at high rpm.The advent of the AWD turbo Audi Quattro gave the rear-wheel-drive, normally aspirated 190E rally car no chance of being successful and the competition car was stillborn. Instead Mercedes-Benz decided to recoup its development cost by selling the car as a road going sports-sedan. Hall detuned the WAA race engine to 185 bhp by reducing the port diameters and a more restrictive fuel injection and induction was substituted for the race items to complete the detune. All WAA 2.3-16 engines were built in the Cosworth factory with the heads being produced by the Coscast method.
Cosworth assisted with the later 2.5-16 engine (WAB), and the short-stroke 2.5-16 Evo engines (WAC) although these were all manufactured in house by Mercedes-Benz. The 190E 2.3-16 became the basis for privateer Mercedes entries into the DTM from 1988. The short-stroke 2.5-16 190E EVO II was race-developed to 375+ bhp, gaining the 1992 DTM crown with Klaus Ludwig at the wheel.
A 4,300 cc (262.4 cu in) V10 designated WDA was also built and tested in a Volvo S80 in 1997, but this did not see production.
A 4,000 cc (244.1 cu in) V12 designated GMA was also built and tested in a Gordon Murray T.50 in 2020, but this production is Released in 2021-2022.


== Cosworth F1 car ==

Cosworth made an attempt at designing a full Formula One Grand Prix car in 1969. The car, designed by Robin Herd, used an original 4WD transmission designed by Keith Duckworth (different from the Ferguson used by all other 4WD F1 cars of the 1960s) and powered by a magnesium version of the DFV unit.  The car was planned to drive at the 1969 British Grand Prix, but it was silently withdrawn.  When Herd left to form March Engineering, the project was cancelled. The external design of the car was a product of Herd's use of Mallite sheeting (a wood-aluminium laminate composite) for the principal structural monocoque sections, a technique he pioneered on the first McLaren single-seat cars, including the McLaren M2B of 1966.


== Formula One World Championship results ==

(key) (Races in bold indicate pole position) (Races in italics indicate fastest lap)

Notes

* – Started illegally.
† – Half points awarded as less than 75% of the race distance was completed.


== Summary of F1 engine use ==


== See also ==
Formula One
Ford Racing
MAHLE Powertrain


== References ==


=== Notes ===


=== Citations ===


== Further reading ==
Tuchen, Bernd (2006). Ford in der Formel 1 1965 bis 1994.  Die Geschichte des legendären Ford Cosworth DFV Motors.  Seine Entstehung, seine Rennställe, seine Siege und Weltmeister (in German). Büchenbach: Verlag Dr. Faustus. ISBN 978-3-933474-38-4.
Robson, Graham (1999). Cosworth: The Search For Power (4th ed.). Haynes Publishing. ISBN 1-85960-610-5.


== External links ==
Cosworth.com — official website
Cosworth Performance Parts
List of Cosworth engine types
List of f1 engines by year"
"A four-stroke (also four-cycle) engine is an internal combustion (IC) engine in which the piston completes four separate strokes while turning the crankshaft. A stroke refers to the full travel of the piston along the cylinder, in either direction. The four separate strokes are termed:

Intake: Also known as induction or suction. This stroke of the piston begins at top dead center (T.D.C.) and ends at bottom dead center (B.D.C.). In this stroke the intake valve must be in the open position while the piston pulls an air-fuel mixture into the cylinder by producing vacuum pressure into the cylinder through its downward motion. The piston is moving down as air is being sucked in by the downward motion against the piston.
Compression: This stroke begins at B.D.C, or just at the end of the suction stroke, and ends at T.D.C.  In this stroke the piston compresses the air-fuel mixture in preparation for ignition during the power stroke (below). Both the intake and exhaust valves are closed during this stage.
Combustion: Also known as power or ignition. This is the start of the second revolution of the four stroke cycle. At this point the crankshaft has completed a full 360 degree revolution. While the piston is at T.D.C. (the end of the compression stroke) the compressed air-fuel mixture is ignited by a spark plug (in a gasoline engine) or by heat generated by high compression (diesel engines), forcefully returning the piston to B.D.C. This stroke produces mechanical work from the engine to turn the crankshaft.
Exhaust: Also known as outlet. During the exhaust stroke, the piston, once again, returns from B.D.C. to T.D.C. while the exhaust valve is open. This action expels the spent air-fuel mixture through the exhaust valve.


== History ==


=== Otto cycle ===

Nicolaus August Otto was a traveling salesman for a grocery concern. In his travels, he encountered the internal combustion engine built in Paris by Belgian expatriate Jean Joseph Etienne Lenoir.  In 1860, Lenoir successfully created a double-acting engine that ran on illuminating gas at 4% efficiency. The 18 litre Lenoir Engine produced only 2 horsepower. The Lenoir engine ran on illuminating gas made from coal, which had been developed in Paris by Philip Lebon.In testing a replica of the Lenoir engine in 1861, Otto became aware of the effects of compression on the fuel charge. In 1862, Otto attempted to produce an engine to improve on the poor efficiency and reliability of the Lenoir engine. He tried to create an engine that would compress the fuel mixture prior to ignition, but failed as that engine would run no more than a few minutes prior to its destruction. Many other engineers were trying to solve the problem, with no success.In 1864, Otto and Eugen Langen founded the first internal combustion engine production company, NA Otto and Cie (NA Otto and Company). Otto and Cie succeeded in creating a successful atmospheric engine that same year.
The factory ran out of space and was moved to the town of Deutz, Germany in 1869, where the company was renamed to Deutz Gasmotorenfabrik AG (The Deutz Gas Engine Manufacturing Company). In 1872, Gottlieb Daimler was technical director and Wilhelm Maybach was the head of engine design. Daimler was a gunsmith who had worked on the Lenoir engine.
By 1876, Otto and Langen succeeded in creating the first internal combustion engine that compressed the fuel mixture prior to combustion for far higher efficiency than any engine created to this time.
Daimler and Maybach left their employ at Otto and Cie and developed the first high-speed Otto engine in 1883. In 1885, they produced the first automobile to be equipped with an Otto engine. The Daimler Reitwagen used a hot-tube ignition system and the fuel known as Ligroin to become the world's first vehicle  powered by an internal combustion engine. It used a four-stroke engine based on Otto's design. The following year, Karl Benz produced a four-stroke engined automobile that is regarded as the first car.In 1884, Otto's company, then known as Gasmotorenfabrik Deutz (GFD), developed electric ignition and the carburetor. In 1890, Daimler and Maybach formed a company known as Daimler Motoren Gesellschaft. Today, that company is Daimler-Benz.


=== Atkinson cycle ===

The Atkinson-cycle engine is a type of single stroke internal combustion engine invented by James Atkinson in 1882. The Atkinson cycle is designed to provide efficiency at the expense of power density, and is used in some modern hybrid electric applications.
The original Atkinson-cycle piston engine allowed the intake, compression, power, and exhaust strokes of the four-stroke cycle to occur in a single turn of the crankshaft and was designed to avoid infringing certain patents covering Otto-cycle engines.Due to the unique crankshaft design of the Atkinson, its expansion ratio can differ from its compression ratio and, with a power stroke longer than its compression stroke, the engine can achieve greater thermal efficiency than a traditional piston engine. While Atkinson's original design is no more than a historical curiosity, many modern engines use unconventional valve timing to produce the effect of a shorter compression stroke/longer power stroke, thus realizing the fuel economy improvements the Atkinson cycle can provide.


=== Diesel cycle ===

The diesel engine is a technical refinement of the 1876 Otto-cycle engine. Where Otto had realized in 1861 that the efficiency of the engine could be increased by first compressing the fuel mixture prior to its ignition, Rudolf Diesel wanted to develop a more efficient type of engine that could run on much heavier fuel. The Lenoir, Otto Atmospheric, and Otto Compression engines (both 1861 and 1876) were designed to run on Illuminating Gas (coal gas). With the same motivation as Otto, Diesel wanted to create an engine that would give small industrial companies their own power source to enable them to compete against larger companies, and like Otto, to get away from the requirement to be tied to a municipal fuel supply. Like Otto, it took more than a decade to produce the high-compression engine that could self-ignite fuel sprayed into the cylinder. Diesel used an air spray combined with fuel in his first engine.
During initial development, one of the engines burst, nearly killing Diesel. He persisted, and finally created a successful engine in 1893. The high-compression engine, which ignites its fuel by the heat of compression, is now called the diesel engine, whether a four-stroke or two-stroke design.
The four-stroke diesel engine has been used in the majority of heavy-duty applications for many decades. It uses a heavy fuel containing more energy and requiring less refinement to produce. The most efficient Otto-cycle engines run near 30% thermal efficiency.


== Thermodynamic analysis ==

The thermodynamic analysis of the actual four-stroke and two-stroke cycles is not a simple task. However, the analysis can be simplified significantly if air standard assumptions are utilized. The resulting cycle, which closely resembles the actual operating conditions, is the Otto cycle.
During normal operation of the engine, as the air/fuel mixture is being compressed, an electric spark is created to ignite the mixture. At low rpm this occurs close to TDC (Top Dead Centre). As engine rpm rises, the speed of the flame front does not change so the spark point is advanced earlier in the cycle to allow a greater proportion of the cycle for the charge to combust before the power stroke commences. This advantage is reflected in the various Otto engine designs; the atmospheric (non-compression) engine operates at 12% efficiency whereas the compressed-charge engine has an operating efficiency around 30%.


== Fuel considerations ==
A problem with compressed charge engines is that the temperature rise of the compressed charge can cause pre-ignition. If this occurs at the wrong time and is too energetic, it can damage the engine. Different fractions of petroleum have widely varying flash points (the temperatures at which the fuel may self-ignite). This must be taken into account in engine and fuel design.
The tendency for the compressed fuel mixture to ignite early is limited by the chemical composition of the fuel. There are several grades of fuel to accommodate differing performance levels of engines. The fuel is altered to change its self ignition temperature. There are several ways to do this. As engines are designed with higher compression ratios the result is that pre-ignition is much more likely to occur since the fuel mixture is compressed to a higher temperature prior to deliberate ignition. The higher temperature more effectively evaporates fuels such as gasoline, which increases the efficiency of the compression engine. Higher Compression ratios also means that the distance that the piston can push to produce power is greater (which is called the Expansion ratio).
The octane rating of a given fuel is a measure of the fuel's resistance to self-ignition. A fuel with a higher numerical octane rating allows for a higher compression ratio, which extracts more energy from the fuel and more effectively converts that energy into useful work while at the same time preventing engine damage from pre-ignition. High Octane fuel is also more expensive.
Many modern four-stroke engines employ gasoline direct injection or GDI. In a gasoline direct-injected engine, the injector nozzle protrudes into the combustion chamber. The direct fuel injector injects gasoline under a very high pressure into the cylinder during the compression stroke, when the piston is closer to the top.Diesel engines by their nature do not have concerns with pre-ignition. They have a concern with whether or not combustion can be started. The description of how likely Diesel fuel is to ignite is called the Cetane rating. Because Diesel fuels are of low volatility, they can be very hard to start when cold.  Various techniques are used to start a cold Diesel engine, the most common being the use of a glow plug.


== Design and engineering principles ==


=== Power output limitations ===

The maximum amount of power generated by an engine is determined by the maximum amount of air ingested. The amount of power generated by a piston engine is related to its size (cylinder volume), whether it is a two-stroke engine or four-stroke design, volumetric efficiency, losses, air-to-fuel ratio, the calorific value of the fuel, oxygen content of the air and speed (RPM). The speed is ultimately limited by material strength and lubrication. Valves, pistons and connecting rods suffer severe acceleration forces. At high engine speed, physical breakage and piston ring flutter can occur, resulting in power loss or even engine destruction. Piston ring flutter occurs when the rings oscillate vertically within the piston grooves they reside in. Ring flutter compromises the seal between the ring and the cylinder wall, which causes a loss of cylinder pressure and power. If an engine spins too quickly, valve springs cannot act quickly enough to close the valves. This is commonly referred to as 'valve float', and it can result in piston to valve contact, severely damaging the engine. At high speeds the lubrication of piston cylinder wall interface tends to break down. This limits the piston speed for industrial engines to about 10 m/s.


==== Intake/exhaust port flow ====
The output power of an engine is dependent on the ability of intake (air–fuel mixture) and exhaust matter to move quickly through valve ports, typically located in the cylinder head. To increase an engine's output power, irregularities in the intake and exhaust paths, such as casting flaws, can be removed, and, with the aid of an air flow bench, the radii of valve port turns and valve seat configuration can be modified to reduce resistance. This process is called porting, and it can be done by hand or with a CNC machine.


=== Waste heat recovery of an internal combustion engine ===
An internal combustion engine is on average capable of converting only 40-45% of supplied energy into mechanical work. A large part of the waste energy is in the form of heat that is released to the environment through coolant, fins etc. If we could somehow recover the waste heat we can improve the engine's performance. It has been found that even if 6% of the entirely wasted heat is recovered it can increase the engine efficiency greatly.Many methods have been devised in order to extract waste heat out of an engine exhaust and use it further to extract some useful work, decreasing the exhaust pollutants at the same time. Use of the Rankine Cycle, turbocharging and thermoelectric generation can be very useful as a waste heat recovery system.
Though these systems are used more frequently some issues, like their low efficiency at lower heat supply rates and high pumping losses, remain a cause of concern.


==== Supercharging ====
One way to increase engine power is to force more air into the cylinder so that more power can be produced from each power stroke. This can be done using some type of air compression device known as a supercharger, which can be powered by the engine crankshaft.
Supercharging increases the power output limits of an internal combustion engine relative to its displacement. Most commonly, the supercharger is always running, but there have been designs that allow it to be cut out or run at varying speeds (relative to engine speed). Mechanically driven supercharging has the disadvantage that some of the output power is used to drive the supercharger, while power is wasted in the high pressure exhaust, as the air has been compressed twice and then gains more potential volume in the combustion but it is only expanded in one stage.


==== Turbocharging ====
A turbocharger is a supercharger that is driven by the engine's exhaust gases, by means of a turbine. A turbocharger is incorporated into the exhaust system of a vehicle to make use of the expelled exhaust. It consists of a two piece, high-speed turbine assembly with one side that compresses the intake air, and the other side that is powered by the exhaust gas outflow.
When idling, and at low-to-moderate speeds, the turbine produces little power from the small exhaust volume, the turbocharger has little effect and the engine operates nearly in a naturally aspirated manner. When much more power output is required, the engine speed and throttle opening are increased until the exhaust gases are sufficient to 'spool up' the turbocharger's turbine to start compressing much more air than normal into the intake manifold. Thus, additional power (and speed) is expelled through the function of this turbine.
Turbocharging allows for more efficient engine operation because it is driven by exhaust pressure that would otherwise be (mostly) wasted, but there is a design limitation known as turbo lag. The increased engine power is not immediately available due to the need to sharply increase engine RPM, to build up pressure and to spin up the turbo, before the turbo starts to do any useful air compression. The increased intake volume causes increased exhaust and spins the turbo faster, and so forth until steady high power operation is reached. Another difficulty is that the higher exhaust pressure causes the exhaust gas to transfer more of its heat to the mechanical parts of the engine.


=== Rod and piston-to-stroke ratio ===
The rod-to-stroke ratio is the ratio of the length of the connecting rod to the length of the piston stroke. A longer rod reduces sidewise pressure of the piston on the cylinder wall and the stress forces, increasing engine life. It also increases the cost and engine height and weight.
A ""square engine"" is an engine with a bore diameter equal to its stroke length. An engine where the bore diameter is larger than its stroke length is an oversquare engine, conversely, an engine with a bore diameter that is smaller than its stroke length is an undersquare engine.


=== Valve train ===
The valves are typically operated by a camshaft rotating at half the speed of the crankshaft. It has a series of cams along its length, each designed to open a valve during the appropriate part of an intake or exhaust stroke. A tappet between valve and cam is a contact surface on which the cam slides to open the valve. Many engines use one or more camshafts “above” a row (or each row) of cylinders, as in the illustration, in which each cam directly actuates a valve through a flat tappet. In other engine designs the camshaft is in the crankcase, in which case each cam usually contacts a push rod, which contacts a rocker arm that opens a valve, or in case of a flathead engine a push rod is not necessary. The overhead cam design typically allows higher engine speeds because it provides the most direct path between cam and valve.


==== Valve clearance ====
Valve clearance refers to the small gap between a valve lifter and a valve stem that ensures that the valve completely closes. On engines with mechanical valve adjustment, excessive clearance causes noise from the valve train. A too-small valve clearance can result in the valves not closing properly. This results in a loss of performance and possibly overheating of exhaust valves. Typically, the clearance must be readjusted each 20,000 miles (32,000 km) with a feeler gauge.
Most modern production engines use  hydraulic lifters to automatically compensate for valve train component wear. Dirty engine oil may cause lifter failure.


=== Energy balance ===
Otto engines are about 30% efficient; in other words, 30% of the energy generated by combustion is converted into useful rotational energy at the output shaft of the engine, while the remainder being losses due to waste heat, friction and engine accessories. There are a number of ways to recover some of the energy lost to waste heat. The use of a Turbocharger in Diesel engines is very effective by boosting incoming air pressure and in effect, provides the same increase in performance as having more displacement. The Mack Truck company, decades ago, developed a turbine system that converted waste heat into kinetic energy that it fed  back into the engine's transmission. In 2005, BMW announced the development of the turbosteamer, a two-stage heat-recovery system similar to the Mack system that recovers 80% of the energy in the exhaust gas and raises the efficiency of an Otto engine by 15%. By contrast, a six-stroke engine may reduce fuel consumption by as much as 40%.
Modern engines are often intentionally built to be slightly less efficient than they could otherwise be. This is necessary for emission controls such as exhaust gas recirculation and catalytic converters that reduce smog and other atmospheric pollutants. Reductions in efficiency may be counteracted with an engine control unit using lean burn techniques.In the United States, the Corporate Average Fuel Economy mandates that vehicles must achieve an average of 34.9 mpg‑US (6.7 L/100 km; 41.9 mpg‑imp) compared to the current standard of 25 mpg‑US (9.4 L/100 km; 30.0 mpg‑imp). As automakers look to meet these standards by 2016, new ways of engineering the traditional internal combustion engine (ICE) have to be considered. Some potential solutions to increase fuel efficiency to meet new mandates include firing after the piston is farthest from the crankshaft, known as top dead centre, and applying the Miller cycle. Together, this redesign could significantly reduce fuel consumption and NO x  emissions.


== See also ==


== References ==


== General sources ==
Hardenberg, Horst O. (1999). The Middle Ages of the Internal combustion Engine. Society of Automotive Engineers (SAE). ISBN 978-0-7680-0391-8.
scienceworld.wolfram.com/physics/OttoCycle.html
Cengel, Yunus A; Michael A Boles; Yaling He (2009). Thermodynamics An Engineering Approach. N.p. The McGraw Hill Companies. ISBN 978-7-121-08478-2.
Benson, Tom (11 July 2008). ""4 Stroke Internal Combustion Engine"". p. National Aeronautics and Space Administration. Retrieved 5 May 2011.


== External links ==
U.S. Patent 194,047
Four stroke engine animation
Detailed Engine Animations
How Car Engines Work
Animated Engines, four stroke, another explanation of the four-stroke engine.
CDX eTextbook, some videos of car components in action.
New 4 stroke"
"A V8 engine is an eight-cylinder piston engine in which the cylinders share a common crankshaft and are arranged in a V configuration.The first known working V8 engine was produced by the French company Antoinette in 1904 for use in aircraft, and the 1914–1935 Cadillac L-Head engine is considered the first automotive V8 engine to be produced in significant quantities. The popularity of V8 engines in cars was greatly increased following the 1932 introduction of the Ford Flathead V8. 


== Design ==


=== V-angle ===

The majority of V8 engines use a V-angle (the angle between the two banks of cylinders) of 90 degrees. This angle results in good engine balance, which results in low vibrations; however, the downside is a larger width than V8 engines that use a smaller V-angle.
V8 engines with a 60 degree V-angle were used in the 1996–1999 Ford Taurus SHO, the 2005–2011 Volvo XC90, and the 2006–2009 Volvo S80. The Ford engine used a 60 degree V-angle because it was based on a V6 engine with a 60 degree V-angle. Both the Ford and Volvo engines were used in transverse engine chassis, which were designed for a front-wheel drive layout (with on-demand all-wheel drive system in the case of the Volvos). To reduce the vibrations caused by the unbalanced 60 degree V-angle, the Volvo engines used a balance shaft and offset split crankpins. The Rolls-Royce Meteorite tank engine also used a 60 degree V-angle, since it was derived from the 60 degree Rolls-Royce Merlin V12 engine.Other V-angles have been used occasionally. The Lancia Trikappa, Lancia Dilambda, and Lancia Astura, produced 1922–1939, used narrow angle V8 engines (based on the Lancia V4 engine) with V-angles of 14—24 degrees. The 1932 Miller four-wheel drive racing cars used a V8 engine with a V-angle of 45 degrees. The 8-cylinder versions of the 1945–1966 EMD 567 diesel locomotive engine also used a V-angle of 45 degrees.


=== Crankshaft configuration ===


==== Cross-plane crankshaft ====
Most V8 engines fitted to road cars use a cross-plane crankshaft, since this configuration has less vibrations due to the perfect primary balance and secondary balance. The cross-plane crankshaft has the four crank pins (numbered from the front) at angles of 0, 90, 180, and 270 degrees, which results in a cross shape for the crankshaft when it is viewed from one end.
The iconic rumbling exhaust sound produced by a typical cross-plane V8 engine is partly due to the uneven firing order within each of the two banks of four cylinders. A typical firing order of L-R-L-L-R-L-R-R (or R-L-R-R-L-R-L-L) results in uneven intake and exhaust pulse spacing for each bank. When separate exhaust systems are used for each bank of cylinders, this uneven pulsing results in the rumbling sound that is typically associated with V8 engines. However, racing engines seek to avoid these uneven exhaust pressure pulses, in order to maximise the power output. In order to link the exhaust systems from each bank (to provide even exhaust gas pulses), 1960s cross-plane V8 racing engines have either used long primary exhaust pipes (such as the Ford GT40 endurance racing car) or located the exhaust ports on the inside of the V-angle (such as the Lotus 38 IndyCar).


==== Flat-plane crankshaft ====
On the other hand, a flat-plane crankshaft is used by many V8 engines fitted to racing cars.This configuration provides two benefits. Mechanically, the crankshaft can be machined from a flat billet, and does not require counterweights so it is lighter. However it produces more vibration due to a secondary imbalance.
From the gas dynamics aspect, the flat-plane crankshaft allows for even exhaust gas pulsing to be achieved with a simple exhaust system. The design was popularized in motor racing by the 1961–1965 Coventry Climax FWMV Formula One engine, and the 1967–1985 Cosworth DFV engine was highly successful in Formula One. Several production sports cars have used flat-plane V8 engines, such as every Ferrari V8 model (from the 1973 Ferrari 308 GT4 to the 2019-present Ferrari F8 Tributo), the Lotus Esprit V8, the Porsche 918 Spyder, and the McLaren MP4-12C.
Most early V8 road car engines also used a flat-plane crankshaft, since this was simpler to design and build than a cross-plane crankshaft. Early flat-plane V8 engines included the 1910 De Dion-Bouton engine, the 1915 Peerless engine, and the 1915 Cadillac engine.


== Origins ==

The first known V8 engine was the Antoinette engine, designed by Léon Levavasseur, which was first built in 1904. The Antoinette was built in France for use in speedboat racing and airplanes. A 1905 version of the Antoinette engine produced 50 hp (37 kW) with 86 kg (190 lb) of weight (including cooling water), resulting in a power-to-weight ratio that was not surpassed for 25 years. Also in 1904, V8 engines began small-scale production by Renault and Buchet for use in airplanes and racing cars.In 1905, the first V8 engine used in a road-going car was the Rolls-Royce V-8 built in the United Kingdom. This model was initially produced with a 3.5 L (214 cu in) V8 engine, however only three cars were produced before Rolls-Royce reverted to using straight-six engines. In 1907, the Hewitt Touring Car became the first car built in the United States with a V8 engine. The 1910 De Dion-Bouton— built in France— is considered to be the first V8 engine produced in significant quantities.The 1914 Cadillac L-head V8 engine is considered to be the first mass-production V8 engine. This engine was built in the United States and was greatly assisted by Cadillac's pioneering use of electric starter motors.
Early airplanes continued to use V8 engines, such as the 1915 Hispano-Suiza 8 SOHC engine designed in Switzerland. This engine was used by American, French, and British military aircraft in World War One. It is estimated that approximately half of all Allied aircraft were powered by the Hispano-Suiza 8 engine.

		


== Usage in automobiles ==
The V8 engine with a cross-plane crankshaft is a common configuration for large automobile engines. The displacement of modern V8 engines is typically between 3.5 to 6.0 L (214 to 366 cu in), though larger and smaller examples have been produced, such as the 8.2 L (500 cu in) V8 engine used in the 1971–1978 Cadillac Eldorado.
Due to its large external dimensions, V8 engines are typically used in cars that use a longitudinal engine layout and rear-wheel drive (or all-wheel drive). However, V8 engines have also occasionally been used in transverse engine front-wheel drive vehicles, sometimes using closer cylinder bore spacings and narrower cylinder bank angles to reduce their space requirements.


=== Australia ===

The first Australian designed car to use a V8 engine was the 1965 Chrysler Valiant (AP6), which was available with an American-built 4.5 L (273 cu in) Chrysler engine. The first locally designed V8 Ford was the 1966 Ford Falcon (XR) and the first V8 Holden was the 1968 Holden HK, both using engines supplied by their parent companies in the United States.
The first V8 engine to be mass-produced in Australia was the 1969–2000 Holden V8 engine. This cast-iron overhead valve engine used a V-angle of 90 degrees and was built in displacements of 4.1 L (253 cu in) and 5.0 L (308 cu in), the latter being de-stroked to 5.0 L (304 cu in) in 1985. The Holden V8 engine was used in various models including the Kingswood, Monaro, Torana, Commodore, and Statesman. Versions tuned for higher performance were sold by Holden Dealer Team and Holden Special Vehicles, including versions stroked to up to 5.7 L (350 cu in). The Holden V8 engine was also used in touring car racing and formed the basis of the Repco-Holden engined used in Formula 5000 racing. In 1999, the Holden V8 engine began to be replaced by the imported General Motors LS1 V8 engine.
In 1971, Ford Australia began local production of the Ford 'Cleveland' V8, an overhead valve cast-iron engine. The engine was produced in displacements of 4.9 L (302 cu in) and 5.8 L (351 cu in) for use in the Australian Ford Falcon and Ford Fairlane models. It was also used in several low-volume DeTomaso sports cars and luxury sedans built in Italy. Australian production ceased in 1982, when Ford Australia temporarily ceased production of V8 cars. From 1991 to 2016, the Ford Falcon was available with the imported Ford Windsor, Ford Barra or Ford Modular V8 engines; the latter were marketed as ""Boss"" and locally assembled from a mix of imported and local parts.
A 4.4 L (269 cu in) version of the Rover V8 engine was produced in Australia for the ill-fated 1973–1975 Leyland P76 sedan. The engine was an overhead valve design and the only all-aluminium engine produced in Australia.


=== China ===
The 1958–1965 Hongqi CA72 was a luxury car, of which approximately 200 were built for government officials. It was powered by a 5.6 L (340 cu in) Chrysler LA engine and built on the chassis of a 1950s Chrysler Imperial.


=== Czech Republic ===

The 1934–1938 Tatra 77 rear-engined sedan was initially powered by 3.0 L (183 cu in) petrol V8, which was air-cooled and used an overhead camshaft that operated the valves using a 'walking beam' rocker arrangement. This model line continued until 1999, when the Tatra 700 ended production. 
Tatra also produced diesel V8 truck engines from the 1939 Tatra 81 to the present day Tatra 815.


=== France ===
French manufacturers were pioneering in their use of V8 engines in the early 1900s with the 1904 Antoinette aircraft engine (the first known V8 engine) and the 1910 De Dion-Bouton. However, there were few French automotive V8 engines in the following decades, with manufacturers such as Delage, Delahaye, Talbot-Lago, Bugatti, and Hotchkiss instead using six-cylinder or straight-eight engines.
From 1935 to 1954, Matford (Ford's French subsidiary, later renamed to 'Ford SAF') produced cars with V8 engines, closely based on contemporary American Ford models. Simca purchased the Ford SAF in 1954 and continued to produce various models powered by the Ford Flathead V8 until 1969.After WW2, France imposed very steep tax horsepower charges - the owners of cars with engines above 2 litres were financially penalized, so France had a very small domestic market for larger engined cars, such as the V8. Despite this, Facel Vega produced luxury and sports cars powered by Chrysler V8 engines from 1954 to 1964.


=== Germany ===

One of the first German V8 engines was the 1928–1945 Argus As 10 aircraft engine. This engine was air-cooled, used an 'inverted V' design and was used in several training, reconnaissance and communications airplanes. 
From 1933 to 1940, the Horch 830 luxury cars were powered by V8 engines (sold alongside Horch's larger straight-eight engines). Shortly after, the 1934–1937 Stoewer Greif V8 was powered by a 2.5 L (153 cu in) V8 engine.
BMW's first V8 engine was the 1954–1965 BMW OHV V8 engine, a petrol engine with overhead valves and all-aluminium construction. The company resumed production of V8 engines in 1992 with the BMW M60 aluminium double overhead camshaft engine, and V8 engines have remained in production until the present day. The first turbocharged V8 engine from BMW was the 2008-present BMW N63 engine.
Mercedes-Benz began production of the Mercedes-Benz M100 petrol V8 engine in 1963 and has continued production of V8 engines to the present day. The M100 had a single overhead camshaft, a cast-iron block and an aluminium head. Supercharging was first used on the Mercedes-Benz M113 engine in 2002 and turbocharging was first used on the Mercedes-Benz M278 engine in 2010.
Porsche's first road car to use a V8 engine was the 1978 Porsche 928 coupe.
Audi's first road car to use a V8 engine was the 1988 Audi V8 luxury sedan.


=== Italy ===
Alfa RomeoThe first V8-engined Alfa Romeo road car was the 1967–1969 Alfa Romeo 33 Stradale mid-engined sports car, of which 18 cars were produced. This was followed by the 1970–1977 Alfa Romeo Montreal front-engined sports car. The engines for both cars are based on the 90-degree V8 engine from the Alfa Romeo Tipo 33 racing car, and have double overhead camshafts and a dry sump. The 33 Stradale engine has a displacement of 2.00 L (122 cu in) and a flat-plane crankshaft, while the Montreal uses an engine enlarged to 2.6 L (160 cu in) and uses a cross-plane crankshaft.The 2007–2010 Alfa Romeo 8C Competizione / Spider sports cars are powered by a 4.7 L (290 cu in) version of the Ferrari F136 engine with a cross-plane crankshaft.

Ferrari
Ferrari's first contact with V8 engines was the 1955 Lancia-Ferrari D50, a Formula One racing car that the company acquired as part of its purchase of Lancia's Formula One racing department. The first Ferrari-developed V8 engines were used in the 1962 Ferrari 248 SP and Ferrari 268 SP sports prototype racing cars, designed by Carlo Chiti. This engine had a single overhead camshaft and was rear-mounted in the cars.
The company's first V8 road car was the 1973–1974 Dino 308 GT4 mid-engined sports car. The engine is a 90-degree all-aluminium V8 with double overhead camshafts. In 1975, the 2.0 L (122 cu in) engine in the Ferrari 208 GT4 became the smallest production V8 engine ever produced. The model lineage of mid-engined V8 road cars continues to the 2019-present Ferrari F8 Tributo.
Five-valve-per-cylinder versions were used 1994–2005 in the Ferrari F355 and Ferrari 360. Turbocharging was introduced on the 1984–1987 Ferrari 288 GTO flagship car and the range of entry-level mid-engined sports cars switched to turbocharging with the 2015 Ferrari 488.
The Formula One team resumed usage of V8 engines for the 2006–2013 seasons, beginning with the Ferrari 248 F1.

Maserati
The first Maserati V8 road car was the 1959–1965 Maserati 5000 GT luxury coupe, of which only 34 cars were produced. The 5000 GT used a 4.9 L (299 cu in) overhead camshaft engine derived from the Maserati 450S racing car. Developments of this engine were used in the 1963–1969 Maserati Quattroporte I luxury sedan, the 1967–1973 Maserati Ghibli, the 1971–1978 Maserati Bora 2-seat coupe, and several other models.
The 1990–1996 Maserati Shamal 2+2 coupe introduced a 3.2 L (195 cu in) turbocharged V8 engine based on the existing Maserati Biturbo V6. This engine was later replaced by the naturally aspirated 4.2 L (256 cu in) Ferrari F136 V8 engine, beginning with the 2001 Maserati Coupé / Spyder.

Other Italian manufacturersDuring the 1920s and 1930s, Lancia produced a line of range-topping luxury cars powered by V8 engines: the 1922–1925 Lancia Trikappa, the 1928–1935 Lancia Dilambda, and the 1931–1939 Lancia Astura. The engines ranged in displacement from 2.6–4.6 L (159–281 cu in) and used unusually narrow V-angles of 14 to 24 degrees with a single overhead camshaft. In the 1980s, an engine derived from Ferrari's V8 engine was transverse mounted in the Lancia Thema 8.32.
The only Fiat car to use a V8 engine was the Fiat 8V, of which approximately 100 were produced 1952–1954. The 2.0 L (122 cu in) pushrod engine used an all-aluminium construction and an unusual V-angle of 70 degrees. Fiat also began production of V8 diesel truck engines for the 1975 Des-8280, initially in naturally aspirated form before switching to turbocharging in the mid-1980s.
Lamborghini's V8 powered models are the 1972–1979 Lamborghini Urraco 2+2 coupe, 1976–1979 Lamborghini Silhouette 2-seat convertible, and 1981–1988 Lamborghini Jalpa 2-seat convertible. The 2018-present Lamborghini Urus SUV uses a Volkswagen Group turbocharged V8 engine.


=== Japan ===

Japanese manufacturers have not been large producers of V8 engines for passenger cars, due to Japanese government road tax regulations that impose higher charges for engines that exceed 2.0 L (122 cu in). However several passenger cars have been produced with V8 engines to meet the needs of consumers, as well as for use in motor racing.

HondaHonda has never produced V8 engines for passenger vehicles. In the late 1990s, the company resisted considerable pressure from its American dealers for a V8 engine with American Honda reportedly sending one dealer a shipment of ""V8"" vegetable juice to silence them. The only Honda car sold with a V8 engine was the 1993–1998 Honda Crossroad SUV, which was a rebadged Land Rover Discovery Series I fitted with the Rover V8 engine.
In motor racing, the Honda Indy V8 was produced for the 2003–2011 IndyCar racing series and was the control engine for the 2006–2011 seasons. The engine was a 3.0–3.5 L (183–214 cu in) all-aluminium V8 with double overhead camshafts and a redline of 10,300 rpm redline. The 2006–2008 Honda Racing F1 Team used V8 engines, as mandated by Formula One regulations.

MitsubishiFrom 1999 to 2000, Mitsubishi briefly sold the Mitsubishi 8A8 engine, which was a 4.5 L (275 cu in) all-aluminium V8 engine with double overhead camshafts and direct injection. The engine was fitted to the Mitsubishi Proudia luxury sedan and Mitsubishi Dignity limousine, however financial pressures forced the company to discontinue sales of both these vehicles after only fifteen months.
NissanThe 1965–1989 Nissan Y engine is Nissan's first V8 engine, which uses a pushrod design and had a displacement of 4.0 L (244 cu in). Its main use was in the Nissan President limousine. The Y engine was replaced by the 1989–2001 Nissan VH engine, which is an all-aluminium construction with double overhead camshafts and displacements of 4.1–4.5 L (250–275 cu in). This was replaced by the Nissan VK engine in 2002, which remains in production to the present day. The VK engine is an all-aluminium construction with double overhead camshafts and displacements of 4.5–5.6 L (275–342 cu in).

ToyotaThe first mass-produced Japanese V8 engine was the Toyota V engine, which was introduced in the 1964 Toyota Crown Eight luxury car. The Toyota V engine was an all-aluminium construction, used a pushrod valvetrain and was produced until 1997. The Toyota UZ engine has double overhead camshafts and was produced 1989–2013, while the Toyota UR engine added direct injection and has been in production since 2006.
From 2006 to 2009, the Toyota Racing Formula One team cars were powered by 2.4 L (146 cu in) naturally aspirated engines, as mandated by the Formula One rules. These Toyota engines were also used by the Williams, Midland, and Jordan teams.


=== Korea ===
Hyundai's first passenger car V8 engine was the 1999–2009 Hyundai Omega engine, which was based on the Mitsubishi 8A8 engine (see above). The Omega engine was replaced by the Hyundai Tau engine, which is an all-aluminium construction with double overhead camshafts and has been produced from 2008-present.


=== Sweden ===
Koenigsegg initially used twin-supercharged versions of the Ford Modular V8 engine in its 2002–2004 Koenigsegg CC8S and 2004–2006 Koenigsegg CCR. The company switched to its own twin-supercharged engine for the 2006–2010 Koenigsegg CCX. A twin-turbocharged V8 engine was introduced in the 2011 Koenigsegg Agera and has been used on all models since.


=== Soviet Union ===

The 1958–1967 ZIL-111 limousine was among the first Soviet cars to be powered by a V8 engine. The engine was an all-aluminium construction with a pushrod valvetrain. Production of ZIL limousines powered by V8 engines continued until the ZIL-41047 was discontinued in 2002.
The 1959–1988 GAZ Chaika was powered by a 5.5 L (336 cu in) V8 engine with an all-aluminium construction and a pushrod valvetrain. This engine was also used in several limited edition models for the KGB.


=== United Kingdom ===
Aston MartinThe 1969–1972 Aston Martin DBS V8 coupe/convertible was Aston Martin's first V8 model. This engine was an all-aluminium construction with double overhead camshafts, and was used in several models up until 2000, when the Virage model was discontinued.
Production of V8-engined Aston Martin cars resumed in 2005 with a new generation of the Vantage, powered by the Jaguar AJ-V8 naturally aspirated V8 engine. Since 2016, Aston Martin has switched to the Mercedes-Benz M177 turbocharged V8 engine, beginning with the DB11 model.
McLarenEvery McLaren road car since the brand's 2010 relaunch has been powered by the McLaren M838T twin-turbocharged V8 engine, which was introduced in the McLaren 12C (then called the 'MP4-12C') coupe. This engine is an all-aluminium construction with double overhead camshafts and a flat-plane crankshaft.

Rolls-Royce
The first V8 engine to be produced in the United Kingdom was fitted to the 1905 Rolls-Royce V-8, of which 3 cars were produced. This engine used a side valve design, a V-angle of 90 degrees and had a displacement of 3.5 L (214 cu in).
Mass-production of V8 engines began in 1959 with the release of the Rolls-Royce–Bentley L-series V8 engine in the Rolls-Royce Silver Cloud II, the Rolls-Royce Phantom IV, and the Bentley S2. This engine is an all-aluminium construction with a pushrod valvetrain and a V-angle of 90 degrees. It has been produced in displacements of 5.2–7.4 L (317–452 cu in), with a twin-turbocharged version introduced in 1985. The L-series V8 engine remains in production in the Bentley Mulsanne luxury sedan.
RoverRover began production of automotive V8 engines in 1967 with the Rover V8 engine. This engine used the design and tooling of the Buick V8 engine purchased from General Motors. The Rover V8 is an all-aluminium construction with a pushrod valvetrain, displacements of 4–5 L (215–305 cu in) and a V-angle of 90 degrees. It was used in various automobiles by Rover, Land Rover, and MG.
Production continued until 2006, when it was largely replaced by the Jaguar AJ-V8 engine.

Other U.K. manufacturersThe Daimler V8 engine was introduced in the 1959 Daimler SP250 sports car and was produced until 1969. This engine has an iron block, an alloy cylinder head, a pushrod drivetrain and was produced in displacements of 2.5–4.5 L (153–275 cu in).
The Jaguar AJ-V8 engine— Jaguar's first V8 engine for road cars— has been in production since 1996. This engine is an all-aluminium construction with double overhead camshafts. It has been produced in both naturally aspirated and supercharged configurations.
Land Rover and Range Rover produced vehicles fitted with the Rover V8 naturally aspirated petrol engine 1970–2004, the Ford TDV8 turbocharged diesel engine 2007–2012, the BMW M62 naturally aspirated petrol engine 2002–2006, the Jaguar AJ-V8 from petrol engine (in both naturally aspirated and supercharged configurations) from 2006-present and the Ford 4.4 Turbo Diesel engine from 2010-present.
The 1970–1977 Triumph V8 was used solely for the Triumph Stag coupe. This engine had a cast iron block, an aluminium cylinder head, single overhead camshafts and a displacement of 3.0 L (183 cu in).
The 1996–2003 TVR Speed Eight engine was used in the Chimera road cars and the Tuscan Challenge racing cars. This engine had an all-aluminium construction, single overhead camshafts, a flat-plane crankshaft and an unusual V-angle of 75 degrees.


=== United States ===

The first automotive V8 engine to reach production was the 1914–1935 Cadillac L-Head engine introduced in the Type 51. The L-head had an alloy crankcase, a single iron casting for each cylinder block and head, side valves, a flat-plane crankshaft and a displacement of 5.1 L (314 cu in). An electric starter motor was used, eliminating the large engines being difficult to start with hand-cranking. The Cadillac engine was followed by a V8 model from Peerless (using an engine manufactured by an amusement park manufacturer) in 1915.The first American V8 production engine with overhead valves (a 'pushrod' engine) was used by the 1917 Chevrolet Series D. This engine used a counterweighted crankshaft, a detachable crossflow cylinder head, and had a displacement of 4.7 L (288 cu in). Production of the Series D models ceased in 1918, Chevrolet did not produce another V8 engine until 1955.
The 1924 Cadillac Type V-63 was powered by the first American V8 to use a cross-plane crankshaft, which reduced vibrations. A year later, Peerless also introduced a cross-plane crankshaft V8. Other manufacturers producing V8 engines by the mid-1920s included Lincoln, Ferro, Northway (supplier to Cadillac), Cole (Indianapolis and Mississippi), Perkins (Detroit), Murray, Vernon, and Yale.A significant development in providing V8 engines in more affordable cars was the 1932–1954 Ford Flathead V8. The Flathead V8 reduced production costs by using a monobloc (or ""en block"") construction, where each cylinder bank is made from a single piece of cast metal. The engine was fitted to the low cost Ford Model 18 car, offering superior performance to its competitors.Demand for larger cars increased in the years following World War II and the wider bodies were well suited to the fitment of V8 engines. This led to many manufacturers introducing overhead valve V8 engines, such as the 1949–1964 Oldsmobile Rocket engine, the 1949–1962 Cadillac 331 engine, the 1951–1958 Chrysler Firepower engine, the Studebaker's 1952 V8 engine, the 1953–1966 Buick Nailhead engine, the 1954–2002 Chevrolet small-block engine, the 1954–1963 Lincoln Y-block V8 engine, the 1955–1981 Pontiac V8 engine, and the 1956–1967 AMC Rambler engine.Engine displacements grew in conjunction with the expanding size of full-size cars through the 1950s to mid-1970s. This led to 'big block' engines such as:

7.0 L (428 cu in) Ford FE engine released in 1956
6.0 L (368 cu in) Lincoln Y-block engine released in 1956
6.9 L (421 cu in) Pontiac Super Duty engine released in 1961
7.0 L (426 cu in) Chrysler Hemi engine released in 1965
7.4 L (454 cu in) Chevrolet big-block engine released in 1970.The classification of 'big-block' or 'small-block' refers to the engine's external dimensions and is not necessarily indicative of the actual engine displacement. Engines with displacements between 6.0–6.6 L (366–403 cu in) have been classified as both small-block and big-block, depending on the particular manufacturer's range of engines. Big-block engines reached their zenith with the 8.2 L (500 cu in) Cadillac 500 engine used in the 1970 Cadillac Eldorado coupe. During the 1970s, due to the oil crises and the gradual tightening of emission-standards, big-block V8s were affected and as a result their use in passenger cars decreased as manufacturers began to phase them out for more efficient designs. 
Prior to the late 1970s, sharing of engines across General Motors' divisions was not commonplace. This enabled each division to have its own unique engine character, but made for much duplication of effort. The company has since implemented sharing of engines across divisions, however some divisions (such as Cadillac) still maintain some engines specific to their division. Ford and Chrysler had fewer divisions, and favoured brand-specific shared designs.
In 2011 GM built its 100-millionth unit of the Chevrolet small-block engine, making that engine family the most produced V8 engine in the world.American manufacturers continue to produce large displacement V8 engines, despite the strategy of downsizing engines (often in conjunction with turbocharging) being adopted by many European and Asian manufacturers. These engines continued to use pushrod (overhead valve) valvetrains long after most overseas engines had switched to dual overhead camshaft designs. Examples include the 6.4 L (392 cu in) Chrysler Apache engine produced from 2011-present, the 7.3 L (445 cu in) Ford Godzilla engine produced from 2020-present, and the 6.6 L (401 cu in) Chevrolet L8T engine produced from 2020-present.Cadillac's Cadillac LTA engine codenamed ""Blackwing"" developed, hand built, and exclusively used by Cadillac on its mid-range vehicles sporty sedans and coupes employs a turbocharged 4.2 L (256 cu in) configuration with double overhead camshaft valve train, marking the first time in the brand's 100-plus-year history that a twin-turbo charged V8 unit is used.


=== Motorsport ===

V8 engines have been used in many forms of motorsport, from Formula One, IndyCar and NASCAR circuit racing, to Top Fuel drag racing.

Formula OneAmong the first V8 Formula One cars to compete were the 1952 AFM entry and the 1954 Lancia D50, with a development of the latter powering Juan Manuel Fangio's 1956 car to victory in the driver's championship. The 1.5 L Formula One era of 1961–1965 included V8 engines from Ferrari, Coventry Climax, British Racing Motors (BRM), and Automobili Turismo e Sport (ATS). The driver's championships for the 1962, 1963, 1964, and 1965 seasons were won by drivers of V8-powered cars. Also, from 1962 to 1965, the top three manufacturers in each season's Constructor's Championship all predominantly used V8 engines in their cars. In 1966, the engine capacity limits were increased to 3.0 litres (or 1.5 litres with a supercharger), and 1966–1967 Constructor's Championships were won by cars powered by the Brabham-Repco V8 engine.
From 1968 to 1981, the Cosworth DFV V8 engine dominated Formula One racing. During this time, the Manufacturers' Championship was won by Cosworth DFV powered cars every season except 1975, 1976, 1977, and 1979, which were won by 12-cylinder Ferraris. After a very long period of dominance, the Cosworth DFV was eventually outpaced by turbocharged straight-four and V6 engines.
The next period of significant V8 usage in Formula One was from 2006 to 2013, when the rules mandated use of 2.4 L (146 cu in) naturally aspirated V8 engines (in order to reduce the power outputs being achieved by the previous 3.0 litre V10 engines). These were replaced by 1.6 litre turbocharged V6 engines for the 2014-present seasons.

NASCARAmerican premier stock car racing NASCAR series has been dominated by V8 engines since the its inaugural 1949 season.

Drag racingIn the American Top Fuel class of drag racing, V8 engines displacing 500 cu in (8 L) today produce outputs of over 7,000 kW (10,000 hp). and 10,000 N⋅m (7,400 lb⋅ft). The engines used in Top Fuel and Funny car drag racing are typically based on the aluminum-conversion Chrysler 426 Hemi engine and run on highly explosive nitromethane fuel.
Land speed record racingThe world's fastest non-jet-powered (i.e. piston-engine powered) wheeled land vehicle, the Speed Demon, which achieved a speed of 462.345 mph in 2017, is powered by an V8 engine based on the Chevrolet small-block engine design.

		


== Usage in airplanes ==

Several early aircraft engines used a V8 configuration, such as the French 1904 Antoinette engine and 1906 Buchet engines. During World War One, V8 aircraft engines included the French Renault 8G, the Spanish Hispano-Suiza 8, the British Sunbeam Arab, and the American Curtiss OX-5.
After this time, flat-eight engines became more commonplace than V8 engines due to their lighter crankshafts and better suitability to air cooling. One of the few remaining V8 airplane engines by World War Two was the German Argus As 10 inverted V8, which was air-cooled and used in several trainer as well as small utility aircraft.


== Usage in marine vessels ==

The V8 configuration is not commonly used in marine vessels, however several marine diesel V8 engines have been produced by companies such as Brons, Scania, and Yanmar.


== Usage in motorcycles ==
Motorcycles have rarely used V8 engines, with the few in existence being built for motor racing.
In 1907, Glen Curtiss set an unofficial world record of 136.36 mph (219.45 km/h) on a home-made 4.0 L (244 cu in) motorcycle. The Moto Guzzi V8 was a 499 cc (30.5 cu in) motorcycle used for Grand Prix racing from 1955 to 1957. The 1994 Morbidelli V8 was a 848 cc (51.7 cu in) concept motorcycle which did not reach production.


== See also ==
Flat-eight engine
Straight-eight engine
W8 engine


== References =="
"In automotive design, an FR, or front-engine, rear-wheel-drive layout is one where the engine is located at the front of the vehicle and driven wheels are located at the rear. This was the traditional automobile layout for most of the 20th century. Modern designs commonly use the front-engine, front-wheel-drive layout (FF). It is also used in high-floor buses and school buses 


== Front mid-engine, rear-wheel-drive layout ==

In automotive design, a front mid-engine, rear-wheel-drive layout (FMR) is one that places the engine in the front, with the rear wheels of vehicle being driven. In contrast to the front-engine, rear-wheel-drive layout (FR), the engine is pushed back far enough that its center of mass is to the rear of the front axle. This aids in weight distribution and reduces the moment of inertia, improving the vehicle's handling. The mechanical layout of an FMR is substantially the same as an FR car. Some models of the same vehicle can be classified as either FR or FMR depending on the length of the installed engine (e.g. 4-cylinder vs. 6-cylinder) and its centre of mass in relation to the front axle.


=== Characteristics ===
FMR cars are often characterized by a long hood and front wheels that are pushed forward to the corners of the vehicle, close to the front bumper. Grand tourers often have FMR layouts, as a rear engine would not leave much space for the rear seats.
FMR should also not be  confused with a ""front midships"" location of the engine, referring to the engine being located fully behind the front axle centerline, in which case a car meeting the above FMR center of mass definition could be classified as a FR layout instead. The V35 Nissan Skyline / Infiniti G35 / Nissan 350Z are FM cars.
FMR layout came standard in most pre–World War II, front-engine / rear-wheel-drive cars.


=== Gallery ===

		
		
		
		


== References =="
"In automotive design, an FR, or front-engine, rear-wheel-drive layout is one where the engine is located at the front of the vehicle and driven wheels are located at the rear. This was the traditional automobile layout for most of the 20th century. Modern designs commonly use the front-engine, front-wheel-drive layout (FF). It is also used in high-floor buses and school buses 


== Front mid-engine, rear-wheel-drive layout ==

In automotive design, a front mid-engine, rear-wheel-drive layout (FMR) is one that places the engine in the front, with the rear wheels of vehicle being driven. In contrast to the front-engine, rear-wheel-drive layout (FR), the engine is pushed back far enough that its center of mass is to the rear of the front axle. This aids in weight distribution and reduces the moment of inertia, improving the vehicle's handling. The mechanical layout of an FMR is substantially the same as an FR car. Some models of the same vehicle can be classified as either FR or FMR depending on the length of the installed engine (e.g. 4-cylinder vs. 6-cylinder) and its centre of mass in relation to the front axle.


=== Characteristics ===
FMR cars are often characterized by a long hood and front wheels that are pushed forward to the corners of the vehicle, close to the front bumper. Grand tourers often have FMR layouts, as a rear engine would not leave much space for the rear seats.
FMR should also not be  confused with a ""front midships"" location of the engine, referring to the engine being located fully behind the front axle centerline, in which case a car meeting the above FMR center of mass definition could be classified as a FR layout instead. The V35 Nissan Skyline / Infiniti G35 / Nissan 350Z are FM cars.
FMR layout came standard in most pre–World War II, front-engine / rear-wheel-drive cars.


=== Gallery ===

		
		
		
		


== References =="
"Google App Engine (often referred to as GAE or simply App Engine) is a Platform as a Service and cloud computing platform for developing and hosting web applications in Google-managed data centers. Applications are sandboxed and run across multiple servers. App Engine offers automatic scaling for web applications—as the number of requests increases for an application, App Engine automatically allocates more resources for the web application to handle the additional demand.Google App Engine primarily supports Go, PHP, Java, Python, Node.js, .NET, and Ruby applications, although it can also support other languages via ""custom runtimes"". The service is free up to a certain level of consumed resources and only in standard environment but not in flexible environment. Fees are charged for additional storage, bandwidth, or instance hours required by the application. It was first released as a preview version in April 2008 and came out of preview in September 2011.


== Supported features/restrictions ==


== Runtimes and framework ==
Google App Engine primarily supports Go, PHP, Java, Python, Node.js, .NET, and Ruby applications, although it can also support other languages via ""custom runtimes"".Python web frameworks that run on Google App Engine include Django, CherryPy, Pyramid, Flask, web2py and webapp2, as well as a custom Google-written webapp framework and several others designed specifically for the platform that emerged since the release. Any Python framework that supports the WSGI using the CGI adapter can be used to create an application; the framework can be uploaded with the developed application. Third-party libraries written in pure Python may also be uploaded.Google App Engine supports many Java standards and frameworks.  Core to this is the servlet 2.5 technology using the open-source Jetty Web Server, along with accompanying technologies such as JSP.  JavaServer Faces operates with some workarounds. A newer release of App Engine Standard Java in Beta supports Java8, Servlet 3.1 and Jetty9.
Though the integrated database, Google Cloud Datastore, may be unfamiliar to programmers, it is accessed and supported with JPA, JDO, and by the simple low-level API. There are several alternative libraries and frameworks you can use to model and map the data to the database such as Objectify,  Slim3 and Jello framework.The Spring Framework works with GAE. However, the Spring Security module (if used) requires workarounds.  Apache Struts 1 is supported, and Struts 2 runs with workarounds.The Django web framework and applications running on it can be used on App Engine with modification. Django-nonrel aims to allow Django to work with non-relational databases and the project includes support for App Engine.


=== Reliability and Support ===
All billed App Engine applications have a 99.95% uptime SLA.App Engine is designed in such a way that it can sustain multiple datacenter outages without any downtime. This resilience to downtime is shown by the statistic that the High Replication Datastore saw 0% downtime over a period of a year.Free support is offered in the App Engine Groups, Stack Overflow, Server Fault, and GitHub. However, assistance by a Google staff member is not guaranteed.
Paid support from Google engineers is offered as part of Premier Accounts.


=== Bulk downloading ===
SDK version 1.2.2 adds support for bulk downloads of data using Python. The open source Python projects gaebar, approcket, and gawsh also allow users to download and back up App Engine data. No method for bulk downloading data from GAE using Java currently exists.


=== Restrictions ===
Developers have read-only access to the filesystem on App Engine. Applications can use only virtual filesystems, like gae-filestore.
App Engine can only execute code called from an HTTP request (scheduled background tasks allow for self calling HTTP requests).
Users may upload arbitrary Python modules, but only if they are pure-Python; C and Pyrex modules are not supported.
Java applications may only use a subset (The JRE Class White List) of the classes from the JRE standard edition. This restriction does not exist with the App Engine Standard Java8 runtime.
A process started on the server to answer a request can't last more than 60 seconds (with the 1.4.0 release, this restriction does not apply to background jobs anymore).
Does not support sticky sessions (a.k.a. session affinity), only replicated sessions are supported including limitation of the amount of data being serialized and time for session serialization.


== Major differences ==


=== Differences with other application hosting ===
Compared to other scalable hosting services such as Amazon EC2, App Engine provides more infrastructure to make it easy to write scalable applications, but can only run a limited range of applications designed for that infrastructure.
App Engine's infrastructure removes many of the system administration and development challenges of building applications to scale to hundreds of requests per second and beyond. Google handles deploying code to a cluster, monitoring, failover, and launching application instances as necessary.
While other services let users install and configure nearly any *NIX compatible software, App Engine requires developers to use only its supported languages, APIs, and frameworks. Current APIs allow storing and retrieving data from the document-oriented Google Cloud Datastore database; making HTTP requests; sending e-mail; manipulating images; and caching. Google Cloud SQL can be used for App Engine applications requiring a relational MySQL compatible database backend.Per-day and per-minute quotas restrict bandwidth and CPU use, number of requests served, number of concurrent requests, and calls to the various APIs, and individual requests are terminated if they take more than 60 seconds or return more than 32MB of data.


=== Differences between SQL and GQL ===
Google App Engine's integrated Google Cloud Datastore database has a SQL-like syntax called ""GQL"". GQL does not support the Join statement. Instead, one-to-many and many-to-many relationships can be accomplished using ReferenceProperty().  This shared-nothing approach allows disks to fail without the system failing. Switching from a relational database to Cloud Datastore requires a paradigm shift for developers when modeling their data.


== Portability concerns ==
Developers worry that the applications will not be portable from App Engine and fear being locked into the technology. In response, there are a number of projects to create open-source back-ends for the various proprietary/closed APIs of app engine, especially the datastore.
AppScale, CapeDwarf and TyphoonAE are a few of the open source efforts.
AppScale automatically deploys and scales unmodified Google App Engine applications over popular public and private cloud systems and on-premises clusters. AppScale can run Python, Java, PHP, and Go applications on EC2, Google Compute Engine, Softlayer, Azure and other cloud vendors.
TyphoonAE can run Python App Engine applications on any cloud that support linux machines.
Web2py web framework offers migration between SQL Databases and Google App Engine, however it doesn't support several App Engine-specific features such as transactions and namespaces.Kubernetes is an open-source job control system invented by Google to abstract away the infrastructure so that open-source (e.g. Docker) containerized applications can run on many types of infrastructure, such as Amazon Web Services, Microsoft Azure, and others.  This is one of Google's answers to the portability concern.


== Backends ==
In Google I/O 2011, Google announced App Engine Backends, which are allowed to run continuously, and consume more memory. The Backend API was deprecated as of March 13, 2014 in favor of the Modules API.


== Google Cloud SQL ==
In Oct 2011, Google previewed a zero maintenance SQL database, which supports JDBC and DB-API. This service allows creating, configuring, and using relational databases with App Engine applications. Google Cloud SQL offers MySQL 5.5 and 5.6.


== Usage quotas ==
Google App Engine requires a Google account to get started, and an account may allow the developer to register up to 25 free applications and an unlimited number of paid applications.Google App Engine defines usage quotas for free applications. Extensions to these quotas can be requested, and application authors can pay for additional resources.


== See also ==


== References ==


== Bibliography ==


== External links ==
Official marketing page
Official website
Official Google Cloud Platform Blog
Release notes
Google App Engine - Run your web applications on Google's infrastructure - a technical talk by Google engineer Guido van Rossum atStanford University. (online video archive)

Benefits of adopting Google App Engine
Using an external database with Google App Engine
Java Frameworks and libraries supported
Web2py book -- online documentation -- Google App Engine deployment recipe
Google Cloud SQL Sample Projects
Google Cloud supports node.js
Appmd: Python development sample project. App Engine/django/Google Closure/Endpoints/Material design"
"Technology (""science of craft"", from Greek τέχνη, techne, ""art, skill, cunning of hand""; and -λογία, -logia) is the sum of techniques, skills, methods, and processes used in the production of goods or services or in the accomplishment of objectives, such as scientific investigation. Technology can be the knowledge of techniques, processes, and the like, or it can be embedded in machines to allow for operation without detailed knowledge of their workings. Systems (e.g. machines) applying technology by taking an input, changing it according to the system's use, and then producing an outcome are referred to as technology systems or technological systems.
The simplest form of technology is the development and use of basic tools. The prehistoric discovery of how to control fire and the later Neolithic Revolution increased the available sources of food, and the invention of the wheel helped humans to travel in and control their environment. Developments in historic times, including the printing press, the telephone, and the Internet, have lessened physical barriers to communication and allowed humans to interact freely on a global scale.
Technology has many effects. It has helped develop more advanced economies (including today's global economy) and has allowed the rise of a leisure class. Many technological processes produce unwanted by-products known as pollution and deplete natural resources to the detriment of Earth's environment. Innovations have always influenced the values of a society and raised new questions in the ethics of technology. Examples include the rise of the notion of efficiency in terms of human productivity, and the challenges of bioethics.
Philosophical debates have arisen over the use of technology, with disagreements over whether technology improves the human condition or worsens it. Neo-Luddism, anarcho-primitivism, and similar reactionary movements criticize the pervasiveness of technology, arguing that it harms the environment and alienates people; proponents of ideologies such as transhumanism and techno-progressivism view continued technological progress as beneficial to society and the human condition.


== Definition and usage ==

The use of the term ""technology"" has changed significantly over the last 200 years. Before the 20th century, the term was uncommon in English, and it was used either to refer to the description or study of the useful arts or to allude to technical education, as in the Massachusetts Institute of Technology (chartered in 1861).The term ""technology"" rose to prominence in the 20th century in connection with the Second Industrial Revolution. The term's meanings changed in the early 20th century when American social scientists, beginning with Thorstein Veblen, translated ideas from the German concept of Technik into ""technology."" In German and other European languages, a distinction exists between technik and technologie that is absent in English, which usually translates both terms as ""technology."" By the 1930s, ""technology"" referred not only to the study of the industrial arts but to the industrial arts themselves.In 1937, the American sociologist Read Bain wrote that ""technology includes all tools, machines, utensils, weapons, instruments, housing, clothing, communicating and transporting devices and the skills by which we produce and use them."" Bain's definition remains common among scholars today, especially social scientists.  Scientists and engineers usually prefer to define technology as applied science, rather than as the things that people make and use. More recently, scholars have borrowed from European philosophers of ""technique"" to extend the meaning of technology to various forms of instrumental reason, as in Foucault's work on technologies of the self (techniques de soi).
Dictionaries and scholars have offered a variety of definitions. The Merriam-Webster Learner's Dictionary offers a definition of the term: ""the use of science in industry, engineering, etc., to invent useful things or to solve problems"" and ""a machine, piece of equipment, method, etc., that is created by technology."" Ursula Franklin, in her 1989 ""Real World of Technology"" lecture, gave another definition of the concept; it is ""practice, the way we do things around here."" The term is often used to imply a specific field of technology, or to refer to high technology or just consumer electronics, rather than technology as a whole. Bernard Stiegler, in Technics and Time, 1, defines technology in two ways: as ""the pursuit of life by means other than life,"" and as ""organized inorganic matter.""Technology can be most broadly defined as the entities, both material and immaterial, created by the application of mental and physical effort in order to achieve some value. In this usage, technology refers to tools and machines that may be used to solve real-world problems. It is a far-reaching term that may include simple tools, such as a crowbar or wooden spoon, or more complex machines, such as a space station or particle accelerator. Tools and machines need not be material; virtual technology, such as computer software and business methods, fall under this definition of technology. W. Brian Arthur defines technology in a similarly broad way as ""a means to fulfill a human purpose.""The word ""technology"" can also be used to refer to a collection of techniques. In this context, it is the current state of humanity's knowledge of how to combine resources to produce desired products, to solve problems, fulfill needs, or satisfy wants; it includes technical methods, skills, processes, techniques, tools and raw materials. When combined with another term, such as ""medical technology"" or ""space technology,"" it refers to the state of the respective field's knowledge and tools. ""State-of-the-art technology"" refers to the high technology available to humanity in any field.

Technology can be viewed as an activity that forms or changes culture. Additionally, technology is the application of mathematics, science, and the arts for the benefit of life as it is known. A modern example is the rise of communication technology, which has lessened barriers to human interaction and as a result has helped spawn new subcultures; the rise of cyberculture has at its basis the development of the Internet and the computer. Not all technology enhances culture in a creative way; technology can also help facilitate political oppression and war via tools such as guns. As a cultural activity, technology predates both science and engineering, each of which formalize some aspects of technological endeavor.


== Science, engineering, and technology ==

The distinction between science, engineering, and technology is not always clear. Science is systematic knowledge of the physical or material world gained through observation and experimentation. Technologies are not usually exclusively products of science, because they have to satisfy requirements such as utility, usability, and safety.Engineering is the goal-oriented process of designing and making tools and systems to exploit natural phenomena for practical human means, often (but not always) using results and techniques from science. The development of technology may draw upon many fields of knowledge, including scientific, engineering, mathematical, linguistic, and historical knowledge, to achieve some practical result.
Technology is often a consequence of science and engineering, although technology as a human activity precedes the two fields. For example, science might study the flow of electrons in electrical conductors by using already-existing tools and knowledge. This new-found knowledge may then be used by engineers to create new tools and machines such as semiconductors, computers, and other forms of advanced technology. In this sense, scientists and engineers may both be considered technologists; the three fields are often considered as one for the purposes of research and reference.The exact relations between science and technology, in particular, have been debated by scientists, historians, and policymakers in the late 20th century, in part because the debate can inform the funding of basic and applied science. In the immediate wake of World War II, for example, it was widely considered in the United States that technology was simply ""applied science"" and that to fund basic science was to reap technological results in due time. An articulation of this philosophy could be found explicitly in Vannevar Bush's treatise on postwar science policy, Science – The Endless Frontier: ""New products, new industries, and more jobs require continuous additions to knowledge of the laws of nature ... This essential new knowledge can be obtained only through basic scientific research."" In the late-1960s, however, this view came under direct attack, leading towards initiatives to fund science for specific tasks (initiatives resisted by the scientific community). The issue remains contentious, though most analysts resist the model that technology is a result of scientific research.


== History ==


=== Paleolithic (2.5 Ma – 10 ka) ===

The use of tools by early humans was partly a process of discovery and of evolution. Early humans evolved from a species of foraging hominids which were already bipedal, with a brain mass approximately one third of modern humans. Tool use remained relatively unchanged for most of early human history. Approximately 50,000 years ago, the use of tools and complex set of behaviors emerged, believed by many archaeologists to be connected to the emergence of fully modern language.


==== Stone tools ====

Hominids started using primitive stone tools millions of years ago. The earliest stone tools were little more than a fractured rock, but approximately 75,000 years ago, pressure flaking provided a way to make much finer work.


==== Fire ====

The discovery and use of fire, a simple energy source with many profound uses, was a turning point in the technological evolution of humankind. The exact date of its discovery is not known; evidence of burnt animal bones at the Cradle of Humankind suggests that the domestication of fire occurred before 1 Ma; scholarly consensus indicates that Homo erectus had controlled fire by between 500 and 400 ka. Fire, fueled with wood and charcoal, allowed early humans to cook their food to increase its digestibility, improving its nutrient value and broadening the number of foods that could be eaten.


==== Clothing and shelter ====
Other technological advances made during the Paleolithic era were clothing and shelter; the adoption of both technologies cannot be dated exactly, but they were a key to humanity's progress. As the Paleolithic era progressed, dwellings became more sophisticated and more elaborate; as early as 380 ka, humans were constructing temporary wood huts. Clothing, adapted from the fur and hides of hunted animals, helped humanity expand into colder regions; humans began to migrate
out of Africa by 200 ka and into other continents such as Eurasia.


=== Neolithic through classical antiquity (10 ka – 300 CE) ===

Human's technological ascent began in earnest in what is known as the Neolithic Period (""New Stone Age""). The invention of polished stone axes was a major advance that allowed forest clearance on a large scale to create farms. This use of polished stone axes increased greatly in the Neolithic, but were originally used in the preceding Mesolithic in some areas such as Ireland. Agriculture fed larger populations, and the transition to sedentism allowed simultaneously raising more children, as infants no longer needed to be carried, as nomadic ones must. Additionally, children could contribute labor to the raising of crops more readily than they could to the hunter-gatherer economy.With this increase in population and availability of labor came an increase in labor specialization. What triggered the progression from early Neolithic villages to the first cities, such as Uruk, and the first civilizations, such as Sumer, is not specifically known; however, the emergence of increasingly hierarchical social structures and specialized labor, of trade and war amongst adjacent cultures, and the need for collective action to overcome environmental challenges such as irrigation, are all thought to have played a role.


==== Metal tools ====
Continuing improvements led to the furnace and bellows and provided, for the first time, the ability to smelt and forge gold, copper, silver, and lead  – native metals found in relatively pure form in nature. The advantages of copper tools over stone, bone, and wooden tools were quickly apparent to early humans, and native copper was probably used from near the beginning of Neolithic times (about 10 ka). Native copper does not naturally occur in large amounts, but copper ores are quite common and some of them produce metal easily when burned in wood or charcoal fires. Eventually, the working of metals led to the discovery of alloys such as bronze and brass (about 4000 BCE). The first uses of iron alloys such as steel dates to around 1800 BCE.


==== Energy and transport ====

Meanwhile, humans were learning to harness other forms of energy. The earliest known use of wind power is the sailing ship; the earliest record of a ship under sail is that of a Nile boat dating to the 8th-millennium BCE. From prehistoric times, Egyptians probably used the power of the annual flooding of the Nile to irrigate their lands, gradually learning to regulate much of it through purposely built irrigation channels and ""catch"" basins. The ancient Sumerians in Mesopotamia used a complex system of canals and levees to divert water from the Tigris and Euphrates rivers for irrigation.

According to archaeologists, the wheel was invented around 4000 BCE probably independently and nearly simultaneously in Mesopotamia (in present-day Iraq), the Northern Caucasus (Maykop culture) and Central Europe. Estimates on when this may have occurred range from 5500 to 3000 BCE with most experts putting it closer to 4000 BCE. The oldest artifacts with drawings depicting wheeled carts date from about 3500 BCE; however, the wheel may have been in use for millennia before these drawings were made. More recently, the oldest-known wooden wheel in the world was found in the Ljubljana marshes of Slovenia.The invention of the wheel revolutionized trade and war. It did not take long to discover that wheeled wagons could be used to carry heavy loads. The ancient Sumerians used the potter's wheel and may have invented it. A stone pottery wheel found in the city-state of Ur dates to around 3429 BCE, and even older fragments of wheel-thrown pottery have been found in the same area. Fast (rotary) potters' wheels enabled early mass production of pottery, but it was the use of the wheel as a transformer of energy (through water wheels, windmills, and even treadmills) that revolutionized the application of nonhuman power sources. The first two-wheeled carts were derived from travois and were first used in Mesopotamia and Iran in around 3000 BCE.The oldest known constructed roadways are the stone-paved streets of the city-state of Ur, dating to circa 4000 BCE and timber roads leading through the swamps of Glastonbury, England, dating to around the same time period. The first long-distance road, which came into use around 3500 BCE, spanned 1,500 miles from the Persian Gulf to the Mediterranean Sea, but was not paved and was only partially maintained. In around 2000 BCE, the Minoans on the Greek island of Crete built a fifty-kilometer (thirty-mile) road leading from the palace of Gortyn on the south side of the island, through the mountains, to the palace of Knossos on the north side of the island. Unlike the earlier road, the Minoan road was completely paved.


==== Plumbing ====

Ancient Minoan private homes had running water. A bathtub virtually identical to modern ones was unearthed at the Palace of Knossos. Several Minoan private homes also had toilets, which could be flushed by pouring water down the drain. The ancient Romans had many public flush toilets, which emptied into an extensive sewage system. The primary sewer in Rome was the Cloaca Maxima; construction began on it in the sixth century BCE and it is still in use today.The ancient Romans also had a complex system of aqueducts, which were used to transport water across long distances. The first Roman aqueduct was built in 312 BCE. The eleventh and final ancient Roman aqueduct was built in 226 CE. Put together, the Roman aqueducts extended over 450 kilometers, but less than seventy kilometers of this was above ground and supported by arches.


=== Medieval and modern history (300 CE – present) ===

Innovations continued through the Middle Ages with innovations such as silk-manufacture (introduced into Europe after centuries of development in Asia), the horse collar and horseshoes in the first few hundred years after the 5th-century fall of the Roman Empire. Medieval technology saw the use of simple machines (such as the lever, the screw, and the pulley) being combined to form more complicated tools, such as the wheelbarrow, windmills and clocks, and a system of universities developed and spread scientific ideas and practices. The Renaissance era produced many innovations, including the printing press (which facilitated the communication of knowledge), and technology became increasingly associated with science, beginning a cycle of mutual advancement. Advances in technology in this era allowed a more reliable supply of food, followed by the wider availability of consumer goods.

Starting in the United Kingdom in the 18th century, the Industrial Revolution was a period of great technological discovery, particularly in the areas of agriculture, manufacturing, mining, metallurgy, and transport, driven by the discovery of steam power and the widespread application of the factory system. Technology took another step in a second industrial revolution (c.  1870 to c.  1914) with the harnessing of electricity to allow such innovations as the electric motor, light bulb, and countless others. Scientific advances and the discovery of new concepts later allowed for powered flight and developments in medicine, chemistry, physics, and engineering. The rise in technology has led to skyscrapers and broad urban areas whose inhabitants rely on motors to transport them and their food supplies. Communication improved with the invention of the telegraph, telephone, radio and television. The late-19th and early-20th centuries saw a revolution in transportation with the invention of the airplane and automobile.

The 20th century brought a host of innovations. In physics, the discovery of nuclear fission has led to both nuclear weapons and nuclear power. Computers were invented and later miniaturized using transistors and integrated circuits. Information technology subsequently led to the birth in the 1980s of the Internet, which ushered in the current Information Age. Humans started to explore space with satellites (late 1950s, later used for telecommunication) and in manned missions (1960s) going all the way to the moon. In medicine, this era brought innovations such as open-heart surgery and later stem-cell therapy along with new medications and treatments.
Complex manufacturing and construction techniques and organizations are needed to make and maintain some of the newer technologies, and entire industries have arisen to support and develop succeeding generations of increasingly more complex tools. Modern technology increasingly relies on training and education – their designers, builders, maintainers, and users often require sophisticated general and specific training. Moreover, these technologies have become so complex that entire fields have developed to support them, including engineering, medicine, and computer science; and other fields have become more complex, such as construction, transportation, and architecture.


== Philosophy ==


=== Technicism ===
Generally, technicism is the belief in the utility of technology for improving human societies. Taken to an extreme, technicism ""reflects a fundamental attitude which seeks to control reality, to resolve all problems with the use of scientific–technological methods and tools."" In other words, human beings will someday be able to master all problems and possibly even control the future using technology. Some, such as Stephen V. Monsma, connect these ideas to the abdication of religion as a higher moral authority.


=== Optimism ===

Optimistic assumptions are made by proponents of ideologies such as transhumanism and singularitarianism, which view technological development as generally having beneficial effects for the society and the human condition. In these ideologies, technological development is morally good.
Transhumanists generally believe that the point of technology is to overcome barriers, and that what we commonly refer to as the human condition is just another barrier to be surpassed.
Singularitarians believe in some sort of ""accelerating change""; that the rate of technological progress accelerates as we obtain more technology, and that this will culminate in a ""Singularity"" after artificial general intelligence is invented in which progress is nearly infinite; hence the term. Estimates for the date of this Singularity vary, but prominent futurist Ray Kurzweil estimates the Singularity will occur in 2045.
Kurzweil is also known for his history of the universe in six epochs: (1) the physical/chemical epoch, (2) the life epoch, (3) the human/brain epoch, (4) the technology epoch, (5) the artificial intelligence epoch, and (6) the universal colonization epoch. Going from one epoch to the next is a Singularity in its own right, and a period of speeding up precedes it. Each epoch takes a shorter time, which means the whole history of the universe is one giant Singularity event.Some critics see these ideologies as examples of scientism and techno-utopianism and fear the notion of human enhancement and technological singularity which they support. Some have described Karl Marx as a techno-optimist.


=== Skepticism and critics ===

On the somewhat skeptical side are certain philosophers like Herbert Marcuse and John Zerzan, who believe that technological societies are inherently flawed. They suggest that the inevitable result of such a society is to become evermore technological at the cost of freedom and psychological health.
Many, such as the Luddites and prominent philosopher Martin Heidegger, hold serious, although not entirely, deterministic reservations about technology (see ""The Question Concerning Technology""). According to Heidegger scholars Hubert Dreyfus and Charles Spinosa, ""Heidegger does not oppose technology. He hopes to reveal the essence of technology in a way that 'in no way confines us to a stultified compulsion to push on blindly with technology or, what comes to the same thing, to rebel helplessly against it.' Indeed, he promises that 'when we once open ourselves expressly to the essence of technology, we find ourselves unexpectedly taken into a freeing claim.' What this entails is a more complex relationship to technology than either techno-optimists or techno-pessimists tend to allow.""Some of the most poignant criticisms of technology are found in what are now considered to be dystopian literary classics such as Aldous Huxley's Brave New World, Anthony Burgess's A Clockwork Orange, and George Orwell's Nineteen Eighty-Four. In Goethe's Faust, Faust selling his soul to the devil in return for power over the physical world is also often interpreted as a metaphor for the adoption of industrial technology. More recently, modern works of science fiction such as those by Philip K. Dick and William Gibson and films such as Blade Runner and Ghost in the Shell project highly ambivalent or cautionary attitudes toward technology's impact on human society and identity.
The late cultural critic Neil Postman distinguished tool-using societies from technological societies and from what he called ""technopolies,"" societies that are dominated by the ideology of technological and scientific progress to the exclusion or harm of other cultural practices, values, and world-views.Darin Barney has written about technology's impact on practices of citizenship and democratic culture, suggesting that technology can be construed as (1) an object of political debate, (2) a means or medium of discussion, and (3) a setting for democratic deliberation and citizenship. As a setting for democratic culture, Barney suggests that technology tends to make ethical questions, including the question of what a good life consists in, nearly impossible because they already give an answer to the question: a good life is one that includes the use of more and more technology.Nikolas Kompridis has also written about the dangers of new technology, such as genetic engineering, nanotechnology, synthetic biology, and robotics. He warns that these technologies introduce unprecedented new challenges to human beings, including the possibility of the permanent alteration of our biological nature. These concerns are shared by other philosophers, scientists and public intellectuals who have written about similar issues (e.g. Francis Fukuyama, Jürgen Habermas, William Joy, and Michael Sandel).Another prominent critic of technology is Hubert Dreyfus, who has published books such as On the Internet and What Computers Still Can't Do.
A more infamous anti-technological treatise is Industrial Society and Its Future, written by the Unabomber Ted Kaczynski and printed in several major newspapers (and later books) as part of an effort to end his bombing campaign of the techno-industrial infrastructure. There are also subcultures that disapprove of some or most technology, such as self-identified off-gridders.


=== Appropriate technology ===

The notion of appropriate technology was developed in the 20th century by thinkers such as E.F. Schumacher and Jacques Ellul to describe situations where it was not desirable to use very new technologies or those that required access to some centralized infrastructure or parts or skills imported from elsewhere. The ecovillage movement emerged in part due to this concern.


=== Optimism and skepticism in the 21st century ===
This section mainly focuses on American concerns even if it can reasonably be generalized to other Western countries. 

The inadequate quantity and quality of American jobs is one of the most fundamental economic challenges we face. [...] What's the linkage between technology and this fundamental problem?
In his article, Jared Bernstein, a Senior Fellow at the Center on Budget and Policy Priorities, questions the widespread idea that automation, and more broadly, technological advances, have mainly contributed to this growing labor market problem.
His thesis appears to be a third way between optimism and skepticism. Essentially, he stands for a neutral approach of the linkage between technology and American issues concerning unemployment and declining wages.
He uses two main arguments to defend his point.
First, because of recent technological advances, an increasing number of workers are losing their jobs. Yet, scientific evidence fails to clearly demonstrate that technology has displaced so many workers that it has created more problems than it has solved. Indeed, automation threatens repetitive jobs but higher-end jobs are still necessary because they complement technology and manual jobs that ""requires flexibility judgment and common sense"" remain hard to replace with machines. Second, studies have not shown clear links between recent technology advances and the wage trends of the last decades.
Therefore, according to Bernstein, instead of focusing on technology and its hypothetical influences on current American increasing unemployment and declining wages, one needs to worry more about ""bad policy that fails to offset the imbalances in demand, trade, income, and opportunity.""For people who use both the Internet and mobile devices in excessive quantities it is likely for them to experience fatigue and over exhaustion as a result of disruptions in their sleeping patterns. Continuous studies have shown that increased BMI and weight gain are associated with people who spend long hours online and not exercising frequently.  Heavy Internet use is also displayed in the school lower grades of those who use it in excessive amounts.  It has also been noted that the use of mobile phones whilst driving has increased the occurrence of road accidents — particularly amongst teen drivers. Statistically, teens reportedly have fourfold the number of road traffic incidents as those who are 20 years or older, and a very high percentage of adolescents write (81%) and read (92%) texts while driving. In this context, mass media and technology have a negative impact on people, on both their mental and physical health.


=== Complex technological systems ===
Thomas P. Hughes stated that because technology has been considered as a key way to solve problems, we need to be aware of its complex and varied characters to use it more efficiently. What is the difference between a wheel or a compass and cooking machines such as an oven or a gas stove? Can we consider all of them, only a part of them, or none of them as technologies?
Technology is often considered too narrowly; according to Hughes, ""Technology is a creative process involving human ingenuity"". This definition's emphasis on creativity avoids unbounded definitions that may mistakenly include cooking ""technologies,"" but it also highlights the prominent role of humans and therefore their responsibilities for the use of complex technological systems.
Yet, because technology is everywhere and has dramatically changed landscapes and societies, Hughes argues that engineers, scientists, and managers have often believed that they can use technology to shape the world as they want. They have often supposed that technology is easily controllable and this assumption has to be thoroughly questioned. For instance, Evgeny Morozov particularly challenges two concepts: ""Internet-centrism"" and ""solutionism."" Internet-centrism refers to the idea that our society is convinced that the Internet is one of the most stable and coherent forces. Solutionism is the ideology that every social issue can be solved thanks to technology and especially thanks to the internet. In fact, technology intrinsically contains uncertainties and limitations. According to Alexis Madrigal's review of Morozov's theory, to ignore it will lead to ""unexpected consequences that could eventually cause more damage than the problems they seek to address."" Benjamin R. Cohen and Gwen Ottinger also discussed the multivalent effects of technology.Therefore, recognition of the limitations of technology, and more broadly, scientific knowledge, is needed – especially in cases dealing with environmental justice and health issues. Ottinger continues this reasoning and argues that the ongoing recognition of the limitations of scientific knowledge goes hand in hand with scientists and engineers’ new comprehension of their role. Such an approach of technology and science ""[require] technical professionals to conceive of their roles in the process differently. [They have to consider themselves as] collaborators in research and problem solving rather than simply providers of information and technical solutions.""


== Other animal species ==

The use of basic technology is also a feature of other animal species apart from humans. These include primates such as chimpanzees, some dolphin communities, and crows. Considering a more generic perspective of technology as ethology of active environmental conditioning and control, we can also refer to animal examples such as beavers and their dams, or bees and their honeycombs.
The ability to make and use tools was once considered a defining characteristic of the genus Homo. However, the discovery of tool construction among chimpanzees and related primates has discarded the notion of the use of technology as unique to humans. For example, researchers have observed wild chimpanzees using tools for foraging: some of the tools used include leaf sponges, termite fishing probes, pestles and levers. West African chimpanzees also use stone hammers and anvils for cracking nuts, as do capuchin monkeys of Boa Vista, Brazil.


== Future technology ==

Theories of technology often attempt to predict the future of technology based on the high technology and science of the time. As with all predictions of the future, however, technology is uncertain.
In 2005, futurist Ray Kurzweil predicted that the future of technology would mainly consist of an overlapping ""GNR Revolution"" of genetics, nanotechnology and robotics, with robotics being the most important of the three.


== See also ==


== References ==


== Further reading ==

Ambrose, Stanley H. (2 March 2001). ""Paleolithic Technology and Human Evolution"" (PDF). Science. 291 (5509): 1748–53. Bibcode:2001Sci...291.1748A. doi:10.1126/science.1059487. PMID 11249821. Archived from the original (PDF) on 14 June 2007. Retrieved 10 March 2007.
Huesemann, M.H., and J.A. Huesemann (2011). Technofix: Why Technology Won’t Save Us or the Environment, New Society Publishers, ISBN 0-86571-704-4.
Kremer, Michael (1993). ""Population Growth and Technological Change: One Million B.C. to 1990"". Quarterly Journal of Economics. 108 (3): 681–716. doi:10.2307/2118405. JSTOR 2118405..
Kevin Kelly. What Technology Wants. New York, Viking Press, 14 October 2010, hardcover, 416 pages. ISBN 978-0-670-02215-1
Mumford, Lewis. (2010). Technics and Civilization. University of Chicago Press, ISBN 0-226-55027-3.
Rhodes, Richard. (2000). Visions of Technology: A Century of Vital Debate about Machines, Systems, and the Human World. Simon & Schuster, ISBN 0-684-86311-1.
Teich, A.H. (2008). Technology and the Future. Wadsworth Publishing, 11th edition, ISBN 0-495-57052-4.
Tooze, Adam, ""Democracy and Its Discontents"", The New York Review of Books, vol. LXVI, no. 10 (6 June 2019), pp. 52–53, 56–57.  ""Democracy has no clear answer for the mindless operation of bureaucratic and technological power.  We may indeed be witnessing its extension in the form of artificial intelligence and robotics.  Likewise, after decades of dire warning, the environmental problem remains fundamentally unaddressed.... Bureaucratic overreach and environmental catastrophe are precisely the kinds of slow-moving existential challenges that democracies deal with very badly.... Finally, there is the threat du jour:  corporations and the technologies they promote.""  (pp. 56–57.)
Wright, R.T. (2008). Technology. Goodheart-Wilcox Company, 5th edition, ISBN 1-59070-718-4."
"TCL Technology (originally an abbreviation for Telephone Communication Limited) is a Chinese multinational electronics company headquartered in Huizhou, Guangdong Province. It designs, develops, manufactures and sells products including television sets, mobile phones, air conditioners, washing machines, refrigerators and small electrical appliances. In 2010 it was the world's 25th-largest consumer electronics producer. Since 2015, it remains the third-largest television manufacturer by market share.TCL comprises four listed companies: TCL Technology which is listed on the Shenzhen Stock Exchange, and TCL Electronics Holdings, Ltd. (SEHK: 1070), TCL Communication Technology Holdings, Ltd.(former code SEHK: 2618; delisted in 2016), China Display Optoelectronics Technology Holdings Ltd. (SEHK: 334) and Tonly Electronics Holdings Ltd. (SEHK: 1249) which are listed on the Hong Kong Stock Exchange.TCL's corporate slogan is ""The Creative Life"".On 7 February 2020, TCL Corporation changed its name to TCL Technology.


== History ==
The company was founded in 1981 under the brand name TTK as an audio cassette manufacturer. In 1985, after being sued by TDK for intellectual property violation, the company changed its brand name to TCL by taking the initials from Telephone Communication Limited. After 30 years of development, TCL has rapidly developed to be the leader of China's electronic information industry. TCL Technology is one of China's largest enterprise groups of consumer electronics on global scale, which owns five listed companies: TCL Technology Group Corporation (SZSE:000100), TCL Electronics Holdings Limited (HKEX:1070), TCL Communication Technology Holdings Limited (HKEX:2618), China Display Optoelectronics Technology Holdings Limited (HKEX:334) and Tonly Electronics Holdings Limited (HKEX:1249), with major consumer products including color TVs, mobile phones, air conditioners, refrigerators, washing machines, small appliances and more. Additional unlisted industry groups formed by TCL include the System Technology Business Division, Techne Group, Emerging Business Group, Investment Group, Highly Information Industry, Financial Business Division and other business segments.On 19 September 2002, TCL announced the acquisition of all consumer electronics related assets of the former German company Schneider Rundfunkwerke AG, including the right to use its trademarks as Schneider, Dual, Albona, Joyce and Logix.In July 2003, TCL chairman Li Dongsheng formally announced a ""Dragon and Tiger Plan"" to establish two competitive TCL businesses in global markets (""Dragons"") and three leading businesses inside China (""Tigers"").In November 2003, TCL and Thomson SA of France announced the creation of a joint venture to produce televisions and DVD players worldwide. TCL took a 67 percent stake in the joint venture, with Thomson SA holding the rest of the shares, and it was agreed that televisions made by TCL-Thomson would be marketed under the TCL brand in Asia and the Thomson and RCA brands in Europe and North America.In April 2004, TCL and Alcatel announced the creation of a mobile phone manufacturing joint venture: Alcatel Mobile Phones. TCL injected 55 million euros in the venture in return for a 55 per cent shareholding.In April 2005 TCL closed its manufacturing plant in Türkheim, Bavaria. 120 former Schneider employees lost their jobs.
In May 2005, TCL announced that its Hong Kong-listed unit would acquire Alcatel's 45 per cent stake in their mobile-phone joint venture for consideration of HK$63.34 million ($8.1 million) worth of TCL Communication shares.In June 2007, TCL announced that its mobile phone division planned to cease using the Alcatel brand and switch entirely to the TCL brand within five years.In April 2008, Samsung Electronics announced that it would be outsourcing the production of some LCD TV modules to TCL.In July 2008, TCL announced that it planned to raise 1.7 billion yuan ($249 million) via a share placement on the Shenzhen Stock Exchange to fund the construction of two production lines for LCD televisions; one for screens of up to 42 inches, and the other for screens of up to 56 inches. TCL sold a total of 4.18 million LCD TV sets in 2008, more than triple the number during 2007.In January 2009, TCL announced plans to double its LCD TV production capacity to 10 million units by the end of 2009.In November 2009, TCL announced that it had formed a joint-venture with the Shenzhen government to construct an 8.5-generation thin film transistor-liquid crystal display production facility in the city at a cost of $3.9 billion.In March 2010, TCL Multimedia raised HK$525 million through the sale of shares on the Hong Kong Stock Exchange, in order to fund the development of its LCD and LED businesses and to generate working capital.In May 2011, TCL launched the China Smart Multimedia Terminal Technology Association in partnership with Hisense Electric Co. and Sichuan Changhong Electric Co., with the aim of helping to establish industry standards for smart televisions.In January 2013, TCL bought the naming rights for Grauman's Chinese Theatre for $5 million.

In 2014, TCL changed the meaning of its identifying initials from ""Telephone Communication Limited"" to a branding slogan, ""The Creative Life"", for commercial purposes.In February 2014, TCL spent 280 million RMB to purchase 11% shareholdings of Tianjin 712 Communication & Broadcasting Co., Ltd, a Chinese military-owned company which produces communication devices and navigation systems for the Chinese army.In August 2014, TCL Corporation and Tonly Electronics was implicated in bribing a government official in Guangdong province in exchange for government subsidies.
In October 2014, TCL acquired the Palm brand from HP for use on smartphones.In 2016, TCL reached an agreement with BlackBerry Limited to produce smartphones under the BlackBerry brand, under BlackBerry Mobile. This deal will cease on 31 August 2020.


== Operations ==
TCL is organized into five business divisions:
Multimedia: TV sets
Communications: cell phones and MIFI devices
Home Appliances: AC units and laundry machines
Home Electronics / Consumer Electronics: ODM products, like DVD, etc.
China Star Optoelectronics Technology (CSOT): display panels for TVIn addition it has four affiliated business areas:
Real estate and investment
Logistics and services
Online education
FinanceTCL has operations in more than 80 cities across Africa, Asia, Australasia, Europe, North America and South America. It has 18 R&D centers, 20 major manufacturing facilities and over 40 sales offices worldwide.TCL Corporation also has its own research facility called TCL Corporate Research, which is located at Shenzhen, China with the objective to research cutting-edge technology innovations for other subsidiaries.


== Products ==

TCL's primary products are TVs, DVD players, air conditioners, mobile phones, home appliances, electric lighting, and digital media.
It primarily sells its products under the following brand names:

TCL (in Africa, Asia, Australasia, Europe, North America, South America, and Russia (TV, air conditioners);
Alcatel and Thomson mobile phones (global)
BlackBerry (smartphones) global
RCA branded electrical products in the United States.The company, as of April 2012, is in venture with Swedish furniture giant IKEA to provide the consumer electronics behind the Uppleva integrated HDTV and entertainment system product.

Smartphones
In 2016, it contract manufactured the DTEK50 and DTEK60, for BlackBerry Limited, under their flagship BlackBerry brand. In December 2016, it became a licensee of the BlackBerry brand, to manufacture, distribute, and design devices for the global market. As of 2017, it distributes BlackBerry devices under the name of BlackBerry Mobile.

TCL is also the owner of the Palm brand. The company launched the Palm ""ultra-mobile companion"" smartphone in 2018.
In late 2019, TCL released their first own-branded Android phone, called the TCL Plex.TCL announced the 10 series for 2020, consisting of the TCL 10 SE, TCL 10L, TCL 10 Pro, TCL 10 Plus and TCL 10 5G.


== Streaming television service: GoLive TV ==
Since 2015, TCL offers its own video streaming service: GoLive TV or simply GoLive.


== References ==


== External links ==
TCL News and Updates
Official website 
Official website TCL (USA)"
"Information technology (IT) is the use of computers to store, retrieve, transmit, and manipulate data or information. IT is typically used within the context of business operations as opposed to personal or entertainment technologies. IT is considered to be a subset of information and communications technology (ICT). An information technology system (IT system) is generally an information system, a communications system or, more specifically speaking, a computer system – including all hardware, software and peripheral equipment – operated by a limited group of users.
Humans have been storing, retrieving, manipulating, and communicating information since the Sumerians in Mesopotamia developed writing in about 3000 BC, but the term information technology in its modern sense first appeared in a 1958 article published in the Harvard Business Review; authors Harold J. Leavitt and Thomas L. Whisler commented that ""the new technology does not yet have a single established name. We shall call it information technology (IT)."" Their definition consists of three categories: techniques for processing, the application of statistical and mathematical methods to decision-making, and the simulation of higher-order thinking through computer programs.The term is commonly used as a synonym for computers and computer networks, but it also encompasses other information distribution technologies such as television and telephones. Several products or services within an economy are associated with information technology, including computer hardware, software, electronics, semiconductors, internet, telecom equipment, and e-commerce.Based on the storage and processing technologies employed, it is possible to distinguish four distinct phases of IT development: pre-mechanical (3000 BC – 1450 AD), mechanical (1450–1840), electromechanical (1840–1940), and electronic (1940–present). This article focuses on the most recent period (electronic).


== History of computer technology ==

Devices have been used to aid computation for thousands of years, probably initially in the form of a tally stick. The Antikythera mechanism, dating from about the beginning of the first century BC, is generally considered to be the earliest known mechanical analog computer, and the earliest known geared mechanism. Comparable geared devices did not emerge in Europe until the 16th century, and it was not until 1645 that the first mechanical calculator capable of performing the four basic arithmetical operations was developed.Electronic computers, using either relays or valves, began to appear in the early 1940s. The electromechanical Zuse Z3, completed in 1941, was the world's first programmable computer, and by modern standards one of the first machines that could be considered a complete computing machine. Colossus, developed during the Second World War to decrypt German messages, was the first electronic digital computer. Although it was programmable, it was not general-purpose, being designed to perform only a single task. It also lacked the ability to store its program in memory; programming was carried out using plugs and switches to alter the internal wiring. The first recognisably modern electronic digital stored-program computer was the Manchester Baby, which ran its first program on 21 June 1948.The development of transistors in the late 1940s at Bell Laboratories allowed a new generation of computers to be designed with greatly reduced power consumption. The first commercially available stored-program computer, the Ferranti Mark I, contained 4050 valves and had a power consumption of 25 kilowatts. By comparison, the first transistorized computer developed at the University of Manchester and operational by November 1953, consumed only 150 watts in its final version.Several later breakthroughs in semiconductor technology include the integrated circuit (IC) invented by Jack Kilby at Texas Instruments and Robert Noyce at Fairchild Semiconductor in 1959, the metal-oxide-semiconductor field-effect transistor (MOSFET) invented by Mohamed Atalla and Dawon Kahng at Bell Laboratories in 1959, and the microprocessor invented by Ted Hoff, Federico Faggin, Masatoshi Shima and Stanley Mazor at Intel in 1971. These important inventions led to the development of the personal computer (PC) in the 1970s, and the emergence of information and communications technology (ICT).


== Electronic data processing ==


=== Data storage ===

Early electronic computers such as Colossus made use of punched tape, a long strip of paper on which data was represented by a series of holes, a technology now obsolete. Electronic data storage, which is used in modern computers, dates from World War II, when a form of delay line memory was developed to remove the clutter from radar signals, the first practical application of which was the mercury delay line. The first random-access digital storage device was the Williams tube, based on a standard cathode ray tube, but the information stored in it and delay line memory was volatile in that it had to be continuously refreshed, and thus was lost once power was removed. The earliest form of non-volatile computer storage was the magnetic drum, invented in 1932 and used in the Ferranti Mark 1, the world's first commercially available general-purpose electronic computer.IBM introduced the first hard disk drive in 1956, as a component of their 305 RAMAC computer system. Most digital data today is still stored magnetically on hard disks, or optically on media such as CD-ROMs. Until 2002 most information was stored on analog devices, but that year digital storage capacity exceeded analog for the first time. As of 2007 almost 94% of the data stored worldwide was held digitally: 52% on hard disks, 28% on optical devices and 11% on digital magnetic tape. It has been estimated that the worldwide capacity to store information on electronic devices grew from less than 3 exabytes in 1986 to 295 exabytes in 2007, doubling roughly every 3 years.


==== Databases ====

Database Management Systems (DMS) emerged in the 1960s to address the problem of storing and retrieving large amounts of data accurately and quickly. An early such systems was IBM's Information Management System (IMS), which is still widely deployed more than 50 years later. IMS stores data hierarchically, but in the 1970s Ted Codd proposed an alternative relational storage model based on set theory and predicate logic and the familiar concepts of tables, rows and columns. In 1981, the first commercially available relational database management system (RDBMS) was released by Oracle.All DMS consist of components, they allow the data they store to be accessed simultaneously by many users while maintaining its integrity. All databases are common in one point that the structure of the data they contain is defined and stored separately from the data itself, in a database schema.In recent years, the extensible markup language (XML) has become a popular format for data representation. Although XML data can be stored in normal file systems, it is commonly held in relational databases to take advantage of their ""robust implementation verified by years of both theoretical and practical effort"". As an evolution of the Standard Generalized Markup Language (SGML), XML's text-based structure offers the advantage of being both machine and human-readable.


=== Data retrieval ===
The relational database model introduced a programming-language independent Structured Query Language (SQL), based on relational algebra.
The terms ""data"" and ""information"" are not synonymous. Anything stored is data, but it only becomes information when it is organized and presented meaningfully. Most of the world's digital data is unstructured, and stored in a variety of different physical formats even within a single organization. Data warehouses began to be developed in the 1980s to integrate these disparate stores. They typically contain data extracted from various sources, including external sources such as the Internet, organized in such a way as to facilitate decision support systems (DSS).


=== Data transmission ===
Data transmission has three aspects: transmission, propagation, and reception. It can be broadly categorized as broadcasting, in which information is transmitted unidirectionally downstream, or telecommunications, with bidirectional upstream and downstream channels.XML has been increasingly employed as a means of data interchange since the early 2000s, particularly for machine-oriented interactions such as those involved in web-oriented protocols such as SOAP, describing ""data-in-transit rather than ... data-at-rest"".


=== Data manipulation ===
Hilbert and Lopez identify the exponential pace of technological change (a kind of Moore's law): machines' application-specific capacity to compute information per capita roughly doubled every 14 months between 1986 and 2007; the per capita capacity of the world's general-purpose computers doubled every 18 months during the same two decades; the global telecommunication capacity per capita doubled every 34 months; the world's storage capacity per capita required roughly 40 months to double (every 3 years); and per capita broadcast information has doubled every 12.3 years.Massive amounts of data are stored worldwide every day, but unless it can be analysed and presented effectively it essentially resides in what have been called data tombs: ""data archives that are seldom visited"". To address that issue, the field of data mining – ""the process of discovering interesting patterns and knowledge from large amounts of data"" – emerged in the late 1980s.


== Perspectives ==


=== Academic perspective ===
In an academic context, the Association for Computing Machinery defines IT as ""undergraduate degree programs that prepare students to meet the computer technology needs of business, government, healthcare, schools, and other kinds of organizations .... IT specialists assume responsibility for selecting hardware and software products appropriate for an organization, integrating those products with organizational needs and infrastructure, and installing, customizing, and maintaining those applications for the organization’s computer users.""


=== Commercial and employment perspective ===
Companies in the information technology field are often discussed as a group as the ""tech sector"" or the ""tech industry"".Many companies now have IT departments for managing the computers, networks, and other technical areas of their businesses.
In a business context, the Information Technology Association of America has defined information technology as ""the study, design, development, application, implementation, support or management of computer-based information systems"". The responsibilities of those working in the field include network administration, software development and installation, and the planning and management of an organization's technology life cycle, by which hardware and software are maintained, upgraded and replaced.

		
		
		
		


=== Ethical perspectives ===

The field of information ethics was established by mathematician Norbert Wiener in the 1940s. Some of the ethical issues associated with the use of information technology include:
Breaches of copyright by those downloading files stored without the permission of the copyright holders
Employers monitoring their employees' emails and other Internet usage
Unsolicited emails
Hackers accessing online databases
Web sites installing cookies or spyware to monitor a user's online activities


== See also ==
Center for Minorities and People with Disabilities in Information Technology
Computing
Computer science
Data processing
Health information technology
Information and communications technology (ICT)
Information management
Journal of Cases on Information Technology
Knowledge society
List of the largest information technology companies
Outline of information technology
World Information Technology and Services Alliance


== References ==


=== Notes ===


=== Citations ===


=== Bibliography ===


== Further reading ==
Allen, T.; Morton, M. S. Morton, eds. (1994), Information Technology and the Corporation of the 1990s, Oxford University Press
Gitta, Cosmas and South, David (2011). Southern Innovator Magazine Issue 1: Mobile Phones and Information Technology: United Nations Office for South-South Cooperation. ISSN 2222-9280
Gleick, James (2011).The Information: A History, a Theory, a Flood. New York: Pantheon Books.
Price, Wilson T. (1981), Introduction to Computer Data Processing, Holt-Saunders International Editions, ISBN 978-4-8337-0012-2
Shelly, Gary, Cashman, Thomas, Vermaat, Misty, and Walker, Tim. (1999). Discovering Computers 2000: Concepts for a Connected World. Cambridge, Massachusetts: Course Technology.
Webster, Frank, and Robins, Kevin. (1986). Information Technology – A Luddite Analysis. Norwood, NJ: Ablex.


== External links ==
 Learning materials related to Information technology at Wikiversity
 Media related to Information technology at Wikimedia Commons
 Quotations related to Information technology at Wikiquote"
"Massachusetts Institute of Technology (MIT) is a private research university in Cambridge, Massachusetts. The institute is a land-grant, sea-grant, and space-grant university, with an urban campus that extends more than a mile (1.6 km) alongside the Charles River. The institute also encompasses a number of major off-campus facilities such as the MIT Lincoln Laboratory, the Bates Center, and the Haystack Observatory, as well as affiliated laboratories such as the Broad and Whitehead Institutes. Founded in 1861 in response to the increasing industrialization of the United States, MIT adopted a European polytechnic university model and stressed laboratory instruction in applied science and engineering. It has since played a key role in the development of many aspects of modern science, engineering, mathematics, and technology, and is widely known for its innovation and academic strength.As of October 2019, 96 Nobel laureates, 26 Turing Award winners, and 8 Fields Medalists have been affiliated with MIT as alumni, faculty members, or researchers. In addition, 58 National Medal of Science recipients, 29 National Medals of Technology and Innovation recipients, 50 MacArthur Fellows, 73 Marshall Scholars, 48 Rhodes Scholars, 41 astronauts, and 16 Chief Scientists of the U.S. Air Force have been affiliated with MIT. The school also has a strong entrepreneurial culture. MIT is a member of the Association of American Universities (AAU).


== History ==


=== Foundation and vision ===

In 1859, a proposal was submitted to the Massachusetts General Court to use newly filled lands in Back Bay, Boston for a ""Conservatory of Art and Science"", but the proposal failed. A charter for the incorporation of the Massachusetts Institute of Technology, proposed by William Barton Rogers, was signed by John Albion Andrew, the governor of Massachusetts, on April 10, 1861.Rogers, a professor from the University of Virginia, wanted to establish an institution to address rapid scientific and technological advances. He did not wish to found a professional school, but a combination with elements of both professional and liberal education, proposing that:

The true and only practicable object of a polytechnic school is, as I conceive, the teaching, not of the minute details and manipulations of the arts, which can be done only in the workshop, but the inculcation of those scientific principles which form the basis and explanation of them, and along with this, a full and methodical review of all their leading processes and operations in connection with physical laws.
The Rogers Plan reflected the German research university model, emphasizing an independent faculty engaged in research, as well as instruction oriented around seminars and laboratories.


=== Early developments ===

Two days after MIT was chartered, the first battle of the Civil War broke out. After a long delay through the war years, MIT's first classes were held in the Mercantile Building in Boston in 1865. The new institute was founded as part of the Morrill Land-Grant Colleges Act to fund institutions ""to promote the liberal and practical education of the industrial classes"" and was a land-grant school. In 1863 under the same act, the Commonwealth of Massachusetts founded the Massachusetts Agricultural College, which developed as the University of Massachusetts Amherst. In 1866, the proceeds from land sales went toward new buildings in the Back Bay.MIT was informally called ""Boston Tech"". The institute adopted the European polytechnic university model and emphasized laboratory instruction from an early date. Despite chronic financial problems, the institute saw growth in the last two decades of the 19th century under President Francis Amasa Walker. Programs in electrical, chemical, marine, and sanitary engineering were introduced, new buildings were built, and the size of the student body increased to more than one thousand.The curriculum drifted to a vocational emphasis, with less focus on theoretical science. The fledgling school still suffered from chronic financial shortages which diverted the attention of the MIT leadership. During these ""Boston Tech"" years, MIT faculty and alumni rebuffed Harvard University president (and former MIT faculty) Charles W. Eliot's repeated attempts to merge MIT with Harvard College's Lawrence Scientific School. There would be at least six attempts to absorb MIT into Harvard. In its cramped Back Bay location, MIT could not afford to expand its overcrowded facilities, driving a desperate search for a new campus and funding. Eventually, the MIT Corporation approved a formal agreement to merge with Harvard, over the vehement objections of MIT faculty, students, and alumni. However, a 1917 decision by the Massachusetts Supreme Judicial Court effectively put an end to the merger scheme.

In 1916, the MIT administration and the MIT charter crossed the Charles River on the ceremonial barge Bucentaur built for the occasion, to signify MIT's move to a spacious new campus largely consisting of filled land on a one-mile-long (1.6 km) tract along the Cambridge side of the Charles River. The neoclassical ""New Technology"" campus was designed by William W. Bosworth and had been funded largely by anonymous donations from a mysterious ""Mr. Smith"", starting in 1912. In January 1920, the donor was revealed to be the industrialist George Eastman of Rochester, New York, who had invented methods of film production and processing, and founded Eastman Kodak. Between 1912 and 1920, Eastman donated $20 million ($236.6 million in 2015 dollars) in cash and Kodak stock to MIT.In 1931 Stanislav Shumovsky enrolled. He later communicated much technical information on aviation to the Soviet Union. Other MIT spies sent other secrets about American technology, eventually including atomic bomb secrets.


=== Curricular reforms ===
In the 1930s, President Karl Taylor Compton and Vice-President (effectively Provost) Vannevar Bush emphasized the importance of pure sciences like physics and chemistry and reduced the vocational practice required in shops and drafting studios. The Compton reforms ""renewed confidence in the ability of the Institute to develop leadership in science as well as in engineering"". Unlike Ivy League schools, MIT catered more to middle-class families, and depended more on tuition than on endowments or grants for its funding. The school was elected to the Association of American Universities in 1934.Still, as late as 1949, the Lewis Committee lamented in its report on the state of education at MIT that ""the Institute is widely conceived as basically a vocational school"", a ""partly unjustified"" perception the committee sought to change. The report comprehensively reviewed the undergraduate curriculum, recommended offering a broader education, and warned against letting engineering and government-sponsored research detract from the sciences and humanities. The School of Humanities, Arts, and Social Sciences and the MIT Sloan School of Management were formed in 1950 to compete with the powerful Schools of Science and Engineering. Previously marginalized faculties in the areas of economics, management, political science, and linguistics emerged into cohesive and assertive departments by attracting respected professors and launching competitive graduate programs. The School of Humanities, Arts, and Social Sciences continued to develop under the successive terms of the more humanistically oriented presidents Howard W. Johnson and Jerome Wiesner between 1966 and 1980.


=== Defense research ===

MIT's involvement in military science surged during World War II. In 1941, Vannevar Bush was appointed head of the federal Office of Scientific Research and Development and directed funding to only a select group of universities, including MIT. Engineers and scientists from across the country gathered at MIT's Radiation Laboratory, established in 1940 to assist the British military in developing microwave radar. The work done there significantly affected both the war and subsequent research in the area. Other defense projects included gyroscope-based and other complex control systems for gunsight, bombsight, and inertial navigation under Charles Stark Draper's Instrumentation Laboratory; the development of a digital computer for flight simulations under Project Whirlwind; and high-speed and high-altitude photography under Harold Edgerton. By the end of the war, MIT became the nation's largest wartime R&D contractor (attracting some criticism of Bush), employing nearly 4000 in the Radiation Laboratory alone and receiving in excess of $100 million ($1.2 billion in 2015 dollars) before 1946. Work on defense projects continued even after then. Post-war government-sponsored research at MIT included SAGE and guidance systems for ballistic missiles and Project Apollo.

These activities affected MIT profoundly. A 1949 report noted the lack of ""any great slackening in the pace of life at the Institute"" to match the return to peacetime, remembering the ""academic tranquility of the prewar years"", though acknowledging the significant contributions of military research to the increased emphasis on graduate education and rapid growth of personnel and facilities. The faculty doubled and the graduate student body quintupled during the terms of Karl Taylor Compton, president of MIT between 1930 and 1948; James Rhyne Killian, president from 1948 to 1957; and Julius Adams Stratton, chancellor from 1952 to 1957, whose institution-building strategies shaped the expanding university. By the 1950s, MIT no longer simply benefited the industries with which it had worked for three decades, and it had developed closer working relationships with new patrons, philanthropic foundations and the federal government.In late 1960s and early 1970s, student and faculty activists protested against the Vietnam War and MIT's defense research. In this period MIT's various departments were researching helicopters, smart bombs and counterinsurgency techniques for the war in Vietnam as well as guidance systems for nuclear missiles. The Union of Concerned Scientists was founded on March 4, 1969 during a meeting of faculty members and students seeking to shift the emphasis on military research toward environmental and social problems. MIT ultimately divested itself from the Instrumentation Laboratory and moved all classified research off-campus to the MIT Lincoln Laboratory facility in 1973 in response to the protests. The student body, faculty, and administration remained comparatively unpolarized during what was a tumultuous time for many other universities. Johnson was seen to be highly successful in leading his institution to ""greater strength and unity"" after these times of turmoil. However six MIT students were sentenced to prison terms at this time and some former student leaders, such as Michael Albert and George Katsiaficas, are still indignant about MIT's role in military research and its suppression of these protests. (Richard Leacock's film, November Actions, records some of these tumultuous events.)
In the 1980s, there was more controversy at MIT over its involvement in SDI (space weaponry) and CBW (chemical and biological warfare) research. More recently, MIT's research for the military has included work on robots, drones and 'battle suits'.


=== Recent history ===

MIT has kept pace with and helped to advance the digital age. In addition to developing the predecessors to modern computing and networking technologies, students, staff, and faculty members at Project MAC, the Artificial Intelligence Laboratory, and the Tech Model Railroad Club wrote some of the earliest interactive computer video games like Spacewar! and created much of modern hacker slang and culture. Several major computer-related organizations have originated at MIT since the 1980s: Richard Stallman's GNU Project and the subsequent Free Software Foundation were founded in the mid-1980s at the AI Lab; the MIT Media Lab was founded in 1985 by Nicholas Negroponte and Jerome Wiesner to promote research into novel uses of computer technology; the World Wide Web Consortium standards organization was founded at the Laboratory for Computer Science in 1994 by Tim Berners-Lee; the OpenCourseWare project has made course materials for over 2,000 MIT classes available online free of charge since 2002; and the One Laptop per Child initiative to expand computer education and connectivity to children worldwide was launched in 2005.MIT was named a sea-grant college in 1976 to support its programs in oceanography and marine sciences and was named a space-grant college in 1989 to support its aeronautics and astronautics programs. Despite diminishing government financial support over the past quarter century, MIT launched several successful development campaigns to significantly expand the campus: new dormitories and athletics buildings on west campus; the Tang Center for Management Education; several buildings in the northeast corner of campus supporting research into biology, brain and cognitive sciences, genomics, biotechnology, and cancer research; and a number of new ""backlot"" buildings on Vassar Street including the Stata Center. Construction on campus in the 2000s included expansions of the Media Lab, the Sloan School's eastern campus, and graduate residences in the northwest. In 2006, President Hockfield launched the MIT Energy Research Council to investigate the interdisciplinary challenges posed by increasing global energy consumption.In 2001, inspired by the open source and open access movements, MIT launched OpenCourseWare to make the lecture notes, problem sets, syllabi, exams, and lectures from the great majority of its courses available online for no charge, though without any formal accreditation for coursework completed. While the cost of supporting and hosting the project is high, OCW expanded in 2005 to include other universities as a part of the OpenCourseWare Consortium, which currently includes more than 250 academic institutions with content available in at least six languages. In 2011, MIT announced it would offer formal certification (but not credits or degrees) to online participants completing coursework in its ""MITx"" program, for a modest fee. The ""edX"" online platform supporting MITx was initially developed in partnership with Harvard and its analogous ""Harvardx"" initiative. The courseware platform is open source, and other universities have already joined and added their own course content. In March 2009 the MIT faculty adopted an open-access policy to make its scholarship publicly accessible online.MIT has its own police force. Three days after the Boston Marathon bombing of April 2013, MIT Police patrol officer Sean Collier was fatally shot by the suspects Dzhokhar and Tamerlan Tsarnaev, setting off a violent manhunt that shut down the campus and much of the Boston metropolitan area for a day. One week later, Collier's memorial service was attended by more than 10,000 people, in a ceremony hosted by the MIT community with thousands of police officers from the New England region and Canada. On November 25, 2013, MIT announced the creation of the Collier Medal, to be awarded annually to ""an individual or group that embodies the character and qualities that Officer Collier exhibited as a member of the MIT community and in all aspects of his life"". The announcement further stated that ""Future recipients of the award will include those whose contributions exceed the boundaries of their profession, those who have contributed to building bridges across the community, and those who consistently and selflessly perform acts of kindness"".In September 2017, the school announced the creation of an artificial intelligence research lab called the MIT-IBM Watson AI Lab. IBM will spend $240 million over the next decade, and the lab will be staffed by MIT and IBM scientists. In October 2018 MIT announced that it would open a new Schwarzman College of Computing dedicated to the study of artificial intelligence, named after lead donor and The Blackstone Group CEO Stephen Schwarzman. The focus of the new college is to study not just AI, but interdisciplinary AI education, and how AI can be used in fields as diverse as history and biology. The cost of buildings and new faculty for the new college is expected to be $1 billion upon completion.Over the course of 20 years, MIT received approximately $800,000 via foundations controlled by Jeffrey Epstein, convicted sex offender charged with the sex trafficking and sexual abuse of minors. All of those gifts went either to the MIT Media Lab or to Professor Seth Lloyd. Both Lloyd and former Media Lab Director Joi Ito have made public statements apologizing to Jeffrey Epstein's victims and others for judgments made over a series of years. Ito resigned from his position as Media Lab Director and professor, but Lloyd did not. Lloyd has been placed on temporary leave and there have been several protests from the MIT community urging for his resignation.


== Campus ==

MIT's 166-acre (67.2 ha) campus in the city of Cambridge spans approximately a mile along the north side of the Charles River basin. The campus is divided roughly in half by Massachusetts Avenue, with most dormitories and student life facilities to the west and most academic buildings to the east. The bridge closest to MIT is the Harvard Bridge, which is known for being marked off in a non-standard unit of length – the smoot.The Kendall/MIT MBTA Red Line station is located on the northeastern edge of the campus, in Kendall Square. The Cambridge neighborhoods surrounding MIT are a mixture of high tech companies occupying both modern office and rehabilitated industrial buildings, as well as socio-economically diverse residential neighborhoods. In early 2016, MIT presented its updated Kendall Square Initiative to the City of Cambridge, with plans for mixed-use educational, retail, residential, startup incubator, and office space in a dense high-rise transit-oriented development plan. The MIT Museum will eventually be moved immediately adjacent to a Kendall Square subway entrance, joining the List Visual Arts Center on the eastern end of the campus.Each building at MIT has a number (possibly preceded by a W, N, E, or NW) designation and most have a name as well. Typically, academic and office buildings are referred to primarily by number while residence halls are referred to by name. The organization of building numbers roughly corresponds to the order in which the buildings were built and their location relative (north, west, and east) to the original center cluster of Maclaurin buildings. Many of the buildings are connected above ground as well as through an extensive network of tunnels, providing protection from the Cambridge weather as well as a venue for roof and tunnel hacking.MIT's on-campus nuclear reactor is one of the most powerful university-based nuclear reactors in the United States. The prominence of the reactor's containment building in a densely populated area has been controversial, but MIT maintains that it is well-secured. In 1999 Bill Gates donated US$20 million to MIT for the construction of a computer laboratory named the ""William H. Gates Building"", and designed by architect Frank Gehry. While Microsoft had previously given financial support to the institution, this was the first personal donation received from Gates.MIT Nano, also known as Building 12, is an interdisciplinary facility for nanoscale research. Its 100,000-square-foot (9,300 m2) cleanroom and research space, visible through expansive glass facades, is the largest research facility of its kind in the nation. With a cost of US$400 million, it is also one of the costliest buildings on campus. The facility also provides state-of-the-art nanoimaging capabilities with vibration damped imaging and metrology suites sitting atop a 5-million-pound (2,300,000 kg) slab of concrete underground.Other notable campus facilities include a pressurized wind tunnel for testing aerodynamic research, a towing tank for testing ship and ocean structure designs, and Alcator C-Mod, the largest fusion device operated by any university. MIT's campus-wide wireless network was completed in the fall of 2005 and consists of nearly 3,000 access points covering 9.4 million square feet (870,000 m2) of campus.In 2001, the Environmental Protection Agency sued MIT for violating the Clean Water Act and the Clean Air Act with regard to its hazardous waste storage and disposal procedures. MIT settled the suit by paying a $155,000 fine and launching three environmental projects. In connection with capital campaigns to expand the campus, the Institute has also extensively renovated existing buildings to improve their energy efficiency. MIT has also taken steps to reduce its environmental impact by running alternative fuel campus shuttles, subsidizing public transportation passes, and building a low-emission cogeneration plant that serves most of the campus electricity, heating, and cooling requirements.The MIT Police with state and local authorities, in the 2009–2011 period, have investigated reports of 12 forcible sex offenses, 6 robberies, 3 aggravated assaults, 164 burglaries, 1 case of arson, and 4 cases of motor vehicle theft on campus; affecting a community of around 22,000 students and employees.
MIT has substantial commercial real estate holdings in Cambridge on which it pays property taxes, plus an additional voluntary payment in lieu of taxes (PILOT) on academic buildings which are legally tax-exempt. As of 2017, it is the largest taxpayer in the city, contributing approximately 14% of the city's annual revenues. Holdings include Technology Square, parts of Kendall Square, and many properties in Cambridgeport and Area 4 neighboring the educational buildings. The land is held for investment purposes and potential long-term expansion.


=== Architecture ===

MIT's School of Architecture, now the School of Architecture and Planning, was the first in the United States, and it has a history of commissioning progressive buildings. The first buildings constructed on the Cambridge campus, completed in 1916, are sometimes called the ""Maclaurin buildings"" after Institute president Richard Maclaurin who oversaw their construction. Designed by William Welles Bosworth, these imposing buildings were built of reinforced concrete, a first for a non-industrial – much less university – building in the US. Bosworth's design was influenced by the City Beautiful Movement of the early 1900s and features the Pantheon-esque Great Dome housing the Barker Engineering Library. The Great Dome overlooks Killian Court, where graduation ceremonies are held each year. The friezes of the limestone-clad buildings around Killian Court are engraved with the names of important scientists and philosophers. The spacious Building 7 atrium at 77 Massachusetts Avenue is regarded as the entrance to the Infinite Corridor and the rest of the campus.Alvar Aalto's Baker House (1947), Eero Saarinen's MIT Chapel and Kresge Auditorium (1955), and I.M. Pei's Green, Dreyfus, Landau, and Wiesner buildings represent high forms of post-war modernist architecture. More recent buildings like Frank Gehry's Stata Center (2004), Steven Holl's Simmons Hall (2002), Charles Correa's Building 46 (2005), and Fumihiko Maki's Media Lab Extension (2009) stand out among the Boston area's classical architecture and serve as examples of contemporary campus ""starchitecture"". These buildings have not always been well received; in 2010, The Princeton Review included MIT in a list of twenty schools whose campuses are ""tiny, unsightly, or both"".


=== Housing ===

Undergraduates are guaranteed four-year housing in one of MIT's 10 undergraduate dormitories. Those living on campus can receive support and mentoring from live-in graduate student tutors, resident advisors, and faculty housemasters. Because housing assignments are made based on the preferences of the students themselves, diverse social atmospheres can be sustained in different living groups; for example, according to the Yale Daily News staff's The Insider's Guide to the Colleges, 2010, ""The split between East Campus and West Campus is a significant characteristic of MIT. East Campus has gained a reputation as a thriving counterculture."" MIT also has 5 dormitories for single graduate students and 2 apartment buildings on campus for married student families.MIT has an active Greek and co-op housing system, including thirty-six fraternities, sororities, and independent living groups (FSILGs). As of 2015, 98% of all undergraduates lived in MIT-affiliated housing; 54% of the men participated in fraternities and 20% of the women were involved in sororities. Most FSILGs are located across the river in Back Bay near where MIT was founded, and there is also a cluster of fraternities on MIT's West Campus that face the Charles River Basin. After the 1997 alcohol-related death of Scott Krueger, a new pledge at the Phi Gamma Delta fraternity, MIT required all freshmen to live in the dormitory system starting in 2002. Because FSILGs had previously housed as many as 300 freshmen off-campus, the new policy could not be implemented until Simmons Hall opened in that year.In 2013–2014, MIT abruptly closed and then demolished undergrad dorm Bexley Hall, citing extensive water damage that made repairs infeasible. In 2017, MIT shut down Senior House after a century of service as an undergrad dorm. That year, MIT administrators released data showing just 60% of Senior House residents had graduated in four years. Campus-wide, the four-year graduation rate is 84% (the cumulative graduation rate is significantly higher).


== Organization and administration ==

MIT is chartered as a non-profit organization and is owned and governed by a privately appointed board of trustees known as the MIT Corporation. The current board consists of 43 members elected to five-year terms, 25 life members who vote until their 75th birthday, 3 elected officers (President, Treasurer, and Secretary), and 4 ex officio members (the president of the alumni association, the Governor of Massachusetts, the Massachusetts Secretary of Education, and the Chief Justice of the Massachusetts Supreme Judicial Court). The board is chaired by Robert Millard, a co-founder of L-3 Communications Holdings. The Corporation approves the budget, new programs, degrees and faculty appointments, and elects the President to serve as the chief executive officer of the university and preside over the Institute's faculty. MIT's endowment and other financial assets are managed through a subsidiary called MIT Investment Management Company (MITIMCo). Valued at $16.4 billion in 2018, MIT's endowment was then the sixth-largest among American colleges and universities.MIT has five schools (Science, Engineering, Architecture and Planning, Management, and Humanities, Arts, and Social Sciences) and one college (Schwarzman College of Computing), but no schools of law or medicine. While faculty committees assert substantial control over many areas of MIT's curriculum, research, student life, and administrative affairs, the chair of each of MIT's 32 academic departments reports to the dean of that department's school, who in turn reports to the Provost under the President. The current president is L. Rafael Reif, who formerly served as provost under President Susan Hockfield, the first woman to hold the post.


== Academics ==
MIT is a large, highly residential, research university with a majority of enrollments in graduate and professional programs. The university has been accredited by the New England Association of Schools and Colleges since 1929. MIT operates on a 4–1–4 academic calendar with the fall semester beginning after Labor Day and ending in mid-December, a 4-week ""Independent Activities Period"" in the month of January, and the spring semester commencing in early February and ceasing in late May.MIT students refer to both their majors and classes using numbers or acronyms alone. Departments and their corresponding majors are numbered in the approximate order of their foundation; for example, Civil and Environmental Engineering is Course 1, while Linguistics and Philosophy is Course 24. Students majoring in Electrical Engineering and Computer Science (EECS), the most popular department, collectively identify themselves as ""Course 6"". MIT students use a combination of the department's course number and the number assigned to the class to identify their subjects; for instance, the introductory calculus-based classical mechanics course is simply ""8.01"" at MIT.


=== Undergraduate program ===
The four-year, full-time undergraduate program maintains a balance between professional majors and those in the arts and sciences, and has been dubbed ""most selective"" by U.S. News, admitting few transfer students and 6.7% of its applicants in the 2017–2018 admissions cycle. MIT offers 44 undergraduate degrees across its five schools. In the 2017–2018 academic year, 1,045 bachelor of science degrees (abbreviated ""SB"") were granted, the only type of undergraduate degree MIT now awards. In the 2011 fall term, among students who had designated a major, the School of Engineering was the most popular division, enrolling 63% of students in its 19 degree programs, followed by the School of Science (29%), School of Humanities, Arts, & Social Sciences (3.7%), Sloan School of Management (3.3%), and School of Architecture and Planning (2%). The largest undergraduate degree programs were in Electrical Engineering and Computer Science (Course 6–2), Computer Science and Engineering (Course 6–3), Mechanical Engineering (Course 2), Physics (Course 8), and Mathematics (Course 18).
All undergraduates are required to complete a core curriculum called the General Institute Requirements (GIRs). The Science Requirement, generally completed during freshman year as prerequisites for classes in science and engineering majors, comprises two semesters of physics, two semesters of calculus, one semester of chemistry, and one semester of biology. There is a Laboratory Requirement, usually satisfied by an appropriate class in a course major. The Humanities, Arts, and Social Sciences (HASS) Requirement consists of eight semesters of classes in the humanities, arts, and social sciences, including at least one semester from each division as well as the courses required for a designated concentration in a HASS division. Under the Communication Requirement, two of the HASS classes, plus two of the classes taken in the designated major must be ""communication-intensive"", including ""substantial instruction and practice in oral presentation"". Finally, all students are required to complete a swimming test; non-varsity athletes must also take four quarters of physical education classes.Most classes rely on a combination of lectures, recitations led by associate professors or graduate students, weekly problem sets (""p-sets""), and periodic quizzes or tests. While the pace and difficulty of MIT coursework has been compared to ""drinking from a fire hose"", the freshmen retention rate at MIT is similar to other research universities. The ""pass/no-record"" grading system relieves some pressure for first-year undergraduates. For each class taken in the fall term, freshmen transcripts will either report only that the class was passed, or otherwise not have any record of it. In the spring term, passing grades (A, B, C) appear on the transcript while non-passing grades are again not recorded. (Grading had previously been ""pass/no record"" all freshman year, but was amended for the Class of 2006 to prevent students from gaming the system by completing required major classes in their freshman year.) Also, freshmen may choose to join alternative learning communities, such as Experimental Study Group, Concourse, or Terrascope.In 1969, Margaret MacVicar founded the Undergraduate Research Opportunities Program (UROP) to enable undergraduates to collaborate directly with faculty members and researchers. Students join or initiate research projects (""UROPs"") for academic credit, pay, or on a volunteer basis through postings on the UROP website or by contacting faculty members directly. A substantial majority of undergraduates participate. Students often become published, file patent applications, and/or launch start-up companies based upon their experience in UROPs.In 1970, the then-Dean of Institute Relations, Benson R. Snyder, published The Hidden Curriculum, arguing that education at MIT was often slighted in favor of following a set of unwritten expectations and that graduating with good grades was more often the product of figuring out the system rather than a solid education. The successful student, according to Snyder, was the one who was able to discern which of the formal requirements were to be ignored in favor of which unstated norms. For example, organized student groups had compiled ""course bibles""—collections of problem-set and examination questions and answers for later students to use as references. This sort of gamesmanship, Snyder argued, hindered development of a creative intellect and contributed to student discontent and unrest.


=== Graduate program ===
MIT's graduate program has high coexistence with the undergraduate program, and many courses are taken by qualified students at both levels. MIT offers a comprehensive doctoral program with degrees in the humanities, social sciences, and STEM fields as well as professional degrees. The Institute offers graduate programs leading to academic degrees such as the Master of Science (which is abbreviated as SM at MIT), various Engineer's Degrees, Doctor of Philosophy (PhD), and Doctor of Science (ScD) and interdisciplinary graduate programs such as the MD-PhD (with Harvard Medical School) and a joint program in oceanography with Woods Hole Oceanographic Institution.Admission to graduate programs is decentralized; applicants apply directly to the department or degree program. More than 90% of doctoral students are supported by fellowships, research assistantships (RAs), or teaching assistantships (TAs).MIT awarded 1,547 master's degrees and 609 doctoral degrees in the academic year 2010–11. In the 2011 fall term, the School of Engineering was the most popular academic division, enrolling 45.0% of graduate students, followed by the Sloan School of Management (19%), School of Science (16.9%), School of Architecture and Planning (9.2%), Whitaker College of Health Sciences (5.1%), and School of Humanities, Arts, and Social Sciences (4.7%). The largest graduate degree programs were the Sloan MBA, Electrical Engineering and Computer Science, and Mechanical Engineering.


=== Rankings ===
MIT also places among the top five in many overall rankings of universities (see right) and rankings based on students' revealed preferences. For several years, U.S. News & World Report, the QS World University Rankings, and the Academic Ranking of World Universities have ranked MIT's School of Engineering first, as did the 1995 National Research Council report. In the same lists, MIT's strongest showings apart from in engineering are in computer science, the natural sciences, business, architecture, economics, linguistics, mathematics, and, to a lesser extent, political science and philosophy.Times Higher Education has recognized MIT as one of the world's ""six super brands"" on its World Reputation Rankings, along with Berkeley, Cambridge, Harvard, Oxford and Stanford. In 2019, it ranked 3rd among the universities around the world by SCImago Institutions Rankings. In 2017, the Times Higher Education World University Rankings rated MIT the #2 university for arts and humanities. MIT was ranked #7 in 2015 and #6 in 2017 of the Nature Index Annual Tables, which measure the largest contributors to papers published in 82 leading journals.


=== Collaborations ===

The university historically pioneered research and training collaborations between academia, industry and government.  In 1946, President Compton, Harvard Business School professor Georges Doriot, and Massachusetts Investor Trust chairman Merrill Grisswold founded American Research and Development Corporation, the first American venture-capital firm.  In 1948, Compton established the MIT Industrial Liaison Program. Throughout the late 1980s and early 1990s, American politicians and business leaders accused MIT and other universities of contributing to a declining economy by transferring taxpayer-funded research and technology to international – especially Japanese – firms that were competing with struggling American businesses. On the other hand, MIT's extensive collaboration with the federal government on research projects has led to several MIT leaders serving as presidential scientific advisers since 1940. MIT established a Washington Office in 1991 to continue effective lobbying for research funding and national science policy.The US Justice Department began an investigation in 1989, and in 1991 filed an antitrust suit against MIT, the eight Ivy League colleges, and eleven other institutions for allegedly engaging in price-fixing during their annual ""Overlap Meetings"", which were held to prevent bidding wars over promising prospective students from consuming funds for need-based scholarships. While the Ivy League institutions settled, MIT contested the charges, arguing that the practice was not anti-competitive because it ensured the availability of aid for the greatest number of students. MIT ultimately prevailed when the Justice Department dropped the case in 1994.

MIT's proximity to Harvard University (""the other school up the river"") has led to a substantial number of research collaborations such as the Harvard-MIT Division of Health Sciences and Technology and the Broad Institute. In addition, students at the two schools can cross-register for credits toward their own school's degrees without any additional fees. A cross-registration program between MIT and Wellesley College has also existed since 1969, and in 2002 the Cambridge–MIT Institute launched an undergraduate exchange program between MIT and the University of Cambridge. MIT also has a long term partnership with Imperial College London, for both student exchanges and research collaboration. More modest cross-registration programs have been established with Boston University, Brandeis University, Tufts University, Massachusetts College of Art and the School of the Museum of Fine Arts, Boston.MIT maintains substantial research and faculty ties with independent research organizations in the Boston area, such as the Charles Stark Draper Laboratory, the Whitehead Institute for Biomedical Research, and the Woods Hole Oceanographic Institution. Ongoing international research and educational collaborations include the Amsterdam Institute for Advanced Metropolitan Solutions (AMS Institute), Singapore-MIT Alliance, MIT-Politecnico di Milano, MIT-Zaragoza International Logistics Program, and projects in other countries through the MIT International Science and Technology Initiatives (MISTI) program.The mass-market magazine Technology Review is published by MIT through a subsidiary company, as is a special edition that also serves as an alumni magazine. The MIT Press is a major university press, publishing over 200 books and 30 journals annually, emphasizing science and technology as well as arts, architecture, new media, current events and social issues.


=== Libraries, collections and museums ===

The MIT library system consists of five subject libraries: Barker (Engineering), Dewey (Economics), Hayden (Humanities and Science), Lewis (Music), and Rotch (Arts and Architecture). There are also various specialized libraries and archives. The libraries contain more than 2.9 million printed volumes, 2.4 million microforms, 49,000 print or electronic journal subscriptions, and 670 reference databases. The past decade has seen a trend of increased focus on digital over print resources in the libraries. Notable collections include the Lewis Music Library with an emphasis on 20th and 21st-century music and electronic music, the List Visual Arts Center's rotating exhibitions of contemporary art, and the Compton Gallery's cross-disciplinary exhibitions. MIT allocates a percentage of the budget for all new construction and renovation to commission and support its extensive public art and outdoor sculpture collection.The MIT Museum was founded in 1971 and collects, preserves, and exhibits artifacts significant to the culture and history of MIT. The museum now engages in significant educational outreach programs for the general public, including the annual Cambridge Science Festival, the first celebration of this kind in the United States. Since 2005, its official mission has been, ""to engage the wider community with MIT's science, technology and other areas of scholarship in ways that will best serve the nation and the world in the 21st century"".


=== Research ===
MIT was elected to the Association of American Universities in 1934 and is classified among ""R1: Doctoral Universities – Very high research activity""; research expenditures totaled $952 million in 2017. The federal government was the largest source of sponsored research, with the Department of Health and Human Services granting $255.9 million, Department of Defense $97.5 million, Department of Energy $65.8 million, National Science Foundation $61.4 million, and NASA $27.4 million. MIT employs approximately 1300 researchers in addition to faculty. In 2011, MIT faculty and researchers disclosed 632 inventions, were issued 153 patents, earned $85.4 million in cash income, and received $69.6 million in royalties. Through programs like the Deshpande Center, MIT faculty leverage their research and discoveries into multi-million-dollar commercial ventures.In electronics, magnetic core memory, radar, single electron transistors, and inertial guidance controls were invented or substantially developed by MIT researchers. Harold Eugene Edgerton was a pioneer in high speed photography and sonar. Claude E. Shannon developed much of modern information theory and discovered the application of Boolean logic to digital circuit design theory. In the domain of computer science, MIT faculty and researchers made fundamental contributions to cybernetics, artificial intelligence, computer languages, machine learning, robotics, and cryptography. At least nine Turing Award laureates and seven recipients of the Draper Prize in engineering have been or are currently associated with MIT.Current and previous physics faculty have won eight Nobel Prizes, four Dirac Medals, and three Wolf Prizes predominantly for their contributions to subatomic and quantum theory. Members of the chemistry department have been awarded three Nobel Prizes and one Wolf Prize for the discovery of novel syntheses and methods. MIT biologists have been awarded six Nobel Prizes for their contributions to genetics, immunology, oncology, and molecular biology. Professor Eric Lander was one of the principal leaders of the Human Genome Project. Positronium atoms, synthetic penicillin, synthetic self-replicating molecules, and the genetic bases for Amyotrophic lateral sclerosis (also known as ALS or Lou Gehrig's disease) and Huntington's disease were first discovered at MIT. Jerome Lettvin transformed the study of cognitive science with his paper ""What the frog's eye tells the frog's brain"". Researchers developed a system to convert MRI scans into 3D printed physical models.In the domain of humanities, arts, and social sciences, as of October 2019 MIT economists have been awarded seven Nobel Prizes and nine John Bates Clark Medals. Linguists Noam Chomsky and Morris Halle authored seminal texts on generative grammar and phonology. The MIT Media Lab, founded in 1985 within the School of Architecture and Planning and known for its unconventional research, has been home to influential researchers such as constructivist educator and Logo creator Seymour Papert.Spanning many of the above fields, MacArthur Fellowships (the so-called ""Genius Grants"") have been awarded to 50 people associated with MIT. Five Pulitzer Prize–winning writers currently work at or have retired from MIT. Four current or former faculty are members of the American Academy of Arts and Letters.Allegations of research misconduct or improprieties have received substantial press coverage. Professor David Baltimore, a Nobel Laureate, became embroiled in a misconduct investigation starting in 1986 that led to Congressional hearings in 1991. Professor Ted Postol has accused the MIT administration since 2000 of attempting to whitewash potential research misconduct at the Lincoln Lab facility involving a ballistic missile defense test, though a final investigation into the matter has not been completed. Associate Professor Luk Van Parijs was dismissed in 2005 following allegations of scientific misconduct and found guilty of the same by the United States Office of Research Integrity in 2009.In 2019, Clarivate Analytics named 54 members of MIT's faculty to its list of ""Highly Cited Researchers"". That number places MIT 8th among the world's universities.


== Discoveries and innovation ==


=== Natural sciences ===
Oncogene – Robert Weinberg discovered genetic basis of human cancer.
Reverse transcription – David Baltimore independently isolated, in 1970 at MIT, two RNA tumor viruses: R-MLV and again RSV.
Thermal death time – Samuel Cate Prescott and William Lyman Underwood from 1895 to 1898. Done for canning of food. Applications later found useful in medical devices, pharmaceuticals, and cosmetics.


=== Computer and applied sciences ===
Akamai Technologies – Daniel Lewin and Tom Leighton discovered and developed a faster content delivery network and is one of the world's largest distributed computing platforms, responsible for serving between 15 and 30 percent of all web traffic.
Cryptography – MIT researchers Ron Rivest, Adi Shamir and Leonard Adleman developed one of the first practical public-key cryptosystems and started a company RSA (cryptosystem).
Digital circuits – Claude Shannon, while a master's degree student at MIT, developed the digital circuit design theory which paved the way for modern computers.
Electronic ink – developed by Joseph Jacobson at MIT Media Lab.
Emacs (text editor) – development began during the 1970s at the MIT AI Lab.
Flight recorder (black box) – Charles Stark Draper developed the black box at MIT's Instrumentation Laboratory. That lab later made the Apollo Moon landings possible through the Apollo Guidance Computer it designed for NASA.
GNU Project – Richard Stallman formally founded the free software movement in 1983 by launching the GNU Project at MIT.
Lisp (programming language) – John McCarthy invented lisp in 1958 while he was at MIT. McCarthy published its design in a paper in Communications of the ACM in 1960, entitled ""Recursive Functions of Symbolic Expressions and Their Computation by Machine, Part I"".
Lithium-ion battery efficiencies – Yet-Ming Chiang and his group at MIT showed a substantial improvement in the performance of lithium batteries by boosting the material's conductivity by doping it with aluminium, niobium and zirconium.
MIT OpenCourseWare – the OpenCourseWare movement started in 1999 when the University of Tübingen in Germany published videos of lectures online for its timms initiative (Tübinger Internet Multimedia Server). The OCW movement only took off, however, with the launch of MIT OpenCourseWare and the Open Learning Initiative at Carnegie Mellon University in October 2002. The movement was soon reinforced by the launch of similar projects at Yale, Utah State University, the University of Michigan and the University of California Berkeley.
Perdix micro-drone – autonomous drone that uses artificial intelligence to swarm with many other Perdix drones.
Project MAC – groundbreaking research in operating systems, artificial intelligence, and the theory of computation. DARPA funded project.
Radar – developed at MIT's Radiation Laboratory during World War II.
SKETCHPAD – invented by Ivan Sutherland at MIT (presented in his PhD thesis). It pioneered the way for human–computer interaction (HCI). Sketchpad is considered to be the ancestor of modern computer-aided design (CAD) programs as well as a major breakthrough in the development of computer graphics in general.
VisiCalc – first spreadsheet computer program for personal computers, originally released for the Apple II by VisiCorp. MIT alumni Dan Bricklin and Bob Frankston rented time sharing at night on an MIT mainframe computer (that cost $1/hr for use).
World Wide Web Consortium – founded in 1994 by Tim Berners-Lee, (W3C) is the main international standards organization for the World Wide Web
X Window System – pioneering architecture-independent system for graphical user interfaces that has been widely used for Unix and Linux systems.


=== Companies and entrepreneurship ===
MIT alumni and faculty have founded numerous companies, some of which are shown below:Analog Devices, 1965, co-founders Ray Stata, (SB, SM) and Matthew Lorber (SB)
BlackRock, 1988, co-founder Bennett Golub, (SB, SM, PhD)
Bose Corporation, 1964, founder Amar Bose (SB, PhD)
Buzzfeed, 2006, co-founder Jonah Peretti (SM)
Dropbox, 2007, founders Drew Houston (SB) and Arash Ferdowsi (drop-out)
E*Trade, 1982, co-founder William A. Porter (MBA)
Hewlett-Packard, 1939, co-founder William R. Hewlett (SM)
HuffPost, 2005, co-founder Jonah Peretti (SM)
Intel, 1968, co-founder Robert Noyce (PhD)
Koch Industries, 1940, founder Fred C. Koch (SB), sons William (SB, PhD), David (SB)
Qualcomm, 1985, co-founders Irwin M. Jacobs (SM, PhD) and Andrew Viterbi (SB, SM)
Raytheon, 1922, co-founder Vannevar Bush (DEng, Professor)
Renaissance Technologies, 1982, founder James Simons (SB)
Texas Instruments, 1930, founder Cecil Howard Green (SB, SM)
TSMC, 1987, founder Morris Chang (SB, SM)
VMware, 1998, co-founder Diane Greene (SM)
Zipcar, 2000, co-founder Robin Chase (MBA)


== Traditions and student activities ==

The faculty and student body place a high value on meritocracy and on technical proficiency. MIT has never awarded an honorary degree, nor does it award athletic scholarships, ad eundem degrees, or Latin honors upon graduation. However, MIT has twice awarded honorary professorships: to Winston Churchill in 1949 and Salman Rushdie in 1993.Many upperclass students and alumni wear a large, heavy, distinctive class ring known as the ""Brass Rat"". Originally created in 1929, the ring's official name is the ""Standard Technology Ring"". The undergraduate ring design (a separate graduate student version exists as well) varies slightly from year to year to reflect the unique character of the MIT experience for that class, but always features a three-piece design, with the MIT seal and the class year each appearing on a separate face, flanking a large rectangular bezel bearing an image of a beaver. The initialism IHTFP, representing the informal school motto ""I Hate This Fucking Place"" and jocularly euphemized as ""I Have Truly Found Paradise"", ""Institute Has The Finest Professors"", ""Institute of Hacks, Tomfoolery and Pranks"", ""It's Hard to Fondle Penguins"", and other variations, has occasionally been featured on the ring given its historical prominence in student culture.


=== Activities ===

MIT has over 500 recognized student activity groups, including a campus radio station, The Tech student newspaper, an annual entrepreneurship competition, and weekly screenings of popular films by the Lecture Series Committee. Less traditional activities include the ""world's largest open-shelf collection of science fiction"" in English, a model railroad club, and a vibrant folk dance scene. Students, faculty, and staff are involved in over 50 educational outreach and public service programs through the MIT Museum, Edgerton Center, and MIT Public Service Center.Fraternities and sororities provide a base of activities in addition to housing. Approximately 1,000 undergrads, 48% of men and 30% of women, participate in one of several dozen Greek Life men's, women's and co-ed chapters on the campus.The Independent Activities Period is a four-week-long ""term"" offering hundreds of optional classes, lectures, demonstrations, and other activities throughout the month of January between the Fall and Spring semesters. Some of the most popular recurring IAP activities are Autonomous Robot Design (course 6.270), Robocraft Programming (6.370), and MasLab competitions, the annual ""mystery hunt"", and Charm School. More than 250 students pursue externships annually at companies in the US and abroad.Many MIT students also engage in ""hacking"", which encompasses both the physical exploration of areas that are generally off-limits (such as rooftops and steam tunnels), as well as elaborate practical jokes. Recent high-profile hacks have included the abduction of Caltech's cannon, reconstructing a Wright Flyer atop the Great Dome, and adorning the John Harvard statue with the Master Chief's Mjölnir Helmet.


=== Athletics ===

MIT sponsors 31 varsity sports and has one of the three broadest NCAA Division III athletic programs. MIT participates in the NCAA's Division III, the New England Women's and Men's Athletic Conference, the New England Football Conference, NCAA's Division I Patriot League for women's crew, and the Collegiate Water Polo Association (CWPA) for Men's Water Polo. Men's crew competes outside the NCAA in the Eastern Association of Rowing Colleges (EARC). The intercollegiate sports teams, called the MIT Engineers won 22 Team National Championships, 42 Individual National Championships. MIT is the all-time Division III leader in producing Academic All-Americas (302) and rank second across all NCAA Divisions only behind the University of Nebraska. MIT Athletes won 13 Elite 90 awards and ranks first among NCAA Division III programs, and third among all divisions. In April 2009, budget cuts led to MIT eliminating eight of its 41 sports, including the mixed men's and women's teams in alpine skiing and pistol; separate teams for men and women in ice hockey and gymnastics; and men's programs in golf and wrestling.


== People ==


=== Students ===
MIT enrolled 4,602 undergraduates and 6,972 graduate students in 2018–2019. Women constituted 45 percent of undergraduate students. Undergraduate and graduate students came from all 50 US states as well as from 115 foreign countries.MIT received 20,075 applications for admission to the undergraduate Class of 2024: it admitted 1,457 (7.2 percent). In 2019, 29,114 applications were received for graduate and advanced degree programs across all departments; 3,670 were admitted (12.6 percent) and 2,312 enrolled (63 percent).The interquartile range on the SAT was 2090–2340 and 97 percent of students ranked in the top tenth of their high school graduating class. 97 percent of the Class of 2012 returned as sophomores; 82 percent of the Class of 2007 graduated within 4 years, and 93 percent (91 percent of the men and 95 percent of the women) graduated within 6 years.Undergraduate tuition and fees total $40,732 per student and annual expenses are estimated at $52,507 as of 2012. 62 percent of students received need-based financial aid in the form of scholarships and grants from federal, state, institutional, and external sources averaging $38,964 per student. Students were awarded a total of $102 million in scholarships and grants, primarily from institutional support ($84 million). The annual increase in expenses has led to a student tradition (dating back to the 1960s) of tongue-in-cheek ""tuition riots"".MIT has been nominally co-educational since admitting Ellen Swallow Richards in 1870. Richards also became the first female member of MIT's faculty, specializing in sanitary chemistry. Female students remained a small minority prior to the completion of the first wing of a women's dormitory, McCormick Hall, in 1963. Between 1993 and 2009 the proportion of women rose from 34 percent to 45 percent of undergraduates and from 20 percent to 31 percent of graduate students. As of 2009, women outnumbered men in Biology, Brain & Cognitive Sciences, Architecture, Urban Planning, and Biological Engineering.A number of student deaths in the late 1990s and early 2000s resulted in considerable media attention focussing on MIT's culture and student life. After the alcohol-related death of Scott Krueger in September 1997 as a new member at the Phi Gamma Delta fraternity, MIT began requiring all freshmen to live in the dormitory system. The 2000 suicide of MIT undergraduate Elizabeth Shin drew attention to suicides at MIT and created a controversy over whether MIT had an unusually high suicide rate. In late 2001 a task force's recommended improvements in student mental health services were implemented, including expanding staff and operating hours at the mental health center. These and later cases were significant as well because they sought to prove the negligence and liability of university administrators in loco parentis.


=== Faculty and staff ===

As of 2013, MIT had 1,030 faculty members. Faculty are responsible for lecturing classes, for advising both graduate and undergraduate students, and for sitting on academic committees, as well as for conducting original research. Between 1964 and 2009 a total of seventeen faculty and staff members affiliated with MIT won Nobel Prizes (thirteen of them in the latter 25 years). As of October 2019, 37 MIT faculty members, past or present, have won Nobel Prizes, the majority in Economics or Physics.As of October 2013, current faculty and teaching staff included 67 Guggenheim Fellows, 6 Fulbright Scholars, and 22 MacArthur Fellows. Faculty members who have made extraordinary contributions to their research field as well as the MIT community are granted appointments as Institute Professors for the remainder of their tenures.
A 1998 MIT study concluded that a systemic bias against female faculty existed in its School of Science, although the study's methods were controversial. Since the study, though, women have headed departments within the Schools of Science and of Engineering, and MIT has appointed several female vice-presidents, although allegations of sexism continue. Susan Hockfield, a molecular neurobiologist, served as MIT's president from 2004 to 2012 – the first woman to hold the post.Tenure issues have vaulted MIT into the national spotlight on several occasions. The 1984 dismissal of David F. Noble (a historian of technology) became a cause célèbre about the extent to which academics are granted freedom of speech after he published several books and papers critical of MIT's and other research universities' reliance upon financial support from corporations and the military. Former materials-science professor Gretchen Kalonji sued MIT in 1994, alleging that she was denied tenure because of sexual discrimination. Several years later, the lawsuit was settled with undisclosed payments and the establishment of a project to encourage women and minorities to seek faculty positions. In 1997 the Massachusetts Commission Against Discrimination issued a probable-cause finding supporting UMass Boston Professor James Jennings' allegations of racial discrimination after a senior faculty search committee in the Department of Urban Studies and Planning did not offer him reciprocal tenure.In 2006–2007, MIT's denial of tenure to African-American stem-cell scientist professor James Sherley reignited accusations of racism in the tenure process, eventually leading to a protracted public dispute with the administration, a brief hunger-strike, and the resignation of Professor Frank L. Douglas in protest. The Boston Globe reported on February 6, 2007: ""Less than half of MIT's junior faculty members are granted tenure. After Sherley was initially denied tenure, his case was examined three times before the university established that neither racial discrimination nor conflict of interest affected the decision. Twenty-one of Sherley's colleagues later issued a statement saying that the professor was treated fairly in tenure review.""MIT faculty members have often been recruited to lead other colleges and universities. Founding faculty-member Charles W. Eliot became president of Harvard University in 1869, a post he would hold for 40 years, during which he wielded considerable influence both on American higher education and on secondary education. MIT alumnus and faculty member George Ellery Hale played a central role in the development of the California Institute of Technology (Caltech), and other faculty members have been key founders of Franklin W. Olin College of Engineering in nearby Needham, Massachusetts.
As of 2014 former provost Robert A. Brown served as president of Boston University; former provost Mark Wrighton is chancellor of Washington University in St. Louis; former associate provost Alice Gast is president of Lehigh University; and former professor Suh Nam-pyo is president of KAIST. Former dean of the School of Science Robert J. Birgeneau was the chancellor of the University of California, Berkeley (2004–2013); former professor John Maeda was president of Rhode Island School of Design (RISD, 2008–2013); former professor David Baltimore was president of Caltech (1997–2006); and MIT alumnus and former assistant professor Hans Mark served as chancellor of the University of Texas system (1984–1992).
In addition, faculty members have been recruited to lead governmental agencies; for example, former professor Marcia McNutt is president of the National Academy of Sciences, urban studies professor Xavier de Souza Briggs served as the associate director of the White House Office of Management and Budget, and biology professor Eric Lander was a co-chair of the President's Council of Advisors on Science and Technology. In 2013, faculty member Ernest Moniz was nominated by President Obama and later confirmed as United States Secretary of Energy. Former professor Hans Mark served as Secretary of the Air Force from 1979 to 1981. Alumna and Institute Professor Sheila Widnall served as Secretary of the Air Force between 1993 and 1997, making her the first female Secretary of the Air Force and first woman to lead an entire branch of the US military in the Department of Defense.
As of 2017, MIT was the second-largest employer in the city of Cambridge. Based on feedback from employees, MIT was ranked #7 as a place to work, among US colleges and universities as of March 2013. Surveys cited a ""smart"", ""creative"", ""friendly"" environment, noting that the work-life balance tilts towards a ""strong work ethic"" but complaining about ""low pay"" compared to an industry position.


=== Notable alumni ===

Many of MIT's over 120,000 alumni have had considerable success in scientific research, public service, education, and business. As of October 2019, 39 MIT alumni have won the Nobel Prize, 47 have been selected as Rhodes Scholars, and 61 have been selected as Marshall Scholars.Alumni in American politics and public service include former Chairman of the Federal Reserve Ben Bernanke, former MA-1 Representative John Olver, former CA-13 Representative Pete Stark, Representative Thomas Massie, former National Economic Council chairman Lawrence H. Summers, and former Council of Economic Advisors chairman Christina Romer. MIT alumni in international politics include Foreign Affairs Minister of Iran Ali Akbar Salehi, Israeli Prime Minister Benjamin Netanyahu, President of Colombia Virgilio Barco Vargas, President of the European Central Bank Mario Draghi, former Governor of the Reserve Bank of India Raghuram Rajan, former British Foreign Minister David Miliband, former Greek Prime Minister Lucas Papademos, former UN Secretary General Kofi Annan, former Iraqi Deputy Prime Minister Ahmed Chalabi, former Minister of Education and Culture of The Republic of Indonesia Yahya Muhaimin, former Jordanian Minister of Education, Higher Education and Scientific Research & former Jordanian Minister of Energy and Mineral Resources Khaled Toukan. Alumni in sports have included Olympic fencing champion Johan Harmenberg.
MIT alumni founded or co-founded many notable companies, such as Intel, McDonnell Douglas, Texas Instruments, 3Com, Qualcomm, Bose, Raytheon, Apotex, Koch Industries, Rockwell International, Genentech, Dropbox, and Campbell Soup. According to the British newspaper, The Guardian, ""a survey of living MIT alumni found that they have formed 25,800 companies, employing more than three million people including about a quarter of the workforce of Silicon Valley. Those firms collectively generate global revenues of about $1.9 trillion (£1.2 trillion) a year"". If the companies founded by MIT alumni were a country, they would have the 11th highest GDP of any nation in the world.Prominent institutions of higher education have been led by MIT alumni, including the University of California system, Harvard University, New York Institute of Technology, Johns Hopkins University, Carnegie Mellon University, Tufts University, Rochester Institute of Technology, Rhode Island School of Design (RISD), New Jersey Institute of Technology, Northeastern University, Tel Aviv University, Lahore University of Management Sciences, Rensselaer Polytechnic Institute, Tecnológico de Monterrey, Purdue University, Virginia Polytechnic Institute, KAIST, and Quaid-e-Azam University. Berklee College of Music, the largest independent college of contemporary music in the world, was founded and led by MIT alumnus Lawrence Berk for more than three decades.
More than one third of the United States' manned spaceflights have included MIT-educated astronauts, more than any university excluding the United States service academies. Of the 12 people who have been on the Moon as of 2019, four graduated from MIT (among them Apollo 11 Lunar Module Pilot Buzz Aldrin). Alumnus and former faculty member Qian Xuesen led the Chinese nuclear weapons program and was instrumental in the PRC rocket program.Noted alumni in non-scientific fields include author Hugh Lofting, sculptor Daniel Chester French, guitarist Tom Scholz of the band Boston, the British BBC and ITN correspondent and political advisor David Walter, The New York Times columnist and Nobel Prize Winning economist Paul Krugman, The Bell Curve author Charles Murray, United States Supreme Court building architect Cass Gilbert, Pritzker Prize-winning architects I.M. Pei and Gordon Bunshaft.

		
		
		
		
		
		
		
		
		
		
		
		
		


== See also ==
The Coop, campus bookstore
Engineering
Glossary of engineering


== Notes ==


== References ==


=== Sources ===
Also see the bibliography maintained by MIT's Institute Archives & Special Collections and Written Works in MIT in popular culture.


== External links ==
Official website
 Texts on Wikisource:
""Massachusetts Institute of Technology"" . Collier's New Encyclopedia. 1921.
""Massachusetts Institute of Technology, The"". Encyclopedia Americana. 1920.
""Massachusetts Institute of Technology"" . The New Students Reference Work . 1914.
""Massachusetts Institute of Technology"". New International Encyclopedia. 1905.
Swain, George Fillmore (July 1900). ""Technical Education at the Massachusetts Institute of Technology"" . Popular Science Monthly. 57."
"This is a global list of largest technology companies by revenue, according to the Fortune Global 500. It shows companies identified by Fortune as being in the technology sector, ranked by total annual revenue. Other metrics not shown here, in particular market capitalization, are often used alternatively to define the size of a company.
The list includes companies whose primary business  activities are associated with technology industry which includes computer hardware, software, electronics, semiconductor, internet, telecom equipment, e-commerce and computer services. Note: This list shows only companies with annual revenues exceeding US$50 billion.


== Legend ==


== 2019 list ==
Companies are ranked by total revenues for their respective fiscal years ended on or before March 31, 2019. All data in the table is taken from the Fortune Global 500 list of technology sector companies for 2019 unless otherwise specified.
As of 2019, Fortune lists Amazon (revenue of $232.887 billion) in the retailing sector rather than the technology sector.


== 2018 list ==
Ranked by total revenues for respective fiscal years ended on or before March 31, 2018.


== See also ==
List of largest Internet companies
List of the largest software companies


== References ==


== External links ==
[1] − Fortune Global 500"
"Nanotechnology (or ""nanotech"") is  manipulation of matter on an atomic, molecular, and supramolecular scale. The earliest, widespread description of nanotechnology referred to the particular technological goal of precisely manipulating atoms and molecules for fabrication of macroscale products, also now referred to as molecular nanotechnology. A more generalized description of nanotechnology was subsequently established by the National Nanotechnology Initiative, which defined nanotechnology as the manipulation of matter with at least one dimension sized from 1 to 100 nanometers. This definition reflects the fact that quantum mechanical effects are important at this quantum-realm scale, and so the definition shifted from a particular technological goal to a research category inclusive of all types of research and technologies that deal with the special properties of matter which occur below the given size threshold. It is therefore common to see the plural form ""nanotechnologies"" as well as ""nanoscale technologies"" to refer to the broad range of research and applications whose common trait is size.
Nanotechnology as defined by size is naturally broad, including fields of science as diverse as surface science, organic chemistry, molecular biology, semiconductor physics, energy storage, engineering, microfabrication, and molecular engineering.  The associated research and applications are equally diverse, ranging from extensions of conventional device physics to completely new approaches based upon molecular self-assembly, from developing new materials with dimensions on the nanoscale to direct control of matter on the atomic scale.
Scientists currently debate the future implications of nanotechnology. Nanotechnology may be able to create many new materials and devices with a vast range of applications, such as in nanomedicine, nanoelectronics, biomaterials energy production, and consumer products. On the other hand, nanotechnology raises many of the same issues as any new technology, including concerns about the toxicity and environmental impact of nanomaterials, and their potential effects on global economics, as well as speculation about various doomsday scenarios. These concerns have led to a debate among advocacy groups and governments on whether special regulation of nanotechnology is warranted.


== Origins ==

The concepts that seeded nanotechnology were first discussed in 1959 by renowned physicist Richard Feynman in his talk There's Plenty of Room at the Bottom, in which he described the possibility of synthesis via direct manipulation of atoms.
In 1960, Egyptian engineer Mohamed Atalla and Korean engineer Dawon Kahng at Bell Labs fabricated the first MOSFET (metal–oxide–semiconductor field-effect transistor) with a gate oxide thickness of 100 nm, along with a gate length of 20 µm. In 1962, Atalla and Kahng fabricated a nanolayer-base metal–semiconductor junction (M–S junction) transistor that used gold (Au) thin films with a thickness of 10 nm.

The term ""nano-technology"" was first used by Norio Taniguchi in 1974, though it was not widely known. Inspired by Feynman's concepts, K. Eric Drexler used the term ""nanotechnology"" in his 1986 book Engines of Creation: The Coming Era of Nanotechnology, which proposed the idea of a nanoscale ""assembler"" which would be able to build a copy of itself and of other items of arbitrary complexity with atomic control. Also in 1986, Drexler co-founded The Foresight Institute (with which he is no longer affiliated) to help increase public awareness and understanding of nanotechnology concepts and implications.
The emergence of nanotechnology as a field in the 1980s occurred through convergence of Drexler's theoretical and public work, which developed and popularized a conceptual framework for nanotechnology, and high-visibility experimental advances that drew additional wide-scale attention to the prospects of atomic control of matter. Since the popularity spike in the 1980s, most of nanotechnology has involved investigation of several approaches to making mechanical devices out of a small number of atoms.In the 1980s, two major breakthroughs sparked the growth of nanotechnology in modern era. First, the invention of the scanning tunneling microscope in 1981 which provided unprecedented visualization of individual atoms and bonds, and was successfully used to manipulate individual atoms in 1989. The microscope's developers Gerd Binnig and Heinrich Rohrer at IBM Zurich Research Laboratory received a Nobel Prize in Physics in 1986. Binnig, Quate and Gerber also invented the analogous atomic force microscope that year.

Second, fullerenes were discovered in 1985 by Harry Kroto, Richard Smalley, and Robert Curl, who together won the 1996 Nobel Prize in Chemistry. C60 was not initially described as nanotechnology; the term was used regarding subsequent work with related graphene tubes (called carbon nanotubes and sometimes called Bucky tubes) which suggested potential applications for nanoscale electronics and devices. The discovery of carbon nanotubes is largely attributed to Sumio Iijima of NEC in 1991, for which Iijima won the inaugural 2008 Kavli Prize in Nanoscience.
In 1987, Bijan Davari led an IBM research team that demonstrated the first MOSFET with a 10 nm gate oxide thickness, using tungsten-gate technology. Multi-gate MOSFETs enabled scaling below 20 nm gate length, starting with the FinFET (fin field-effect transistor), a three-dimensional, non-planar, double-gate MOSFET. The FinFET originates from the research of Digh Hisamoto at Hitachi Central Research Laboratory in 1989. At UC Berkeley, FinFET devices were fabricated by a group consisting of Hisamoto along with TSMC's Chenming Hu and other international researchers including Tsu-Jae King Liu, Jeffrey Bokor, Hideki Takeuchi, K. Asano, Jakub Kedziersk, Xuejue Huang, Leland Chang, Nick Lindert, Shibly Ahmed and Cyrus Tabery. The team fabricated FinFET devices down to a 17 nm process in 1998, and then 15 nm in 2001. In 2002, a team including Yu, Chang, Ahmed, Hu, Liu, Bokor and Tabery fabricated a 10 nm FinFET device.In the early 2000s, the field garnered increased scientific, political, and commercial attention that led to both controversy and progress. Controversies emerged regarding the definitions and potential implications of nanotechnologies, exemplified by the Royal Society's report on nanotechnology. Challenges were raised regarding the feasibility of applications envisioned by advocates of molecular nanotechnology, which culminated in a public debate between Drexler and Smalley in 2001 and 2003.Meanwhile, commercialization of products based on advancements in nanoscale technologies began emerging. These products are limited to bulk applications of nanomaterials and do not involve atomic control of matter. Some examples include the Silver Nano platform for using silver nanoparticles as an antibacterial agent, nanoparticle-based transparent sunscreens, carbon fiber strengthening using silica nanoparticles, and carbon nanotubes for stain-resistant textiles.Governments moved to promote and fund research into nanotechnology, such as in the U.S. with the National Nanotechnology Initiative, which formalized a size-based definition of nanotechnology and established funding for research on the nanoscale, and in Europe via the European Framework Programmes for Research and Technological Development.
By the mid-2000s new and serious scientific attention began to flourish.  Projects emerged to produce nanotechnology roadmaps  which center on atomically precise manipulation of matter and discuss existing and projected capabilities, goals, and applications.
In 2006, a team of Korean researchers from the Korea Advanced Institute of Science and Technology (KAIST) and the National Nano Fab Center developed a 3 nm MOSFET, the world's smallest nanoelectronic device. It was based on gate-all-around (GAA) FinFET technology.Over sixty countries created nanotechnology research and development (R&D) government programs between 2001 and 2004. Government funding was exceeded by corporate spending on nanotechnology R&D, with most of the funding coming from corporations based in the United States, Japan and Germany. The top five organizations that filed the most intellectual patents on nanotechnology R&D between 1970 and 2011 were Samsung Electronics (2,578 first patents), Nippon Steel (1,490 first patents), IBM (1,360 first patents), Toshiba (1,298 first patents) and Canon (1,162 first patents). The top five organizations that published the most scientific papers on nanotechnology research between 1970 and 2012 were the Chinese Academy of Sciences, Russian Academy of Sciences, Centre national de la recherche scientifique, University of Tokyo and Osaka University.


== Fundamental concepts ==
Nanotechnology is the engineering of functional systems at the molecular scale. This covers both current work and concepts that are more advanced. In its original sense, nanotechnology refers to the projected ability to construct items from the bottom up, using techniques and tools being developed today to make complete, high performance products.
One nanometer (nm) is one billionth, or 10−9, of a meter. By comparison, typical carbon-carbon bond lengths, or the spacing between these atoms in a molecule, are in the range 0.12–0.15 nm, and a DNA double-helix has a diameter around 2 nm. On the other hand, the smallest cellular life-forms, the bacteria of the genus Mycoplasma, are around 200 nm in length. By convention, nanotechnology is taken as the scale range 1 to 100 nm following the definition used by the National Nanotechnology Initiative in the US. The lower limit is set by the size of atoms (hydrogen has the smallest atoms, which are approximately a quarter of a nm kinetic diameter) since nanotechnology must build its devices from atoms and molecules. The upper limit is more or less arbitrary but is around the size below which  phenomena not observed in larger structures start to become apparent and can be made use of in the nano device. These new phenomena make nanotechnology distinct from devices which are merely miniaturised versions of an equivalent macroscopic device; such devices are on a larger scale and come under the description of microtechnology.To put that scale in another context, the comparative size of a nanometer to a meter is the same as that of a marble to the size of the earth. Or another way of putting it: a nanometer is the amount an average man's beard grows in the time it takes him to raise the razor to his face.Two main approaches are used in nanotechnology. In the ""bottom-up"" approach, materials and devices are built from molecular components which assemble themselves chemically by principles of molecular recognition. In the ""top-down"" approach, nano-objects are constructed from larger entities without atomic-level control.Areas of physics such as nanoelectronics, nanomechanics, nanophotonics and nanoionics have evolved during the last few decades to provide a basic scientific foundation of nanotechnology.


=== Larger to smaller: a materials perspective ===

Several phenomena become pronounced as the size of the system decreases. These include statistical mechanical effects, as well as quantum mechanical effects, for example the ""quantum size effect"" where the electronic properties of solids are altered with great reductions in particle size. This effect does not come into play by going from macro to micro dimensions. However, quantum effects can become significant when the nanometer size range is reached, typically at distances of 100 nanometers or less, the so-called quantum realm. Additionally, a number of physical (mechanical, electrical, optical, etc.) properties change when compared to macroscopic systems. One example is the increase in surface area to volume ratio altering mechanical, thermal and catalytic properties of materials. Diffusion and reactions at nanoscale, nanostructures materials and nanodevices with fast ion transport are generally referred to nanoionics. Mechanical properties of nanosystems are of interest in the nanomechanics research. The catalytic activity of nanomaterials also opens potential risks in their interaction with biomaterials.
Materials reduced to the nanoscale can show different properties compared to what they exhibit on a macroscale, enabling unique applications. For instance, opaque substances can become transparent (copper); stable materials can turn combustible (aluminium); insoluble materials may become soluble (gold). A material such as gold, which is chemically inert at normal scales, can serve as a potent chemical catalyst at nanoscales. Much of the fascination with nanotechnology stems from these quantum and surface phenomena that matter exhibits at the nanoscale.


=== Simple to complex: a molecular perspective ===

Modern synthetic chemistry has reached the point where it is possible to prepare small molecules to almost any structure. These methods are used today to manufacture a wide variety of useful chemicals such as pharmaceuticals or commercial polymers. This ability raises the question of extending this kind of control to the next-larger level, seeking methods to assemble these single molecules into supramolecular assemblies consisting of many molecules arranged in a well defined manner.
These approaches utilize the concepts of molecular self-assembly and/or supramolecular chemistry to automatically arrange themselves into some useful conformation through a bottom-up approach. The concept of molecular recognition is especially important: molecules can be designed so that a specific configuration or arrangement is favored due to non-covalent intermolecular forces. The Watson–Crick basepairing rules are a direct result of this, as is the specificity of an enzyme being targeted to a single substrate, or the specific folding of the protein itself. Thus, two or more components can be designed to be complementary and mutually attractive so that they make a more complex and useful whole.
Such bottom-up approaches should be capable of producing devices in parallel and be much cheaper than top-down methods, but could potentially be overwhelmed as the size and complexity of the desired assembly increases. Most useful structures require complex and thermodynamically unlikely arrangements of atoms. Nevertheless, there are many examples of self-assembly based on molecular recognition in biology, most notably Watson–Crick basepairing and enzyme-substrate interactions. The challenge for nanotechnology is whether these principles can be used to engineer new constructs in addition to natural ones.


=== Molecular nanotechnology: a long-term view ===

Molecular nanotechnology, sometimes called molecular manufacturing, describes engineered nanosystems (nanoscale machines) operating on the molecular scale. Molecular nanotechnology is especially associated with the molecular assembler, a machine that can produce a desired structure or device atom-by-atom using the principles of mechanosynthesis. Manufacturing in the context of productive nanosystems is not related to, and should be clearly distinguished from, the conventional technologies used to manufacture nanomaterials such as carbon nanotubes and nanoparticles.
When the term ""nanotechnology"" was independently coined and popularized by Eric Drexler (who at the time was unaware of an earlier usage by Norio Taniguchi) it referred to a future manufacturing technology based on molecular machine systems. The premise was that molecular scale biological analogies of traditional machine components demonstrated molecular machines were possible: by the countless examples found in biology, it is known that sophisticated, stochastically optimised biological machines can be produced.
It is hoped that developments in nanotechnology will make possible their construction by some other means, perhaps using biomimetic principles. However, Drexler and other researchers have proposed that advanced nanotechnology, although perhaps initially implemented by biomimetic means, ultimately could be based on mechanical engineering principles, namely, a manufacturing technology based on the mechanical functionality of these components (such as gears, bearings, motors, and structural members) that would enable programmable, positional assembly to atomic specification. The physics and engineering performance of exemplar designs were analyzed in Drexler's book Nanosystems.
In general it is very difficult to assemble devices on the atomic scale, as one has to position atoms on other atoms of comparable size and stickiness. Another view, put forth by Carlo Montemagno, is that future nanosystems will be hybrids of silicon technology and biological molecular machines. Richard Smalley argued that mechanosynthesis are impossible due to the difficulties in mechanically manipulating individual molecules.
This led to an exchange of letters in the ACS publication Chemical & Engineering News in 2003. Though biology clearly demonstrates that molecular machine systems are possible, non-biological molecular machines are today only in their infancy. Leaders in research on non-biological molecular machines are Dr. Alex Zettl and his colleagues at Lawrence Berkeley Laboratories and UC Berkeley.[1] They have constructed at least three distinct molecular devices whose motion is controlled from the desktop with changing voltage: a nanotube nanomotor, a molecular actuator, and a nanoelectromechanical relaxation oscillator. See nanotube nanomotor for more examples.
An experiment indicating that positional molecular assembly is possible was performed by Ho and Lee at Cornell University in 1999. They used a scanning tunneling microscope to move an individual carbon monoxide molecule (CO) to an individual iron atom (Fe) sitting on a flat silver crystal, and chemically bound the CO to the Fe by applying a voltage.


== Current research ==


=== Nanomaterials ===
The nanomaterials field includes subfields which develop or study materials having unique properties arising from their nanoscale dimensions.
Interface and colloid science has given rise to many materials which may be useful in nanotechnology, such as carbon nanotubes and other fullerenes, and various nanoparticles and nanorods. Nanomaterials with fast ion transport are related also to nanoionics and nanoelectronics.
Nanoscale materials can also be used for bulk applications; most present commercial applications of nanotechnology are of this flavor.
Progress has been made in using these materials for medical applications; see Nanomedicine.
Nanoscale materials such as nanopillars are sometimes used in solar cells which combats the cost of traditional silicon solar cells.
Development of applications incorporating semiconductor nanoparticles to be used in the next generation of products, such as display technology, lighting, solar cells and biological imaging; see quantum dots.
Recent application of nanomaterials include a range of biomedical applications, such as tissue engineering, drug delivery, and biosensors.


=== Bottom-up approaches ===
These seek to arrange smaller components into more complex assemblies.

DNA nanotechnology utilizes the specificity of Watson–Crick basepairing to construct well-defined structures out of DNA and other nucleic acids.
Approaches from the field of ""classical"" chemical synthesis (Inorganic and organic synthesis) also aim at designing molecules with well-defined shape (e.g. bis-peptides).
More generally, molecular self-assembly seeks to use concepts of supramolecular chemistry, and molecular recognition in particular, to cause single-molecule components to automatically arrange themselves into some useful conformation.
Atomic force microscope tips can be used as a nanoscale ""write head"" to deposit a chemical upon a surface in a desired pattern in a process called dip pen nanolithography. This technique fits into the larger subfield of nanolithography.
Molecular Beam Epitaxy allows for bottom up assemblies of materials, most notably semiconductor materials commonly used in chip and computing applications, stacks, gating, and nanowire lasers.


=== Top-down approaches ===
These seek to create smaller devices by using larger ones to direct their assembly.

Many technologies that descended from conventional solid-state silicon methods for fabricating microprocessors are now capable of creating features smaller than 100 nm, falling under the definition of nanotechnology. Giant magnetoresistance-based hard drives already on the market fit this description, as do atomic layer deposition (ALD) techniques. Peter Grünberg and Albert Fert received the Nobel Prize in Physics in 2007 for their discovery of Giant magnetoresistance and contributions to the field of spintronics.
Solid-state techniques can also be used to create devices known as nanoelectromechanical systems or NEMS, which are related to microelectromechanical systems or MEMS.
Focused ion beams can directly remove material, or even deposit material when suitable precursor gasses are applied at the same time. For example, this technique is used routinely to create sub-100 nm sections of material for analysis in Transmission electron microscopy.
Atomic force microscope tips can be used as a nanoscale ""write head"" to deposit a resist, which is then followed by an etching process to remove material in a top-down method.


=== Functional approaches ===
These seek to develop components of a desired functionality without regard to how they might be assembled.

Magnetic assembly for the synthesis of anisotropic superparamagnetic materials such as recently presented magnetic nano chains.
Molecular scale electronics seeks to develop molecules with useful electronic properties. These could then be used as single-molecule components in a nanoelectronic device. For an example see rotaxane.
Synthetic chemical methods can also be used to create synthetic molecular motors, such as in a so-called nanocar.


=== Biomimetic approaches ===
Bionics or biomimicry seeks to apply biological methods and systems found in nature, to the study and design of engineering systems and modern technology. Biomineralization is one example of the systems studied.
Bionanotechnology is the use of biomolecules for applications in nanotechnology, including use of viruses and lipid assemblies. Nanocellulose is a potential bulk-scale application.


=== Speculative ===
These subfields seek to anticipate what inventions nanotechnology might yield, or attempt to propose an agenda along which inquiry might progress. These often take a big-picture view of nanotechnology, with more emphasis on its societal implications than the details of how such inventions could actually be created.

Molecular nanotechnology is a proposed approach which involves manipulating single molecules in finely controlled, deterministic ways. This is more theoretical than the other subfields, and many of its proposed techniques are beyond current capabilities.
Nanorobotics centers on self-sufficient machines of some functionality operating at the nanoscale. There are hopes for applying nanorobots in medicine. Nevertheless, progress on innovative materials and methodologies has been demonstrated with some patents granted about new nanomanufacturing devices for future commercial applications, which also progressively helps in the development towards nanorobots with the use of embedded nanobioelectronics concepts.
Productive nanosystems are ""systems of nanosystems"" which will be complex nanosystems that produce atomically precise parts for other nanosystems, not necessarily using novel nanoscale-emergent properties, but well-understood fundamentals of manufacturing. Because of the discrete (i.e. atomic) nature of matter and the possibility of exponential growth, this stage is seen as the basis of another industrial revolution. Mihail Roco, one of the architects of the USA's National Nanotechnology Initiative, has proposed four states of nanotechnology that seem to parallel the technical progress of the Industrial Revolution, progressing from passive nanostructures to active nanodevices to complex nanomachines and ultimately to productive nanosystems.
Programmable matter seeks to design materials whose properties can be easily, reversibly and externally controlled though a fusion of information science and materials science.
Due to the popularity and media exposure of the term nanotechnology, the words picotechnology and femtotechnology have been coined in analogy to it, although these are only used rarely and informally.


=== Dimensionality in nanomaterials ===
Nanomaterials can be classified in 0D, 1D, 2D and 3D nanomaterials. The dimensionality play a major role in determining the characteristic of nanomaterials including physical, chemical and biological characteristics. With the decrease in dimensionality, an increase in surface-to-volume ratio is observed. This indicate that smaller dimensional nanomaterials have higher surface area compared to 3D nanomaterials. Recently, two dimensional (2D) nanomaterials are extensively investigated for electronic, biomedical, drug delivery and biosensor applications.


== Tools and techniques ==

There are several important modern developments. The atomic force microscope (AFM) and the Scanning Tunneling Microscope (STM) are two early versions of scanning probes that launched nanotechnology. There are other types of scanning probe microscopy. Although conceptually similar to the scanning confocal microscope developed by Marvin Minsky in 1961 and the scanning acoustic microscope (SAM) developed by Calvin Quate and coworkers in the 1970s, newer scanning probe microscopes have much higher resolution, since they are not limited by the wavelength of sound or light.
The tip of a scanning probe can also be used to manipulate nanostructures (a process called positional assembly). Feature-oriented scanning methodology may be a promising way to implement these nanomanipulations in automatic mode. However, this is still a slow process because of low scanning velocity of the microscope.
Various techniques of nanolithography such as optical lithography, X-ray lithography, dip pen nanolithography, electron beam lithography or nanoimprint lithography were also developed. Lithography is a top-down fabrication technique where a bulk material is reduced in size to nanoscale pattern.
Another group of nanotechnological techniques include those used for fabrication of nanotubes and nanowires, those used in semiconductor fabrication such as deep ultraviolet lithography, electron beam lithography, focused ion beam machining, nanoimprint lithography, atomic layer deposition, and molecular vapor deposition, and further including molecular self-assembly techniques such as those employing di-block copolymers. The precursors of these techniques preceded the nanotech era, and are extensions in the development of scientific advancements rather than techniques which were devised with the sole purpose of creating nanotechnology and which were results of nanotechnology research.The top-down approach anticipates nanodevices that must be built piece by piece in stages, much as manufactured items are made. Scanning probe microscopy is an important technique both for characterization and synthesis of nanomaterials. Atomic force microscopes and scanning tunneling microscopes can be used to look at surfaces and to move atoms around. By designing different tips for these microscopes, they can be used for carving out structures on surfaces and to help guide self-assembling structures. By using, for example, feature-oriented scanning approach, atoms or molecules can be moved around on a surface with scanning probe microscopy techniques. At present, it is expensive and time-consuming for mass production but very suitable for laboratory experimentation.
In contrast, bottom-up techniques build or grow larger structures atom by atom or molecule by molecule. These techniques include chemical synthesis, self-assembly and positional assembly. Dual polarisation interferometry is one tool suitable for characterisation of self assembled thin films. Another variation of the bottom-up approach is molecular beam epitaxy or MBE. Researchers at Bell Telephone Laboratories like John R. Arthur. Alfred Y. Cho, and Art C. Gossard developed and implemented MBE as a research tool in the late 1960s and 1970s. Samples made by MBE were key to the discovery of the fractional quantum Hall effect for which the 1998 Nobel Prize in Physics was awarded. MBE allows scientists to lay down atomically precise layers of atoms and, in the process, build up complex structures. Important for research on semiconductors, MBE is also widely used to make samples and devices for the newly emerging field of spintronics.
However, new therapeutic products, based on responsive nanomaterials, such as the ultradeformable, stress-sensitive Transfersome vesicles, are under development and already approved for human use in some countries.


== Research and development ==

Because of the variety of potential applications (including industrial and military), governments have invested billions of dollars in nanotechnology research. Prior to 2012, the USA invested $3.7 billion using its National Nanotechnology Initiative, the European Union invested $1.2 billion, and Japan invested $750 million. Over sixty countries created nanotechnology research and development (R&D) programs between 2001 and 2004. In 2012, the US and EU each invested $2.1 billion on nanotechnology research, followed by Japan with $1.2 billion. Global investment reached $7.9 billion in 2012. Government funding was exceeded by corporate R&D spending on nanotechnology research, which was $10 billion in 2012. The largest corporate R&D spenders were from the US, Japan and Germany which accounted for a combined $7.1 billion.


== Applications ==

As of August 21, 2008, the Project on Emerging Nanotechnologies estimates that over 800 manufacturer-identified nanotech products are publicly available, with new ones hitting the market at a pace of 3–4 per week. The project lists all of the products in a publicly accessible online database. Most applications are limited to the use of ""first generation"" passive nanomaterials which includes titanium dioxide in sunscreen, cosmetics, surface coatings, and some food products; Carbon allotropes used to produce gecko tape; silver in food packaging, clothing, disinfectants and household appliances; zinc oxide in sunscreens and cosmetics, surface coatings, paints and outdoor furniture varnishes; and cerium oxide as a fuel catalyst.Further applications allow tennis balls to last longer, golf balls to fly straighter, and even bowling balls to become more durable and have a harder surface. Trousers and socks have been infused with nanotechnology so that they will last longer and keep people cool in the summer. Bandages are being infused with silver nanoparticles to heal cuts faster. Video game consoles and personal computers may become cheaper, faster, and contain more memory thanks to nanotechnology. Also, to build structures for on chip computing with light, for example on chip optical quantum information processing, and picosecond transmission of information.Nanotechnology may have the ability to make existing medical applications cheaper and easier to use in places like the general practitioner's office and at home. Cars are being manufactured with nanomaterials so they may need fewer metals and less fuel to operate in the future.Scientists are now turning to nanotechnology in an attempt to develop diesel engines with cleaner exhaust fumes. Platinum is currently used as the diesel engine catalyst in these engines. The catalyst is what cleans the exhaust fume particles. First a reduction catalyst is employed to take nitrogen atoms from NOx molecules in order to free oxygen. Next the oxidation catalyst oxidizes the hydrocarbons and carbon monoxide to form carbon dioxide and water. Platinum is used in both the reduction and the oxidation catalysts. Using platinum though, is inefficient in that it is expensive and unsustainable. Danish company InnovationsFonden invested DKK 15 million in a search for new catalyst substitutes using nanotechnology. The goal of the project, launched in the autumn of 2014, is to maximize surface area and minimize the amount of material required. Objects tend to minimize their surface energy; two drops of water, for example, will join to form one drop and decrease surface area. If the catalyst's surface area that is exposed to the exhaust fumes is maximized, efficiency of the catalyst is maximized. The team working on this project aims to create nanoparticles that will not merge. Every time the surface is optimized, material is saved. Thus, creating these nanoparticles will increase the effectiveness of the resulting diesel engine catalyst—in turn leading to cleaner exhaust fumes—and will decrease cost. If successful, the team hopes to reduce platinum use by 25%.Nanotechnology also has a prominent role in the fast developing field of Tissue Engineering. When designing scaffolds, researchers attempt to mimic the nanoscale features of a cell's microenvironment to direct its differentiation down a suitable lineage. For example, when creating scaffolds to support the growth of bone, researchers may mimic osteoclast resorption pits.Researchers have successfully used DNA origami-based nanobots capable of carrying out logic functions to achieve targeted drug delivery in cockroaches. It is said that the computational power of these nanobots can be scaled up to that of a Commodore 64.


=== Nanoelectronics ===

Commercial nanoelectronic semiconductor device fabrication began in the 2010s. In 2013, SK Hynix began commercial mass-production of a 16 nm process, TSMC began production of a 16 nm FinFET process, and Samsung Electronics began production of a 10 nm process. TSMC began production of a 7 nm process in 2017, and Samsung began production of a 5 nm process in 2018. In 2019, Samsung announced plans for the commercial production of a 3 nm GAAFET process by 2021.Commercial production of nanoelectronic semiconductor memory also began in the 2010s. In 2013, SK Hynix began mass-production of 16 nm NAND flash memory, and Samsung began production of 10 nm multi-level cell (MLC) NAND flash memory. In 2017, TSMC began production of SRAM memory using a 7 nm process.


== Implications ==

An area of concern is the effect that industrial-scale manufacturing and use of nanomaterials would have on human health and the environment, as suggested by nanotoxicology research. For these reasons, some groups advocate that nanotechnology be regulated by governments. Others counter that overregulation would stifle scientific research and the development of beneficial innovations. Public health research agencies, such as the National Institute for Occupational Safety and Health are actively conducting research on potential health effects stemming from exposures to nanoparticles.Some nanoparticle products may have unintended consequences. Researchers have discovered that bacteriostatic silver nanoparticles used in socks to reduce foot odor are being released in the wash. These particles are then flushed into the waste water stream and may destroy bacteria which are critical components of natural ecosystems, farms, and waste treatment processes.Public deliberations on risk perception in the US and UK carried out by the Center for Nanotechnology in Society found that participants were more positive about nanotechnologies for energy applications than for health applications, with health applications raising moral and ethical dilemmas such as cost and availability.Experts, including director of the Woodrow Wilson Center's Project on Emerging Nanotechnologies David Rejeski, have testified that successful commercialization depends on adequate oversight, risk research strategy, and public engagement. Berkeley, California is currently the only city in the United States to regulate nanotechnology; Cambridge, Massachusetts in 2008 considered enacting a similar law, but ultimately rejected it. Over the next several decades, applications of nanotechnology will likely include much higher-capacity computers, active materials of various kinds, and cellular-scale biomedical devices.


=== Health and environmental concerns ===

Nanofibers are used in several areas and in different products, in everything from aircraft wings to tennis rackets. Inhaling airborne nanoparticles and nanofibers may lead to a number of pulmonary diseases, e.g. fibrosis.  Researchers have found that when rats breathed in nanoparticles, the particles settled in the brain and lungs, which led to significant increases in biomarkers for inflammation and stress response and that nanoparticles induce skin aging through oxidative stress in hairless mice.A two-year study at UCLA's School of Public Health found lab mice consuming nano-titanium dioxide showed DNA and chromosome damage to a degree ""linked to all the big killers of man, namely cancer, heart disease, neurological disease and aging"".A major study published more recently in Nature Nanotechnology suggests some forms of carbon nanotubes – a poster child for the ""nanotechnology revolution"" – could be as harmful as asbestos if inhaled in sufficient quantities. Anthony Seaton of the Institute of Occupational Medicine in Edinburgh, Scotland, who contributed to the article on carbon nanotubes said ""We know that some of them probably have the potential to cause mesothelioma. So those sorts of materials need to be handled very carefully."" In the absence of specific regulation forthcoming from governments, Paull and Lyons (2008) have called for an exclusion of engineered nanoparticles in food. A newspaper article reports that workers in a paint factory developed serious lung disease and nanoparticles were found in their lungs.


== Regulation ==

Calls for tighter regulation of nanotechnology have occurred alongside a growing debate related to the human health and safety risks of nanotechnology. There is significant debate about who is responsible for the regulation of nanotechnology. Some regulatory agencies currently cover some nanotechnology products and processes (to varying degrees) – by ""bolting on"" nanotechnology to existing regulations – there are clear gaps in these regimes. Davies (2008) has proposed a regulatory road map describing steps to deal with these shortcomings.Stakeholders concerned by the lack of a regulatory framework to assess and control risks associated with the release of nanoparticles and nanotubes have drawn parallels with bovine spongiform encephalopathy (""mad cow"" disease), thalidomide, genetically modified food, nuclear energy, reproductive technologies, biotechnology, and asbestosis. Dr. Andrew Maynard, chief science advisor to the Woodrow Wilson Center's Project on Emerging Nanotechnologies, concludes that there is insufficient funding for human health and safety research, and as a result there is currently limited understanding of the human health and safety risks associated with nanotechnology. As a result, some academics have called for stricter application of the precautionary principle, with delayed marketing approval, enhanced labelling and additional safety data development requirements in relation to certain forms of nanotechnology.The Royal Society report identified a risk of nanoparticles or nanotubes being released during disposal, destruction and recycling, and recommended that ""manufacturers of products that fall under extended producer responsibility regimes such as end-of-life regulations publish procedures outlining how these materials will be managed to minimize possible human and environmental exposure"" (p. xiii).
The Center for Nanotechnology in Society has found that people respond to nanotechnologies differently, depending on application – with participants in public deliberations more positive about nanotechnologies for energy than health applications – suggesting that any public calls for nano regulations may differ by technology sector.


== See also ==


== References ==


== External links ==
Nanotechnology at Curlie
What is Nanotechnology? (A Vega/BBC/OU Video Discussion)."
"Educational technology (commonly abbreviated as EduTech, or EdTech) is the combined use of computer hardware, software, and educational theory and practice to facilitate learning. Educational technology creates, uses, and manages technological processes and educational resources to help improve user academic performance. The field has been described as a persisting initiative that seeks to bring learners, teacher, and technical means together in an effective way.
In addition to experiential knowledge drawn from educational practice, educational technology is based on theoretical knowledge that emerges from various disciplines such as communication, education, psychology, sociology, artificial intelligence, and computer science, among others. It encompasses several domains including learning theory, computer-based training, online learning, and m-learning, where mobile technologies are used. 


== Definition ==
The Association for Educational Communications and Technology (AECT) defined educational technology as ""the study and ethical practice of facilitating learning and improving performance by creating, using and managing appropriate technological processes and resources"". It denoted instructional technology as ""the theory and practice of design, development, utilization, management, and evaluation of processes and resources for learning"". As such, educational technology refers to all valid and reliable applied education sciences, such as equipment, as well as processes and procedures that are derived from scientific research, and in a given context may refer to theoretical, algorithmic or heuristic processes: it does not necessarily imply physical technology. Educational technology is the process of integrating technology into education in a positive manner that promotes a more diverse learning environment and a way for students to learn how to use technology as well as their common assignments.
Accordingly, there are several discrete aspects to describing the intellectual and technical development of educational technology:

Educational technology as the theory and practice of educational approaches to learning.
Educational technology as technological tools and media, for instance massive online courses, that assist in the communication of knowledge, and its development and exchange. This is usually what people are referring to when they use the term ""EdTech"".
Educational technology for learning management systems (LMS), such as tools for student and curriculum management, and education management information systems (EMIS).
Educational technology as back-office management, such as training management systems for logistics and budget management, and Learning Record Store (LRS) for learning data storage and analysis.
Educational technology itself as an educational subject; such courses may be called ""computer studies"" or ""information and communications technology (ICT)"".


== Related terms ==

Educational technology is an inclusive term for both the material tools and the theoretical foundations for supporting learning and teaching. Educational technology is not restricted to high technology but is anything that enhances classroom learning in the utilization of blended, face to face, or online learning.An educational technologist is someone who is trained in the field of educational technology. Educational technologists try to analyze, design, develop, implement, and evaluate process and tools to enhance learning. While the term educational technologist is used primarily in the United States, learning technologist is synonymous and used in the UK as well as Canada.
Modern electronic educational technology is an important part of society today. Educational technology encompasses e-learning, instructional technology, information and communication technology (ICT) in education, EdTech,  learning technology, multimedia learning, technology-enhanced learning (TEL), computer-based instruction (CBI), computer managed instruction, computer-based training (CBT), computer-assisted instruction or computer-aided instruction (CAI), internet-based training (IBT), flexible learning, web-based training (WBT), online education,  digital educational collaboration, distributed learning, computer-mediated communication, cyber-learning, and multi-modal instruction, virtual education, personal learning environments, networked learning, virtual learning environments (VLE) (which are also called learning platforms), m-learning, ubiquitous learning and digital education.
Each of these numerous terms has had its advocates, who point up potential distinctive features. However, many terms and concepts in educational technology have been defined nebulously; for example, Fiedler's review of the literature found a complete lack agreement of the components of a personal learning environment. Moreover, Moore saw these terminologies as emphasizing particular features such as digitization approaches, components or delivery methods rather than being fundamentally dissimilar in concept or principle. For example, m-learning emphasizes mobility, which allows for altered timing, location, accessibility and context of learning; nevertheless, its purpose and conceptual principles are those of educational technology.In practice, as technology has advanced, the particular ""narrowly defined"" terminological aspect that was initially emphasized by name has blended into the general field of educational technology. Initially, ""virtual learning"" as narrowly defined in a semantic sense implied entering an environmental simulation within a virtual world, for example in treating posttraumatic stress disorder (PTSD). In practice, a ""virtual education course"" refers to any instructional course in which all, or at least a significant portion, is delivered by the Internet. ""Virtual"" is used in that broader way to describe a course that is not taught in a classroom face-to-face but through a substitute mode that can conceptually be associated ""virtually"" with classroom teaching, which means that people do not have to go to the physical classroom to learn. Accordingly, virtual education refers to a form of distance learning in which course content is delivered by various methods such as course management applications, multimedia resources, and videoconferencing. Virtual education and simulated learning opportunities, such as games or dissections, offer opportunities for students to connect classroom content to authentic situations.Educational content, pervasively embedded in objects, is all around the learner, who may not even be conscious of the learning process. The combination of adaptive learning, using an individualized interface and materials, which accommodate to an individual, who thus receives personally differentiated instruction, with ubiquitous access to digital resources and learning opportunities in a range of places and at various times, has been termed smart learning. Smart learning is a component of the smart city concept.


== History ==

Helping people and children learn in ways that are easier, faster, more accurate, or less expensive can be traced back to the emergence of very early tools, such as paintings on cave walls. Various types of abacus have been used. Writing slates and blackboards have been used for at least a millennium. From their introduction, books and pamphlets have held a prominent role in education. From the early twentieth century, duplicating machines such as the mimeograph and Gestetner stencil devices were used to produce short copy runs (typically 10–50 copies) for classroom or home use. The use of media for instructional purposes is generally traced back to the first decade of the 20th century with the introduction of educational films (1900s) and Sidney Pressey's mechanical teaching machines (1920s).  The first all multiple choice, large-scale assessment was the Army Alpha, used to assess the intelligence and, more specifically, the aptitudes of World War I military recruits. Further large-scale use of technologies was employed in training soldiers during and after WWII using films and other mediated materials, such as overhead projectors. The concept of hypertext is traced to the description of memex by Vannevar Bush in 1945.

Slide projectors were widely used during the 1950s in educational institutional settings. Cuisenaire rods were devised in the 1920s and saw widespread use from the late 1950s.
In the mid-1960s, Stanford University psychology professors, Patrick Suppes and Richard C. Atkinson, experimented with using computers to teach arithmetic and spelling via Teletypes to elementary school students in the Palo Alto Unified School District in California.  Stanford's Education Program for Gifted Youth is descended from those early experiments.
Online education originated from the University of Illinois in 1960. Although the internet would not be created for another nine years, students were able to access class information with linked computer terminals. The first online course was offered in 1986 by the Electronic University Network for DOS and Commodore 64 computers. Computer Assisted Learning eventually offered the first online courses with real interaction. In 2002, MIT began providing online classes free of charge. As of 2009, approximately 5.5 million students were taking at least one class online. Currently, one out of three college students takes at least one online course while in college. At DeVry University, out of all students that are earning a bachelor's degree, 80% earn two-thirds of their requirements online. Also, in 2014, 2.85 million students out of 5.8 million students that took courses online, took all of their courses online. From this information, it can be concluded that the number of students taking classes online is on the steady increase.

In 1971, Ivan Illich published a hugely influential book called, Deschooling Society, in which he envisioned ""learning webs"" as a model for people to network the learning they needed. The 1970s and 1980s saw notable contributions in computer-based learning by Murray Turoff and Starr Roxanne Hiltz at the New Jersey Institute of Technology as well as developments at the University of Guelph in Canada. In the UK, the Council for Educational Technology supported the use of educational technology, in particular administering the government's National Development Programme in Computer Aided Learning (1973–77) and the Microelectronics Education Programme (1980–86).
By the mid-1980s, accessing course content became possible at many college libraries. In computer-based training (CBT) or computer-based learning (CBL), the learning interaction was between the student and computer drills or micro-world simulations.
Digitized communication and networking in education started in the mid-1980s. Educational institutions began to take advantage of the new medium by offering distance learning courses using computer networking for information. Early e-learning systems, based on computer-based learning/training often replicated autocratic teaching styles whereby the role of the e-learning system was assumed to be for transferring knowledge, as opposed to systems developed later based on computer supported collaborative learning (CSCL), which encouraged the shared development of knowledge.
Videoconferencing was an important forerunner to the educational technologies known today. This work was especially popular with museum education. Even in recent years, videoconferencing has risen in popularity to reach over 20,000 students across the United States and Canada in 2008–2009. Disadvantages of this form of educational technology are readily apparent: image and sound quality is often grainy or pixelated; videoconferencing requires setting up a type of mini-television studio within the museum for broadcast, space becomes an issue, and specialised equipment is required for both the provider and the participant.The Open University in Britain and the University of British Columbia (where Web CT, now incorporated into Blackboard Inc., was first developed) began a revolution of using the Internet to deliver learning, making heavy use of web-based training, online distance learning and online discussion between students. Practitioners such as Harasim (1995) put heavy emphasis on the use of learning networks.
With the advent of World Wide Web in the 1990s, teachers embarked on the method using emerging technologies to employ multi-object oriented sites, which are text-based online virtual reality systems, to create course websites along with simple sets of instructions for its students.
By 1994, the first online high school had been founded. In 1997, Graziadei described criteria for evaluating products and developing technology-based courses that include being portable, replicable, scalable, affordable, and having a high probability of long-term cost-effectiveness.Improved Internet functionality enabled new schemes of communication with multimedia or webcams. The National Center for Education Statistics estimate the number of K-12 students enrolled in online distance learning programs increased by 65 percent from 2002 to 2005, with greater flexibility, ease of communication between teacher and student, and quick lecture and assignment feedback.
According to a 2008 study conducted by the U.S Department of Education, during the 2006–2007 academic year about 66% of postsecondary public and private schools participating in student financial aid programs offered some distance learning courses; records show 77% of enrollment in for-credit courses with an online component. In 2008, the Council of Europe passed a statement endorsing e-learning's potential to drive equality and education improvements across the EU.Computer-mediated communication (CMC) is between learners and instructors, mediated by the computer. In contrast, CBT/CBL usually means individualized (self-study) learning, while CMC involves educator/tutor facilitation and requires scenarization of flexible learning activities. In addition, modern ICT provides education with tools for sustaining learning communities and associated knowledge management tasks.
Students growing up in this digital age have extensive exposure to a variety of media. Major high-tech companies have funded schools to provide them the ability to teach their students through technology.2015 was the first year that private nonprofit organizations enrolled more online students than for-profits, although public universities still enrolled the highest number of online students.  In the fall of 2015, more than 6 million students enrolled in at least one online course.In 2020 due to Coronavirus outbreak many schools are closed and more and more students are enrolling in online courses to enforce distant learning. Organizations such as Unesco have listed educational technology solutions to help schools facilitate distance education.


== Theory ==

Various pedagogical perspectives or learning theories may be considered in designing and interacting with educational technology. E-learning theory examines these approaches. These theoretical perspectives are grouped into three main theoretical schools or philosophical frameworks: behaviorism, cognitivism and constructivism.


=== Behaviorism ===
This theoretical framework was developed in the early 20th century based on animal learning experiments by Ivan Pavlov, Edward Thorndike, Edward C. Tolman, Clark L. Hull, and B.F. Skinner. Many psychologists used these results to develop theories of human learning, but modern educators generally see behaviorism as one aspect of a holistic synthesis. Teaching in behaviorism has been linked to training, emphasizing the animal learning experiments. Since behaviorism consists of the view of teaching people how to do something with rewards and punishments, it is related to training people.B.F. Skinner wrote extensively on improvements of teaching based on his functional analysis of verbal behavior and wrote ""The Technology of Teaching"", an attempt to dispel the myths underlying contemporary education as well as promote his system he called programmed instruction. Ogden Lindsley developed a learning system, named Celeration, that was based on behavior analysis but that substantially differed from Keller's and Skinner's models.


=== Cognitivism ===
Cognitive science underwent significant change in the 1960s and 1970s to the point that some described the period as a ""cognitive revolution"" particularly in reaction to behaviorism. While retaining the empirical framework of behaviorism, cognitive psychology theories look beyond behavior to explain brain-based learning by considering how human memory works to promote learning. It refers to learning as ""all processes by which the sensory input is transformed, reduced, elaborated, stored, recovered, and used"" by the human mind. The Atkinson-Shiffrin memory model and Baddeley's working memory model were established as theoretical frameworks. Computer Science and Information Technology have had a major influence on Cognitive Science theory. The Cognitive concepts of working memory (formerly known as short-term memory) and long-term memory have been facilitated by research and technology from the field of Computer Science. Another major influence on the field of Cognitive Science is Noam Chomsky. Today researchers are concentrating on topics like cognitive load, information processing, and media psychology. These theoretical perspectives influence instructional design.There are two separate schools of cognitivism, and these are the cognitivist and social cognitivist. The former focuses on the understanding of the thinking or cognitive processes of an individual while the latter includes social processes as influences in learning besides cognition. These two schools, however, share the view that learning is more than a behavioral change but as a mental process used by the learner.


=== Constructivism ===
Educational psychologists distinguish between several types of constructivism: individual (or psychological) constructivism, such as Piaget's theory of cognitive development, and social constructivism. This form of constructivism has a primary focus on how learners construct their own meaning from new information, as they interact with reality and with other learners who bring different perspectives. Constructivist learning environments require students to use their prior knowledge and experiences to formulate new, related, and/or adaptive concepts in learning (Termos, 2012). Under this framework the role of the teacher becomes that of a facilitator, providing guidance so that learners can construct their own knowledge. Constructivist educators must make sure that the prior learning experiences are appropriate and related to the concepts being taught. Jonassen (1997) suggests ""well-structured"" learning environments are useful for novice learners and that ""ill-structured"" environments are only useful for more advanced learners. Educators utilizing a constructivist perspective may emphasize an active learning environment that may incorporate learner centered problem-based learning, project-based learning, and inquiry-based learning, ideally involving real-world scenarios, in which students are actively engaged in critical thinking activities. An illustrative discussion and example can be found in the 1980s deployment of constructivist cognitive learning in computer literacy, which involved programming as an instrument of learning. LOGO, a programming language, embodied an attempt to integrate Piagetan ideas with computers and technology. Initially there were broad, hopeful claims, including ""perhaps the most controversial claim"" that it would ""improve general problem-solving skills"" across disciplines. However, LOGO programming skills did not consistently yield cognitive benefits. It was ""not as concrete"" as advocates claimed, it privileged ""one form of reasoning over all others,"" and it was difficult to apply the thinking activity to non-LOGO-based activities. By the late 1980s, LOGO and other similar programming languages had lost their novelty and dominance and were gradually de-emphasized amid criticisms.


== Practice ==

The extent to which e-learning assists or replaces other learning and teaching approaches is variable, ranging on a continuum from none to fully online distance learning. A variety of descriptive terms have been employed (somewhat inconsistently) to categorize the extent to which technology is used. For example, ""hybrid learning"" or ""blended learning"" may refer to classroom aids and laptops, or may refer to approaches in which traditional classroom time is reduced but not eliminated, and is replaced with some online learning. ""Distributed learning"" may describe either the e-learning component of a hybrid approach, or fully online distance learning environments.


=== Synchronous and asynchronous ===
E-learning may either be synchronous or asynchronous. Synchronous learning occurs in real-time, with all participants interacting at the same time, while asynchronous learning is self-paced and allows participants to engage in the exchange of ideas or information without the dependency of other participants′ involvement at the same time.Synchronous learning refers to the exchange of ideas and information with one or more participants during the same period. Examples are face-to-face discussion, online real-time live teacher instruction and feedback, Skype conversations, and chat rooms or virtual classrooms where everyone is online and working collaboratively at the same time. Since students are working collaboratively, synchronized learning helps students become more open-minded because they have to actively listen and learn from their peers.  Synchronized learning fosters online awareness and improves many students' writing skills.Asynchronous learning may use technologies such as learning management systems,  email, blogs, wikis, and discussion boards, as well as web-supported textbooks, hypertext documents,  audio video courses, and social networking using web 2.0. At the professional educational level, training may include virtual operating rooms. Asynchronous learning is beneficial for students who have health problems or who have child care responsibilities.  They have the opportunity to complete their work in a low-stress environment and within a more flexible time frame. In asynchronous online courses, students are allowed the freedom to complete work at their own pace. Being a non-traditional student, they can manage their daily life and school with and still have the social aspect. Asynchronous collaborations allow the student to reach out for help when needed and provides helpful guidance, depending on how long it takes them to complete the assignment. Many tools used for these courses are but not limited to: videos, class discussions, and group projects. Through online courses, students can earn their diplomas faster, or repeat failed courses without being in a class with younger students. Students have access to an incredible variety of enrichment courses in online learning, and still participate in college courses, internships, sports, or work and still graduate with their class.


=== Linear learning ===
Computer-based training (CBT) refers to self-paced learning activities delivered on a computer or handheld device such as a tablet or smartphone.  CBT initially delivered content via CD-ROM, and typically presented content linearly, much like reading an online book or manual.  For this reason, CBT is often used to teach static processes, such as using software or completing mathematical equations.  Computer-based training is conceptually similar to web-based training (WBT), which is delivered via Internet using a web browser.
Assessing learning in a CBT is often by assessments that can be easily scored by a computer such as multiple-choice questions, drag-and-drop, radio button, simulation or other interactive means. Assessments are easily scored and recorded via online software, providing immediate end-user feedback and completion status. Users are often able to print completion records in the form of certificates.CBTs provide learning stimulus beyond traditional learning methodology from textbook, manual, or classroom-based instruction.  CBTs can be a good alternative to printed learning materials since rich media, including videos or animations, can be embedded to enhance the learning.Help, CBTs pose some learning challenges.  Typically, the creation of effective CBTs requires enormous resources.  The software for developing CBTs is often more complex than a subject matter expert or teacher is able to use. The lack of human interaction can limit both the type of content that can be presented and the type of assessment that can be performed and may need supplementation with online discussion or other interactive elements.


=== Collaborative learning ===

Computer-supported collaborative learning (CSCL) uses instructional methods designed to encourage or require students to work together on learning tasks, allowing social learning. CSCL is similar in concept to the terminology, ""e-learning 2.0"" and ""networked collaborative learning"" (NCL). With Web 2.0 advances, sharing information between multiple people in a network has become much easier and use has increased. One of the main reasons for its usage states that it is ""a breeding ground for creative and engaging educational endeavors."" Learning takes place through conversations about content and grounded interaction about problems and actions. This collaborative learning differs from instruction in which the instructor is the principal source of knowledge and skills. The neologism ""e-learning 1.0"" refers to direct instruction used in early computer-based learning and training systems (CBL). In contrast to that linear delivery of content, often directly from the instructor's material, CSCL uses social software such as blogs, social media, wikis, podcasts, cloud-based document portals, and discussion groups and virtual worlds. This phenomenon has been referred to as Long Tail Learning. Advocates of social learning claim that one of the best ways to learn something is to teach it to others. Social networks have been used to foster online learning communities around subjects as diverse as test preparation and language education. mobile-assisted language learning (MALL) is the use of handheld computers or cell phones to assist in language learning.
Collaborative apps allow students and teachers to interact while studying. Apps are designed after games, which provide a fun way to revise. When the experience is enjoyable, the students become more engaged. Games also usually come with a sense of progression, which can help keep students motivated and consistent while trying to improve.Classroom 2.0 refers to online multi-user virtual environments (MUVEs) that connect schools across geographical frontiers. Known as ""eTwinning"", computer-supported collaborative learning (CSCL) allows learners in one school to communicate with learners in another that they would not get to know otherwise, enhancing educational outcomes and cultural integration.
Further, many researchers distinguish between collaborative and cooperative approaches to group learning. For example, Roschelle and Teasley (1995) argue that ""cooperation is accomplished by the division of labour among participants, as an activity where each person is responsible for a portion of the problem solving"", in contrast with collaboration that involves the ""mutual engagement of participants in a coordinated effort to solve the problem together.""


=== Flipped classroom ===

This is an instructional strategy in which computer-assisted teaching is integrated with classroom instruction. Students are given basic essential instruction, such as lectures, before class instead of during class. Instructional content is delivered outside of the classroom, often online. The out-of-class delivery includes streaming video, reading materials, online chats, and other resources. This frees up classroom time for teachers to more actively engage with learners.


== Technologies ==

Educational media and tools can be used for:

task structuring support: help with how to do a task (procedures and processes),
access to knowledge bases (help user find information needed)
alternate forms of knowledge representation (multiple representations of knowledge, e.g. video, audio, text, image, data)Numerous types of physical technology are currently used: digital cameras, video cameras, interactive whiteboard tools, document cameras, electronic media, and LCD projectors. Combinations of these techniques include blogs, collaborative software, ePortfolios, and virtual classrooms.
The current design of this type of applications includes the evaluation through tools of cognitive analysis that allow to identify which elements optimize the use of these platforms.


=== Audio and video ===
Video technology has included VHS tapes and DVDs, as well as on-demand and synchronous methods with digital video via server or web-based options such as streamed video and webcams. Telecommuting can connect with speakers and other experts. Interactive digital video games are being used at K-12 and higher education institutions.Radio offers a synchronous educational vehicle, while streaming audio over the internet with webcasts and podcasts can be asynchronous.  Classroom microphones, often wireless, can enable learners and educators to interact more clearly.
Screencasting allows users to share their screens directly from their browser and make the video available online so that other viewers can stream the video directly. The presenter thus has the ability to show their ideas and flow of thoughts rather than simply explain them as simple text content. In combination with audio and video, the educator can mimic the one-on-one experience of the classroom. Learners have the ability to pause and rewind, to review at their own pace, something a classroom cannot always offer.
Webcams and webcasting have enabled creation of virtual classrooms and virtual learning environment. Webcams are also being used to counter plagiarism and other forms of academic dishonesty that might occur in an e-learning environment.


=== Computers, tablets and mobile devices ===

Collaborative learning is a group-based learning approach in which learners are mutually engaged in a coordinated fashion to achieve a learning goal or complete a learning task. With recent developments in smartphone technology, the processing powers and storage capabilities of modern mobiles allow for advanced development and the use of apps. Many app developers and education experts have been exploring smartphone and tablet apps as a medium for collaborative learning.
Computers and tablets enable learners and educators to access websites as well as applications. Many mobile devices support m-learning.Mobile devices such as clickers and smartphones can be used for interactive audience response feedback. Mobile learning can provide performance support for checking the time, setting reminders, retrieving worksheets, and instruction manuals.Such devices as iPads are used for helping disabled (visually impaired or with multiple disabilities) children in communication development as well as in improving physiological activity, according to the iStimulation Practice Report.Computers in the classroom have been shown to increase rates of engagement and interest when computers and smart devices are utilized educationally in classrooms.


=== Collaborative and social learning ===

Group webpages, blogs, wikis, and Twitter allow learners and educators to post thoughts, ideas, and comments on a website in an interactive learning environment. Social networking sites are virtual communities for people interested in a particular subject to communicate by voice, chat, instant message, video conference, or blogs. The National School Boards Association found that 96% of students with online access have used social networking technologies, and more than 50% talk online about schoolwork. Social networking encourages collaboration and engagement and can be a motivational tool for self-efficacy amongst students.


=== Whiteboards ===

There are three types of whiteboards. The initial whiteboards, analogous to blackboards, date from the late 1950s. The term whiteboard is also used metaphorically to refer to virtual whiteboards in which computer software applications simulate whiteboards by allowing writing or drawing. This is a common feature of groupware for virtual meetings, collaboration, and instant messaging. Interactive whiteboards allow learners and instructors to write on the touch screen. The screen markup can be on either a blank whiteboard or any computer screen content. Depending on permission settings, this visual learning can be interactive and participatory, including writing and manipulating images on the interactive whiteboard.


=== Virtual classroom ===
 
A virtual learning environment (VLE), also known as a learning platform, simulates a virtual classroom or meetings by simultaneously mixing several communication technologies. Web conferencing software enables students and instructors to communicate with each other via webcam, microphone, and real-time chatting in a group setting. Participants can raise hands, answer polls or take tests.  Students are able to whiteboard and screencast when given rights by the instructor, who sets permission levels for text notes, microphone rights and mouse control.A virtual classroom provides an opportunity for students to receive direct instruction from a qualified teacher in an interactive environment.  Learners can have direct and immediate access to their instructor for instant feedback and direction.  The virtual classroom provides a structured schedule of classes, which can be helpful for students who may find the freedom of asynchronous learning to be overwhelming.  In addition, the virtual classroom provides a social learning environment that replicates the traditional ""brick and mortar"" classroom.  Most virtual classroom applications provide a recording feature.  Each class is recorded and stored on a server, which allows for instant playback of any class over the course of the school year.  This can be extremely useful for students to retrieve missed material or review concepts for an upcoming exam.  Parents and auditors have the conceptual ability to monitor any classroom to ensure that they are satisfied with the education the learner is receiving.
In higher education especially, a virtual learning environment (VLE) is sometimes combined with a management information system (MIS) to create a managed learning environment, in which all aspects of a course are handled through a consistent user interface throughout the institution. Physical universities and newer online-only colleges offer select academic degrees and certificate programs via the Internet. Some programs require students to attend some campus classes or orientations, but many are delivered completely online.  Several universities offer online student support services, such as online advising and registration, e-counseling, online textbook purchases, student governments and student newspapers.


==== Augmented Reality ====
Augmented reality (AR) provides students and teachers with the opportunity to create layers of digital information, including both virtual world and real world elements, to interact with in real time.
AR technology plays an important role in the future of the classroom where human / AI co-orchestration takes place seamlessly. Students would switch between individual and collaborative learning dynamically, based on their own learning pace, while teachers, with the help of AR, monitor the classroom and provide necessary interventions in cases where computer systems are not yet designed to handle. In this vision, the technology's role is to enhance, rather than replace, human teachers' capabilities.


=== Learning management system ===

A learning management system (LMS) is software used for delivering, tracking and managing training and education. It tracks data about attendance, time on task, and student progress. Educators can post announcements, grade assignments, check on course activity, and participate in class discussions. Students can submit their work, read and respond to discussion questions, and take quizzes. An LMS may allow teachers, administrators, students, and permitted additional parties (such as parents, if appropriate) to track various metrics. LMSs range from systems for managing training/educational records to software for distributing courses over the Internet and offering features for online collaboration. The creation and maintenance of comprehensive learning content require substantial initial and ongoing investments of human labor. Effective translation into other languages and cultural contexts requires even more investment by knowledgeable personnel.Internet-based learning management systems include Canvas, Blackboard Inc. and Moodle. These types of LMS allow educators to run a learning system partially or fully online, asynchronously or synchronously. Learning Management Systems also offer a non-linear presentation of content and curricular goals, giving students the choice of pace and order of information learned. Blackboard can be used for K-12 education, Higher Education, Business, and Government collaboration. Moodle is a free-to-download Open Source Course Management System that provides blended learning opportunities as well as platforms for distance learning courses.


==== Learning content management system ====
A learning content management system (LCMS) is software for author content (courses, reusable content objects). An LCMS may be solely dedicated to producing and publishing content that is hosted on an LMS, or it can host the content itself.  The Aviation Industry Computer-Based Training Committee (AICC) specification provides support for content that is hosted separately from the LMS.
A recent trend in LCMSs is to address this issue through crowdsourcing (cf.SlideWiki).


==== Computer-aided assessment ====
Computer-aided assessment (e-assessment) ranges from automated multiple-choice tests to more sophisticated systems. With some systems, feedback can be geared towards a student's specific mistakes, or the computer can navigate the student through a series of questions adapting to what the student appears to have learned or not learned. Formative assessment sifts out the incorrect answers, and these questions are then explained by the teacher. The learner then practices with slight variations of the sifted out questions. The process is completed by summative assessment using a new set of questions that only cover the topics previously taught.


==== Training management system ====
A training management system or training resource management system is a software designed to optimize instructor-led training management. Similar to an enterprise resource planning (ERP), it is a back office tool which aims at streamlining every aspect of the training process: planning (training plan and budget forecasting), logistics (scheduling and resource management), financials (cost tracking, profitability), reporting, and sales for-profit training providers. A training management system can be used to schedule instructors, venues and equipment through graphical agendas, optimize resource utilization, create a training plan and track remaining budgets, generate reports and share data between different teams.
While training management systems focus on managing instructor-led training, they can complete an LMS. In this situation, an LMS will manage e-learning delivery and assessment, while a training management system will manage ILT and back-office budget planning, logistics and reporting.


== Standards and ecosystem ==


=== Learning objects ===


=== Content ===
Content and design architecture issues include pedagogy and learning object re-use. One approach looks at five aspects:
Fact – unique data (e.g. symbols for Excel formula, or the parts that make up a learning objective)
Concept – a category that includes multiple examples (e.g. Excel formulas, or the various types/theories of instructional design)
Process – a flow of events or activities (e.g. how a spreadsheet works, or the five phases in ADDIE)
Procedure – step-by-step task (e.g. entering a formula into a spreadsheet or the steps that should be followed within a phase in ADDIE)
Strategic principle – a task performed by adapting guidelines (e.g. doing a financial projection in a spreadsheet, or using a framework for designing learning environments)


==== Pedagogical elements ====
Pedagogical elements are defined as structures or units of educational material. They are the educational content that is to be delivered. These units are independent of format, meaning that although the unit may be delivered in various ways, the pedagogical structures themselves are not the textbook, web page, video conference, Podcast, lesson, assignment, multiple-choice question, quiz, discussion group or a case study, all of which are possible methods of delivery.


=== Learning objects standards ===
Much effort has been put into the technical reuse of electronically based teaching materials and, in particular, creating or re-using learning objects. These are self-contained units that are properly tagged with keywords, or other metadata, and often stored in an XML file format. Creating a course requires putting together a sequence of learning objects. There are both proprietary and open, non-commercial and commercial, peer-reviewed repositories of learning objects such as the Merlot repository. Sharable Content Object Reference Model (SCORM) is a collection of standards and specifications that applies to certain web-based e-learning. Other specifications, such as Schools Interoperability Framework, allow for the transporting of learning objects, or for categorizing metadata (LOM).


=== Artificial intelligence ===

As artificial intelligence (AI) becomes more prominent in this age of big data, it has also been widely adopted in K-12 classrooms. One prominent class of AI-enhanced educational technology is intelligent tutoring systems (ITSs), designed to provide immediate and personalized feedbacks to students. The incentive to develop ITS comes from educational studies showing that individual tutoring is much more effective than group teaching, in addition to the need for promoting learning on a larger scale. Over the years, a combination of cognitive science theories and data-driven techniques have greatly enhanced the capabilities of ITS, allowing it to model a wide range of students' characteristics, such as knowledge, affect, off-task behavior and wheel spinning. There is ample evidence that ITSs are highly effective in helping students learn.Recent works have also focused on developing AI-enhanced learning tools that supports human teachers in coordinating classroom activities. The teacher can support students in a way that AI cannot, but is unable to process the large amount of real-time data analytics provided by the computer system. On the other hand, AI can share the workload and recommend the best course of actions (e.g., by pointing out which students require the most help), but can only operate in the pre-specified domain and cannot handle tasks such as providing emotional support or remedial lessons to students in need. However, existing systems were designed under the assumption that students progress at the same pace. Understanding how to support teachers in a realistic, highly differentiated, self-paced classroom, remains an open research problem.


== Settings and sectors ==


=== Preschool ===
Various forms of electronic media can be a feature of preschool life. Although parents report a positive experience, the impact of such use has not been systematically assessed.The age when a given child might start using a particular technology such as a cellphone or computer might depend on matching a technological resource to the recipient's developmental capabilities, such as the age-anticipated stages labeled by Swiss psychologist, Jean Piaget. Parameters, such as age-appropriateness, coherence with sought-after values, and concurrent entertainment and educational aspects, have been suggested for choosing media.At the preschool level, technology can be introduced in several ways. At the most basic is the use of computers, tablets, and audio and video resources in classrooms. Additionally, there are many resources available for parents and educators to introduce technology to young children or to use technology to augment lessons and enhance learning. Some options that are age-appropriate are video- or audio- recording of their creations, introducing them to the use of the internet through browsing age-appropriate websites, providing assistive technology to allow differently-abled children to participate with the rest of their peers, educational apps, electronic books, and educational videos. There are many free and paid educational website and apps that are directly targeting the educational needs of preschool children. These include Starfall, ABC mouse, PBS Kids Video, Teachme, and Montessori crosswords. Educational technology in the form of electronic books [109] offer preschool children the option to store and retrieve several books on one device, thus bringing together the traditional action of reading along with the use of educational technology. Educational technology is also thought to improve hand-eye coordination, language skills, visual attention and motivation to complete educational tasks, and allows children to experience things they otherwise wouldn't. There are several keys to making the most educational use out of introducing technology at the preschool level: technology must be used appropriately, should allow access to learning opportunities, should include the interaction of parents and other adults with the preschool children, and should be developmentally appropriate. Allowing access to learning opportunities especially for allowing disabled children to have access to learning opportunities, giving bilingual children the opportunity to communicate and learn in more than one language, bringing in more information about STEM subjects, and bringing in images of diversity that may be lacking in the child's immediate environment.


=== Primary and secondary ===

E-learning is utilized by public K–12 schools in the United States as well as private schools. Some e-learning environments take place in a traditional classroom; others allow students to attend classes from home or other locations. There are several states that are utilizing virtual school platforms for e-learning across the country that continue to increase. Virtual school enables students to log into synchronous learning or asynchronous learning courses anywhere there is an internet connection.
E-learning is increasingly being utilized by students who may not want to go to traditional brick and mortar schools due to severe allergies or other medical issues, fear of school violence and school bullying and students whose parents would like to homeschool but do not feel qualified. Online schools create a haven for students to receive a quality education while almost completely avoiding these common problems. Online charter schools also often are not limited by location, income level or class size in the way brick and mortar charter schools are.E-learning also has been rising as a supplement to the traditional classroom. Students with special talents or interests outside of the available curricula use e-learning to advance their skills or exceed grade restrictions. Some online institutions connect students with instructors via web conference technology to form a digital classroom.
National private schools are also available online. These provide the benefits of e-learning to students in states where charter online schools are not available. They also may allow students greater flexibility and exemption from state testing. Some of these schools are available at the high school level and offer college prep courses to students.
Virtual education in K-12 schooling often refers to virtual schools, and in higher education to virtual universities. Virtual schools are ""cybercharter schools"" with innovative administrative models and course delivery technology.Education technology also seems to be an interesting method of engaging gifted youths that are under-stimulated in their current educational program. This can be achieved with after-school programs or even technologically-integrated curricula, for example: Virtual reality integrated courses (VRIC) can be developed for any course in order to give them such stimulation. 3D printing integrated courses (3dPIC) can also give youths the stimulation they need in their educational journey. Université de Montréal's Projet SEUR in collaboration with Collège Mont-Royal and La Variable are heavily developing this field.


=== Higher education ===

Online college course enrolment has seen a 29% increase in enrolment with nearly one third of all college students, or an estimated 6.7 million students are currently enrolled in online classes. In 2009, 44 percent of post-secondary students in the USA were taking some or all of their courses online, which was projected to rise to 81 percent by 2014.Although a large proportion of for-profit higher education institutions now offer online classes, only about half of private, non-profit schools do so.  Private institutions may become more involved with on-line presentations as the costs decrease. Properly trained staff must also be hired to work with students online. These staff members need to understand the content area, and also be highly trained in the use of the computer and Internet. Online education is rapidly increasing, and online doctoral programs have even developed at leading research universities.Although massive open online courses (MOOCs) may have limitations that preclude them from fully replacing college education, such programs have significantly expanded. MIT, Stanford and Princeton University offer classes to a global audience, but not for college credit.  University-level programs, like edX founded by Massachusetts Institute of Technology and Harvard University, offer wide range of disciplines at no charge, while others permit students to audit a course at no charge but require a small fee for accreditation. MOOCs have not had a significant impact on higher education and declined after the initial expansion, but are expected to remain in some form. Lately, MOOCs are used by smaller universities to profile themselves with highly specialized courses for special-interest audiences, as for example in a course on technological privacy compliance.MOOCs have been observed to lose the majority of their initial course participants. In a study performed by Cornell and Stanford universities, student-drop-out rates from MOOCs have been attributed to student anonymity, the solitude of the learning experience and to the lack of interaction with peers and with teachers. Effective student engagement measures that reduce drop-outs are forum interactions and virtual teacher or teaching assistant presence - measures which induce staff cost that grows with the number of participating students.


=== Corporate and professional ===
E-learning is being used by companies to deliver mandatory compliance training and updates for regulatory compliance, soft skills and IT skills training, continuing professional development (CPD) and other valuable workplace skills. Companies with spread out distribution chains use e-learning for delivering information about the latest product developments. Most of corporate e-learning is asynchronous and delivered and managed via learning management systems. The big challenge in corporate e-learning is to engage the staff, especially on compliance topics for which periodic staff training is mandated by the law or regulations.


=== Government and public ===
There is an important need for recent, reliable, and high-quality health information to be made available to the public as well as in summarized form for public health providers. Providers have indicated the need for automatic notification of the latest research, a single searchable portal of information, and access to grey literature. The Maternal and Child Health (MCH) Library is funded by the U.S. Maternal and Child Health Bureau to screen the latest research and develop automatic notifications to providers through the MCH Alert. Another application in public health is the development of mHealth (use of mobile telecommunication and multimedia into global public health). MHealth has been used to promote prenatal and newborn services, with positive outcomes. In addition, ""Health systems have implemented mHealth programs to facilitate emergency medical responses, point-of-care support, health promotion and data collection.""
In low and middle-income countries, mHealth is most frequently used as one-way text messages or phone reminders to promote treatment adherence and gather data.


== Benefits ==
Effective technology use deploys multiple evidence-based strategies concurrently (e.g. adaptive content, frequent testing, immediate feedback, etc.), as do effective teachers. Using computers or other forms of technology can give students practice on core content and skills while the teacher can work with others, conduct assessments, or perform other tasks.  Through the use of educational technology, education is able to be individualized for each student allowing for better differentiation and allowing students to work for mastery at their own pace.Modern educational technology can improve access to education, including full degree programs. It enables better integration for non-full-time students, particularly in continuing education, and improved interactions between students and instructors. Learning material can be used for long-distance learning and are accessible to a wider audience. Course materials are easy to access. In 2010, 70.3% of American family households had access to the internet. In 2013, according to Canadian Radio Television and Telecommunications Commission Canada, 79% of homes have access to the internet. Students can access and engage with numerous online resources at home. Using online resources can help students spend more time on specific aspects of what they may be learning in school, but at home.  Schools like the Massachusetts Institute of Technology (MIT) have made certain course materials free online. Although some aspects of a classroom setting are missed by using these resources, they are helpful tools to add additional support to the educational system. The necessity to pay for transport to the educational facility is removed.
Students appreciate the convenience of e-learning, but report greater engagement in face-to-face learning environments. Colleges and universities are working towards combating this issue by utilizing WEB 2.0 technologies as well as incorporating more mentorships between students and faculty members.According to James Kulik, who studies the effectiveness of computers used for instruction, students usually learn more in less time when receiving computer-based instruction, and they like classes more and develop more positive attitudes toward computers in computer-based classes. Students can independently solve problems. There are no intrinsic age-based restrictions on difficulty level, i.e. students can go at their own pace. Students editing their written work on word processors improve the quality of their writing. According to some studies, the students are better at critiquing and editing written work that is exchanged over a computer network with students they know. Studies completed in ""computer intensive"" settings found increases in student-centric, cooperative and higher-order learning, writing skills, problem solving, and using technology. In addition, attitudes toward technology as a learning tool by parents, students and teachers are also improved.
Employers' acceptance of online education has risen over time. More than 50% of human resource managers SHRM surveyed for an August 2010 report said that if two candidates with the same level of experience were applying for a job, it would not have any kind of effect whether the candidate's obtained degree was acquired through an online or a traditional school. Seventy-nine percent said they had employed a candidate with an online degree in the past 12 months. However, 66% said candidates who get degrees online were not seen as positively as a job applicant with traditional degrees.The use of educational apps generally has a positive effect on learning. Pre- and post-tests have revealed that the use of educational apps on mobile devices reduces the achievement gap between struggling and average students. Some educational apps improve group work by allowing students to receive feedback on answers and promoting collaboration in solving problems. The benefits of app-assisted learning have been exhibited in all age groups. Kindergarten students that use iPads show much higher rates of literacy than non-users.  Medical students at University of California Irvine that utilized iPad academically have been reported to score 23% higher on national exams than previous classes that did not.


== Disadvantages ==
Globally, factors like change management, technology obsolescence and vendor- developer partnership are major restraints that are hindering the growth of Educational technology market.In US, state and the federal government increased funding, as well as private venture capital has been flowing into education sector. However, as of 2013, none were looking at technology return on investment (ROI) to connect expenditures on technology with improved student outcomes.New technologies are frequently accompanied by unrealistic hype and promise regarding their transformative power to change education for the better or in allowing better educational opportunities to reach the masses. Examples include silent film, broadcast radio, and television, none of which have maintained much of a foothold in the daily practices of mainstream, formal education. Technology, in and of itself, does not necessarily result in fundamental improvements to educational practice. The focus needs to be on the learner's interaction with technology—not the technology itself. It needs to be recognized as ""ecological"" rather than ""additive"" or ""subtractive"". In this ecological change, one significant change will create total change.According to Branford et al., ""technology does not guarantee effective learning,"" and inappropriate use of technology can even hinder it. A University of Washington study of infant vocabulary shows that it is slipping due to educational baby DVDs. Published in the Journal of Pediatrics, a 2007 University of Washington study on the vocabulary of babies surveyed over 1,000 parents in Washington and Minnesota. The study found that for every one hour that babies 8–16 months of age watched DVDs and Videos, they knew 6-8 fewer of 90 common baby words than the babies that did not watch them. Andrew Meltzoff, a surveyor in this study, states that the result makes sense, that if the baby's ""alert time"" is spent in front of DVDs and TV, instead of with people speaking, the babies are not going to get the same linguistic experience. Dr. Dimitri Chistakis, another surveyor reported that the evidence is mounting that baby DVDs are of no value and may be harmful.Adaptive instructional materials tailor questions to each student's ability and calculate their scores, but this encourages students to work individually rather than socially or collaboratively (Kruse, 2013). Social relationships are important, but high-tech environments may compromise the balance of trust, care and respect between teacher and student.Massively open online courses (MOOCs), although quite popular in discussions of technology and education in developed countries (more so in the US), are not a major concern in most developing or low-income countries. One of the stated goals of MOOCs is to provide less fortunate populations (i.e., in developing countries) an opportunity to experience courses with US-style content and structure. However, research shows only 3% of the registrants are from low-income countries and although many courses have thousands of registered students only 5-10% of them complete the course.  MOOCs also implies that certain curriculum and teaching methods are superior, and this could eventually wash over (or possibly washing out) local educational institutions, cultural norms and educational traditions.With the Internet and social media, using educational apps makes the students highly susceptible to distraction and sidetracking. Even though proper use has shown to increase student performances, being distracted would be detrimental. Another disadvantage is an increased potential for cheating. Smartphones can be very easy to hide and use inconspicuously, especially if their use is normalized in the classroom. These disadvantages can be managed with strict rules and regulations on mobile phone use.


=== Over-stimulation ===
Electronic devices such as cellphones and computers facilitate rapid access to a stream of sources, each of which may receive cursory attention. Michel Rich, an associate professor at Harvard Medical School and executive director of the center on Media and Child Health in Boston, said of the digital generation, ""Their brains are rewarded not for staying on task, but for jumping to the next thing. The worry is we're raising a generation of kids in front of screens whose brains are going to be wired differently."" Students have always faced distractions; computers and cellphones are a particular challenge because the stream of data can interfere with focusing and learning. Although these technologies affect adults too, young people may be more influenced by it as their developing brains can easily become habituated to switching tasks and become unaccustomed to sustaining attention. Too much information, coming too rapidly, can overwhelm thinking.Technology is ""rapidly and profoundly altering our brains.""  High exposure levels stimulate brain cell alteration and release neurotransmitters, which causes the strengthening of some neural pathways and weakening of others. This leads to heightened stress levels on the brain that, at first, boost energy levels, but, over time, actually augment memory, impair cognition, lead to depression, alter the neural circuitry of the hippocampus, amygdala and prefrontal cortex. These are the brain regions that control mood and thought. If unchecked, the underlying structure of the brain could be altered. Over-stimulation due to technology may begin too young. When children are exposed before the age of seven, important developmental tasks may be delayed, and bad learning habits might develop, which ""deprives children of the exploration and play that they need to develop."" Media psychology is an emerging specialty field that embraces electronic devices and the sensory behaviors occurring from the use of educational technology in learning.


=== Sociocultural criticism ===
According to Lai, ""the learning environment is a complex system where the interplay and interactions of many things impact the outcome of learning."" When technology is brought into an educational setting, the pedagogical setting changes in that technology-driven teaching can change the entire meaning of an activity without adequate research validation. If technology monopolizes an activity, students can begin to develop the sense that ""life would scarcely be thinkable without technology.""Leo Marx considered the word ""technology"" itself as problematic, susceptible to reification and ""phantom objectivity"", which conceals its fundamental nature as something that is only valuable insofar as it benefits the human condition.  Technology ultimately comes down to affecting the relations between people, but this notion is obfuscated when technology is treated as an abstract notion devoid of good and evil.  Langdon Winner makes a similar point by arguing that the underdevelopment of the philosophy of technology leaves us with an overly simplistic reduction in our discourse to the supposedly dichotomous notions of the ""making"" versus the ""uses"" of new technologies and that a narrow focus on ""use"" leads us to believe that all technologies are neutral in moral standing.  These critiques would have us ask not, ""How do we maximize the role or advancement of technology in education?"", but, rather, ""What are the social and human consequences of adopting any particular technology?""
Winner viewed technology as a ""form of life"" that not only aids human activity, but that also represents a powerful force in reshaping that activity and its meaning. For example, the use of robots in the industrial workplace may increase productivity, but they also radically change the process of production itself, thereby redefining what is meant by ""work"" in such a setting.  In education, standardized testing has arguably redefined the notions of learning and assessment. We rarely explicitly reflect on how strange a notion it is that a number between, say, 0 and 100 could accurately reflect a person's knowledge about the world. According to Winner, the recurring patterns in everyday life tend to become an unconscious process that we learn to take for granted.  Winner writes,

By far, the greatest latitude of choice exists the very first time a particular instrument, system, or technique is introduced.  Because choices tend to become strongly fixed in material equipment, economic investment, and social habit, the original flexibility vanishes for all practical purposes once the initial commitments are made.  In that sense, technological innovations are similar to legislative acts or political foundings that establish a framework for public order that will endure over many generations. (p. 29) 
When adopting new technologies, there may be one best chance to ""get it right."" Seymour Papert (p. 32) points out a good example of a (bad) choice that has become strongly fixed in social habit and material equipment: our ""choice"" to use the QWERTY keyboard. The QWERTY arrangement of letters on the keyboard was originally chosen, not because it was the most efficient for typing, but because early typewriters were prone to jam when adjacent keys were struck in quick succession.  Now that typing has become a digital process, this is no longer an issue, but the QWERTY arrangement lives on as a social habit, one that is very difficult to change.
Neil Postman endorsed the notion that technology impacts human cultures, including the culture of classrooms, and that this is a consideration even more important than considering the efficiency of a new technology as a tool for teaching.  Regarding the computer's impact on education, Postman writes (p. 19):

What we need to consider about the computer has nothing to do with its efficiency as a teaching tool.  We need to know in what ways it is altering our conception of learning, and how in conjunction with television, it undermines the old idea of school.There is an assumption that technology is inherently interesting so it must be helpful in education; based on research by Daniel Willingham, that is not always the case.  He argues that it does not necessarily matter what the technological medium is, but whether or not the content is engaging and utilizes the medium in a beneficial way.


==== Digital divide ====

The concept of the digital divide is a gap between those who have access to digital technologies and those who do not. Access may be associated with age, gender, socio-economic status, education, income, ethnicity, and geography.


=== Data protection ===
According to a report by the Electronic Frontier Foundation, large amounts of personal data on children are collected by electronic devices that are distributed in schools in the United States. Often, far more information than necessary is collected, uploaded and stored indefinitely. Aside name and date of birth, this information can include the child's browsing history, search terms, location data, contact lists, as well as behavioral information. Parents are not informed or, if informed, have little choice. According to the report, this constant surveillance resulting from educational technology can ""warp children's privacy expectations, lead them to self-censor, and limit their creativity"". In a 2018 public service announcement, the FBI warned that widespread collection of student information by educational technologies, including web browsing history, academic progress, medical information, and biometrics, created the potential for privacy and safety threats if such data was compromised or exploited.


== Teacher training ==
Since technology is not the end goal of education, but rather a means by which it can be accomplished, educators must have a good grasp of the technology and its advantages and disadvantages. Teacher training aims for effective integration of classroom technology.The evolving nature of technology may unsettle teachers, who may experience themselves as perpetual novices. Finding quality materials to support classroom objectives is often difficult. Random professional development days are inadequate.According to Jenkins, ""Rather than dealing with each technology in isolation, we would do better to take an ecological approach, thinking about the interrelationship among different communication technologies, the cultural communities that grow up around them, and the activities they support."" Jenkins also suggested that the traditional school curriculum guided teachers to train students to be autonomous problem solvers. However, today's workers are increasingly asked to work in teams, drawing on different sets of expertise, and collaborating to solve problems. Learning styles and the methods of collecting information have evolved, and ""students often feel locked out of the worlds described in their textbooks through the depersonalized and abstract prose used to describe them"". These twenty-first century skills can be attained through the incorporation and engagement with technology. Changes in instruction and use of technology can also promote a higher level of learning among students with different types of intelligence.


== Assessment ==

There are two distinct issues of assessment: the assessment of educational technology  and assessment with technology.Assessments of educational technology have included the Follow Through project.
Educational assessment with technology may be either formative assessment or summative assessment. Instructors use both types of assessments to understand student progress and learning in the classroom. Technology has helped teachers create better assessments to help understand where students who are having trouble with the material are having issues.
Formative assessment is more difficult, as the perfect form is ongoing and allows the students to show their learning in different ways depending on their learning styles. Technology has helped some teachers make their formative assessments better, particularly through the use of classroom response systems (CRS). A CRS is a tool in which the students each have a handheld device that partners up with the teacher's computer. The instructor then asks multiple choice or true or false questions and the students answer on their device. Depending on the software used, the answers may then be shown on a graph so students and teacher can see the percentage of students who gave each answer and the teacher can focus on what went wrong.Summative assessments are more common in classrooms and are usually set up to be more easily graded, as they take the form of tests or projects with specific grading schemes.  One huge benefit to tech-based testing is the option to give students immediate feedback on their answers. When students get these responses, they are able to know how they are doing in the class which can help push them to improve or give them confidence that they are doing well. Technology also allows for different kinds of summative assessment, such as digital presentations, videos, or anything else the teacher/students may come up with, which allows different learners to show what they learned more effectively. Teachers can also use technology to post graded assessments online for students to have a better idea of what a good project is.
Electronic assessment uses information technology. It encompasses several potential applications, which may be teacher or student-oriented, including educational assessment throughout the continuum of learning, such as computerized classification testing, computerized adaptive testing, student testing, and grading an exam. E-Marking is an examiner led activity closely related to other e-assessment activities such as e-testing, or e-learning which are student-led. E-marking allows markers to mark a scanned script or online response on a computer screen rather than on paper.
There are no restrictions on the types of tests that can use e-marking, with e-marking applications designed to accommodate multiple choice, written, and even video submissions for performance examinations. E-marking software is used by individual educational institutions and can also be rolled out to the participating schools of awarding exam organisations. e-marking has been used to mark many well known high stakes examinations, which in the United Kingdom include  A levels and GCSE exams, and in the US includes the SAT test for college admissions. Ofqual reports that e-marking is the main type of marking used for general qualifications in the United Kingdom.
In 2014, the Scottish Qualifications Authority (SQA) announced that most of the National 5 question papers would be e-marked.In June 2015, the Odisha state government in India announced that it planned to use e-marking for all Plus II papers from 2016.


== Analytics ==
The importance of self-assessment through tools made available on Educational Technology platforms has been growing. Self-assessment in education technology relies on students analyzing their strengths, weaknesses and areas where improvement is possible to set realistic goals in learning, improve their educational performances and track their progress. One of the unique tools for self-assessment made possible by education technology is Analytics. Analytics is data gathered on the student's activities on the learning platform, drawn into meaningful patterns that lead to a valid conclusion, usually through the medium of data visualization such as graphs. Learning analytics is the field that focuses on analyzing and reporting data about student's activities in order to facilitate learning.


== Expenditure ==
The five key sectors of the e-learning industry are consulting, content, technologies, services and support. Worldwide, e-learning was estimated in 2000 to be over $48 billion according to conservative estimates. Commercial growth has been brisk. In 2014, the worldwide commercial market activity was estimated at $6 billion venture capital over the past five years, with self-paced learning generating $35.6 billion in 2011. North American e-learning generated $23.3 billion in revenue in 2013, with a 9% growth rate in cloud-based authoring tools and learning platforms.


== Careers ==

Educational technologists and psychologists apply basic educational and psychological research into an evidence-based applied science (or a technology) of learning or instruction. In research, these professions typically require a graduate degree (Master's, Doctorate, Ph.D., or D.Phil.) in a field related to educational psychology, educational media, experimental psychology, cognitive psychology or, more purely, in the fields of educational, instructional or human performance technology or instructional design. In industry, educational technology is utilized to train students and employees by a wide range of learning and communication practitioners, including instructional designers, technical trainers, technical communication and professional communication specialists, technical writers, and of course primary school and college teachers of all levels. The transformation of educational technology from a cottage industry to a profession is discussed by Shurville et al.


== See also ==

Mobile learning for refugees


== References ==


== External links ==
 Media related to Educational technology at Wikimedia Commons"
"ETH Zurich (Swiss Federal Institute of Technology in Zurich; German: Eidgenössische Technische Hochschule Zürich; French: École polytechnique fédérale de Zurich; Italian: Politecnico federale di Zurigo) is a public research university in the city of Zürich, Switzerland. Founded by the Swiss Federal Government in 1854 with the stated mission to educate engineers and scientists, the school focuses exclusively on science, technology, engineering and mathematics. Like its sister institution EPFL, it is part of the Swiss Federal Institutes of Technology Domain (ETH Domain), part of the Swiss Federal Department of Economic Affairs, Education and Research.In the 2021 edition of the QS World University Rankings ETH Zurich is ranked 6th in the world, and 2nd in Europe and 8th by the Times Higher Education World Rankings 2020.   In the 2020 QS World University Rankings by subject it is ranked 4th in the world for engineering and technology (2nd in Europe) and 1st for earth & marine science.As of November 2019, 21 Nobel laureates, 2 Fields Medalists, 2 Pritzker Prize winners, and 1 Turing Award winner have been affiliated with the Institute, including Albert Einstein. It is a founding member of the IDEA League and the International Alliance of Research Universities (IARU) and a member of the CESAER network.


== History ==

ETH was founded on 7 February 1854 by the Swiss Confederation and began giving its first lectures on 16 October 1855 as a polytechnic institute (eidgenössische polytechnische Schule) at various sites throughout the city of Zurich. It was initially composed of six faculties: architecture, civil engineering, mechanical engineering, chemistry, forestry, and an integrated department for the fields of mathematics, natural sciences, literature, and social and political sciences.
It is locally still known as Polytechnikum, or simply as Poly, derived from the original name eidgenössische polytechnische Schule, which translates to ""federal polytechnic school"".
ETH is a federal institute (i.e., under direct administration by the Swiss government), whereas the University of Zurich is a cantonal institution. The decision for a new federal university was heavily disputed at the time; the liberals pressed for a ""federal university"", while the conservative forces wanted all universities to remain under cantonal control, worried that the liberals would gain more political power than they already had. In the beginning, both universities were co-located in the buildings of the University of Zurich.
From 1905 to 1908, under the presidency of Jérôme Franel, the course program of ETH was restructured to that of a real university and ETH was granted the right to award doctorates. In 1909 the first doctorates were awarded. In 1911, it was given its current name, Eidgenössische Technische Hochschule. In 1924, another reorganization structured the university in 12 departments. However, it now has 16 departments.

ETH Zurich, the EPFL, and four associated research institutes form the ""ETH Domain"" with the aim of collaborating on scientific projects.


== Reputation and ranking ==
ETH Zurich is ranked among the top universities in the world. Typically, popular rankings place the institution as the best university in continental Europe and ETH Zurich is consistently ranked among the top 1-5 universities in Europe, and among the top 3-10 best universities of the world.
Historically, ETH Zurich has achieved its reputation particularly in the fields of chemistry, mathematics and physics. There are 32 Nobel laureates who are associated with ETH, the most recent of whom is Richard F. Heck, awarded the Nobel Prize in chemistry in 2010. Albert Einstein is perhaps its most famous alumnus.In 2018, the QS World University Rankings placed ETH Zurich at 7th overall in the world. In 2015, ETH was ranked 5th in the world in Engineering, Science and Technology, just behind the Massachusetts Institute of Technology, Stanford University and Cambridge University. In 2015, ETH also ranked 6th in the world in Natural Sciences, and in 2016 ranked 1st in the world for Earth & Marine Sciences for the second consecutive year.In 2016, Times Higher Education World University Rankings ranked ETH Zurich 9th overall in the world and 8th in the world in the field of Engineering & Technology, just behind the Massachusetts Institute of Technology, Stanford University, California Institute of Technology, Princeton University, Cambridge University, Imperial College London and Oxford University.In a comparison of Swiss universities by swissUP Ranking and in rankings published by CHE comparing the universities of German-speaking countries, ETH Zurich traditionally is ranked first in natural sciences, computer science and engineering sciences.
In the survey CHE ExcellenceRanking on the quality of Western European graduate school programmes in the fields biology, chemistry, physics and mathematics, ETH was assessed as one of the three institutions to have excellent graduate programmes in all considered fields, the other two being Imperial College London and the University of Cambridge. ETH Zurich had a total budget of 1.885 billion CHF in the year 2017.


== Admission and education ==

For Swiss students, ETH is not selective in its undergraduate admission procedures. Like every public university in Switzerland, ETH is obliged to grant admission to every Swiss resident who took the Matura. Applicants from foreign countries are required to take either the reduced entrance exam or the comprehensive entrance exam although some applicants from several European countries are exempted from this rule. An applicant can be admitted to ETH even without any verifiable educational records by passing the comprehensive entrance exam.As at all universities in Switzerland, the academic year is divided into two semesters. Examinations are often held during examination sessions which are immediately before the beginning of the next semester (only a few select courses offer an exam immediately after the semester ends). After the first year of study, bachelor students must pass a block examination of all courses taken in the first year, called the Basisprüfung (basis examination). If the weighted average score is not sufficient, a student is required to retake the entire Basisprüfung which usually means having to re-sit the whole first year. About 50% of the students fail the Basisprüfung on the first try and many of them choose to drop out of the course instead of repeating the Basisprüfung.
The structure of examinations in higher academic years is similar to the Basisprüfung, but with a higher success rate.
The regular time to reach graduation is six semesters for the Bachelor of Science degree and three or four further semesters for the Master of Science degree. The final semester is dedicated to writing a thesis.
Education at ETH Zurich generally focuses more on theoretical aspects than application and most degree programs contain a high amount of mathematical training. The main language of instruction in undergraduate (Bachelor) studies is German and for admission a proof of sufficient knowledge of the German language is required for Bachelor students. Most Master's programmes and doctoral studies are in English.


== Campus ==

ETH Zurich has two campuses. The main building was constructed 1858–1864 outside and right above the eastern border of the town, but nowadays it is located right in the heart of the city. As the town and university grew, the ETH spread into the surrounding vineyards and later quarters. As a result, the Zentrum campus consists of various buildings and institutions throughout Zürich and firmly integrates the ETH in the city. The main building stands directly across the street from the University Hospital of Zurich and the University of Zurich.
Because this geographic situation substantially hindered the expansion of ETH, a new campus was built from 1964 to 1976 on the Hönggerberg on a northern hill in the outskirts of the city. The last major expansion project of this new campus was completed in 2003; since then, the Hönggerberg location houses the departments of architecture, civil engineering, biology, chemistry, materials science and physics.


=== Main building ===

The main building of ETH was built from 1858 to 1864 under Gustav Zeuner; the architect, however, was Gottfried Semper, who was a professor of architecture at ETH at the time and one of the most important architectural writers and theorists of the age. Semper worked in a neoclassical style that was unique to him; and the namesake and architect of the Semperoper in Dresden. It emphasized bold and clear massings with a detailing, such as the rusticated ground level and giant order above, that derived in part from the work of Andrea Palladio and Donato Bramante. During the construction of the University of Zürich, the south wing of the building was allocated to the University until its own new main building was constructed (1912–1914). At about the same time, Semper's ETH building was enlarged and received its impressive cupola.


=== Science City ===
In the year of ETH Zurich's 150th anniversary, an extensive project called ""Science City"" for the Hönggerberg Campus was started with the goal to transform the campus into an attractive district based on the principle of sustainability.

In September 2014 a new project to connect Science City by train was published.


==== ETH Laboratory of Ion Beam Physics ====
The ETH Laboratory of Ion Beam Physics (LIB) is a physics laboratory located in Science City. It specializes in accelerator mass spectrometry (AMS) and the use of ion beam based techniques with applications in archeology, earth sciences, life sciences, material sciences and fundamental physics. An example of such application is the tracing of isotopes and the detection of rare radionuclides with radiocarbon dating and the use of techniques such as Rutherford backscattering spectrometry or elastic recoil detection. The LIB is developing the next generation of AMS machines. It is also a laboratory available for users interested in applying the techniques of ion beam analysis.


== Student life ==
ETH students were found to be the busiest students of all institutions of higher education in Switzerland. The undergraduates' tight curriculum consists of as much as twice the number of lectures as comparable courses of other Swiss universities.ETH has well over 100 student associations. Most notable is the VSETH (Verband der Studierenden an der ETH) which comprises all department associations. The associations regularly organize events with varying size and popularity. Events of the neighboring University of Zürich are well-attended by ETH students and vice versa. The VSETH organizes events of greater public attention, such as the Polyball, the Polyparty (does not exist any more) and the Erstsemestrigenfest, the first two housed in the main building of ETH. Sometimes, the annual Erstsemestrigenfest takes place at extraordinary locations, for example the Zurich Airport. All freshmen enjoy special treatment at that event.
Some of the notable associations that are not affiliated with a specific department are the ETH Entrepreneur Club and ETH Model United Nations. Both organisations enjoy high international standings and are regularly awarded for excellence in their field. ETH Juniors is another student-run organisation. It forms a bridge between industry and the ETH and offers many services for students and companies alike.The Academic Sports Association of Zürich (ASVZ) offers more than 120 sports. The biggest annual sports event is the SOLA-Stafette (SOLA relay race) which consists of 14 sections over a total distance of 140 kilometers. More than 760 teams participated in the 2009 edition. The 40th edition of the SOLA, held on 4 May 2013, had 900 enrolled teams, of which 893 started and 876 were classified. In 2014 ASVZ celebrated their 75th anniversary.


== Traditions ==
The annual Polyball is the most prestigious public event at ETH, with a long tradition since the 1880s. At the end of November, the Polyball welcomes around 10,000 dancers, music-lovers and partygoers in the extensively decorated main building of ETH. This is the biggest decorated ball in Europe.
The amicable rivalry between ETH and the neighbouring University of Zürich has been cultivated since 1951 (Uni-Poly). There has been an annual rowing match between teams from the two institutions on the river Limmat.
There are many regular symposia and conferences at ETH, most notably the annual Wolfgang Pauli Lectures, in honor of former ETH Professor Wolfgang Pauli. Distinct lecturers, among them 24 Nobel laureates, have held lectures of the various fields of natural sciences at this conference since 1962.


== Notable alumni and faculty ==

The names listed below are taken from the official record compiled by the ETH. It includes only graduates of the ETH and professors who have been awarded the Nobel Prize for their achievements at ETH.


=== Nobel Prize in Physics ===
1901 Wilhelm Conrad Röntgen (graduate)
1920 Charles-Edouard Guillaume (graduate)
1921 Albert Einstein (student and professor)
1943 Otto Stern (lecturer)
1945 Wolfgang Pauli (professor)
1952 Felix Bloch (graduate)
1986 Heinrich Rohrer (graduate)
1987 Georg Bednorz (graduate)
1987 Karl Alexander Müller (graduate)


=== Nobel Prize in Chemistry ===
1913 Alfred Werner (graduate)
1915 Richard Martin Willstätter (professor)
1918 Fritz Haber (attended for one semester)
1936 Peter Debye (professor)
1938 Richard Kuhn (professor)
1939 Leopold Ružička (professor)
1953 Hermann Staudinger (lecturer)
1975 Vladimir Prelog (professor)
1991 Richard Ernst (graduate and professor)
2002 Kurt Wüthrich (professor)
2010 Richard F. Heck (postdoctoral student)


=== Nobel Prize in Medicine ===
1950 Tadeus Reichstein (graduate)
1978 Werner Arber (graduate)


=== Other Nobel laureates directly affiliated with the ETH ===
1912 Nils Gustaf Dalén (in collaboration with Aurel Stodola)
1943 George de Hevesy
1945 Artturi Ilmari Virtanen (in collaboration with Georg Wiegner)
1954 Max Born (in collaboration with Adolf Hurwitz)
1964 Konrad E. Bloch (in collaboration with Leopold Ružička and Vladimir Prelog)
1968 Lars Onsager (in collaboration with Peter Debye and Erich Hückel)
1968 Har Gobind Khorana (in collaboration with Vladimir Prelog)
1969 Max Delbrück (in collaboration with Wolfgang Pauli)
1987 Jean-Marie Lehn


=== ETH rectors ===
Sarah Springman 1 January 2015
Lino Guzzella 2013 – 31 December 2014
Heidi Wunderli-Allenspach September 2007 - August 2013
Konrad Osterwalder 1995 - September 2007
Albin Herzog 1895-1899


=== ETH presidents ===
Joël Mesot January 2019
Lino Guzzella January 2015 - December 2018
Ralph Eichler September 2007 – December 2014
Konrad Osterwalder President Pro Tempore November 2006 – September 2007
Ernst Hafen December 2005 – November 2006ETH Zurich has produced and attracted many famous scientists in its short history, including Albert Einstein. More than twenty Nobel laureates have either studied at ETH or were awarded the Nobel Prize for their work achieved at ETH. Other alumni include scientists who were distinguished with the highest honours in their respective fields, amongst them Fields Medal, Pritzker Prize and Turing Award winners. Academic achievements aside, ETH has been alma mater to many Olympic medalists and world champions.


== Related organizations ==


=== Collegium Helveticum ===
The Collegium Helveticum is an Institute for Advanced Study.  It is jointly supported and operated by the ETH Zurich, the University of Zurich and the Zurich University of the Arts. It is dedicated to transdisciplinary research and acts as a think tank as well. Fellows are elected for five years to work together on a particular subject. For the period 2016–2020, the research focus is on digital societies.


=== ETH Zurich Foundation ===
The ETH Zurich Foundation is a legal entity on its own (a Swiss non-profit foundation) and as such not part of the ETH Zurich. Its purpose is to raise funds to support chosen institutes, projects, faculty and students at the ETH Zurich. It receives charitable donations from companies, foundations and private individuals. It can be compared with university endowments in the USA. However, the ETH Zurich is a public university so that the funds of this foundation are much smaller than at comparable private universities.  
Examples of funded teaching and research are:
New institutes such as the Wyss Translational Center Zurich
Additional professorships
Rössler Prize
Pioneer fellowships
Excellence scholarships


=== Military Academy ===
The Military Academy is an institution for the education, training and development of career officers of the Swiss Armed Forces. The scientific part of this organization is attached to the ETH Zurich, while other parts such as training and an assessment center are under the direct management of the defence sector of the Swiss Federal Government.


=== Swiss National Supercomputing Center ===
The Swiss National Supercomputing Centre is an autonomous organizational unit of the ETH Zurich. It is a national facility based in Lugano-Cornaredo, offering high-performance computing services for Swiss-based scientists.


== Gallery ==

		
		
		


== See also ==

École Polytechnique Fédérale de Lausanne (Swiss Federal Institute of Technology in Lausanne, EPFL)
Engineering
Laboratory for Energy Conversion
List of universities in Switzerland
List of largest universities by enrollment in Switzerland
List of forestry universities and colleges
Science and technology in Switzerland
2000-watt society
Disney Research
e-rara.ch
Swiss Electromagnetics Research and Engineering Centre
ETH Zurich University Archives
Category:ETH Zurich alumni
Category:ETH Zurich faculty


== Notes and references ==


== Further reading ==
David Gugerli, Patrick Kupper, Daniel Speich (2005), Die Zukunftsmaschine. Konjunkturen der ETH Zürich 1855-2005. (in German), Zurich, Switzerland: CHRONOS – via www.ethistory.ethz.chCS1 maint: uses authors parameter (link)


== External links ==
Official website"
"Financial technology (abbreviated fintech or FinTech) is the technology and innovation that aims to compete with traditional financial methods in the delivery of financial services. It is an emerging industry that uses technology to improve activities in finance. The use of smartphones for mobile banking, investing, borrowing services, and cryptocurrency are examples of technologies aiming to make financial services more accessible to the general public. Financial technology companies consist of both startups and established financial institutions and technology companies trying to replace or enhance the usage of financial services provided by existing financial companies.


== Definition ==
After reviewing more than 200 scientific papers citing the term ""fintech,"" a study on the definition of fintech concluded that ""fintech is a new financial industry that applies technology to improve financial activities.""  Fintech is the new applications, processes, products, or business models in the financial services industry, composed of one or more complementary financial services and provided as an end-to-end process via the Internet. Fintech can also be considered as “any innovative ideas that improve financial service processes by proposing technology solutions according to different business situations, while the ideas could also lead to new business models or even new businesses."" 


== Key areas ==
Financial technology has been used to automate investments, insurance, trading, banking services and risk management.The services may originate from various independent service providers including at least one licensed bank or insurer. The interconnection is enabled through open APIs and open banking and supported by regulations such as the European Payment Services Directive.
In trading on capital markets, innovative electronic trading platforms facilitate trades online and in real time. Social trading networks allow investors to observe the trading behavior of their peers and expert traders and to follow their investment strategies on currency exchange and capital markets. The platforms require little or no knowledge about financial markets, and have been described as disruptors which provide ""a low-cost, sophisticated alternative to traditional wealth managers"" by the World Economic Forum.Robo-advisers are a class of automated financial adviser that provide financial advice or investment management online with moderate to minimal human intervention. They provide digital financial advice based on mathematical rules or algorithms, and thus can provide a low-cost alternative to a human advisers.
Global investment in financial technology increased more than 2,200% from $930 million in 2008 to more than $22 billion in 2015. The nascent financial technology industry in London has seen rapid growth over the last few years, according to the office of the Mayor of London. Forty percent of the City of London's workforce is employed in financial and technology services.In Europe, $1.5 billion was invested in financial technology companies in 2014, with London-based companies receiving $539 million, Amsterdam-based companies $306 million, and Stockholm-based companies receiving $266 million in investment. After London, Stockholm is the second highest funded city in Europe in the past 10 years. Europe's fintech deals reached a five-quarter high, rising from 37 in Q4 2015 to 47 in Q1 2016. Lithuania is starting to become a northern European hub for financial technology companies since the news in 2016 about the possible exit of Britain from the European Union. Lithuania has issued 51 fintech licenses since 2016, 32 of those in 2017. Fintech companies in the United States raised $12.4 billion in 2018, a 43% increase over 2017 figures. In the Asia Pacific region, the growth will see a new financial technology hub to be opened in Sydney, in April 2015. According to KPMG, Sydney's financial services sector in 2017 creates 9 per cent of national GDP and is bigger than the financial services sector in either Hong Kong or Singapore. A financial technology innovation lab was launched in Hong Kong in 2015.  In 2015, the Monetary Authority of Singapore launched an initiative named Fintech and Information Group to draw in start-ups from around the world. It pledged to spend $225 million in the fintech sector over the next five years.While Singapore has been one of the central Fintech hubs in Asia, start ups in the sector from Vietnam and Indonesia have been attracting more venture capital investments in recent years. Since 2014, Southeast Asian Fintech companies have increased VC funding from $35 million to $679 million in 2018 and $1.14 billion in 2019.Fintech start-ups around the world have been noted for their innovation, creativity, and cutting-edge work styles, and as a result these aspects have worked their way into each workplaces’ culture. This emphasis on collaboration and alliance has resulted in workplaces where afternoon office happy hours occur every Friday, in-office yoga classes are offered to help relieve employees’ stress, and other engaging activities are hosted. These environments are not only fun for employees, but build a more productive and friendly workplace that enhance company performance.  What makes fintech’s workplace culture especially unique is the methods used to preserve this special environment, which is through the hiring process. There are three key ways fintech start-ups maintain this state-of-the-art culture through their hiring process: involving the whole crew, being consistent, and clarifying their mission. By allowing multiple departments to have a say in who is hired and making their mission clear to all prospective employees, start-ups are able to attract prospects who hold the same values and goals as the company itself.  The unique workplace culture fintech startups operate around gives fintech an edge over traditional banking and explains why fintech is the future of the financial industry.


== Technologies ==
Within the financial services industry, some of the used technologies include artificial intelligence (AI), big data, robotic process automation (RPA), and blockchain.
Artificial Intelligence is a blanket term for many different technologies. In terms of the ""fintech"" industry, AI is used in various forms. AI algorithms can be used to predict changes in the stock market and give insight into the economy. AI is used to provide insight on customer spending habits and allows financial institutions to better understand their clients. Chatbots are another AI-driven tool that banks are starting to use to help with customer service.Big Data is another ""fintech"" technology that financial institutions utilize. In the finance sector, big data can be used to predict client investments and market changes and create new strategies and portfolios. Big Data can be used to analyze customer spending habits and therefore improve fraud detection. Big Data helps banks create segmented marketing strategies and can be used to optimize the operations of a company.Robotic Process Automation is an artificial intelligence technology that focuses on automating specific repetitive tasks. In terms of ""fintech"", RPA is used to perform manual tasks that often are repetitive and completed daily. These tasks just involve the input of information into a system and do not require much skill thus companies are replacing them with RPA which can complete the task quicker and more efficiently. RPA helps to process financial information such as accounts payable and receivable more efficiently than the manual process and often more accurately. RPA can be used to increase the productivity of the financial company.Blockchain is another financial technology that is beginning to be used in the industry. Out of all the ""fintech"" technologies, blockchain was developed for the purposes of finance and thus has direct ties to financial institutions. Though blockchain is still an emerging technology, many companies recognize the impact that it will have and are investing accordingly.


== Awards and recognition ==
Financial magazine Forbes created a list of the leading disruptors in financial technology for its Forbes 2019 global Fintech 50. In Europe there is a list called the FinTech 50, which aims to recognise the most innovative companies in fintech.A report published in February 2016 by EY commissioned by the UK Treasury compared seven leading fintech hubs: the United Kingdom, California, New York City, Singapore, Germany, Australia and Hong Kong. It ranked California first for 'talent' and 'capital', the United Kingdom first for 'government policy' and New York City first for 'demand'.For the past few years, PwC has posted a report called the ""Global Fintech Report"". In the 2019, the report covers many topics revolving around the financial technology sector. The report discusses the landscape of the ""Fintech"" industry and some of the emerging technologies in the sector. It provides strategies for financial institutions on how to incorporate more ""fintech"" technologies into their business. 


== Outlook ==
Finance is seen as one of the industries most vulnerable to disruption by software because financial services, much like publishing, are made of information rather than concrete goods. In particular blockchains have the potential to reduce the cost of transacting in a financial system.  While finance has been shielded by regulation until now, and weathered the dot-com boom without major upheaval, a new wave of startups is increasingly ""disaggregating"" global banks. However, aggressive enforcement of the Bank Secrecy Act and money transmission regulations represents an ongoing threat to fintech companies. In response, the International Monetary Fund (IMF) and the World Bank jointly presented Bali Fintech Agenda on October 11, 2018 which consists of 12 policy elements acting as a guidelines for various governments and central banking institutions to adopt and deploy ""rapid advances in financial technology"".The New York Venture Capital Association (NYVCA) hosts annual summits to educate those interested in learning more about fintech. In 2018 alone, fintech was responsible for over 1,700 deals worth over 40 billion dollars.


== Challenges and solutions ==
In addition to established competitors, fintech companies often face doubts from financial regulators like issuing banks and the Federal Government. In July 2018, the Trump Administration issued a policy statement that allowed FinTech companies to apply for special purpose national bank charters from the federal Office of the Comptroller of the Currency. Federal preemption applies to state law regarding federally chartered banks.Data security is another issue regulators are concerned about because of the threat of hacking as well as the need to protect sensitive consumer and corporate financial data. Leading global fintech companies are proactively turning to cloud technology to meet increasingly stringent compliance regulations.The Federal Trade Commission provides free resources for corporations of all sizes to meet their legal obligations of protecting sensitive data. Several private initiatives suggest that multiple layers of defense can help isolate and secure financial data.In the European Union, fintech companies must adhere to data protection laws, such as GDPR. Companies need to proactively protect users and companies data or face fines of 20 million euros, or in the case of an undertaking, up to 4% of their total global turnover. In addition to GDPR, European financial institutions including fintech firms have to update their regulatory affairs departments with the Payment Services Directive (PSD2), meaning they must organise their revenue structure around a central goal of privacy.Any data breach, no matter how small, can result in direct liability to a company (see the Gramm–Leach–Bliley Act) and ruin a fintech company's reputation.The online financial sector is also an increasing target of distributed denial of service extortion attacks. This security challenge is also faced by historical bank companies since they do offer Internet-connected customer services.


== See also ==
Smart contract


== References and notes ==


== Further reading ==
Teigland, R., Siri, S., Larsson, A., Puertas, A. M., & Bogusz, C. I. (Eds.) (2018). The Rise and Development of FinTech (Open Access): Accounts of Disruption from Sweden and Beyond. Routledge. ISBN 9780815378501.CS1 maint: multiple names: authors list (link) CS1 maint: extra text: authors list (link) Media related to Financial technology at Wikimedia Commons"
"The Indian Institutes of Technology (IITs) are autonomous public technical and research universities located across India. They are governed by the Institutes of Technology Act, 1961, which has declared them as institutions of national importance and lays down their powers, duties, and framework for governance. The Institutes of Technology Act, 1961 lists twenty-three institutes. Each IIT is autonomous, linked to the others through a common council (IIT Council), which oversees their administration. The Minister of Human Resource Development is the ex officio Chairperson of the IIT Council. As of 2019, the total number of seats for undergraduate programs in all IITs is 13,376. The only major requirement to admit to these institutions is to pass the JEE Advanced.


== List of institutes ==


== History ==

The history of the IIT system dates back to 1946 when Sir Jogendra Singh of the Viceroy's Executive Council set up a committee whose task was to consider the creation of Higher Technical Institutions for post-war industrial development in India. The 22-member committee, headed by Nalini Ranjan Sarkar, recommended the establishment of these institutions in various parts of India, along the lines of the Massachusetts Institute of Technology, with affiliated secondary institutions.The first Indian Institute of Technology was founded in May 1950 at the site of the Hijli Detention Camp in Kharagpur, West Bengal. The name ""Indian Institute of Technology"" was adopted before the formal inauguration of the institute on 18 August 1951 by Maulana Abul Kalam Azad. On 15 September 1956, the Parliament of India passed the Indian Institute of Technology (Kharagpur) Act, declaring it as an Institute of National Importance. Jawaharlal Nehru, first Prime Minister of India, in the first convocation address of IIT Kharagpur in 1956 said:
Here in the place of that Hijli Detention Camp stands the fine monument of India, representing India's urges, India's future in the making. This picture seems to me symbolical of the changes that are coming to India.

On the recommendations of the Sarkar Committee, four campuses were established at Bombay (1958), Madras (1959), Kanpur (1959), and Delhi (1961). The location of these campuses was chosen to be scattered throughout India to prevent regional imbalance. The Indian Institutes of Technology Act was amended to reflect the addition of new IITs. Student agitations in the state of Assam made Prime Minister Rajiv Gandhi promise the creation of a new IIT in Assam. This led to the establishment of a sixth institution at Guwahati under the Assam Accord in 1994. In 2001, the University of Roorkee, India's oldest engineering college, was converted into IIT Roorkee.

Over the past few years, there have been a number of developments toward establishing new IITs. On 1 October 2003, Prime Minister Atal Bihari Vajpayee announced plans to create more IITs ""by upgrading existing academic institutions that have the necessary promise and potential"". Subsequent developments led to the formation of the S K Joshi Committee, in November 2003, to guide the selection of the five institutions which would be converted into IITs. Based on the initial recommendations of the Sarkar Committee, it was decided that new IITs should be spread throughout the country. When the government expressed its willingness to correct this regional imbalance, 16 states demanded IITs. Since the S K Joshi Committee prescribed strict guidelines for institutions aspiring to be IITs, only seven colleges were selected for final consideration. Plans are also reported to open IITs outside India, although there has not been much progress in this regard. Eventually in the 11th Five year plan, eight states were identified for establishment of new IITs.
In 2008 to 2009, eight new IITs were set up in Gandhinagar, Jodhpur, Hyderabad, Indore, Patna, Bhubaneswar, Ropar, and Mandi. Following same selection process since 1972, in 2012 the Institute of Technology, Banaras Hindu University was made a member of the IITs and renamed as IIT(BHU) Varanasi.
In 2015 to 2016, six new IITs in Tirupati, Palakkad, Dharwad, Bhilai, Goa and Jammu, approved through a 2016 bill amendment, were founded, along with the conversion of Indian School of Mines Dhanbad into IIT(ISM) Dhanbad.
The entire allocation by the central government for 2017-18 budget for all Indian Institutes of Technology (IITs) was slightly over ₹70 billion (US$980 million). However, the aggregate money spent by Indian students for tertiary education in the United States was about six times more than what the central government spends on all IITs.


== Organisational structure ==

The President of India is the most powerful person in the organisational structure of Indian Institutes of Technology, being the ex officio Visitor, and having residual powers. Directly under the President is the IIT Council, which comprises the minister-in-charge of technical education in the Union Government, the Chairmen of all IITs, the Directors of all IITs, the Chairman of the University Grants Commission, the Director General of CSIR, the Chairman of IISc, the Director of IISc, three members of Parliament, the Joint Council Secretary of Ministry of Human Resource and Development, and three appointees each of the Union Government, AICTE, and the Visitor.Under the IIT Council is the Board of Governors of each IIT. Under the Board of Governors is the Director, who is the chief academic and executive officer of the IIT. Under the Director, in the organisational structure, comes the Deputy Director. Under the Director and the Deputy Director, come the Deans, Heads of Departments, Registrar, President of the Students' Council, and Chairman of the Hall Management Committee. The Registrar is the chief administrative officer of the IIT and overviews the day-to-day operations. Below the Heads of Department (HOD) are the faculty members (Professors, Associate Professors, and Assistant Professors). The Wardens come under the Chairman of the Hall Management Committee.


== The Institutes of Technology Act ==

The Institutes of Technology act was later taken as the base for the following years up until date. The Act primarily accepted few IITs as Institutes of National Importance and converted them from 'Societies' to University status.


== Education ==

The IITs receive comparatively higher grants than other engineering colleges in India. While the total government funding to most other engineering colleges is around ₹ 100–200 million ($2–4 million) per year, the amount varies between ₹ 900–1300 million ($19–27 million) per year for each IIT. Other sources of funds include student fees and research funding from industry and contributions from the alumni. The faculty-to-student ratio in the IITs is between 1:6 and 1:8. The Standing Committee of IIT Council (SCIC) prescribes the lower limit for faculty-to-student ratio as 1:9, applied department wise. The IITs subsidise undergraduate student fees by approximately 80% and provide scholarships to all Master of Technology students and Research Scholars in order to encourage students for higher studies, per the recommendations of the Thacker Committee (1959–1961). The cost borne by undergraduate students is around ₹180,000 per year. After students from SC and ST categories, physically challenged students will now be the beneficiaries of fee waiver at the IITs in India.The various IITs function autonomously, and their special status as Institutes of National Importance facilitates the smooth running of IITs, virtually free from both regional as well as student politics. Such autonomy means that IITs can create their own curricula and adapt rapidly to the changes in educational requirements, free from bureaucratic hurdles. The government has no direct control over internal policy decisions of IITs (like faculty recruitment and curricula) but has representation on the IIT Council. The medium of instruction in all IITs is English. The classes are usually held between 7:30  am and 5:30  pm, though there are some variations within each IIT. All the IITs have public libraries for the use of their students. In addition to a collection of prescribed books, the libraries have sections for fiction and other literary genres. The electronic libraries allow students to access on-line journals and periodicals. The IITs and IISc have taken an initiative along with Ministry of Human Resource Development to provide free online videos of actual lectures of different disciplines under National Program on Technology Enhanced Learning. This initiative is undertaken to make quality education accessible to all students.The academic policies of each IIT are decided by its Senate. This comprises all professors of the IIT and student representatives. Unlike many western universities that have an elected senate, the IITs have an academic senate. It controls and approves the curriculum, courses, examinations and results, and appoints committees to look into specific academic matters. The teaching, training and research activities of the institute are periodically reviewed by the senate to maintain educational standards. The Director of an IIT is the ex-officio Chairman of the Senate.

All the IITs follow the credits system of performance evaluation, with proportional weighting of courses based on their importance. The total marks (usually out of 100) form the basis of grades, with a grade value (out of 10) assigned to a range of marks. Sometimes, relative grading is done considering the overall performance of the whole class. For each semester, the students are graded on a scale of 0 to 10 based on their performance, by taking a weighted average of the grade points from all the courses, with their respective credit points. Each semester evaluation is done independently and then the weighted average over all semesters is used to calculate the cumulative Grade Point Average (known as CGPA or CPI—Cumulative Performance Index).


=== Undergraduate education ===
The Bachelor of Technology (BTech) degree is the most common undergraduate degree in the IITs in terms of student enrolment, although dual degrees integrating Master of Science or Master of Arts are also offered. The BTech course is based on a 4-year program with eight semesters, while the Dual Degree and Integrated courses are 5-year programs with ten semesters. In all IITs, the first year of BTech and Dual Degree courses are marked by a common course structure for all the students, though in some IITs, a single department introduction related course is also included. The common courses include the basics from most of the departments like Electronics, Mechanics, Chemistry, Electrical and Physics. At the end of first year (the end of first semester at IIT Madras, IIT Hyderabad, IIT Palakkad and IIT Roorkee), an option to change departments is given to meritorious students on the basis of their performance in the first two semesters. Few such changes ultimately take place as the criteria for them are usually strict, limited to the most meritorious students.
From the second year onward, the students study subjects exclusively from their respective departments. In addition to these, the students have to take compulsory advanced courses from other departments in order to broaden their education. Separate compulsory courses from humanities and social sciences department, and sometimes management courses are also enforced. In the last year of their studies, most of the students are placed into industries and organisations via the placement process of the respective IIT, though some students opt out of this either when going for higher studies or when they take up jobs by applying to the companies directly.


=== Postgraduate and doctoral education ===


==== Master's degrees and postgraduate diplomas ====
The IITs offer a number of postgraduate programs including Master of Technology (MTech), Master of Business Administration (MBA) (only for engineers and post graduates in science), and Master of Science (MSc). Some IITs offer specialised graduate programmes such as Master of Design (M.Des.), the Post Graduate Diploma in Information Technology (PGDIT), Master in Medical Science and Technology (MMST), Master of City Planning (MCP), Master of Arts (MA), Postgraduate Diploma in intellectual property Law (PGDIPL), and the Postgraduate Diploma in Maritime Operation & Management (PGDMOM).
Some of the IITs offer an M.S. (by research) program; the MTech and M.S. are similar to the US universities' non-thesis (course based) and thesis (research based) masters programs respectively. Admissions to masters programs in engineering are made using scores of the Graduate Aptitude Test in Engineering (GATE), while those to masters programs in science are made using scores of the Joint Admission Test to MSc (JAM).
Several IITs have schools of management offering master's degrees in management or business administration.
In April 2015, IIT Bombay launched the first U.S.-India joint EMBA program alongside Washington University in St. Louis.


==== Bachelors-Masters dual degrees ====
The IITs also offer an unconventional BTech and MTech integrated educational program called ""Dual Degree"". It integrates undergraduate and postgraduate studies in selected areas of specialisation. It is completed in five years as against six years in conventional BTech (four years) followed by an MTech (two years). Integrated Master of Science programs are also offered at few IITs which integrates the Undergraduate and Postgraduate studies in Science streams in a single degree program against the conventional University system. These programs were started to allow its graduates to complete postgraduate studies from IIT rather than having to go to another institute.


==== Doctoral degrees ====
The IITs also offer the Doctor of Philosophy degree (PhD) as part of their doctoral education programme. In it, the candidates are given a topic of academic interest by the professor or have to work on a consultancy project given by the industries. The duration of the program is usually unspecified and depends on the specific discipline. PhD candidates have to submit a dissertation as well as provide an oral defence for their thesis. Teaching Assistantships (TA) and Research Assistantships (RA) are often provided.
The IITs, along with NITs and IISc, account for nearly 80% of all engineering PhDs in India. IITs now allow admission in PhD programs without the mandatory GATE score.


== Culture and student life ==
All the IITs provide on-campus residential facilities to the students, research scholars and faculty. The students live in hostels (sometimes referred to as halls) throughout their stay in the IIT. Students in all IITs must choose among National Cadet Corps (NCC), National Service Scheme (NSS) and National Sports Organisation (NSO) in their first years. All the IITs have sports grounds for basketball, cricket, football (soccer), hockey, volleyball, lawn tennis, badminton, and athletics; and swimming pools for aquatic events. Usually the hostels also have their own sports grounds.
Moreover, an Inter IIT Sports Meet is organised annually where participants from all 23 IITs contest for the General Championship Trophy in 13 different sports.


=== Technical and cultural festivals ===

All IITs organise annual technical festivals, typically lasting three or four days. The technical festivals are Shaastra (IIT Madras), Kshitij (IIT Kharagpur), Techfest (IIT Bombay),Technex (IIT-BHU Varanasi), Cognizance (IIT Roorkee), Concetto (IIT-ISM Dhanbad), Nvision (IIT Hyderabad), Amalthea (technical summit), (IIT Gandhinagar), Techkriti (IIT Kanpur), Tryst (IIT Delhi), Techniche (IIT Guwahati), Wissenaire (IIT Bhubaneswar), Technunctus (IIT Jammu), Exodia (IIT Mandi), Fluxus (IIT Indore), Celesta (IIT Patna) and IGNUS (IIT Jodhpur). Most of them are organised in the months of January or March. Techfest (IIT Bombay) is also one of the most popular and largest technical festival in Asia in terms of participants and prize money involved. It has been granted patronage from United Nations Educational, Scientific and Cultural Organisation (UNESCO) for providing a platform to students to showcase their talent in science and technology. Shaastra holds the distinction of being the first student-managed event in the world to implement a formal Quality Management System, earning ISO 9001:2000 certification. Kshitij is the largest in terms of Sponsorship amounts and also branded as a techno-management festival due to its emphasis on both technology and management.
Annual cultural festivals are also organised by the IITs and last three to four days. These include Thomso (IIT Roorkee), Kashiyatra (IIT BHU Varanasi), Alcheringa (IIT Guwahati), Exodia (IIT Mandi), Saarang (IIT Madras, previously Mardi Gras), Spring Fest (IIT Kharagpur, also known as SF), Rendezvous (IIT Delhi), Tirutsva (IIT Tirupati), Srijan (IIT ISM Dhanbad), Tarang (culfest) (previously Rave), Anwesha (IIT Patna), SPANDAN (IIT Jodhpur), Infinito (IIT Jammu), Tirutsava (IIT Tirupati), Blithchron (IIT Gandhinagar), ELAN (IIT Hyderabad), Alma Fiesta (IIT Bhubaneswar), Mood Indigo (IIT Bombay, also known as Mood-I), Antaragni (IIT Kanpur) and Zeitgeist (IIT Ropar).


== Academic rankings ==
IITs are generally ranked above other engineering colleges in India for Engineering. According to Outlook India's Top Engineering Colleges of 2017, the top four engineering colleges within India were IITs. [1] IIT Delhi was the highest-ranked IIT internationally, ranking 172nd in the QS World University Rankings of 2018, followed by IIT Bombay (179th), while 3 other IITs (IIT Madras at 264, IIT Kanpur at 293 and IIT Kharagpur at 308) make the top 310.In the 2019 QS World University Ranking, IIT Bombay ranked highest at 162, followed by IIT Delhi (172), IIT Madras (264), IIT Kanpur (283), IIT Kharagpur (295), IIT Roorkee (381) and IIT Guwahati (472).
In the 2017 QS World Rankings by Subject, IIT Dhanbad featured at 24th, followed by IIT Kharagpur at 35th, in Engineering – Mining and Mineral Science.[2] In the same ranking, IIT Delhi secured 49th place for Electrical Engineering. The only IIT that was listed in the top 400 by the Times Higher Education rankings 2018 was IIT Bombay in the 351–400 category. The Times Asia Rankings 2018 featured IIT Bombay, IIT Kharagpur, IIT Roorkee, IIT Kanpur, and IIT Delhi at 44th, 60th, 65th, 81st, and 86th respectively. In 2016, a new IIT, IIT Indore, was ranked 8th in the world, followed by IIT Kanpur (which was ranked 9th), under a ranking released by HackerRank for the world's best coders. The QS BRICS rankings of some IITs in 2018 : IIT Bombay (9th), Delhi (17th), Madras (18th), Kanpur (21st), Kharagpur (24th), Roorkee (51st), Guwahati (52nd), Hyderabad (100th), and Patna (108th).


== Criticism ==
The IITs have faced criticism from within and outside academia. Major concerns include allegations that they encourage brain drain and that their stringent entrance examinations encourage coaching colleges and put heavy pressure on the student's body. Recently some prominent IITians have also questioned the quality of teaching and research in IITs. In the recent past, the number of student suicides has attracted significant attention.


=== Brain drain ===
Among the criticisms of the IIT system by the media and academia, a common notion is that it encourages brain drain. This trend has been reversed somewhat (dubbed the reverse brain drain) as hundreds of IIT graduates, who have pursued further studies in the US, started returning to India in the 1990s. Additionally, IIT alumni are giving back generously to their parent institutions (examples are Kanwal Rekhi to IIT Bombay, Dr.Prabhakant Sinha to IIT Kharagpur, and many others). Until liberalisation started in the early 1990s, India experienced large scale emigration of IITians to developed countries, especially to the United States. Since 1953, nearly twenty-five thousand IITians have settled in the US. Since the US benefited from subsidised education in IITs at the cost of Indian taxpayers' money, critics say that subsidising education in IITs is useless. Others support the emigration of graduates, arguing that the capital sent home by the IITians has been a major source of the expansion of foreign exchange reserves for India, which, until the 1990s, had a substantial trade deficit.The extent of intellectual loss receded substantially over the 1990s and 2000s, with the percentage of students going abroad dropping from as high as 70% at one time to around 30% in 2005. This is largely attributed to the liberalisation of the Indian economy and the opening of previously closed markets. Government initiatives are encouraging IIT students into entrepreneurship programs and are increasing foreign investment. Emerging scientific and manufacturing industries, and outsourcing of technical jobs from North America and Western Europe have created opportunities for aspiring graduates in India. Many undergraduates go abroad to pursue further studies, such as MS, MBA and PhD.


=== Entrance competition ===
The highly competitive examination in the form of IIT-JEE has led to the establishment of a large number of coaching institutes throughout the country that provide intensive, and specific preparation for the IIT-JEE for substantial fees. It is argued that this favours students from specific regions and richer backgrounds. Some coaching institutes say that they have individually coached nearly 800 successful candidates year after year. According to some estimates, nearly 95% of all students who clear the IIT-JEE had joined coaching classes. Indeed, this was the case regarding preparation for IIT entrance exams even decades ago. In a January 2010 lecture at the Indian Institute of Science, the 2009 Nobel laureate in Chemistry, Venkatraman Ramakrishnan revealed that he failed to get a seat at any of the Indian engineering and medical colleges. He also said that his parents, being old-fashioned, did not believe in coaching classes to prepare for the IIT entrance exam and considered them to be ""nonsense"".In a documentary aired by CBS, Vinod Khosla, co-founder of Sun Microsystems states, ""The IITs probably are the hardest school in the world to get into, to the best of my knowledge"". The documentary further concludes, ""Put Harvard, MIT and Princeton together, and you begin to get an idea of the status of IIT in India"" to depict the competition as well as demand for the elite institutes.
Not all children are of a similar aptitude level and may be skilled in different paradigms and fields. This has led to criticism of the way the examinations are conducted and the way a student is forced in the Indian community. The IIT-JEE format was restructured in 2006 following these complaints.
After the change to the objective pattern of questioning, even the students who initially considered themselves not fit for subjective pattern of IIT-JEE decided to take the examination. Though the restructuring was meant to reduce the dependence of students on coaching classes, it led to an increase in students registering for coaching classes. Some people (mostly IITians) have criticised the changed pattern of the IIT-JEE. Their reasoning is that while IIT-JEE traditionally used to test students understanding of fundamentals and ability to apply them to solve tough unseen problems, the current pattern does not stress much on the application part and might lead to a reduced quality of students.IIT-JEE is conducted only in English and Hindi, making it harder for students with regional languages as their main language. In September 2011, the Gujarat High Court has acted on a Public Interest Litigation by the Gujarati Sahitya Parishad, for conducting the exams in Gujarati. A second petition was made in October by Navsari's Sayaji Vaibhav Sarvajanik Pustakalaya Trust. Another petition was made at the Madras High Court for conducting the exam in Tamil. In the petition it was claimed that not conducting the exam in the regional languages is in violation of article 14 of the Constitution of India. More recently, in November 2019, the Ministry of Human Resource Development has directed the National Testing Agency to prepare for conducting the test in at least 11 languages which include Assamese, Bengali, English, Gujarati, Hindi, Kannada, Marathi, Odiya, Tamil, Telugu and Urdu. This will be offered from 2021. IIT council has recommended major changes in entrance examination structure which will be effected from 2017 onward.


== Alumni ==

As of 2019, IITs have more than 250,000 alumni.


== See also ==
Indian Institutes of Management
Indian Institutes of Information Technology
International Institutes of Information Technology
National Institutes of Technology


== References ==


== Further reading ==


== External links ==
Official website IIT Council
The Institutes of Technology Act, 1961 (PDF)"
"A computer is a machine that can be instructed to carry out sequences of arithmetic or logical operations automatically via computer programming. Modern computers have the ability to follow generalized sets of operations, called programs. These programs enable computers to perform an extremely wide range of tasks. A ""complete"" computer including the hardware, the operating system (main software), and peripheral equipment required and used for ""full"" operation can be referred to as a computer system. This term may as well be used for a group of computers that are connected and work together, in particular a computer network or computer cluster.
Computers are used as control systems for a wide variety of industrial and consumer devices. This includes simple special purpose devices like microwave ovens and remote controls, factory devices such as industrial robots and computer-aided design, and also general purpose devices like personal computers and mobile devices such as smartphones. The Internet is run on computers and it connects hundreds of millions of other computers and their users.
Early computers were only conceived as calculating devices. Since ancient times, simple manual devices like the abacus aided people in doing calculations. Early in the Industrial Revolution, some mechanical devices were built to automate long tedious tasks, such as guiding patterns for looms. More sophisticated electrical machines did specialized analog calculations in the early 20th century. The first digital electronic calculating machines were developed during World War II. The first semiconductor transistors in the late 1940s were followed by the silicon-based MOSFET (MOS transistor) and monolithic integrated circuit (IC) chip technologies in the late 1950s, leading to the microprocessor and the microcomputer revolution in the 1970s. The speed, power and versatility of computers have been increasing dramatically ever since then, with MOS transistor counts increasing at a rapid pace (as predicted by Moore's law), leading to the Digital Revolution during the late 20th to early 21st centuries.
Conventionally, a modern computer consists of at least one processing element, typically a central processing unit (CPU) in the form of a metal-oxide-semiconductor (MOS) microprocessor, along with some type of computer memory, typically MOS semiconductor memory chips. The processing element carries out arithmetic and logical operations, and a sequencing and control unit can change the order of operations in response to stored information. Peripheral devices include input devices (keyboards, mice, joystick, etc.), output devices (monitor screens, printers, etc.), and input/output devices that perform both functions (e.g., the 2000s-era touchscreen). Peripheral devices allow information to be retrieved from an external source and they enable the result of operations to be saved and retrieved.


== Etymology ==

According to the Oxford English Dictionary, the first known use of the word ""computer"" was in 1613 in a book called The Yong Mans Gleanings by English writer Richard Braithwait: ""I haue [sic] read the truest computer of Times, and the best Arithmetician that euer [sic] breathed, and he reduceth thy dayes into a short number."" This usage of the term referred to a human computer, a person who carried out calculations or computations. The word continued with the same meaning until the middle of the 20th century. During the latter part of this period women were often hired as computers because they could be paid less than their male counterparts. By 1943, most human computers were women.The Online Etymology Dictionary gives the first attested use of ""computer"" in the 1640s, meaning ""one who calculates""; this is an ""agent noun from compute (v.)"". The Online Etymology Dictionary states that the use of the term to mean ""'calculating machine' (of any type) is from 1897.""  The Online Etymology Dictionary indicates that the ""modern use"" of the term, to mean ""programmable digital electronic computer"" dates from ""1945 under this name; [in a] theoretical [sense] from 1937, as Turing machine"".


== History ==


=== Pre-20th century ===

Devices have been used to aid computation for thousands of years, mostly using one-to-one correspondence with fingers. The earliest counting device was probably a form of tally stick. Later record keeping aids throughout the Fertile Crescent included calculi (clay spheres, cones, etc.) which represented counts of items, probably livestock or grains, sealed in hollow unbaked clay containers. The use of counting rods is one example.

The abacus was initially used for arithmetic tasks. The Roman abacus was developed from devices used in Babylonia as early as 2400 BC. Since then, many other forms of reckoning boards or tables have been invented. In a medieval European counting house, a checkered cloth would be placed on a table, and markers moved around on it according to certain rules, as an aid to calculating sums of money.

The Antikythera mechanism is believed to be the earliest mechanical analog ""computer"", according to Derek J. de Solla Price. It was designed to calculate astronomical positions. It was discovered in 1901 in the Antikythera wreck off the Greek island of Antikythera, between Kythera and Crete, and has been dated to c. 100 BC. Devices of a level of complexity comparable to that of the Antikythera mechanism would not reappear until a thousand years later.
Many mechanical aids to calculation and measurement were constructed for astronomical and navigation use. The planisphere was a star chart invented by Abū Rayhān al-Bīrūnī in the early 11th century. The astrolabe was invented in the Hellenistic world in either the 1st or 2nd centuries BC and is often attributed to Hipparchus. A combination of the planisphere and dioptra, the astrolabe was effectively an analog computer capable of working out several different kinds of problems in spherical astronomy. An astrolabe incorporating a mechanical calendar computer and gear-wheels was invented by Abi Bakr of Isfahan, Persia in 1235. Abū Rayhān al-Bīrūnī invented the first mechanical geared lunisolar calendar astrolabe, an early fixed-wired knowledge processing machine with a gear train and gear-wheels, c. 1000 AD.
The sector, a calculating instrument used for solving problems in proportion, trigonometry, multiplication and division, and for various functions, such as squares and cube roots, was developed in the late 16th century and found application in gunnery, surveying and navigation.
The planimeter was a manual instrument to calculate the area of a closed figure by tracing over it with a mechanical linkage.

The slide rule was invented around 1620–1630, shortly after the publication of the concept of the logarithm. It is a hand-operated analog computer for doing multiplication and division. As slide rule development progressed, added scales provided reciprocals, squares and square roots, cubes and cube roots, as well as transcendental functions such as logarithms and exponentials, circular and hyperbolic trigonometry and other functions. Slide rules with special scales are still used for quick performance of routine calculations, such as the E6B circular slide rule used for time and distance calculations on light aircraft.
In the 1770s, Pierre Jaquet-Droz, a Swiss watchmaker, built a mechanical doll (automaton) that could write holding a quill pen. By switching the number and order of its internal wheels different letters, and hence different messages, could be produced. In effect, it could be mechanically ""programmed"" to read instructions. Along with two other complex machines, the doll is at the Musée d'Art et d'Histoire of Neuchâtel, Switzerland, and still operates.In 1831–1835, mathematician and engineer Giovanni Plana devised a Perpetual Calendar machine, which, though a system of pulleys and cylinders and over, could predict the perpetual calendar for every year from AD 0 (that is, 1 BC) to AD 4000, keeping track of leap years and varying day length. The tide-predicting machine invented by Sir William Thomson in 1872 was of great utility to navigation in shallow waters. It used a system of pulleys and wires to automatically calculate predicted tide levels for a set period at a particular location.
The differential analyser, a mechanical analog computer designed to solve differential equations by integration, used wheel-and-disc mechanisms to perform the integration. In 1876, Lord Kelvin had already discussed the possible construction of such calculators, but he had been stymied by the limited output torque of the ball-and-disk integrators. In a differential analyzer, the output of one integrator drove the input of the next integrator, or a graphing output. The torque amplifier was the advance that allowed these machines to work. Starting in the 1920s, Vannevar Bush and others developed mechanical differential analyzers.


=== First computing device ===

Charles Babbage, an English mechanical engineer and polymath, originated the concept of a programmable computer. Considered the ""father of the computer"", he conceptualized and invented the first mechanical computer in the early 19th century. After working on his revolutionary difference engine, designed to aid in navigational calculations, in 1833 he realized that a much more general design, an Analytical Engine, was possible. The input of programs and data was to be provided to the machine via punched cards, a method being used at the time to direct mechanical looms such as the Jacquard loom. For output, the machine would have a printer, a curve plotter and a bell. The machine would also be able to punch numbers onto cards to be read in later. The Engine incorporated an arithmetic logic unit, control flow in the form of conditional branching and loops, and integrated memory, making it the first design for a general-purpose computer that could be described in modern terms as Turing-complete.The machine was about a century ahead of its time. All the parts for his machine had to be made by hand – this was a major problem for a device with thousands of parts. Eventually, the project was dissolved with the decision of the British Government to cease funding. Babbage's failure to complete the analytical engine can be chiefly attributed to political and financial difficulties as well as his desire to develop an increasingly sophisticated computer and to move ahead faster than anyone else could follow. Nevertheless, his son, Henry Babbage, completed a simplified version of the analytical engine's computing unit (the mill) in 1888. He gave a successful demonstration of its use in computing tables in 1906.


=== Analog computers ===

During the first half of the 20th century, many scientific computing needs were met by increasingly sophisticated analog computers, which used a direct mechanical or electrical model of the problem as a basis for computation. However, these were not programmable and generally lacked the versatility and accuracy of modern digital computers. The first modern analog computer was a tide-predicting machine, invented by Sir William Thomson in 1872. The differential analyser, a mechanical analog computer designed to solve differential equations by integration using wheel-and-disc mechanisms, was conceptualized in 1876 by James Thomson, the brother of the more famous Lord Kelvin.The art of mechanical analog computing reached its zenith with the differential analyzer, built by H. L. Hazen and Vannevar Bush at MIT starting in 1927. This built on the mechanical integrators of James Thomson and the torque amplifiers invented by H. W. Nieman. A dozen of these devices were built before their obsolescence became obvious. By the 1950s, the success of digital electronic computers had spelled the end for most analog computing machines, but analog computers remained in use during the 1950s in some specialized applications such as education (control systems) and aircraft (slide rule).


=== Digital computers ===


==== Electromechanical ====
By 1938, the United States Navy had developed an electromechanical analog computer small enough to use aboard a submarine. This was the Torpedo Data Computer, which used trigonometry to solve the problem of firing a torpedo at a moving target. During World War II similar devices were developed in other countries as well.

Early digital computers were electromechanical; electric switches drove mechanical relays to perform the calculation. These devices had a low operating speed and were eventually superseded by much faster all-electric computers, originally using vacuum tubes. The Z2, created by German engineer Konrad Zuse in 1939, was one of the earliest examples of an electromechanical relay computer.In 1941, Zuse followed his earlier machine up with the Z3, the world's first working electromechanical programmable, fully automatic digital computer. The Z3 was built with 2000 relays, implementing a 22 bit word length that operated at a clock frequency of about 5–10 Hz. Program code was supplied on punched film while data could be stored in 64 words of memory or supplied from the keyboard. It was quite similar to modern machines in some respects, pioneering numerous advances such as floating point numbers. Rather than the harder-to-implement decimal system (used in Charles Babbage's earlier design), using a binary system meant that Zuse's machines were easier to build and potentially more reliable, given the technologies available at that time. The Z3 was not itself a universal computer but could be extended to be Turing complete.


==== Vacuum tubes and digital electronic circuits ====

Purely electronic circuit elements soon replaced their mechanical and electromechanical equivalents, at the same time that digital calculation replaced analog. The engineer Tommy Flowers, working at the Post Office Research Station in London in the 1930s, began to explore the possible use of electronics for the telephone exchange. Experimental equipment that he built in 1934 went into operation five years later, converting a portion of the telephone exchange network into an electronic data processing system, using thousands of vacuum tubes. In the US, John Vincent Atanasoff and Clifford E. Berry of Iowa State University developed and tested the Atanasoff–Berry Computer (ABC) in 1942, the first ""automatic electronic digital computer"". This design was also all-electronic and used about 300 vacuum tubes, with capacitors fixed in a mechanically rotating drum for memory.

During World War II, the British at Bletchley Park achieved a number of successes at breaking encrypted German military communications. The German encryption machine, Enigma, was first attacked with the help of the electro-mechanical bombes which were often run by women. To crack the more sophisticated German Lorenz SZ 40/42 machine, used for high-level Army communications, Max Newman and his colleagues commissioned Flowers to build the Colossus. He spent eleven months from early February 1943 designing and building the first Colossus. After a functional test in December 1943, Colossus was shipped to Bletchley Park, where it was delivered on 18 January 1944 and attacked its first message on 5 February.Colossus was the world's first electronic digital programmable computer. It used a large number of valves (vacuum tubes). It had paper-tape input and was capable of being configured to perform a variety of boolean logical operations on its data, but it was not Turing-complete. Nine Mk II Colossi were built (The Mk I was converted to a Mk II making ten machines in total). Colossus Mark I contained 1,500 thermionic valves (tubes), but Mark II with 2,400 valves, was both 5 times faster and simpler to operate than Mark I, greatly speeding the decoding process.

The ENIAC (Electronic Numerical Integrator and Computer) was the first electronic programmable computer built in the U.S. Although the ENIAC was similar to the Colossus, it was much faster, more flexible, and it was Turing-complete. Like the Colossus, a ""program"" on the ENIAC was defined by the states of its patch cables and switches, a far cry from the stored program electronic machines that came later. Once a program was written, it had to be mechanically set into the machine with manual resetting of plugs and switches. The programmers of the ENIAC were six women, often known collectively as the ""ENIAC girls"".It combined the high speed of electronics with the ability to be programmed for many complex problems. It could add or subtract 5000 times a second, a thousand times faster than any other machine. It also had modules to multiply, divide, and square root. High speed memory was limited to 20 words (about 80 bytes). Built under the direction of John Mauchly and J. Presper Eckert at the University of Pennsylvania, ENIAC's development and construction lasted from 1943 to full operation at the end of 1945. The machine was huge, weighing 30 tons, using 200 kilowatts of electric power and contained over 18,000 vacuum tubes, 1,500 relays, and hundreds of thousands of resistors, capacitors, and inductors.


=== Modern computers ===


==== Concept of modern computer ====
The principle of the modern computer was proposed by Alan Turing in his seminal 1936 paper, On Computable Numbers. Turing proposed a simple device that he called ""Universal Computing machine"" and that is now known as a universal Turing machine. He proved that such a machine is capable of computing anything that is computable by executing instructions (program) stored on tape, allowing the machine to be programmable. The fundamental concept of Turing's design is the stored program, where all the instructions for computing are stored in memory. Von Neumann acknowledged that the central concept of the modern computer was due to this paper. Turing machines are to this day a central object of study in theory of computation. Except for the limitations imposed by their finite memory stores, modern computers are said to be Turing-complete, which is to say, they have algorithm execution capability equivalent to a universal Turing machine.


==== Stored programs ====

Early computing machines had fixed programs. Changing its function required the re-wiring and re-structuring of the machine. With the proposal of the stored-program computer this changed. A stored-program computer includes by design an instruction set and can store in memory a set of instructions (a program) that details the computation. The theoretical basis for the stored-program computer was laid by Alan Turing in his 1936 paper. In 1945, Turing joined the National Physical Laboratory and began work on developing an electronic stored-program digital computer. His 1945 report ""Proposed Electronic Calculator"" was the first specification for such a device. John von Neumann at the University of Pennsylvania also circulated his First Draft of a Report on the EDVAC in 1945.The Manchester Baby was the world's first stored-program computer. It was built at the Victoria University of Manchester by Frederic C. Williams, Tom Kilburn and Geoff Tootill, and ran its first program on 21 June 1948. It was designed as a testbed for the Williams tube, the first random-access digital storage device. Although the computer was considered ""small and primitive"" by the standards of its time, it was the first working machine to contain all of the elements essential to a modern electronic computer. As soon as the Baby had demonstrated the feasibility of its design, a project was initiated at the university to develop it into a more usable computer, the Manchester Mark 1. Grace Hopper was the first person to develop a compiler for programming language.The Mark 1 in turn quickly became the prototype for the Ferranti Mark 1, the world's first commercially available general-purpose computer. Built by Ferranti, it was delivered to the University of Manchester in February 1951. At least seven of these later machines were delivered between 1953 and 1957, one of them to Shell labs in Amsterdam. In October 1947, the directors of British catering company J. Lyons & Company decided to take an active role in promoting the commercial development of computers. The LEO I computer became operational in April 1951 and ran the world's first regular routine office computer job.


==== Transistors ====

The concept of a field-effect transistor was proposed by Julius Edgar Lilienfeld in 1925. John Bardeen and Walter Brattain, while working under William Shockley at Bell Labs, built the first working transistor, the point-contact transistor, in 1947, which was followed by Shockley's bipolar junction transistor in 1948. From 1955 onwards, transistors replaced vacuum tubes in computer designs, giving rise to the ""second generation"" of computers. Compared to vacuum tubes, transistors have many advantages: they are smaller, and require less power than vacuum tubes, so give off less heat. Junction transistors were much more reliable than vacuum tubes and had longer, indefinite, service life. Transistorized computers could contain tens of thousands of binary logic circuits in a relatively compact space. However, early junction transistors were relatively bulky devices that were difficult to manufacture on a mass-production basis, which limited them to a number of specialised applications.At the University of Manchester, a team under the leadership of Tom Kilburn designed and built a machine using the newly developed transistors instead of valves. Their first transistorised computer and the first in the world, was operational by 1953, and a second version was completed there in April 1955. However, the machine did make use of valves to generate its 125 kHz clock waveforms and in the circuitry to read and write on its magnetic drum memory, so it was not the first completely transistorized computer. That distinction goes to the Harwell CADET of 1955, built by the electronics division of the Atomic Energy Research Establishment at Harwell.

The metal–oxide–silicon field-effect transistor (MOSFET), also known as the MOS transistor, was invented by Mohamed M. Atalla and Dawon Kahng at Bell Labs in 1959. It was the first truly compact transistor that could be miniaturised and mass-produced for a wide range of uses. With its high scalability, and much lower power consumption and higher density than bipolar junction transistors, the MOSFET made it possible to build high-density integrated circuits. In addition to data processing, it also enabled the practical use of MOS transistors as memory cell storage elements, leading to the development of MOS semiconductor memory, which replaced earlier magnetic-core memory in computers. The MOSFET led to the microcomputer revolution, and became the driving force behind the computer revolution. The MOSFET is the most widely used transistor in computers, and is the fundamental building block of digital electronics.


==== Integrated circuits ====

The next great advance in computing power came with the advent of the integrated circuit (IC).
The idea of the integrated circuit was first conceived by a radar scientist working for the Royal Radar Establishment of the Ministry of Defence, Geoffrey W.A. Dummer. Dummer presented the first public description of an integrated circuit at the Symposium on Progress in Quality Electronic Components in Washington, D.C. on 7 May 1952.The first working ICs were invented by Jack Kilby at Texas Instruments and Robert Noyce at Fairchild Semiconductor. Kilby recorded his initial ideas concerning the integrated circuit in July 1958, successfully demonstrating the first working integrated example on 12 September 1958. In his patent application of 6 February 1959, Kilby described his new device as ""a body of semiconductor material ... wherein all the components of the electronic circuit are completely integrated"". However, Kilby's invention was a hybrid integrated circuit (hybrid IC), rather than a monolithic integrated circuit (IC) chip. Kilby's IC had external wire connections, which made it difficult to mass-produce.Noyce also came up with his own idea of an integrated circuit half a year later than Kilby. Noyce's invention was the first true monolithic IC chip. His chip solved many practical problems that Kilby's had not. Produced at Fairchild Semiconductor, it was made of silicon, whereas Kilby's chip was made of germanium. Noyce's monolithic IC was fabricated using the planar process, developed by his colleague Jean Hoerni in early 1959. In turn, the planar process was based on the silicon surface passivation and thermal oxidation processes developed by Mohamed Atalla at Bell Labs in the late 1950s.Modern monolithic ICs are predominantly MOS (metal-oxide-semiconductor) integrated circuits, built from MOSFETs (MOS transistors). After the first MOSFET was invented by Mohamed Atalla and Dawon Kahng at Bell Labs in 1959, Atalla first proposed the concept of the MOS integrated circuit in 1960, followed by Kahng in 1961, both noting that the MOS transistor's ease of fabrication made it useful for integrated circuits. The earliest experimental MOS IC to be fabricated was a 16-transistor chip built by Fred Heiman and Steven Hofstein at RCA in 1962. General Microelectronics later introduced the first commercial MOS IC in 1964, developed by Robert Norman. Following the development of the self-aligned gate (silicon-gate) MOS transistor by Robert Kerwin, Donald Klein and John Sarace at Bell Labs in 1967, the first silicon-gate MOS IC with self-aligned gates was developed by Federico Faggin at Fairchild Semiconductor in 1968. The MOSFET has since become the most critical device component in modern ICs.The development of the MOS integrated circuit led to the invention of the microprocessor, and heralded an explosion in the commercial and personal use of computers. While the subject of exactly which device was the first microprocessor is contentious, partly due to lack of agreement on the exact definition of the term ""microprocessor"", it is largely undisputed that the first single-chip microprocessor was the Intel 4004, designed and realized by Federico Faggin with his silicon-gate MOS IC technology, along with Ted Hoff, Masatoshi Shima and Stanley Mazor at Intel. In the early 1970s, MOS IC technology enabled the integration of more than 10,000 transistors on a single chip.System on a Chip (SoCs) are complete computers on a microchip (or chip) the size of a coin. They may or may not have integrated RAM and flash memory. If not integrated, The RAM is usually placed directly above (known as Package on package) or below (on the opposite side of the circuit board) the SoC, and the flash memory is usually placed right next to the SoC, this all done to improve data transfer speeds, as the data signals don't have to travel long distances. Since ENIAC in 1945, computers have advanced enormously, with modern SoCs (Such as the Snapdragon 865) being the size of a coin while also being hundreds of thousands of times more powerful than ENIAC, integrating billions of transistors, and consuming only a few watts of power.


=== Mobile computers ===
The first mobile computers were heavy and ran from mains power. The 50lb IBM 5100 was an early example. Later portables such as the Osborne 1 and Compaq Portable were considerably lighter but still needed to be plugged in. The first laptops, such as the Grid Compass, removed this requirement by incorporating batteries – and with the continued miniaturization of computing resources and advancements in portable battery life, portable computers grew in popularity in the 2000s. The same developments allowed manufacturers to integrate computing resources into cellular mobile phones by the early 2000s.
These smartphones and tablets run on a variety of operating systems and recently became the dominant computing device on the market. These are powered by System on a Chip (SoCs), which are complete computers on a microchip the size of a coin.


== Types ==

Computers can be classified in a number of different ways, including:


=== By architecture ===
Analog computer
Digital computer
Hybrid computer
Harvard architecture
Von Neumann architecture
Complex instruction set computer
Reduced instruction set computer


=== By size, form-factor and purpose ===
Supercomputer
Mainframe computer
Minicomputer (term no longer used)
Server
Rackmount server
Blade server
Tower server
Personal computer
Workstation
Microcomputer (term no longer used)
Home computer
Desktop computer
Tower desktop
Slimline desktop
Multimedia computer (non-linear editing system computers, video editing PCs and the like)
Gaming computer
All-in-one PC
Nettop (Small form factor PCs, Mini PCs)
Home theater PC
Keyboard computer
Portable computer
Thin client
Internet appliance
Laptop
Desktop replacement computer
Gaming laptop
Rugged laptop
2-in-1 PC
Ultrabook
Chromebook
Subnotebook
Netbook
Mobile computers:
Tablet computer
Smartphone
Ultra-mobile PC
Pocket PC
Palmtop PC
Handheld PC
Wearable computer
Smartwatch
Smartglasses
Single-board computer
Plug computer
Stick PC
Programmable logic controller
Computer-on-module
System on module
System in a package
System-on-chip (Also known as an Application Processor or AP if it lacks circuitry such as radio circuitry)
Microcontroller


== Hardware ==

The term hardware covers all of those parts of a computer that are tangible physical objects. Circuits, computer chips, graphic cards, sound cards, memory (RAM), motherboard, displays, power supplies, cables, keyboards, printers and ""mice"" input devices are all hardware.


=== History of computing hardware ===


=== Other hardware topics ===
A general purpose computer has four main components: the arithmetic logic unit (ALU), the control unit, the memory, and the input and output devices (collectively termed I/O). These parts are interconnected by buses, often made of groups of wires.
Inside each of these parts are thousands to trillions of small electrical circuits which can be turned off or on by means of an electronic switch. Each circuit represents a bit (binary digit) of information so that when the circuit is on it represents a ""1"", and when off it represents a ""0"" (in positive logic representation). The circuits are arranged in logic gates so that one or more of the circuits may control the state of one or more of the other circuits.


=== Input devices ===
When unprocessed data is sent to the computer with the help of input devices, the data is processed and sent to output devices. The input devices may be hand-operated or automated. The act of processing is mainly regulated by the CPU. Some examples of input devices are:

Computer keyboard
Digital camera
Digital video
Graphics tablet
Image scanner
Joystick
Microphone
Mouse
Overlay keyboard
Real-time clock
Trackball
Touchscreen


=== Output devices ===
The means through which computer gives output are known as output devices. Some examples of output devices are:

Computer monitor
Printer
PC speaker
Projector
Sound card
Video card


=== Control unit ===

The control unit (often called a control system or central controller) manages the computer's various components; it reads and interprets (decodes) the program instructions, transforming them into control signals that activate other parts of the computer. Control systems in advanced computers may change the order of execution of some instructions to improve performance.
A key component common to all CPUs is the program counter, a special memory cell (a register) that keeps track of which location in memory the next instruction is to be read from.The control system's function is as follows—note that this is a simplified description, and some of these steps may be performed concurrently or in a different order depending on the type of CPU:

Read the code for the next instruction from the cell indicated by the program counter.
Decode the numerical code for the instruction into a set of commands or signals for each of the other systems.
Increment the program counter so it points to the next instruction.
Read whatever data the instruction requires from cells in memory (or perhaps from an input device). The location of this required data is typically stored within the instruction code.
Provide the necessary data to an ALU or register.
If the instruction requires an ALU or specialized hardware to complete, instruct the hardware to perform the requested operation.
Write the result from the ALU back to a memory location or to a register or perhaps an output device.
Jump back to step (1).Since the program counter is (conceptually) just another set of memory cells, it can be changed by calculations done in the ALU. Adding 100 to the program counter would cause the next instruction to be read from a place 100 locations further down the program. Instructions that modify the program counter are often known as ""jumps"" and allow for loops (instructions that are repeated by the computer) and often conditional instruction execution (both examples of control flow).
The sequence of operations that the control unit goes through to process an instruction is in itself like a short computer program, and indeed, in some more complex CPU designs, there is another yet smaller computer called a microsequencer, which runs a microcode program that causes all of these events to happen.


=== Central processing unit (CPU) ===

The control unit, ALU, and registers are collectively known as a central processing unit (CPU). Early CPUs were composed of many separate components. Since the 1970s, CPUs have typically been constructed on a single MOS integrated circuit chip called a microprocessor.


=== Arithmetic logic unit (ALU) ===

The ALU is capable of performing two classes of operations: arithmetic and logic. The set of arithmetic operations that a particular ALU supports may be limited to addition and subtraction, or might include multiplication, division, trigonometry functions such as sine, cosine, etc., and square roots. Some can only operate on whole numbers (integers) while others use floating point to represent real numbers, albeit with limited precision. However, any computer that is capable of performing just the simplest operations can be programmed to break down the more complex operations into simple steps that it can perform. Therefore, any computer can be programmed to perform any arithmetic operation—although it will take more time to do so if its ALU does not directly support the operation. An ALU may also compare numbers and return boolean truth values (true or false) depending on whether one is equal to, greater than or less than the other (""is 64 greater than 65?""). Logic operations involve Boolean logic: AND, OR, XOR, and NOT. These can be useful for creating complicated conditional statements and processing boolean logic.
Superscalar computers may contain multiple ALUs, allowing them to process several instructions simultaneously. Graphics processors and computers with SIMD and MIMD features often contain ALUs that can perform arithmetic on vectors and matrices.


=== Memory ===

A computer's memory can be viewed as a list of cells into which numbers can be placed or read. Each cell has a numbered ""address"" and can store a single number. The computer can be instructed to ""put the number 123 into the cell numbered 1357"" or to ""add the number that is in cell 1357 to the number that is in cell 2468 and put the answer into cell 1595."" The information stored in memory may represent practically anything. Letters, numbers, even computer instructions can be placed into memory with equal ease. Since the CPU does not differentiate between different types of information, it is the software's responsibility to give significance to what the memory sees as nothing but a series of numbers.
In almost all modern computers, each memory cell is set up to store binary numbers in groups of eight bits (called a byte). Each byte is able to represent 256 different numbers (28 = 256); either from 0 to 255 or −128 to +127. To store larger numbers, several consecutive bytes may be used (typically, two, four or eight). When negative numbers are required, they are usually stored in two's complement notation. Other arrangements are possible, but are usually not seen outside of specialized applications or historical contexts. A computer can store any kind of information in memory if it can be represented numerically. Modern computers have billions or even trillions of bytes of memory.
The CPU contains a special set of memory cells called registers that can be read and written to much more rapidly than the main memory area. There are typically between two and one hundred registers depending on the type of CPU. Registers are used for the most frequently needed data items to avoid having to access main memory every time data is needed. As data is constantly being worked on, reducing the need to access main memory (which is often slow compared to the ALU and control units) greatly increases the computer's speed.
Computer main memory comes in two principal varieties:

random-access memory or RAM
read-only memory or ROMRAM can be read and written to anytime the CPU commands it, but ROM is preloaded with data and software that never changes, therefore the CPU can only read from it. ROM is typically used to store the computer's initial start-up instructions. In general, the contents of RAM are erased when the power to the computer is turned off, but ROM retains its data indefinitely. In a PC, the ROM contains a specialized program called the BIOS that orchestrates loading the computer's operating system from the hard disk drive into RAM whenever the computer is turned on or reset. In embedded computers, which frequently do not have disk drives, all of the required software may be stored in ROM. Software stored in ROM is often called firmware, because it is notionally more like hardware than software. Flash memory blurs the distinction between ROM and RAM, as it retains its data when turned off but is also rewritable. It is typically much slower than conventional ROM and RAM however, so its use is restricted to applications where high speed is unnecessary.In more sophisticated computers there may be one or more RAM cache memories, which are slower than registers but faster than main memory. Generally computers with this sort of cache are designed to move frequently needed data into the cache automatically, often without the need for any intervention on the programmer's part.


=== Input/output (I/O) ===

I/O is the means by which a computer exchanges information with the outside world. Devices that provide input or output to the computer are called peripherals. On a typical personal computer, peripherals include input devices like the keyboard and mouse, and output devices such as the display and printer. Hard disk drives, floppy disk drives and optical disc drives serve as both input and output devices. Computer networking is another form of I/O.
I/O devices are often complex computers in their own right, with their own CPU and memory. A graphics processing unit might contain fifty or more tiny computers that perform the calculations necessary to display 3D graphics. Modern desktop computers contain many smaller computers that assist the main CPU in performing I/O. A 2016-era flat screen display contains its own computer circuitry.


=== Multitasking ===

While a computer may be viewed as running one gigantic program stored in its main memory, in some systems it is necessary to give the appearance of running several programs simultaneously. This is achieved by multitasking i.e. having the computer switch rapidly between running each program in turn. One means by which this is done is with a special signal called an interrupt, which can periodically cause the computer to stop executing instructions where it was and do something else instead. By remembering where it was executing prior to the interrupt, the computer can return to that task later. If several programs are running ""at the same time"". then the interrupt generator might be causing several hundred interrupts per second, causing a program switch each time. Since modern computers typically execute instructions several orders of magnitude faster than human perception, it may appear that many programs are running at the same time even though only one is ever executing in any given instant. This method of multitasking is sometimes termed ""time-sharing"" since each program is allocated a ""slice"" of time in turn.Before the era of inexpensive computers, the principal use for multitasking was to allow many people to share the same computer. Seemingly, multitasking would cause a computer that is switching between several programs to run more slowly, in direct proportion to the number of programs it is running, but most programs spend much of their time waiting for slow input/output devices to complete their tasks. If a program is waiting for the user to click on the mouse or press a key on the keyboard, then it will not take a ""time slice"" until the event it is waiting for has occurred. This frees up time for other programs to execute so that many programs may be run simultaneously without unacceptable speed loss.


=== Multiprocessing ===

Some computers are designed to distribute their work across several CPUs in a multiprocessing configuration, a technique once employed only in large and powerful machines such as supercomputers, mainframe computers and servers. Multiprocessor and multi-core (multiple CPUs on a single integrated circuit) personal and laptop computers are now widely available, and are being increasingly used in lower-end markets as a result.
Supercomputers in particular often have highly unique architectures that differ significantly from the basic stored-program architecture and from general purpose computers. They often feature thousands of CPUs, customized high-speed interconnects, and specialized computing hardware. Such designs tend to be useful only for specialized tasks due to the large scale of program organization required to successfully utilize most of the available resources at once. Supercomputers usually see usage in large-scale simulation, graphics rendering, and cryptography applications, as well as with other so-called ""embarrassingly parallel"" tasks.


== Software ==

Software refers to parts of the computer which do not have a material form, such as programs, data, protocols, etc. Software is that part of a computer system that consists of encoded information or computer instructions, in contrast to the physical hardware from which the system is built. Computer software includes computer programs, libraries and related non-executable data, such as online documentation or digital media. It is often divided into system software and application software Computer hardware and software require each other and neither can be realistically used on its own. When software is stored in hardware that cannot easily be modified, such as with BIOS ROM in an IBM PC compatible computer, it is sometimes called ""firmware"".


=== Languages ===
There are thousands of different programming languages—some intended to be general purpose, others useful only for highly specialized applications.


=== Programs ===
The defining feature of modern computers which distinguishes them from all other machines is that they can be programmed. That is to say that some type of instructions (the program) can be given to the computer, and it will process them. Modern computers based on the von Neumann architecture often have machine code in the form of an imperative programming language. In practical terms, a computer program may be just a few instructions or extend to many millions of instructions, as do the programs for word processors and web browsers for example. A typical modern computer can execute billions of instructions per second (gigaflops) and rarely makes a mistake over many years of operation. Large computer programs consisting of several million instructions may take teams of programmers years to write, and due to the complexity of the task almost certainly contain errors.


==== Stored program architecture ====

This section applies to most common RAM machine–based computers.
In most cases, computer instructions are simple: add one number to another, move some data from one location to another, send a message to some external device, etc. These instructions are read from the computer's memory and are generally carried out (executed) in the order they were given. However, there are usually specialized instructions to tell the computer to jump ahead or backwards to some other place in the program and to carry on executing from there. These are called ""jump"" instructions (or branches). Furthermore, jump instructions may be made to happen conditionally so that different sequences of instructions may be used depending on the result of some previous calculation or some external event. Many computers directly support subroutines by providing a type of jump that ""remembers"" the location it jumped from and another instruction to return to the instruction following that jump instruction.
Program execution might be likened to reading a book. While a person will normally read each word and line in sequence, they may at times jump back to an earlier place in the text or skip sections that are not of interest. Similarly, a computer may sometimes go back and repeat the instructions in some section of the program over and over again until some internal condition is met. This is called the flow of control within the program and it is what allows the computer to perform tasks repeatedly without human intervention.
Comparatively, a person using a pocket calculator can perform a basic arithmetic operation such as adding two numbers with just a few button presses. But to add together all of the numbers from 1 to 1,000 would take thousands of button presses and a lot of time, with a near certainty of making a mistake. On the other hand, a computer may be programmed to do this with just a few simple instructions. The following example is written in the MIPS assembly language:

Once told to run this program, the computer will perform the repetitive addition task without further human intervention. It will almost never make a mistake and a modern PC can complete the task in a fraction of a second.


==== Machine code ====
In most computers, individual instructions are stored as machine code with each instruction being given a unique number (its operation code or opcode for short). The command to add two numbers together would have one opcode; the command to multiply them would have a different opcode, and so on. The simplest computers are able to perform any of a handful of different instructions; the more complex computers have several hundred to choose from, each with a unique numerical code. Since the computer's memory is able to store numbers, it can also store the instruction codes. This leads to the important fact that entire programs (which are just lists of these instructions) can be represented as lists of numbers and can themselves be manipulated inside the computer in the same way as numeric data. The fundamental concept of storing programs in the computer's memory alongside the data they operate on is the crux of the von Neumann, or stored program, architecture. In some cases, a computer might store some or all of its program in memory that is kept separate from the data it operates on. This is called the Harvard architecture after the Harvard Mark I computer. Modern von Neumann computers display some traits of the Harvard architecture in their designs, such as in CPU caches.
While it is possible to write computer programs as long lists of numbers (machine language) and while this technique was used with many early computers, it is extremely tedious and potentially error-prone to do so in practice, especially for complicated programs. Instead, each basic instruction can be given a short name that is indicative of its function and easy to remember – a mnemonic such as ADD, SUB, MULT or JUMP. These mnemonics are collectively known as a computer's assembly language. Converting programs written in assembly language into something the computer can actually understand (machine language) is usually done by a computer program called an assembler.


==== Programming language ====

Programming languages provide various ways of specifying programs for computers to run. Unlike natural languages, programming languages are designed to permit no ambiguity and to be concise. They are purely written languages and are often difficult to read aloud. They are generally either translated into machine code by a compiler or an assembler before being run, or translated directly at run time by an interpreter. Sometimes programs are executed by a hybrid method of the two techniques.


===== Low-level languages =====

Machine languages and the assembly languages that represent them (collectively termed low-level programming languages) are generally unique to the particular architecture of a computer's central processing unit (CPU). For instance, an ARM architecture CPU (such as may be found in a smartphone or a hand-held videogame) cannot understand the machine language of an x86 CPU that might be in a PC. Historically a significant number of other cpu architectures were created and saw extensive use, notably including the MOS Technology 6502 and 6510 in addition to the Zilog Z80.


===== High-level languages =====

Although considerably easier than in machine language, writing long programs in assembly language is often difficult and is also error prone. Therefore, most practical programs are written in more abstract high-level programming languages that are able to express the needs of the programmer more conveniently (and thereby help reduce programmer error). High level languages are usually ""compiled"" into machine language (or sometimes into assembly language and then into machine language) using another computer program called a compiler. High level languages are less related to the workings of the target computer than assembly language, and more related to the language and structure of the problem(s) to be solved by the final program. It is therefore often possible to use different compilers to translate the same high level language program into the machine language of many different types of computer. This is part of the means by which software like video games may be made available for different computer architectures such as personal computers and various video game consoles.


==== Program design ====
Program design of small programs is relatively simple and involves the analysis of the problem, collection of inputs, using the programming constructs within languages, devising or using established procedures and algorithms, providing data for output devices and solutions to the problem as applicable. As problems become larger and more complex, features such as subprograms, modules, formal documentation, and new paradigms such as object-oriented programming are encountered. Large programs involving thousands of line of code and more require formal software methodologies.
The task of developing large software systems presents a significant intellectual challenge. Producing software with an acceptably high reliability within a predictable schedule and budget has historically been difficult; the academic and professional discipline of software engineering concentrates specifically on this challenge.


==== Bugs ====

Errors in computer programs are called ""bugs"". They may be benign and not affect the usefulness of the program, or have only subtle effects. But in some cases, they may cause the program or the entire system to ""hang"", becoming unresponsive to input such as mouse clicks or keystrokes, to completely fail, or to crash. Otherwise benign bugs may sometimes be harnessed for malicious intent by an unscrupulous user writing an exploit, code designed to take advantage of a bug and disrupt a computer's proper execution. Bugs are usually not the fault of the computer. Since computers merely execute the instructions they are given, bugs are nearly always the result of programmer error or an oversight made in the program's design.
Admiral Grace Hopper, an American computer scientist and developer of the first compiler, is credited for having first used the term ""bugs"" in computing after a dead moth was found shorting a relay in the Harvard Mark II computer in September 1947.


== Networking and the Internet ==

Computers have been used to coordinate information between multiple locations since the 1950s. The U.S. military's SAGE system was the first large-scale example of such a system, which led to a number of special-purpose commercial systems such as Sabre. In the 1970s, computer engineers at research institutions throughout the United States began to link their computers together using telecommunications technology. The effort was funded by ARPA (now DARPA), and the computer network that resulted was called the ARPANET. The technologies that made the Arpanet possible spread and evolved.
In time, the network spread beyond academic and military institutions and became known as the Internet. The emergence of networking involved a redefinition of the nature and boundaries of the computer. Computer operating systems and applications were modified to include the ability to define and access the resources of other computers on the network, such as peripheral devices, stored information, and the like, as extensions of the resources of an individual computer. Initially these facilities were available primarily to people working in high-tech environments, but in the 1990s the spread of applications like e-mail and the World Wide Web, combined with the development of cheap, fast networking technologies like Ethernet and ADSL saw computer networking become almost ubiquitous. In fact, the number of computers that are networked is growing phenomenally. A very large proportion of personal computers regularly connect to the Internet to communicate and receive information. ""Wireless"" networking, often utilizing mobile phone networks, has meant networking is becoming increasingly ubiquitous even in mobile computing environments.


== Unconventional computers ==

A computer does not need to be electronic, nor even have a processor, nor RAM, nor even a hard disk. While popular usage of the word ""computer"" is synonymous with a personal electronic computer, the modern definition of a computer is literally: ""A device that computes, especially a programmable [usually] electronic machine that performs high-speed mathematical or logical operations or that assembles, stores, correlates, or otherwise processes information."" Any device which processes information qualifies as a computer, especially if the processing is purposeful.


== Future ==
There is active research to make computers out of many promising new types of technology, such as optical computers, DNA computers, neural computers, and quantum computers. Most computers are universal, and are able to calculate any computable function, and are limited only by their memory capacity and operating speed. However different designs of computers can give very different performance for particular problems; for example quantum computers can potentially break some modern encryption algorithms (by quantum factoring) very quickly.


=== Computer architecture paradigms ===
There are many types of computer architectures:

Quantum computer vs. Chemical computer
Scalar processor vs. Vector processor
Non-Uniform Memory Access (NUMA) computers
Register machine vs. Stack machine
Harvard architecture vs. von Neumann architecture
Cellular architectureOf all these abstract machines, a quantum computer holds the most promise for revolutionizing computing. Logic gates are a common abstraction which can apply to most of the above digital or analog paradigms. The ability to store and execute lists of instructions called programs makes computers extremely versatile, distinguishing them from calculators. The Church–Turing thesis is a mathematical statement of this versatility: any computer with a minimum capability (being Turing-complete) is, in principle, capable of performing the same tasks that any other computer can perform. Therefore, any type of computer (netbook, supercomputer, cellular automaton, etc.) is able to perform the same computational tasks, given enough time and storage capacity.


=== Artificial intelligence ===
A computer will solve problems in exactly the way it is programmed to, without regard to efficiency, alternative solutions, possible shortcuts, or possible errors in the code. Computer programs that learn and adapt are part of the emerging field of artificial intelligence and machine learning. Artificial intelligence based products generally fall into two major categories: rule based systems and pattern recognition systems. Rule based systems attempt to represent the rules used by human experts and tend to be expensive to develop. Pattern based systems use data about a problem to generate conclusions. Examples of pattern based systems include voice recognition, font recognition, translation and the emerging field of on-line marketing.


== Professions and organizations ==
As the use of computers has spread throughout society, there are an increasing number of careers involving computers.

The need for computers to work well together and to be able to exchange information has spawned the need for many standards organizations, clubs and societies of both a formal and informal nature.


== See also ==


== References ==


== Notes ==


== External links ==
 Media related to Computers at Wikimedia Commons
 Wikiversity has a quiz on this article
Warhol & The Computer"
"Computer science is the study of computation and information. Computer science deals with theory of computation, algorithms, computational problems and the design of computer systems hardware, software and applications. Computer science addresses both human-made and natural information processes, such as communication, control, perception, learning and intelligence especially in human-made computing systems and machines. According to Peter Denning, the fundamental question underlying computer science is, What can be automated?Its fields can be divided into theoretical and practical disciplines. For example Computational complexity theory describes the amount of resources required to solve computational problems, while computer graphics and computational geometry emphasizes more specific applications. Algorithmics have been called the heart of computer science. Programming language theory considers approaches to the description of computational processes, while software engineering involves the use of programming languages and complex systems. Computer architecture and computer engineering deals with construction of computer components and computer-controlled equipment. Human–computer interaction considers the challenges in making computers useful, usable, and accessible. Artificial intelligence aims to synthesize goal-orientated processes such as problem-solving, decision-making, environmental adaptation, motion planning, learning, and communication found in humans and animals.


== History ==

The earliest foundations of what would become computer science predate the invention of the modern digital computer. Machines for calculating fixed numerical tasks such as the abacus have existed since antiquity, aiding in computations such as multiplication and division. Algorithms for performing computations have existed since antiquity, even before the development of sophisticated computing equipment. 
Wilhelm Schickard designed and constructed the first working mechanical calculator in 1623. In 1673, Gottfried Leibniz demonstrated a digital mechanical calculator, called the Stepped Reckoner. Leibniz may be considered the first computer scientist and information theorist, for, among other reasons, documenting the binary number system. In 1820, Thomas de Colmar launched the mechanical calculator industry when he invented his simplified arithmometer, the first calculating machine strong enough and reliable enough to be used daily in an office environment. Charles Babbage started the design of the first automatic mechanical calculator, his Difference Engine, in 1822, which eventually gave him the idea of the first programmable mechanical calculator, his Analytical Engine. He started developing this machine in 1834, and ""in less than two years, he had sketched out many of the salient features of the modern computer"". ""A crucial step was the adoption of a punched card system derived from the Jacquard loom"" making it infinitely programmable. In 1843, during the translation of a French article on the Analytical Engine, Ada Lovelace wrote, in one of the many notes she included, an algorithm to compute the Bernoulli numbers, which is considered to be the first published algorithm ever specifically tailored for implementation on a computer. Around 1885, Herman Hollerith invented the tabulator, which used punched cards to process statistical information; eventually his company became part of IBM. Following Babbage, although unaware of his earlier work, Percy Ludgate in 1909 published  the 2nd of the only two designs for mechanical analytical engines in history. In 1937, one hundred years after Babbage's impossible dream, Howard Aiken convinced IBM, which was making all kinds of punched card equipment and was also in the calculator business to develop his giant programmable calculator, the ASCC/Harvard Mark I, based on Babbage's Analytical Engine, which itself used cards and a central computing unit. When the machine was finished, some hailed it as ""Babbage's dream come true"".During the 1940s, with the development of new and more powerful computing machines such as the Atanasoff–Berry computer and ENIAC, the term computer came to refer to the machines rather than their human predecessors. As it became clear that computers could be used for more than just mathematical calculations, the field of computer science broadened to study computation in general. In 1945, IBM founded the Watson Scientific Computing Laboratory at Columbia University in New York City. The renovated fraternity house on Manhattan's West Side was IBM's first laboratory devoted to pure science. The lab is the forerunner of IBM's Research Division, which today operates research facilities around the world. Ultimately, the close relationship between IBM and the university was instrumental in the emergence of a new scientific discipline, with Columbia offering one of the first academic-credit courses in computer science in 1946. Computer science began to be established as a distinct academic discipline in the 1950s and early 1960s. The world's first computer science degree program, the Cambridge Diploma in Computer Science, began at the University of Cambridge Computer Laboratory in 1953. The first computer science department in the United States was formed at Purdue University in 1962. Since practical computers became available, many applications of computing have become distinct areas of study in their own rights.
Although many initially believed it was impossible that computers themselves could actually be a scientific field of study, in the late fifties it gradually became accepted among the greater academic population. It is the now well-known IBM brand that formed part of the computer science revolution during this time. IBM (short for International Business Machines) released the IBM 704 and later the IBM 709 computers, which were widely used during the exploration period of such devices. ""Still, working with the IBM [computer] was frustrating […] if you had misplaced as much as one letter in one instruction, the program would crash, and you would have to start the whole process over again"". During the late 1950s, the computer science discipline was very much in its developmental stages, and such issues were commonplace.The concept of a field-effect transistor was proposed by Julius Edgar Lilienfeld in 1925. John Bardeen and Walter Brattain, while working under William Shockley at Bell Labs, built the first working transistor, the point-contact transistor, in 1947. In 1953, the University of Manchester built the first transistorized computer, called the Transistor Computer. However, early junction transistors were relatively bulky devices that were difficult to manufacture on a mass-production basis, which limited them to a number of specialised applications. The metal–oxide–silicon field-effect transistor (MOSFET, or MOS transistor) was invented by Mohamed Atalla and Dawon Kahng at Bell Labs in 1959. It was the first truly compact transistor that could be miniaturised and mass-produced for a wide range of uses. The MOSFET made it possible to build high-density integrated circuit chips, leading to what is known as the computer revolution or microcomputer revolution.Time has seen significant improvements in the usability and effectiveness of computing technology. Modern society has seen a significant shift in the demographics which make use of computer technology; usage has shifted from being mostly exclusive to experts and professionals, to a near-ubiquitous user base. Initially, computers were quite costly, and some degree of humanitarian aid was needed for efficient use—in part from professional computer operators. As computer adoption became more widespread and affordable, less human assistance was needed for common usage.


== Etymology ==

Although first proposed in 1956, the term ""computer science"" appears in a 1959 article in Communications of the ACM,
in which Louis Fein argues for the creation of a Graduate School in Computer Sciences analogous to the creation of Harvard Business School in 1921, justifying the name by arguing that, like management science, the subject is applied and interdisciplinary in nature, while having the characteristics typical of an academic discipline.
His efforts, and those of others such as numerical analyst George Forsythe, were rewarded: universities went on to create such departments, starting with Purdue in 1962. Despite its name, a significant amount of computer science does not involve the study of computers themselves. Because of this, several alternative names have been proposed. Certain departments of major universities prefer the term computing science, to emphasize precisely that difference. Danish scientist Peter Naur suggested the term datalogy, to reflect the fact that the scientific discipline revolves around data and data treatment, while not necessarily involving computers. The first scientific institution to use the term was the Department of Datalogy at the University of Copenhagen, founded in 1969, with Peter Naur being the first professor in datalogy. The term is used mainly in the Scandinavian countries. An alternative term, also proposed by Naur, is data science; this is now used for a multi-disciplinary field of data analysis, including statistics and databases.
In the early days of computing, a number of terms for the practitioners of the field of computing were suggested in the Communications of the ACM—turingineer, turologist, flow-charts-man, applied meta-mathematician, and applied epistemologist. Three months later in the same journal, comptologist was suggested, followed next year by hypologist. The term computics has also been suggested. In Europe, terms derived from contracted translations of the expression ""automatic information"" (e.g. ""informazione automatica"" in Italian) or ""information and mathematics"" are often used, e.g. informatique (French), Informatik (German), informatica (Italian, Dutch), informática (Spanish, Portuguese), informatika (Slavic languages and Hungarian) or pliroforiki (πληροφορική, which means informatics) in Greek. Similar words have also been adopted in the UK (as in the School of Informatics of the University of Edinburgh).
""In the U.S., however, informatics is linked with applied computing, or computing in the context of another domain.""A folkloric quotation, often attributed to—but almost certainly not first formulated by—Edsger Dijkstra, states that ""computer science is no more about computers than astronomy is about telescopes."" The design and deployment of computers and computer systems is generally considered the province of disciplines other than computer science. For example, the study of computer hardware is usually considered part of computer engineering, while the study of commercial computer systems and their deployment is often called information technology or information systems. However, there has been much cross-fertilization of ideas between the various computer-related disciplines. Computer science research also often intersects other disciplines, such as philosophy, cognitive science, linguistics, mathematics, physics, biology, statistics, and logic.
Computer science is considered by some to have a much closer relationship with mathematics than many scientific disciplines, with some observers saying that computing is a mathematical science. Early computer science was strongly influenced by the work of mathematicians such as Kurt Gödel, Alan Turing, John von Neumann, Rózsa Péter and Alonzo Church and there continues to be a useful interchange of ideas between the two fields in areas such as mathematical logic, category theory, domain theory, and algebra.The relationship between Computer Science and Software Engineering is a contentious issue, which is further muddied by disputes over what the term ""Software Engineering"" means, and how computer science is defined. David Parnas, taking a cue from the relationship between other engineering and science disciplines, has claimed that the principal focus of computer science is studying the properties of computation in general, while the principal focus of software engineering is the design of specific computations to achieve practical goals, making the two separate but complementary disciplines.The academic, political, and funding aspects of computer science tend to depend on whether a department formed with a mathematical emphasis or with an engineering emphasis. Computer science departments with a mathematics emphasis and with a numerical orientation consider alignment with computational science. Both types of departments tend to make efforts to bridge the field educationally if not across all research.


== Philosophy ==

A number of computer scientists have argued for the distinction of three separate paradigms in computer science. Peter Wegner argued that those paradigms are science, technology, and mathematics. Peter Denning's working group argued that they are theory, abstraction (modeling), and design. Amnon H. Eden described them as the ""rationalist paradigm"" (which treats computer science as a branch of mathematics, which is prevalent in theoretical computer science, and mainly employs deductive reasoning), the ""technocratic paradigm"" (which might be found in engineering approaches, most prominently in software engineering), and the ""scientific paradigm"" (which approaches computer-related artifacts from the empirical perspective of natural sciences, identifiable in some branches of artificial intelligence).
Computer science focuses on methods involved in design, specification, programming, verification, implementation and testing of human-made computing systems.


== Fields ==
Computer science is no more about computers than astronomy is about telescopes.

As a discipline, computer science spans a range of topics from theoretical studies of algorithms and the limits of computation to the practical issues of implementing computing systems in hardware and software.CSAB, formerly called Computing Sciences Accreditation Board—which is made up of representatives of the Association for Computing Machinery (ACM), and the IEEE Computer Society (IEEE CS)—identifies four areas that it considers crucial to the discipline of computer science: theory of computation, algorithms and data structures, programming methodology and languages, and computer elements and architecture. In addition to these four areas, CSAB also identifies fields such as software engineering, artificial intelligence, computer networking and communication, database systems, parallel computation, distributed computation, human–computer interaction, computer graphics, operating systems, and numerical and symbolic computation as being important areas of computer science.


=== Theoretical computer science ===

Theoretical Computer Science is mathematical and abstract in spirit, but it derives its motivation from the practical and everyday computation. Its aim is to understand the nature of computation and, as a consequence of this understanding, provide more efficient methodologies. All studies related to mathematical, logic and formal concepts and methods could be considered as theoretical computer science, provided that the motivation is clearly drawn from the field of computing.


==== Theory of computation ====

According to Peter Denning, the fundamental question underlying computer science is, ""What can be automated?"" Theory of computation is focused on answering fundamental questions about what can be computed and what amount of resources are required to perform those computations. In an effort to answer the first question, computability theory examines which computational problems are solvable on various theoretical models of computation. The second question is addressed by computational complexity theory, which studies the time and space costs associated with different approaches to solving a multitude of computational problems.
The famous P = NP? problem, one of the Millennium Prize Problems, is an open problem in the theory of computation.


==== Information and coding theory ====

Information theory, closely related to probability and statistics, is related to the quantification of information. This was developed by Claude Shannon to find fundamental limits on signal processing operations such as compressing data and on reliably storing and communicating data.
Coding theory is the study of the properties of codes (systems for converting information from one form to another) and their fitness for a specific application. Codes are used for data compression, cryptography, error detection and correction, and more recently also for network coding. Codes are studied for the purpose of designing efficient and reliable data transmission methods.


==== Data structures and algorithms ====
Data structures and algorithms are the studies of commonly used computational methods and their computational efficiency.


==== Programming language theory ====

Programming language theory is a branch of computer science that deals with the design, implementation, analysis, characterization, and classification of programming languages and their individual features. It falls within the discipline of computer science, both depending on and affecting mathematics, software engineering, and linguistics. It is an active research area, with numerous dedicated academic journals.


==== Formal methods ====

Formal methods are a particular kind of mathematically based technique for the specification, development and verification of software and hardware systems. The use of formal methods for software and hardware design is motivated by the expectation that, as in other engineering disciplines, performing appropriate mathematical analysis can contribute to the reliability and robustness of a design. They form an important theoretical underpinning for software engineering, especially where safety or security is involved. Formal methods are a useful adjunct to software testing since they help avoid errors and can also give a framework for testing. For industrial use, tool support is required. However, the high cost of using formal methods means that they are usually only used in the development of high-integrity and life-critical systems, where safety or security is of utmost importance. Formal methods are best described as the application of a fairly broad variety of theoretical computer science fundamentals, in particular logic calculi, formal languages, automata theory, and program semantics, but also type systems and algebraic data types to problems in software and hardware specification and verification.


=== Computer systems ===


==== Computer architecture and computer engineering ====

Computer architecture, or digital computer organization, is the conceptual design and fundamental operational structure of a computer system. It focuses largely on the way by which the central processing unit performs internally and accesses addresses in memory. The field often involves disciplines of computer engineering and electrical engineering, selecting and interconnecting hardware components to create computers that meet functional, performance, and cost goals.


==== Computer performance analysis ====

Computer performance analysis is the study of work flowing through computers with the general goals of improving throughput, controlling response time, using resources efficiently, eliminating bottlenecks, and predicting performance under anticipated peak loads.Benchmarks are used to compare the performance of systems carrying different chips and/or system architectures.


==== Concurrent, parallel and distributed systems ====

Concurrency is a property of systems in which several computations are executing simultaneously, and potentially interacting with each other. A number of mathematical models have been developed for general concurrent computation including Petri nets, process calculi and the Parallel Random Access Machine model. When multiple computers are connected in a network while using concurrency, this is known as a distributed system. Computers within that distributed system have their own private memory, and information can be exchanged to achieve common goals.


==== Computer networks ====

This branch of computer science aims to manage networks between computers worldwide


==== Computer security and cryptography ====

Computer security is a branch of computer technology with an objective of protecting information from unauthorized access, disruption, or modification while maintaining the accessibility and usability of the system for its intended users. Cryptography is the practice and study of hiding (encryption) and therefore deciphering (decryption) information. Modern cryptography is largely related to computer science, for many encryption and decryption algorithms are based on their computational complexity.


==== Databases ====

A database is intended to organize, store, and retrieve large amounts of data easily. Digital databases are managed using database management systems to store, create, maintain, and search data, through database models and query languages.


=== Computer applications ===


==== Computer graphics and visualization ====

Computer graphics is the study of digital visual contents and involves the synthesis and manipulation of image data. The study is connected to many other fields in computer science, including computer vision, image processing, and computational geometry, and is heavily applied in the fields of special effects and video games.


==== Human–computer interaction ====

Research that develops theories, principles, and guidelines for user interface designers, so they can create satisfactory user experiences with desktop, laptop, and mobile devices.


==== Scientific computing and simulation ====
Main article: Computational science
Scientific computing (or computational science) is the field of study concerned with constructing mathematical models and quantitative analysis techniques and using computers to analyze and solve scientific problems. A major usage of scientific computing is simulation of various processes, including computational fluid dynamics, physical, electrical, and electronic systems and circuits, as well as societies and social situations (notably war games) along with their habitats, among many others. Modern computers enable optimization of such designs as complete aircraft. Notable in electrical and electronic circuit design are SPICE, as well as software for physical realization of new (or modified) designs. The latter includes essential design software for integrated circuits.


==== Artificial intelligence ====

Artificial intelligence (AI) aims to or is required to synthesize goal-orientated processes such as problem-solving, decision-making, environmental adaptation, learning, and communication found in humans and animals. From its origins in cybernetics and in the Dartmouth Conference (1956), artificial intelligence research has been necessarily cross-disciplinary, drawing on areas of expertise such as applied mathematics, symbolic logic, semiotics, electrical engineering, philosophy of mind, neurophysiology, and social intelligence. AI is associated in the popular mind with robotic development, but the main field of practical application has been as an embedded component in areas of software development, which require computational understanding. The starting point in the late 1940s was Alan Turing's question ""Can computers think?"", and the question remains effectively unanswered, although the Turing test is still used to assess computer output on the scale of human intelligence. But the automation of evaluative and predictive tasks has been increasingly successful as a substitute for human monitoring and intervention in domains of computer application involving complex real-world data.


=== Software engineering ===

Software engineering is the study of designing, implementing, and modifying the software in order to ensure it is of high quality, affordable, maintainable, and fast to build. It is a systematic approach to software design, involving the application of engineering practices to software. Software engineering deals with the organizing and analyzing of software—it doesn't just deal with the creation or manufacture of new software, but its internal arrangement and maintenance.


== Discoveries ==
The philosopher of computing Bill Rapaport noted three Great Insights of Computer Science:
Gottfried Wilhelm Leibniz's, George Boole's, Alan Turing's, Claude Shannon's, and Samuel Morse's insight: there are only two objects that a computer has to deal with in order to represent ""anything"".All the information about any computable problem can be represented using only 0 and 1 (or any other bistable pair that can flip-flop between two easily distinguishable states, such as ""on/off"", ""magnetized/de-magnetized"", ""high-voltage/low-voltage"", etc.).
Alan Turing's insight: there are only five actions that a computer has to perform in order to do ""anything"".Every algorithm can be expressed in a language for a computer consisting of only five basic instructions:move left one location;
move right one location;
read symbol at current location;
print 0 at current location;
print 1 at current location.
Corrado Böhm and Giuseppe Jacopini's insight: there are only three ways of combining these actions (into more complex ones) that are needed in order for a computer to do ""anything"".Only three rules are needed to combine any set of basic instructions into more complex ones:
sequence: first do this, then do that;
 selection: IF such-and-such is the case, THEN do this, ELSE do that;
repetition: WHILE such-and-such is the case, DO this.
Note that the three rules of Boehm's and Jacopini's insight can be further simplified with the use of goto (which means it is more elementary than structured programming).


== Programming paradigms ==

Programming languages can be used to accomplish different tasks in different ways. Common programming paradigms include:

Functional programming, a style of building the structure and elements of computer programs that treats computation as the evaluation of mathematical functions and avoids state and mutable data. It is a declarative programming paradigm, which means programming is done with expressions or declarations instead of statements.
Imperative programming, a programming paradigm that uses statements that change a program's state. In much the same way that the imperative mood in natural languages expresses commands, an imperative program consists of commands for the computer to perform. Imperative programming focuses on describing how a program operates.
Object-oriented programming, a programming paradigm based on the concept of ""objects"", which may contain data, in the form of fields, often known as attributes; and code, in the form of procedures, often known as methods. A feature of objects is that an object's procedures can access and often modify the data fields of the object with which they are associated. Thus object-oriented computer programs are made out of objects that interact with one another.Many languages offer support for multiple paradigms, making the distinction more a matter of style than of technical capabilities.


== Academia ==

Conferences are important events for computer science research. During these conferences, researchers from the public and private sectors present their recent work and meet. Unlike in most other academic fields, in computer science, the prestige of conference papers is greater than that of journal publications. One proposed explanation for this is the quick development of this relatively new field requires rapid review and distribution of results, a task better handled by conferences than by journals.


== Education ==

Computer Science, known by its near synonyms, Computing, Computer Studies, Information Technology (IT) and Information and Computing Technology (ICT), has been taught in UK schools since the days of batch processing, mark sensitive cards and paper tape but usually to a select few students. In 1981, the BBC produced a micro-computer and classroom network and Computer Studies became common for GCE O level students (11–16-year-old), and Computer Science to A level students. Its importance was recognised, and it became a compulsory part of the National Curriculum, for Key Stage 3 & 4. In September 2014 it became an entitlement for all pupils over the age of 4.In the US, with 14,000 school districts deciding the curriculum, provision was fractured. According to a 2010 report by the Association for Computing Machinery (ACM) and Computer Science Teachers Association (CSTA), only 14 out of 50 states have adopted significant education standards for high school computer science.Israel, New Zealand, and South Korea have included computer science in their national secondary education curricula, and several others are following.


== See also ==


== Notes ==


== References ==


== Further reading ==


== External links ==

Computer science at Curlie
Scholarly Societies in Computer Science
What is Computer Science?
Best Papers Awards in Computer Science since 1996
Photographs of computer scientists by Bertrand Meyer
EECS.berkeley.edu


=== Bibliography and academic search engines ===
CiteSeerx (article): search engine, digital library and repository for scientific and academic papers with a focus on computer and information science.
DBLP Computer Science Bibliography (article): computer science bibliography website hosted at Universität Trier, in Germany.
The Collection of Computer Science Bibliographies (article)


=== Professional organizations ===
Association for Computing Machinery
IEEE Computer Society
Informatics Europe
AAAI
AAAS Computer Science


=== Misc ===
Computer Science—Stack Exchange: a community-run question-and-answer site for computer science
What is computer science
Is computer science science?
Computer Science (Software) Must be Considered as an Independent Discipline."
"Computer hardware includes the physical parts of a computer, such as the case, central processing unit (CPU), monitor, mouse, keyboard, computer data storage, graphics card, sound card, speakers and motherboard.By contrast, software is the set of instructions that can be stored and run by hardware. Hardware is so-termed because it is ""hard"" or rigid with respect to changes, whereas software is ""soft"" because it is easy to change.
Hardware is typically directed by the software to execute any command or instruction. A combination of hardware and software forms a usable computing system, although other systems exist with only hardware.


== Von Neumann architecture ==

The template for all modern computers is the Von Neumann architecture, detailed in a 1945 paper by Hungarian mathematician John von Neumann. This describes a design architecture for an electronic digital computer with subdivisions of a processing unit consisting of an arithmetic logic unit and processor registers, a control unit containing an instruction register and program counter, a memory to store both data and instructions, external mass storage, and input and output mechanisms. The meaning of the term has evolved to mean a stored-program computer in which an instruction fetch and a data operation cannot occur at the same time because they share a common bus. This is referred to as the Von Neumann bottleneck and often limits the performance of the system.


== Types of computer systems ==


=== Personal computer ===

The personal computer is one of the most common types of computer due to its versatility and relatively low price. Desktop personal computers have  a monitor, a keyboard, a mouse, and a computer case. The computer case holds the motherboard, fixed or removable disk drives for data storage, the power supply, and may contain other peripheral devices such as modems or network interfaces.  Some models of desktop computers integrated the monitor and keyboard into the same case as the processor and power supply. Separating the elements allows the user to arrange the components in a pleasing, comfortable array, at the cost of managing power and data cables between them. 
Laptops are designed for portability but operate similarly to desktop PCs. They may use lower-power or reduced size components, with lower performance than a similarly priced desktop computer.  Laptops contain the keyboard, display, and processor in one case. The monitor in the folding upper cover of the case can be closed for transportation, to protect the screen and keyboard.  Instead of a mouse, laptops may have a trackpad or pointing stick. 
Tablets are portable computer that uses a touch screen as the primary input device. Tablets generally weigh less and are smaller than laptops. 
Some tablets include fold-out keyboards, or offer connections to separate external keyboards. Some models of laptop computers have a detachable keyboard, which allows the system to be configured as a touch-screen tablet. They are sometimes called ""2-in-1 detachable laptops"" or ""tablet-laptop hybrids"".


==== Case ====

The computer case encloses most of the components of the system. It provides mechanical support and protection for internal elements such as the motherboard, disk drives, and power supplies, and controls and directs the flow of cooling air over internal components. The case is also part of the system to control electromagnetic interference radiated by the computer and protects internal parts from electrostatic discharge. Large tower cases provide space for multiple disk drives or other peripherals and usually stand on the floor, while desktop cases provide less expansion room. All-in-one style designs include a video display built into the same case. Portable and laptop computers require cases that provide impact protection for the unit. Hobbyists may decorate the cases with colored lights, paint, or other features, in an activity called case modding.


==== Power supply ====

A power supply unit (PSU) converts alternating current (AC) electric power to low-voltage direct current (DC) power for the computer. Laptops can run on built-in rechargeable battery. The PSU typically uses a switched-mode power supply (SMPS), with power MOSFETs (power metal–oxide–semiconductor field-effect transistors) used in the converters and regulator circuits of the SMPS.


==== Motherboard ====

The motherboard is the main component of a computer. It is a board with integrated circuitry that connects the other parts of the computer including the CPU, the RAM, the disk drives (CD, DVD, hard disk, or any others) as well as any peripherals connected via the ports or the expansion slots. The integrated circuit (IC) chips in a computer typically contain billions of tiny metal–oxide–semiconductor field-effect transistors (MOSFETs).Components directly attached to or to part of the motherboard include:

The CPU (central processing unit), which performs most of the calculations which enable a computer to function, and is referred to as the brain of the computer which get a hold of program instruction from random-access memory (RAM), interprets and processes it and then sends it back to computer result so that the relevant components can carry out the instructions. The CPU is a microprocessor, which is fabricated on a metal–oxide–semiconductor (MOS) integrated circuit (IC) chip. It is usually cooled by a heat sink and fan, or water-cooling system. Most newer CPU includes an on-die graphics processing unit (GPU). The clock speed of CPU governs how fast it executes instructions and is measured in GHz; typical values lie between 1 GHz and 5 GHz. Many modern computers have the option to overclock the CPU which enhances performance at the expense of greater thermal output and thus a need for improved cooling.
The chipset, which includes the north bridge, mediates communication between the CPU and the other components of the system, including main memory; as well as south bridge, which is connected to the north bridge, and supports auxiliary interfaces and buses; and, finally, a Super I/O chip, connected through the south bridge, which supports the slowest and most legacy components like serial ports, hardware monitoring and fan control.
Random-access memory (RAM), which stores the code and data that are being actively accessed by the CPU. For example, when a web browser is opened on the computer it takes up memory; this is stored in the RAM until the web browser is closed. It is typically a type of dynamic RAM (DRAM), such as synchronous DRAM (SDRAM), where MOS memory chips store data on memory cells consisting of MOSFETs and MOS capacitors. RAM usually comes on dual in-line memory modules (DIMMs) in the sizes of 2GB, 4GB, and 8GB, but can be much larger.
Read-only memory (ROM), which stores the BIOS that runs when the computer is powered on or otherwise begins execution, a process known as Bootstrapping, or ""booting"" or ""booting up"". The ROM is typically a nonvolatile BIOS memory chip, which stores data on floating-gate MOSFET memory cells.
The BIOS (Basic Input Output System) includes boot firmware and power management firmware. Newer motherboards use Unified Extensible Firmware Interface (UEFI) instead of BIOS.
Buses that connect the CPU to various internal components and to expand cards for graphics and sound.
The CMOS (complementary MOS) battery, which powers the CMOS memory for date and time in the BIOS chip. This battery is generally a watch battery.
The video card (also known as the graphics card), which processes computer graphics. More powerful graphics cards are better suited to handle strenuous tasks, such as playing intensive video games or running computer graphics software. A video card contains a graphics processing unit (GPU) and video memory (typically a type of SDRAM), both fabricated on MOS integrated circuit (MOS IC) chips.
Power MOSFETs make up the voltage regulator module (VRM), which controls how much voltage other hardware components receive.


==== Expansion cards ====

An expansion card in computing is a printed circuit board that can be inserted into an expansion slot of a computer motherboard or backplane to add functionality to a computer system via the expansion bus. Expansion cards can be used to obtain or expand on features not offered by the motherboard.


==== Storage devices ====

A storage device is any computing hardware and digital media that is used for storing, porting and extracting data files and objects. It can hold and store information both temporarily and permanently and can be internal or external to a computer, server or any similar computing device. Data storage is a core function and fundamental component of computers.


===== Fixed media =====
Data is stored by a computer using a variety of media. Hard disk drives (HDDs) are found in virtually all older computers, due to their high capacity and low cost, but solid-state drives (SSDs) are faster and more power efficient, although currently more expensive than hard drives in terms of dollar per gigabyte, so are often found in personal computers built post-2007. SSDs use flash memory, which stores data on MOS memory chips consisting of floating-gate MOSFET memory cells. Some systems may use a disk array controller for greater performance or reliability.


===== Removable media =====
To transfer data between computers, an external flash memory device (such as a memory card or USB flash drive) or optical disc (such as a CD-ROM, DVD-ROM or BD-ROM) may be used. Their usefulness depends on being readable by other systems; the majority of machines have an optical disk drive (ODD), and virtually all have at least one Universal Serial Bus (USB) port.


==== Input and output peripherals ====

Input and output devices are typically housed externally to the main computer chassis. The following are either standard or very common to many computer systems.


===== Input device =====
Input devices allow the user to enter information into the system, or control its operation. Most personal computers have a mouse and keyboard, but laptop systems typically use a touchpad instead of a mouse. Other input devices include webcams, microphones, joysticks, and image scanners.


===== Output device =====
Output devices are designed around the senses of human beings. For example, monitors display text that can be read, speakers produce sound that can be heard. Such devices also could include printers or a Braille embosser.


=== Mainframe computer ===

A mainframe computer is a much larger computer that typically fills a room and may cost many hundreds or thousands of times as much as a personal computer. They are designed to perform large numbers of calculations for governments and large enterprises.


=== Departmental computing ===

In the 1960s and 1970s, more and more departments started to use cheaper and dedicated systems for specific purposes like process control and laboratory automation. A minicomputer, or colloquially mini, is a class of smaller computers that was developed in the mid-1960s and sold for much less than mainframe and mid-size computers from IBM and its direct competitors.


=== Supercomputer ===

A supercomputer is superficially similar to a mainframe but is instead intended for extremely demanding computational tasks. As of June 2018, the fastest supercomputer on the TOP500 supercomputer list is the Summit, in the United States, with a LINPACK benchmark score of 122.3 PFLOPS   Light, by around 29 PFLOPS.
The term supercomputer does not refer to a specific technology. Rather it indicates the fastest computations available at any given time. In mid-2011, the fastest supercomputers boasted speeds exceeding one petaflop, or 1 quadrillion (10^15 or 1,000 trillion) floating-point operations per second.
Supercomputers are fast but extremely costly, so they are generally used by large organizations to execute computationally demanding tasks involving large data sets. Supercomputers typically run military and scientific applications. Although costly, they are also being used for commercial applications where huge amounts of data must be analyzed. For example, large banks employ supercomputers to calculate the risks and returns of various investment strategies, and healthcare organizations use them to analyze giant databases of patient data to determine optimal treatments for various diseases and problems incurring to the country.


== Hardware upgrade ==
When using computer hardware, an upgrade means adding new or additional hardware to a computer that improves its performance, increases its capacity, or adds new features. For example, a user could perform a hardware upgrade to replace the hard drive with a faster one or a Solid State Drive (SSD) to get a boost in performance. The user may also install more Random Access Memory (RAM) so the computer can store additional temporary data, or retrieve such data at a faster rate. The user may add a USB 3.0 expansion card to fully use USB 3.0 devices, or could upgrade the Graphics Processing Unit (GPU) for cleaner, more advanced graphics, or more monitors. Performing such hardware upgrades may be necessary for aged computers to meet a new, or updated program's system requirements.


== Sales ==
Global revenue from computer hardware in 2016 reached 408 billion Euros.


== Recycling ==

Because computer parts contain hazardous materials, there is a growing movement to recycle old and outdated parts. Computer hardware contain dangerous chemicals such as: lead, mercury, nickel, and cadmium. According to the EPA these e-wastes have a harmful effect on the environment unless they are disposed of properly. Making hardware requires energy, and recycling parts will reduce air pollution, water pollution, as well as greenhouse gas emissions. Disposing unauthorized computer equipment is in fact illegal. Legislation makes it mandatory to recycle computers through the government approved facilities. Recycling a computer can be made easier by taking out certain reusable parts. For example, the RAM, DVD drive, the graphics card, hard drive or SSD, and other similar removable parts can be reused.
Many materials used in computer hardware can be recovered by recycling for use in future production. Reuse of tin, silicon, iron, aluminium, and a variety of plastics that are present in bulk in computers or other electronics can reduce the costs of constructing new systems. Components frequently contain copper, gold, tantalum, silver, platinum, palladium, and lead as well as other valuable materials suitable for reclamation.


=== Toxic computer components ===
The central processing unit contains many toxic materials. It contains lead and chromium in the metal plates. Resistors, semi-conductors, infrared detectors, stabilizers, cables, and wires contain cadmium. The circuit boards in a computer contain mercury, and chromium. When these types of materials, and chemicals are disposed improperly will become hazardous for the environment.


=== Environmental effects ===
According to the United States Environmental Protection Agency only around 15% of the e-waste actually is recycled. When e-waste byproducts leach into groundwater, are burned, or get mishandled during recycling, it causes harm. Health problems associated with such toxins include impaired mental development, cancer, and damage to the lungs, liver, and kidneys. That's why even wires have to be recycled. Different companies have different techniques to recycle a wire. The most popular one is the grinder that separates the copper wires from the plastic/rubber casing. When the processes are done there are two different piles left; one containing the copper powder, and the other containing plastic/rubber pieces. Computer monitors, mice, and keyboards all have a similar way of being recycled. For example, first, each of the parts are taken apart then all of the inner parts get separated and placed into its own bin.Computer components contain many toxic substances, like dioxins, polychlorinated biphenyls (PCBs), cadmium, chromium, radioactive isotopes and mercury. A typical computer monitor may contain more than 6% lead by weight, much of which is in the lead glass of the cathode ray tube (CRT). A typical 15 inch (38 cm) computer monitor may contain 1.5 pounds (1 kg) of lead but other monitors have been estimated to have up to 8 pounds (4 kg) of lead. Circuit boards contain considerable quantities of lead-tin solders that are more likely to leach into groundwater or create air pollution due to incineration. In US landfills, about 40% of the lead content levels are from e-waste. The processing (e.g. incineration and acid treatments) required to reclaim these precious substances may release, generate, or synthesize toxic byproducts.
Recycling of computer hardware is considered environmentally friendly because it prevents hazardous waste, including heavy metals and carcinogens, from entering the atmosphere, landfill or waterways. While electronics consist a small fraction of total waste generated, they are far more dangerous. There is stringent legislation designed to enforce and encourage the sustainable disposal of appliances, the most notable being the Waste Electrical and Electronic Equipment Directive of the European Union and the United States National Computer Recycling Act.


=== Efforts for minimizing computer hardware waste ===
As computer hardware contain a wide number of metals inside, the United States Environmental Protection Agency (EPA) encourages the collection and recycling of computer hardware. ""E-cycling"", the recycling of computer hardware, refers to the donation, reuse, shredding and general collection of used electronics. Generically, the term refers to the process of collecting, brokering, disassembling, repairing and recycling the components or metals contained in used or discarded electronic equipment, otherwise known as electronic waste (e-waste). ""E-cyclable"" items include, but are not limited to: televisions, computers, microwave ovens, vacuum cleaners, telephones and cellular phones, stereos, and VCRs and DVDs just about anything that has a cord, light or takes some kind of battery.Recycling a computer is made easier by a few of the national services, such as Dell and Apple. Both companies will take back the computer of their make or any other make. Otherwise a computer can be donated to Computer Aid International which is an organization that recycles and refurbishes old computers for hospitals, schools, universities, etc.


== See also ==


== References ==


== External links ==
 Media related to Computer hardware at Wikimedia Commons
 Computer hardware at Wikibooks
 Learning materials related to Computer hardware at Wikiversity"
"A computer program is a collection of instructions that can be executed by a computer to perform a specific task. 
A computer program is usually written by a computer programmer in a programming language. From the program in its human-readable form of source code, a compiler or assembler can derive machine code—a form consisting of instructions that the computer can directly execute. Alternatively, a computer program may be executed with the aid of an interpreter.
A collection of computer programs, libraries, and related data are referred to as software. Computer programs may be categorized along functional lines, such as application software and system software.  The underlying method used for some calculation or manipulation is known as an algorithm.


== History ==

Code-breaking algorithms have existed for centuries. In the 9th century, the Arab mathematician Al-Kindi described a cryptographic algorithm for deciphering encrypted code, in A Manuscript On Deciphering Cryptographic Messages. He gave the first description of cryptanalysis by frequency analysis, the earliest code-breaking algorithm.


=== Early programmable machines ===
The earliest programmable machines preceded the invention of the digital computer. As early as the 9th century, a programmable music sequencer was invented by the Persian Banu Musa brothers, who described an automated mechanical flute player in the Book of Ingenious Devices. In 1206, the Arab engineer Al-Jazari invented a programmable drum machine where musical mechanical automata could be made to play different rhythms and drum patterns. In 1801, Joseph-Marie Jacquard devised a loom that would weave a pattern by following a series of perforated cards. Patterns could be woven and repeated by arranging the cards.


=== Analytical Engine ===

In 1837, Charles Babbage was inspired by Jacquard's loom to attempt to build the Analytical Engine.
The names of the components of the calculating device were borrowed from the textile industry. In the textile industry, yarn was brought from the store to be milled. The device would have had a ""store""—memory to hold 1,000 numbers of 40 decimal digits each.  Numbers from the ""store"" would then have then been transferred to the ""mill"" (analogous to the CPU of a modern machine), for processing. And a ""thread"" being the execution of programmed instructions by the device. It was programmed using two sets of perforated cards—one to direct the operation and the other for the input variables. However, after more than 17,000 pounds of the British government's money, the thousands of cogged wheels and gears never fully worked together.During a nine-month period in 1842–43, Ada Lovelace translated the memoir of Italian mathematician Luigi Menabrea. The memoir covered the Analytical Engine. The translation contained Note G which completely detailed a method for calculating Bernoulli numbers using the Analytical Engine. This note is recognized by some historians as the world's first written computer program.


=== Universal Turing machine ===
In 1936, Alan Turing introduced the Universal Turing machine—a theoretical device that can model every computation that can be performed on a Turing complete computing machine.
It is a finite-state machine that has an infinitely long read/write tape. The machine can move the tape back and forth, changing its contents as it performs an algorithm. The machine starts in the initial state, goes through a sequence of steps, and halts when it encounters the halt state.
This machine is considered by some to be the origin of the stored-program computer—used by John von Neumann (1946) for the ""Electronic Computing Instrument"" that now bears the von Neumann architecture name.


=== Early programmable computers ===
The Z3 computer, invented by Konrad Zuse (1941) in Germany, was a digital and programmable computer. A digital computer uses electricity as the calculating component. The Z3 contained 2,400 relays to create the circuits. The circuits provided a binary, floating-point, nine-instruction computer. Programming the Z3 was through a specially designed keyboard and punched tape.
The Electronic Numerical Integrator And Computer (Fall 1945) was a Turing complete, general-purpose computer that used 17,468 vacuum tubes to create the circuits. At its core, it was a series of Pascalines wired together. Its 40 units weighed 30 tons, occupied 1,800 square feet (167 m2), and consumed $650 per hour (in 1940s currency) in electricity when idle. It had 20 base-10 accumulators. Programming the ENIAC took up to two months. Three function tables were on wheels and needed to be rolled to fixed function panels. Function tables were connected to function panels using heavy black cables. Each function table had 728 rotating knobs. Programming the ENIAC also involved setting some of the 3,000 switches. Debugging a program took a week.  The programmers of the ENIAC were women who were known collectively as the ""ENIAC girls"" and included Jean Jennings Bartik, Betty Holberton, Marlyn Wescoff, Kathleen McNulty, Ruth Teitelbaum, and Frances Spence.

The ENIAC featured parallel operations. Different sets of accumulators could simultaneously work on different algorithms. It used punched card machines for input and output, and it was controlled with a clock signal. It ran for eight years, calculating hydrogen bomb parameters, predicting weather patterns, and producing firing tables to aim artillery guns. 
The Manchester Baby (June 1948) was a stored-program computer. Programming transitioned away from moving cables and setting dials; instead, a computer program was stored in memory as numbers. Only three bits of memory were available to store each instruction, so it was limited to eight instructions. 32 switches were available for programming.


=== Later computers ===

Computers manufactured until the 1970s had front-panel switches for programming. The computer program was written on paper for reference. An instruction was represented by a configuration of on/off settings. After setting the configuration, an execute button was pressed. This process was then repeated. Computer programs also were manually input via paper tape or punched cards. After the medium was loaded, the starting address was set via switches and the execute button pressed.In 1961, the Burroughs B5000 was built specifically to be programmed in the ALGOL 60 language. The hardware featured circuits to ease the compile phase.In 1964, the IBM System/360 was a line of six computers each having the same instruction set architecture. The Model 30 was the smallest and least expensive. Customers could upgrade and retain the same application software. Each System/360 model featured multiprogramming. With operating system support, multiple programs could be in memory at once. When one was waiting for input/output, another could compute. Each model also could emulate other computers. Customers could upgrade to the System/360 and retain their IBM 7094 or IBM 1401 application software.


== Computer programming ==

Computer programming is the process of writing or editing source code. Editing source code involves testing, analyzing, refining, and sometimes coordinating with other programmers on a jointly developed program. A person who practices this skill is referred to as a computer programmer, software developer, and sometimes coder.
The sometimes lengthy process of computer programming is usually referred to as software development. The term software engineering is becoming popular as the process is seen as an engineering discipline.


=== Programming languages ===

Computer programs can be categorized by the programming language paradigm used to produce them. Two of the main paradigms are imperative and declarative.


==== Imperative languages ====
Imperative programming languages specify a sequential algorithm using declarations, expressions, and statements:
A declaration couples a variable name to a datatype – for example:  var x: integer; 
An expression yields a value – for example:  2 + 2  yields 4
A statement might assign an expression to a variable or use the value of a variable to alter the program's control flow – for example: x := 2 + 2; if x = 4 then do_something();One criticism of imperative languages is the side effect of an assignment statement on a class of variables called non-local variables.


==== Declarative languages ====
Declarative programming languages describe what computation should be performed and not how to compute it. Declarative programs omit the control flow and are considered sets of instructions. Two broad categories of declarative languages are functional languages and logical languages. The principle behind functional languages (like Haskell) is to not allow side effects, which makes it easier to reason about programs like mathematical functions. The principle behind logical languages (like Prolog) is to define the problem to be solved – the goal – and leave the detailed solution to the Prolog system itself. The goal is defined by providing a list of subgoals. Then each subgoal is defined by further providing a list of its subgoals, etc. If a path of subgoals fails to find a solution, then that subgoal is backtracked and another path is systematically attempted.


=== Compilation and interpretation ===
A computer program in the form of a human-readable, computer programming language is called source code. Source code may be converted into an executable image by a compiler or assembler, or executed immediately with the aid of an interpreter.
Compilers are used to translate source code from a programming language into either object code or machine code.  Object code needs further processing to become machine code, and machine code consists of the central processing unit's native instructions, ready for execution. Compiled computer programs are commonly referred to as executables, binary images, or simply as binaries – a reference to the binary file format used to store the executable code.
Some compiled and assembled object programs need to be combined as modules with a linker utility in order to produce an executable program.
Interpreters are used to execute source code from a programming language line-by-line. The interpreter decodes each statement and performs its behavior. One advantage of interpreters is that they can easily be extended to an interactive session. The programmer is presented with a prompt, and individual lines of code are typed in and performed immediately.
The main disadvantage of interpreters is computer programs run slower than when compiled. Interpreting code is slower because the interpreter must decode each statement and then perform it. However, software development may be faster using an interpreter because testing is immediate when the compiling step is omitted. Another disadvantage of interpreters is an interpreter must be present on the executing computer. By contrast, compiled computer programs need no compiler present during execution.
Just in time compilers pre-compile computer programs just before execution. For example, the Java virtual machine Hotspot contains a Just In Time Compiler which selectively compiles Java bytecode into machine code – but only code which Hotspot predicts is likely to be used many times.
Either compiled or interpreted programs might be executed in a batch process without human interaction.
Scripting languages are often used to create batch processes. One common scripting language is Unix shell, and its executing environment is called the command-line interface.
No properties of a programming language require it to be exclusively compiled or exclusively interpreted. The categorization usually reflects the most popular method of language execution. For example, Java is thought of as an interpreted language and C a compiled language, despite the existence of Java compilers and C interpreters.


== Storage and execution ==

Typically, computer programs are stored in non-volatile memory until requested either directly or indirectly to be executed by the computer user. Upon such a request, the program is loaded into random-access memory, by a computer program called an operating system, where it can be accessed directly by the central processor. The central processor then executes (""runs"") the program, instruction by instruction, until termination. A program in execution is called a process. Termination is either by normal self-termination, by user intervention, or by error – software or hardware error.


=== Simultaneous execution ===

Many operating systems support multitasking which enables many computer programs to appear to run simultaneously on one computer.  Operating systems may run multiple programs through process scheduling – a software mechanism to switch the CPU among processes often so users can interact with each program while it runs. Within hardware, modern day multiprocessor computers or computers with multicore processors may run multiple programs.


=== Self-modifying programs ===

A computer program in execution is normally treated as being different from the data the program operates on. However, in some cases, this distinction is blurred when a computer program modifies itself. The modified computer program is subsequently executed as part of the same program. Self-modifying code is possible for programs written in machine code, assembly language, Lisp, C, COBOL, PL/1, and Prolog.


== Functional categories ==
Computer programs may be categorized along functional lines. The main functional categories are application software and system software. System software includes the operating system which couples computer hardware with application software. The purpose of the operating system is to provide an environment in which application software executes in a convenient and efficient manner. In addition to the operating system, system software includes embedded programs, boot programs, and micro programs. Application software designed for end users have a user interface. Application software not designed for the end user includes middleware, which couples one application with another. Application software also includes utility programs. The distinction between system software and application software is under debate.


=== Application software ===

There are many types of application software:

The word app came to being in 21st century. It is a clipping of the word ""application"". They have been designed for many platforms, but the word was first used for smaller mobile apps. Desktop apps are traditional computer programs that run on desktop computers. Mobile apps run on mobile devices. Web apps run inside a web browser. Both mobile and desktop apps may be downloaded from the developers' website or purchased from app stores such as Microsoft Store, Apple App Store, Mac App Store, Google Play or Intel AppUp.
An application suite consists of multiple applications bundled together. Examples include Microsoft Office, LibreOffice, and iWork. They bundle a word processor, spreadsheet, and other applications.
Enterprise applications bundle accounting, personnel, customer, and vendor applications. Examples include enterprise resource planning, customer relationship management, and supply chain management software.
Enterprise infrastructure software supports the enterprise's software systems. Examples include databases, email servers, and network servers.
Information worker software are designed for workers at the departmental level. Examples include time management, resource management, analytical, collaborative and documentation tools. Word processors, spreadsheets, email and blog clients, personal information system, and individual media editors may aid in multiple information worker tasks.
Media development software generates print and electronic media for others to consume, most often in a commercial or educational setting. These produce graphics, publications, animations, and videos.
Product engineering software is used to help develop large machines and other application software. Examples includes computer-aided design (CAD), computer-aided engineering (CAE), and integrated development environments.
Entertainment Software can refer to video games, movie recorders and players, and music recorders and players.


=== Utility programs ===
Utility programs are application programs designed to aid system administrators and computer programmers.


=== Operating system ===

An operating system is a computer program that acts as an intermediary between a user of a computer and the computer hardware.
In the 1950s, the programmer, who was also the operator, would write a program and run it. After the program finished executing, the output may have been printed, or it may have been punched onto paper tape or cards for later processing.
More often than not the program did not work. The programmer then looked at the console lights and fiddled with the console switches. If less fortunate, a memory printout was made for further study. In the 1960s, programmers reduced the amount of wasted time by automating the operator's job. A program called an operating system was kept in the computer at all times.Originally, operating systems were programmed in assembly; however, modern operating systems are typically written in C.


=== Boot program ===
A stored-program computer requires an initial computer program stored in its read-only memory to boot. The boot process is to identify and initialize all aspects of the system, from processor registers to device controllers to memory contents. Following the initialization process, this initial computer program loads the operating system and sets the program counter to begin normal operations.


=== Embedded programs ===

Independent of the host computer, a hardware device might have embedded firmware to control its operation. Firmware is used when the computer program is rarely or never expected to change, or when the program must not be lost when the power is off.


=== Microcode programs ===

Microcode programs control some central processing units and some other hardware. This code moves data between the registers, buses, arithmetic logic units, and other functional units in the CPU.  Unlike conventional programs, microcode is not usually written by, or even visible to, the end users of systems, and is usually provided by the manufacturer, and is considered internal to the device.


== See also ==
Artificial intelligence
Automatic programming
Computer virus
Firmware
Killer application
Software
Software bug


== References ==


== Further reading ==
Knuth, Donald E. (1997). The Art of Computer Programming, Volume 1, 3rd Edition. Boston: Addison-Wesley. ISBN 978-0-201-89683-1.
Knuth, Donald E. (1997). The Art of Computer Programming, Volume 2, 3rd Edition. Boston: Addison-Wesley. ISBN 978-0-201-89684-8.
Knuth, Donald E. (1997). The Art of Computer Programming, Volume 3, 3rd Edition. Boston: Addison-Wesley. ISBN 978-0-201-89685-5."
"A personal computer (PC) is a multi-purpose computer whose size, capabilities, and price make it feasible for individual use. Personal computers are intended to be operated directly by an end user, rather than by a computer expert or technician. Unlike large, costly minicomputers and mainframes, time-sharing by many people at the same time is not used with personal computers.
Institutional or corporate computer owners in the 1960s had to write their own programs to do any useful work with the machines. While personal computer users may develop their own applications, usually these systems run commercial software, free-of-charge software (""freeware""), which is most often proprietary, or free and open-source software, which is provided in ""ready-to-run"", or binary, form. Software for personal computers is typically developed and distributed independently from the hardware or operating system manufacturers. Many personal computer users no longer need to write their own programs to make any use of a personal computer, although end-user programming is still feasible. This contrasts with mobile systems, where software is often only available through a manufacturer-supported channel, and end-user program development may be discouraged by lack of support by the manufacturer.Since the early 1990s, Microsoft operating systems and Intel hardware dominated much of the personal computer market, first with MS-DOS and then with Microsoft Windows. Alternatives to Microsoft's Windows operating systems occupy a minority share of the industry. These include Apple's macOS and free and open-source Unix-like operating systems, such as Linux.
The advent of personal computers and the concurrent Digital Revolution have significantly affected the lives of people in all countries.


== Terminology ==
""PC"" is an initialism for ""personal computer"". The IBM Personal Computer incorporated the designation in its model name, but the term evolved to refer to computers of any brand. In some contexts, ""PC"" is used to differentiate contrast with ""Mac"", an Apple Macintosh computer. Since none of these Apple products were mainframes or time-sharing systems, they were all ""personal computers"" and not ""PC"" (brand) computers.


== History ==

The ""brain"" [computer] may one day come down to our level [of the common people] and help with our income-tax and book-keeping calculations. But this is speculation and there is no sign of it so far.
In the history of computing, early experimental machines could be operated by a single attendant. For example, ENIAC which became operational in 1946 could be run by a single, albeit highly trained, person. This mode pre-dated the batch programming, or time-sharing modes with multiple users connected through terminals to mainframe computers. Computers intended for laboratory, instrumentation, or engineering purposes were built, and could be operated by one person in an interactive fashion. Examples include such systems as the Bendix G15 and LGP-30of 1956, and the Soviet MIR series of computers developed from 1965 to 1969.  By the early 1970s, people in academic or research institutions had the opportunity for single-person use of a computer system in interactive mode for extended durations, although these systems would still have been too expensive to be owned by a single person. 
The personal computer was made possible by major advances in semiconductor technology. In 1959, the silicon integrated circuit (IC) chip was developed by Robert Noyce at Fairchild Semiconductor, and the metal-oxide-semiconductor (MOS) transistor was developed by Mohamed Atalla and Dawon Kahng at Bell Labs. The MOS integrated circuit was commercialized by RCA in 1964, and then the silicon-gate MOS integrated circuit was developed by Federico Faggin at Fairchild in 1968. Faggin later used silicon-gate MOS technology to develop the first single-chip microprocessor, the Intel 4004, in 1971. The first microcomputers, based on microprocessors, were developed during the early 1970s. Widespread commercial availability of microprocessors, from the mid-1970s onwards, made computers cheap enough for small businesses and individuals to own.
In what was later to be called the Mother of All Demos, SRI researcher Douglas Engelbart in 1968 gave a preview of features that would later become staples of personal computers: e-mail, hypertext, word processing, video conferencing, and the mouse. The demonstration required technical support staff and a mainframe time-sharing computer that were far too costly for individual business use at the time.
Early personal computers‍—‌generally called microcomputers‍—‌were often sold in a kit form and in limited volumes, and were of interest mostly to hobbyists and technicians. Minimal programming was done with toggle switches to enter instructions, and output was provided by front panel lamps. Practical use required adding peripherals such as keyboards, computer displays, disk drives, and printers.
Micral N was the earliest commercial, non-kit microcomputer based on a microprocessor, the Intel 8008. It was built starting in 1972, and a few hundred units were sold. This had been preceded by the Datapoint 2200 in 1970, for which the Intel 8008 had been commissioned, though not accepted for use. The CPU design implemented in the Datapoint 2200 became the basis for x86 architecture used in the original IBM PC and its descendants.In 1973, the IBM Los Gatos Scientific Center developed a portable computer prototype called SCAMP (Special Computer APL Machine Portable) based on the IBM PALM processor with a Philips compact cassette drive, small CRT, and full function keyboard. SCAMP emulated an IBM 1130 minicomputer in order to run APL/1130. In 1973, APL was generally available only on mainframe computers, and most desktop sized microcomputers such as the Wang 2200 or HP 9800 offered only BASIC. Because SCAMP was the first to emulate APL/1130 performance on a portable, single user computer, PC Magazine in 1983 designated SCAMP a ""revolutionary concept"" and ""the world's first personal computer"". This seminal, single user portable computer now resides in the Smithsonian Institution, Washington, D.C.. Successful demonstrations of the 1973 SCAMP prototype led to the IBM 5100 portable microcomputer launched in 1975 with the ability to be programmed in both APL and BASIC for engineers, analysts, statisticians, and other business problem-solvers. In the late 1960s such a machine would have been nearly as large as two desks and would have weighed about half a ton.Another desktop portable APL machine, the MCM/70, was demonstrated in 1973 and shipped in 1974.  It used the Intel 8008 processor.
A seminal step in personal computing was the 1973 Xerox Alto, developed at Xerox's Palo Alto Research Center (PARC). It had a graphical user interface (GUI) which later served as inspiration for Apple's Macintosh, and Microsoft's Windows operating system. The Alto was a demonstration project, not commercialized, as the parts were too expensive to be affordable.Also in 1973 Hewlett Packard introduced fully BASIC programmable microcomputers that fit entirely on top of a desk, including a keyboard, a small one-line display, and printer. The Wang 2200 microcomputer of 1973 had a full-size cathode ray tube (CRT) and cassette tape storage. These were generally expensive specialized computers sold for business or scientific uses.

1974 saw the introduction of what is considered by many to be the first true ""personal computer"", the Altair 8800 created by Micro Instrumentation and Telemetry Systems (MITS). Based on the 8-bit Intel 8080 Microprocessor, the Altair is widely recognized as the spark that ignited the microcomputer revolution as the first commercially successful personal computer. The computer bus designed for the Altair was to become a de facto standard in the form of the S-100 bus, and the first programming language for the machine was Microsoft's founding product, Altair BASIC.In 1976, Steve Jobs and Steve Wozniak sold the Apple I computer circuit board, which was fully prepared and contained about 30 chips. The Apple I computer differed from the other kit-style hobby computers of era. At the request of Paul Terrell, owner of the Byte Shop, Jobs and Wozniak were given their first purchase order, for 50 Apple I computers, only if the computers were assembled and tested and not a kit computer. Terrell wanted to have computers to sell to a wide range of users, not just experienced electronics hobbyists who had the soldering skills to assemble a computer kit. The Apple I as delivered was still technically a kit computer, as it did not have a power supply, case, or keyboard when it was delivered to the Byte Shop.

The first successfully mass marketed personal computer to be announced was the Commodore PET after being revealed in January 1977. However, it was back-ordered and not available until later that year. Three months later (April), the Apple II (usually referred to as the ""Apple"") was announced with the first units being shipped 10 June 1977, and the TRS-80 from Tandy Corporation / Tandy Radio Shack following in August 1977, which sold over 100,000 units during its lifetime. Together, these 3 machines were referred to as the ""1977 trinity"". Mass-market, ready-assembled computers had arrived, and allowed a wider range of people to use computers, focusing more on software applications and less on development of the processor hardware.
In 1977 the Heath company introduced personal computer kits known as Heathkits, starting with the Heathkit H8, followed by the Heathkit H89 in late 1979. With the purchase of the Heathkit H8 you would obtain the chassis and CPU card to assemble yourself, additional hardware such as the H8-1 memory board that contained 4k of RAM could also be purchased in order to run software. The Heathkit H11 model was released in 1978 and was one of the first 16-bit personal computers, however due to its high retail cost of $1,295 was discontinued in 1982.

During the early 1980s, home computers were further developed for household use, with software for personal productivity, programming and games. They typically could be used with a television already in the home as the computer display, with low-detail blocky graphics and a limited color range, and text about 40 characters wide by 25 characters tall. Sinclair Research, a UK company, produced the ZX Series‍—‌the ZX80 (1980), ZX81 (1981), and the ZX Spectrum; the latter was introduced in 1982, and totaled 8 million unit sold. Following came the Commodore 64, totaled 17 million units sold  and the Amstrad CPC series (464–6128).
In the same year, the NEC PC-98 was introduced, which was a very popular personal computer that sold in more than 18 million units. Another famous personal computer, the revolutionary Amiga 1000, was unveiled by Commodore on July 23, 1985. The Amiga 1000 featured a multitasking, windowing operating system, color graphics with a 4096-color palette, stereo sound, Motorola 68000 CPU, 256 KB RAM, and 880 KB 3.5-inch disk drive, for US$1,295.Somewhat larger and more expensive systems were aimed at office and small business use. These often featured 80-column text displays but might not have had graphics or sound capabilities. These microprocessor based systems were still less costly than time-shared mainframes or minicomputers.
Workstations were characterized by high-performance processors and graphics displays, with large-capacity local disk storage, networking capability, and running under a multitasking operating system. Eventually, due to the influence of the IBM PC on the personal computer market, personal computers and home computers lost any technical distinction. Business computers acquired color graphics capability and sound, and home computers and game systems users used the same processors and operating systems as office workers. Mass-market computers had graphics capabilities and memory comparable to dedicated workstations of a few years before. Even local area networking, originally a way to allow business computers to share expensive mass storage and peripherals, became a standard feature of personal computers used at home.
IBM's first PC was introduced Aug. 12, 1981.In 1982 ""The Computer"" was named Machine of the Year by Time magazine. In the 2010s, several companies such as Hewlett-Packard and Sony sold off their PC and laptop divisions. As a result, the personal computer was declared dead several times during this period.An increasingly important set of uses for personal computers relied on the ability of the computer to communicate with other computer systems, allowing interchange of information. Experimental public access to a shared mainframe computer system was demonstrated as early as 1973 in the Community Memory project, but bulletin board systems and online service providers became more commonly available after 1978. Commercial Internet service providers emerged in the last 1980's, giving public access to the rapidly growing network.
In 1991, the World Wide Web was made available for public use. The combination of powerful personal computers with high resolution graphics and sound, with the infrastructure provided by the Internet, and the standardization of access methods of the Web browsers, established the foundation for a significant fraction of modern life, from bus time tables through unlimited distribution of free pornography through to online user-edited encyclopedias.


== Types ==


=== Stationary ===


==== Workstation ====
 
A workstation is a high-end personal computer designed for technical, mathematical, or scientific applications. Intended primarily to be used by one person at a time, they are commonly connected to a local area network and run multi-user operating systems. Workstations are used for tasks such as computer-aided design, drafting and modeling, computation-intensive scientific and engineering calculations, image processing, architectural modeling, and computer graphics for animation and motion picture visual effects.


==== Desktop computer ====

Before the widespread use of PCs, a computer that could fit on a desk was remarkably small, leading to the ""desktop"" nomenclature. More recently, the phrase usually indicates a particular style of computer case. Desktop computers come in a variety of styles ranging from large vertical tower cases to small models which can be tucked behind or rest directly beneath (and support) LCD monitors.
While the term ""desktop"" often refers to a computer with a vertically aligned computer tower case, these varieties usually rest on the ground or underneath desks. Despite this seeming contradiction, the term ""desktop"" does typically refer to these vertical tower cases as well as the horizontally aligned models which are designed to literally rest on top of desks and are therefore more appropriate to the ""desktop"" term, although both types qualify for this ""desktop"" label in most practical situations aside from certain physical arrangement differences. Both styles of these computer cases hold the systems hardware components such as the motherboard, processor chip, other internal operating parts. Desktop computers have an external monitor with a display screen and an external keyboard, which are plugged into HDMI and USB ports on the back of the computer case. Desktop computers are popular for home and business computing applications as they leave space on the desk for multiple monitors.
A gaming computer is a desktop computer that generally comprises a high-performance video card, processor and memory, to improve the speed and responsiveness of demanding video games.An all-in-one computer (also known as single-unit PCs) is a desktop computer that combines the monitor and processor within a single unit. A separate keyboard and mouse are standard input devices, with some monitors including touchscreen capability. The processor and other working components are typically reduced in size relative to standard desktops, located behind the monitor, and configured similarly to laptops.
A nettops computer was introduced by Intel in February 2008, characterized by low cost and lean functionality. These were intended to be used with an Internet connection to run Web browsers and Internet applications.

A Home theater PC (HTPC) combines the functions of a personal computer and a digital video recorder. It is connected to a TV set or an appropriately sized computer display, and is often used as a digital photo viewer, music and video player, TV receiver, and digital video recorder. HTPCs are also referred to as media center systems or media servers. The goal is to combine many or all components of a home theater setup into one box.  HTPCs can also connect to services providing on-demand movies and TV shows. HTPCs can be purchased pre-configured with the required hardware and software needed to add television programming to the PC, or can be assembled from components.
Keyboard computers are computers inside of keyboards. Examples include the Commodore 64, MSX, Amstrad CPC, Atari ST and the ZX spectrum.


=== Portable ===
The potential utility of portable computers was apparent early on.  Alan Kay described the Dynabook in 1972, but no hardware was developed.  The Xerox NoteTaker was produced in a very small experimental batch around 1978. In 1975, the IBM 5100 could be fit into a transport case, making it a portable computer, but it weighed about 50 pounds.
Before the introduction of the IBM PC, portable computers consisting of a processor, display, disk drives and keyboard, in a suit-case style portable housing, allowed users to bring a computer home from the office or to take notes at a classroom. Examples include the Osborne 1 and Kaypro; and the Commodore SX-64.  These machines were AC powered and included a small CRT display screen. The form factor was intended to allow these systems to be taken on board an airplane as carry-on baggage, though their high power demand meant that they could not be used in flight. The integrated CRT display made for a relatively heavy package, but these machines were more portable than their contemporary desktop equals. Some models had standard or optional connections to drive an external video monitor, allowing a larger screen or use with video projectors.
IBM PC-compatible suitcase format computers became available soon after the introduction of the PC, with the Compaq Portable being a leading example of the type. Later models included a hard drive to give roughly equivalent performance to contemporary desk top computers.
The development of thin plasma display and LCD screens permitted a somewhat smaller form factor, called the ""lunchbox"" computer. The screen formed one side of the enclosure, with a detachable keyboard and one or two half-height floppy disk drives, mounted facing the ends of the computer.  Some variations included a battery, allowing operation away from AC outlets.Notebook computers such as the TRS-80 Model 100 and Epson HX-20 had roughly the plan dimensions of a sheet of typing paper (ANSI A or ISO A4). These machines had a keyboard with slightly reduced dimensions compared to a desktop system, and a fixed LCD display screen coplanar with the keyboard.  These displays were usually small, with 8 to 16 lines of text, sometimes only 40 columns line length.  However, these machines could operate for extended times on disposable or rechargeable batteries. Although they did not usually include internal disk drives, this form factor often included a modem for telephone communication and often had provisions for external cassette or disk storage. Later, clam-shell format laptop computers with similar small plan dimensions were also called ""notebooks"".


==== Laptop ====

A laptop computer is designed for portability with ""clamshell"" design, where the keyboard and computer components are on one panel, with a hinged second panel containing a flat display screen. Closing the laptop protects the screen and keyboard during transportation.  Laptops generally have a rechargeable battery, enhancing their portability.  To save power, weight and space, laptop graphics cards are in many cases integrated into the CPU or chipset and use system RAM, resulting in reduced graphics performance when compared to a desktop machine. For this reason, desktop computers are usually preferred over laptops for gaming purposes.
Unlike desktop computers, only minor internal upgrades (such as memory and hard disk drive) are feasible owing to the limited space and power available. Laptops have the same input and output ports as desktops, for connecting to external displays, mice, cameras, storage devices and keyboards. Laptops are also a little more expensive compared to desktops, as the miniaturized components for laptops themselves are expensive.

A desktop replacement computer is a portable computer that provides the full capabilities of a desktop computer. Such computers are currently large laptops. This class of computers usually includes more powerful components and a larger display than generally found in smaller portable computers, and may have limited battery capacity or no battery.

Netbooks, also called mini notebooks or subnotebooks, were a subgroup of laptops suited for general computing tasks and accessing web-based applications.   Initially, the primary defining characteristic of netbooks was the lack of an optical disc drive,  smaller size, and lower performance than full-size laptops. By mid-2009 netbooks had been offered to users ""free of charge"", with an extended service contract purchase of a cellular data plan. Ultrabooks and Chromebooks have since filled the gap left by Netbooks.


==== Tablet ====

A tablet uses a touchscreen display, which can be controlled using either a stylus pen or finger. Some tablets may use a ""hybrid"" or ""convertible"" design, offering a keyboard that can either be removed as an attachment, or a screen that can be rotated and folded directly over top the keyboard. Some tablets may use desktop-PC operating system such as Windows or Linux, or may run an operating system designed primarily for tablets.  Many tablet computers have USB ports, to which a keyboard or mouse can be connected.


==== Smartphone ====

Smartphones are often similar to tablet computers, the difference being that smartphones always have cellular integration. They are generally smaller than tablets, and may not have a slate form factor.


==== Ultra-mobile PC ====

The ultra-mobile PC (UMP) is a small tablet computer.  It was developed by Microsoft, Intel and Samsung, among others. Current UMPCs typically feature the Windows XP, Windows Vista, Windows 7, or Linux operating system, and low-voltage Intel Atom or VIA C7-M processors.


==== Pocket PC ====

A pocket PC is a hardware specification for a handheld-sized computer (personal digital assistant, PDA) that runs the Microsoft Windows Mobile operating system. It may have the capability to run an alternative operating system like NetBSD or Linux. Pocket PCs have many of the capabilities of desktop PCs. Numerous applications are available for handhelds adhering to the Microsoft Pocket PC specification, many of which are freeware. Microsoft-compliant Pocket PCs can also be used with many other add-ons like GPS receivers, barcode readers, RFID readers and cameras. In 2007, with the release of Windows Mobile 6, Microsoft dropped the name Pocket PC in favor of a new naming scheme: devices without an integrated phone are called Windows Mobile Classic instead of Pocket PC, while devices with an integrated phone and a touch screen are called Windows Mobile Professional.


== Hardware ==

Computer hardware is a comprehensive term for all physical and tangible parts of a computer, as distinguished from the data it contains or operates on, and the software that provides instructions for the hardware to accomplish tasks. Some sub-systems of a personal computer may contain processors that run a fixed program, or firmware, such as a keyboard controller. Firmware usually is not changed by the end user of the personal computer.
Most 2010s-era computers only require users to plug in the power supply, monitor, and other cables. A typical desktop computer consists of a computer case (or ""tower""), a metal chassis that holds the power supply, motherboard, hard disk drive, and often an optical disc drive. Most towers have empty space where users can add additional components. External devices such as a computer monitor or visual display unit, keyboard, and a pointing device (mouse) are usually found in a personal computer.
The motherboard connects all processor, memory and peripheral devices together. The RAM, graphics card and processor are in most cases mounted directly onto the motherboard. The central processing unit (microprocessor chip) plugs into a CPU socket, while the memory modules plug into corresponding memory sockets. Some motherboards have the video display adapter, sound and other peripherals integrated onto the motherboard, while others use expansion slots for graphics cards, network cards, or other I/O devices.  The graphics card or sound card may employ a break out box to keep the analog parts away from the electromagnetic radiation inside the computer case. Disk drives, which provide mass storage, are connected to the motherboard with one cable, and to the power supply through another cable. Usually, disk drives are mounted in the same case as the motherboard; expansion chassis are also made for additional disk storage.
For large amounts of data, a tape drive can be used or extra hard disks can be put together in an external case. The keyboard and the mouse are external devices plugged into the computer through connectors on an I/O panel on the back of the computer case. The monitor is also connected to the input/output (I/O) panel, either through an onboard port on the motherboard, or a port on the graphics card. Capabilities of the personal computers hardware can sometimes be extended by the addition of expansion cards connected via an expansion bus. Standard peripheral buses often used for adding expansion cards in personal computers include PCI, PCI Express (PCIe), and AGP (a high-speed PCI bus dedicated to graphics adapters, found in older computers). Most modern personal computers have multiple physical PCI Express expansion slots, with some having PCI slots as well.
A peripheral is ""a device connected to a computer to provide communication (such as input and output) or auxiliary functions (such as additional storage)"". Peripherals generally connect to the computer through the use of USB ports or inputs located on the I/O panel. USB Flash Drives provide portable storage using flash memory which allows users to access the files stored on the drive on any computer. Memory cards also provide portable storage for users, commonly used on other electronics such as mobile phones and digital cameras, the information stored on these cards can be accessed using a memory card reader to transfer data between devices. Webcams, which are either built into computer hardware or connected via USB are video cameras that records video in real time to either be saved to the computer or streamed somewhere else over the internet. Game controllers can be plugged in via USB and can be used as an input device for video games as an alternative to using keyboard and mouse. Headphones and speakers can be connected via USB or through an auxiliary port (found on I/O panel)  and allow users to listen to audio accessed on their computer, however speakers may also require an additional power source to operate. Microphones can be connected through an audio input port on the I/O panel and allow the computer to convert sound into an electrical signal to be used or transmitted by the computer.


== Software ==

Computer software is any kind of computer program, procedure, or documentation that performs some task on a computer system. The term includes application software such as word processors that perform productive tasks for users, system software such as operating systems that interface with computer hardware to provide the necessary services for application software, and middleware that controls and co-ordinates distributed systems.

Software applications are common for word processing, Internet browsing, Internet faxing, e-mail and other digital messaging, multimedia playback, playing of computer game, and computer programming. The user may have significant knowledge of the operating environment and application programs, but is not necessarily interested in programming nor even able to write programs for the computer. Therefore, most software written primarily for personal computers tends to be designed with simplicity of use, or ""user-friendliness"" in mind. However, the software industry continuously provide a wide range of new products for use in personal computers, targeted at both the expert and the non-expert user.


=== Operating system ===

An operating system (OS) manages computer resources and provides programmers with an interface used to access those resources. An operating system processes system data and user input, and responds by allocating and managing tasks and internal system resources as a service to users and programs of the system. An operating system performs basic tasks such as controlling and allocating memory, prioritizing system requests, controlling input and output devices, facilitating computer networking, and managing files.
Common contemporary desktop operating systems are Microsoft Windows, macOS, Linux, Solaris and FreeBSD. Windows, macOS, and Linux all have server and personal variants. With the exception of Microsoft Windows, the designs of each of them were inspired by or directly inherited from the Unix operating system.
Early personal computers used operating systems that supported command line interaction, using an alphanumeric display and keyboard. The user had to remember a large range of commands to, for example, open a file for editing or to move text from one place to another. Starting in the early 1960s, the advantages of a graphical user interface began to be explored, but widespread adoption required lower cost graphical display equipment. By 1984, mass-market computer systems using graphical user interfaces were available; by the turn of the 21st century, text-mode operating systems were no longer a significant fraction of the personal computer market.


=== Applications ===

Generally, a computer user uses application software to carry out a specific task. System software supports applications and provides common services such as memory management, network connectivity and device drivers, all of which may be used by applications but are not directly of interest to the end user. A simplified analogy in the world of hardware would be the relationship of an electric light bulb (an application) to an electric power generation plant (a system): the power plant merely generates electricity, not itself of any real use until harnessed to an application like the electric light that performs a service that benefits the user.
Typical examples of software applications are word processors, spreadsheets, and media players. Multiple applications bundled together as a package are sometimes referred to as an application suite. Microsoft Office and LibreOffice, which bundle together a word processor, a spreadsheet, and several other discrete applications, are typical examples. The separate applications in a suite usually have a user interface that has some commonality making it easier for the user to learn and use each application. Often, they may have some capability to interact with each other in ways beneficial to the user; for example, a spreadsheet might be able to be embedded in a word processor document even though it had been created in the separate spreadsheet application.
End-user development tailors systems to meet the user's specific needs. User-written software include spreadsheet templates, word processor macros, scientific simulations, graphics and animation scripts; even email filters are a kind of user software. Users create this software themselves and often overlook how important it is.


=== Gaming ===
PC gaming is popular among the high-end PC market. According to an April 2018 market analysis done by Newzoo, PC gaming has fallen behind both console and mobile gaming in terms of market share sitting at a 24% share of the entire market. The market for PC gaming still continues to grow and is expected to generate $32.3 billion in revenue in the year 2021. PC gaming is at the forefront of competitive gaming, known as esports, with games such as Roblox and Minecraft leading the industry that is suspected to surpass a trillion dollars in revenue in 2019.


== Sales ==


=== Market share ===

In 2001, 125 million personal computers were shipped in comparison to 48,000 in 1977. More than 500 million personal computers were in use in 2002 and one billion personal computers had been sold worldwide from the mid-1970s up to this time. Of the latter figure, 75% were professional or work related, while the rest were sold for personal or home use. About 81.5% of personal computers shipped had been desktop computers, 16.4% laptops and 2.1% servers. The United States had received 38.8% (394 million) of the computers shipped, Europe 25% and 11.7% had gone to the Asia-Pacific region, the fastest-growing market as of 2002. The second billion was expected to be sold by 2008. Almost half of all households in Western Europe had a personal computer and a computer could be found in 40% of homes in United Kingdom, compared with only 13% in 1985.The global personal computer shipments were 350.9 million units in 2010,
308.3 million units in 2009
and 302.2 million units in 2008.
The shipments were 264 million units in the year 2007, according to iSuppli, up 11.2% from 239 million in 2006. In 2004, the global shipments were 183 million units, an 11.6% increase over 2003. In 2003, 152.6 million computers were shipped, at an estimated value of $175 billion. In 2002, 136.7 million PCs were shipped, at an estimated value of $175 billion. In 2000, 140.2 million personal computers were shipped, at an estimated value of $226 billion. Worldwide shipments of personal computers surpassed the 100-million mark in 1999, growing to 113.5 million units from 93.3 million units in 1998. In 1999, Asia had 14.1 million units shipped.As of June 2008, the number of personal computers in use worldwide hit one billion, while another billion is expected to be reached by 2014. Mature markets like the United States, Western Europe and Japan accounted for 58% of the worldwide installed PCs. The emerging markets were expected to double their installed PCs by 2012 and to take 70% of the second billion PCs. About 180 million computers (16% of the existing installed base) were expected to be replaced and 35 million to be dumped into landfill in 2008. The whole installed base grew 12% annually.Based on International Data Corporation (IDC) data for Q2 2011, for the first time China surpassed US in PC shipments by 18.5 million and 17.7 million respectively. This trend reflects the rising of emerging markets as well as the relative stagnation of mature regions.
In the developed world, there has been a vendor tradition to keep adding functions to maintain high prices of personal computers. However, since the introduction of the One Laptop per Child foundation and its low-cost XO-1 laptop, the computing industry started to pursue the price too. Although introduced only one year earlier, there were 14 million netbooks sold in 2008. Besides the regular computer manufacturers, companies making especially rugged versions of computers have sprung up, offering alternatives for people operating their machines in extreme weather or environments.In 2011, Deloitte consulting firm predicted that, smartphones and tablet computers as computing devices would surpass the PCs sales (as has happened since 2012). As of 2013, worldwide sales of PCs had begun to fall as many consumers moved to tablets and smartphones. Sales of 90.3 million units in the 4th quarter of 2012 represented a 4.9% decline from sales in the 4th quarter of 2011. Global PC sales fell sharply in the first quarter of 2013, according to IDC data. The 14% year-over-year decline was the largest on record since the firm began tracking in 1994, and double what analysts had been expecting. The decline of Q2 2013 PC shipments marked the fifth straight quarter of falling sales. ""This is horrific news for PCs,"" remarked an analyst. ""It's all about mobile computing now. We have definitely reached the tipping point."" Data from Gartner showed a similar decline for the same time period. China's Lenovo Group bucked the general trend as strong sales to first time buyers in the developing world allowed the company's sales to stay flat overall. Windows 8, which was designed to look similar to tablet/smartphone software, was cited as a contributing factor in the decline of new PC sales. ""Unfortunately, it seems clear that the Windows 8 launch not only didn't provide a positive boost to the PC market, but appears to have slowed the market,"" said IDC Vice President Bob O’Donnell.In August 2013, Credit Suisse published research findings that attributed around 75% of the operating profit share of the PC industry to Microsoft (operating system) and Intel (semiconductors). According to IDC, in 2013 PC shipments dropped by 9.8% as the greatest drop-ever in line with consumers trends to use mobile devices.In the second quarter of 2018, PC sales grew for the first time since the first quarter of 2012. According to research firm Gartner, the growth mainly came from the business market while the consumer market experienced decline.


=== Average selling price ===
Selling prices of personal computers steadily declined due to lower costs of production and manufacture, while the capabilities of computers increased. In 1975, an Altair kit sold for only around US$400, but required customers to solder components into circuit boards; peripherals required to interact with the system in alphanumeric form instead of blinking lights would add another $2,000, and the resultant system was only of use to hobbyists.At their introduction in 1981, the US$1,795 price of the Osborne 1 and its competitor Kaypro was considered an attractive price point; these systems had text-only displays and only floppy disks for storage. By 1982, Michael Dell observed that a personal computer system selling at retail for about $3,000 US was made of components that cost the dealer about $600; typical gross margin on a computer unit was around $1,000. The total value of personal computer purchases in the US in 1983 was about $4 billion, comparable to total sales of pet food. By late 1998, the average selling price of personal computer systems in the United States had dropped below $1,000.For Microsoft Windows systems, the average selling price (ASP) showed a decline in 2008/2009, possibly due to low-cost netbooks, drawing $569 for desktop computers and $689 for laptops at U.S. retail in August 2008. In 2009, ASP had further fallen to $533 for desktops and to $602 for notebooks by January and to $540 and $560 in February. According to research firm NPD, the average selling price of all Windows portable PCs has fallen from $659 in October 2008 to $519 in October 2009.


== Environmental impact ==

External costs of environmental impact are not fully included in the selling price of personal computers.Personal computers have become a large contributor to the 50 million tons of discarded electronic waste generated annually, according to the United Nations Environment Programme. To address the electronic waste issue affecting developing countries and the environment, extended producer responsibility (EPR) acts have been implemented in various countries and states. In the absence of comprehensive national legislation or regulation on the export and import of electronic waste, the Silicon Valley Toxics Coalition and BAN (Basel Action Network) teamed up with  electronic recyclers in the US and Canada to create an e-steward program for the orderly disposal of electronic waste. Some organizations oppose EPR regulation, and claim that manufacturers naturally move toward reduced material and energy use.


== See also ==


== Notes ==


== References ==


== Further reading ==
Accidental Empires: How the boys of Silicon Valley make their millions, battle foreign competition, and still can't get a date, Robert X. Cringely, Addison-Wesley Publishing, (1992), ISBN 0-201-57032-7
PC Magazine, Vol. 2, No. 6, November 1983, ‘'SCAMP: The Missing Link in the PC's Past?‘’


== External links ==
How Stuff Works pages:
Dissecting a PC
How PCs Work
How to Upgrade Your Computer
How to Build a Computer
Global archive with product data-sheets of PCs and Workstations"
"Computer engineering (CpE) is a branch of engineering that integrates several fields of computer science and electronic engineering required to develop computer hardware and software. Computer engineers usually have training in electronic engineering (or electrical engineering), software design, and hardware-software integration instead of only software engineering or electronic engineering. Computer engineers are involved in many hardware and software aspects of computing, from the design of individual microcontrollers, microprocessors, personal computers, and supercomputers, to circuit design. This field of engineering not only focuses on how computer systems themselves work but also how they integrate into the larger picture.Usual tasks involving computer engineers include writing software and firmware for embedded microcontrollers, designing VLSI chips, designing analog sensors, designing mixed signal circuit boards, and designing operating systems. Computer engineers are also suited for robotics research, which relies heavily on using digital systems to control and monitor electrical systems like motors, communications, and sensors.
In many institutions of higher learning, computer engineering students are allowed to choose areas of in-depth study in their junior and senior year because the full breadth of knowledge used in the design and application of computers is beyond the scope of an undergraduate degree. Other institutions may require engineering students to complete one or two years of general engineering before declaring computer engineering as their primary focus.


== History ==

Computer engineering began in 1939 when John Vincent Atanasoff and Clifford Berry began developing the world's first electronic digital computer through physics, mathematics, and electrical engineering. John Vincent Atanasoff was once a physics and mathematics teacher for Iowa State University and Clifford Berry a former graduate under electrical engineering and physics. Together, they created the Atanasoff-Berry computer, also known as the ABC which took 5 years to complete.
While the original ABC was dismantled and discarded in the 1940s a tribute was made to the late inventors, a replica of the ABC was made in 1997 where it took a team of researchers and engineers four years and $350,000 to build.The modern personal computer emerged in the 1970s, after several breakthroughs in semiconductor technology. These include the first working transistor by William Shockley, John Bardeen and Walter Brattain at Bell Labs in 1947, the silicon surface passivation process (via thermal oxidation) by Mohamed Atalla at Bell Labs in 1957, the monolithic integrated circuit chip by Robert Noyce at Fairchild Semiconductor in 1959, the metal-oxide-semiconductor field-effect transistor (MOSFET, or MOS transistor) by Mohamed Atalla and Dawon Kahng at Bell Labs in 1959, and the single-chip microprocessor (Intel 4004) by Federico Faggin, Marcian Hoff, Masatoshi Shima and Stanley Mazor at Intel in 1971.


=== History of computer engineering education ===
The first computer engineering degree program in the United States was established in 1971 at Case Western Reserve University in Cleveland, Ohio. As of 2015, there were 250 ABET-accredited computer engineering programs in the U.S. In Europe, accreditation of computer engineering schools is done by a variety of agencies part of the EQANIE network. Due to increasing job requirements for engineers who can concurrently design hardware, software, firmware, and manage all forms of computer systems used in industry, some tertiary institutions around the world offer a bachelor's degree generally called computer engineering.  Both computer engineering and electronic engineering programs include analog and digital circuit design in their curriculum. As with most engineering disciplines, having a sound knowledge of mathematics and science is necessary for computer engineers.


== Education ==
Computer engineering is referred to as computer science and engineering at some universities. Most entry-level computer engineering jobs require at least a bachelor's degree in computer engineering (or computer science and engineering). Typically one must learn an array of mathematics such as calculus, algebra and trigonometry and some computer science classes. Sometimes a degree in electronic engineering is accepted, due to the similarity of the two fields. Because hardware engineers commonly work with computer software systems, a strong background in computer programming is necessary. According to BLS, ""a computer engineering major is similar to electrical engineering but with some computer science courses added to the curriculum"". Some large firms or specialized jobs require a master's degree.
It is also important for computer engineers to keep up with rapid advances in technology. Therefore, many continue learning throughout their careers. This can be helpful, especially when it comes to learning new skills or improving existing ones. For example, as the relative cost of fixing a bug increases the further along it is in the software development cycle, there can be greater cost savings attributed to developing and testing for quality code as soon as possible in the process, and particularly before release.


== Profession: Computer engineer ==
A person with a profession in computer engineering is called a computer engineer.


== Applications and practice ==
There are two major focuses in computer engineering: hardware and software.


=== Computer hardware engineering ===
According to the BLS, Job Outlook employment for computer hardware engineers, the expected ten-year growth from 2014 to 2024 for computer hardware engineering was an estimated 3% and there was a total of 77,700 jobs that same year. (""Slower than average"" in their own words when compared to other occupations)"" and is down from 7% for the 2012 to 2022 BLS estimate and is further down from 9% in the BLS 2010 to 2020 estimate."" Today, computer hardware is somehow equal to electronic and computer engineering (ECE) and has been divided into many subcategories; the most significant is embedded system design.


=== Computer software engineering ===
According to the U.S. Bureau of Labor Statistics (BLS), ""computer applications software engineers and computer systems software engineers are projected to be among the faster than average growing occupations"" The expected ten-year growth as of 2014 for computer software engineering was an estimated seventeen percent and there was a total of 1,114,000 jobs that same year. This is down from the 2012 to 2022 BLS estimate of 22% for software developers. And, further down from the 30% 2010 to 2020 BLS estimate. In addition, growing concerns over cybersecurity add up to put computer software engineering high above the average rate of increase for all fields. However, some of the work will be outsourced in foreign countries. Due to this, job growth will not be as fast as during the last decade, as jobs that would have gone to computer software engineers in the United States would instead go to computer software engineers in countries such as India. In addition, the BLS Job Outlook for Computer Programmers, 2014–24 has an −8% (a decline, in their words) for those who program computers (i.e. embedded systems) who are not computer application developers. Furthermore, women in software fields has been declining over the years even faster than other engineering fields.


=== Computer engineering licensing and practice ===
Computer engineering is generally practiced within larger product development firms, and such practice may not be subject to licensing.  However, independent consultants who advertise computer engineering, just like any form of engineering, may be subject to state laws which restrict professional engineer practice to only those who have received the appropriate License.  National Council of Examiners for Engineering and Surveying (NCEES) first offered a Principles and Practice of Engineering Examination for computer engineering in 2003. 


== Specialty areas ==
There are many specialty areas in the field of computer engineering.


=== Coding, cryptography, and information protection ===

Computer engineers work in coding, cryptography, and information protection to develop new methods for protecting various information, such as digital images and music, fragmentation, copyright infringement and other forms of tampering. Examples include work on wireless communications, multi-antenna systems, optical transmission, and digital watermarking.


=== Communications and wireless networks ===

Those focusing on communications and wireless networks, work advancements in telecommunications systems and networks (especially wireless networks), modulation and error-control coding, and information theory. High-speed network design, interference suppression and modulation, design, and analysis of fault-tolerant system, and storage and transmission schemes are all a part of this specialty.


=== Compilers and operating systems ===

This specialty focuses on compilers and operating systems design and development. Engineers in this field develop new operating system architecture, program analysis techniques, and new techniques to assure quality. Examples of work in this field include post-link-time code transformation algorithm development and new operating system development.


=== Computational science and engineering ===

Computational science and engineering is a relatively new discipline. According to the Sloan Career Cornerstone Center, individuals working in this area, ""computational methods are applied to formulate and solve complex mathematical problems in engineering and the physical and the social sciences. Examples include aircraft design, the plasma processing of nanometer features on semiconductor wafers, VLSI circuit design, radar detection systems, ion transport through biological channels, and much more"".


=== Computer networks, mobile computing, and distributed systems ===

In this specialty, engineers build integrated environments for computing, communications, and information access. Examples include shared-channel wireless networks, adaptive resource management in various systems, and improving the quality of service in mobile and ATM environments. Some other examples include work on wireless network systems and fast Ethernet cluster wired systems.


=== Computer systems: architecture, parallel processing, and dependability ===

Engineers working in computer systems work on research projects that allow for reliable, secure, and high-performance computer systems. Projects such as designing processors for multi-threading and parallel processing are included in this field. Other examples of work in this field include development of new theories, algorithms, and other tools that add performance to computer systems.Computer architecture includes CPU design, cache hierarchy layout, memory organization and load balancing.


=== Computer vision and robotics ===

In this specialty, computer engineers focus on developing visual sensing technology to sense an environment, representation of an environment, and manipulation of the environment. The gathered three-dimensional information is then implemented to perform a variety of tasks. These include improved human modeling, image communication, and human-computer interfaces, as well as devices such as special-purpose cameras with versatile vision sensors.


=== Embedded systems ===

Individuals working in this area design technology for enhancing the speed, reliability, and performance of systems. Embedded systems are found in many devices from a small FM radio to the space shuttle. According to the Sloan Cornerstone Career Center, ongoing developments in embedded systems include ""automated vehicles and equipment to conduct search and rescue, automated transportation systems, and human-robot coordination to repair equipment in space."" As of 2018, computer embedded computer engineering specializations include system-on-chip design, architecture of edge computing and the Internet of things.


=== Integrated circuits, VLSI design, testing and CAD ===

This specialty of computer engineering requires adequate knowledge of electronics and electrical systems. Engineers working in this area work on enhancing the speed, reliability, and energy efficiency of next-generation very-large-scale integrated (VLSI) circuits and microsystems. An example of this specialty is work done on reducing the power consumption of VLSI algorithms and architecture.


=== Signal, image and speech processing ===

Computer engineers in this area develop improvements in human-computer interaction, including speech recognition and synthesis, medical and scientific imaging, or communications systems. Other work in this area includes computer vision development such as recognition of human facial features.


=== Quantum computing ===


== See also ==


=== Related fields ===


=== Associations ===
Association of Computer Engineers and Technicians
IEEE Computer Society
Association for Computing Machinery


== References ==


== External links ==
 Media related to Computer engineering at Wikimedia Commons"
"Mainframe computers or mainframes, also known as ""big iron"", are computers used primarily by large organizations for critical applications; bulk data processing, such as census, industry and consumer statistics; enterprise resource planning; and transaction processing. They are larger and have more processing power than some other classes of computers: minicomputers, servers, workstations, and personal computers.
The term originally referred to the large cabinets called ""main frames"" that housed the central processing unit and main memory of early computers. Later, the term was used to distinguish high-end commercial machines from less-powerful units. Most large-scale computer-system architectures were established in the 1960s, but continue to evolve. Mainframe computers are often used as servers.


== Design ==
Modern mainframe design is characterized less by raw computational speed and more by:

Redundant internal engineering resulting in high reliability and security
Extensive input-output (""I/O"") facilities with the ability to offload to separate engines
Strict backward compatibility with older software
High hardware and computational utilization rates through virtualization to support massive throughput.
Hot-swapping of hardware, such as processors and memory.Their high stability and reliability enable these machines to run uninterrupted for very long periods of time, with mean time between failures (MTBF) measured in decades.
Mainframes have high availability, one of the primary reasons for their longevity, since they are typically used in applications where downtime would be costly or catastrophic. The term reliability, availability and serviceability (RAS) is a defining characteristic of mainframe computers. Proper planning and implementation are required to realize these features. In addition, mainframes are more secure than other computer types: the NIST vulnerabilities database, US-CERT, rates traditional mainframes such as IBM Z (previously called z Systems, System z and zSeries), Unisys Dorado and Unisys Libra as among the most secure with vulnerabilities in the low single digits as compared with thousands for Windows, UNIX, and Linux. Software upgrades usually require setting up the operating system or portions thereof, and are non-disruptive only when using virtualizing facilities such as IBM z/OS and Parallel Sysplex, or Unisys XPCL, which support workload sharing so that one system can take over another's application while it is being refreshed.
In the late 1950s, mainframes had only a rudimentary interactive interface (the console) and used sets of punched cards, paper tape, or magnetic tape to transfer data and programs. They operated in batch mode to support back office functions such as payroll and customer billing, most of which were based on repeated tape-based sorting and merging operations followed by line printing to preprinted continuous stationery. When interactive user terminals were introduced, they were used almost exclusively for applications (e.g. airline booking) rather than program development. Typewriter and Teletype devices were common control consoles for system operators through the early 1970s, although ultimately supplanted by keyboard/display devices.
By the early 1970s, many mainframes acquired interactive user terminals operating as timesharing computers, supporting hundreds of users simultaneously along with batch processing. Users gained access through keyboard/typewriter terminals and specialized text terminal CRT displays with integral keyboards, or later from personal computers equipped with terminal emulation software. By the 1980s, many mainframes supported graphic display terminals, and terminal emulation, but not graphical user interfaces. This form of end-user computing became obsolete in the 1990s due to the advent of personal computers provided with GUIs. After 2000, modern mainframes partially or entirely phased out classic ""green screen"" and color display terminal access for end-users in favour of Web-style user interfaces.The infrastructure requirements were drastically reduced during the mid-1990s, when CMOS mainframe designs replaced the older bipolar technology. IBM claimed that its newer mainframes reduced data center energy costs for power and cooling, and reduced physical space requirements compared to server farms.


== Characteristics ==

Modern mainframes can run multiple different instances of operating systems at the same time. This technique of virtual machines allows applications to run as if they were on physically distinct computers. In this role, a single mainframe can replace higher-functioning hardware services available to conventional servers. While mainframes pioneered this capability, virtualization is now available on most families of computer systems, though not always to the same degree or level of sophistication.Mainframes can add or hot swap system capacity without disrupting system function, with specificity and granularity to a level of sophistication not usually available with most server solutions. Modern mainframes, notably the IBM zSeries, System z9 and System z10 servers, offer two levels of virtualization: logical partitions (LPARs, via the PR/SM facility) and virtual machines (via the z/VM operating system). Many mainframe customers run two machines: one in their primary data center and one in their backup data center—fully active, partially active, or on standby—in case there is a catastrophe affecting the first building. Test, development, training, and production workload for applications and databases can run on a single machine, except for extremely large demands where the capacity of one machine might be limiting. Such a two-mainframe installation can support continuous business service, avoiding both planned and unplanned outages. In practice many customers use multiple mainframes linked either by Parallel Sysplex and shared DASD (in IBM's case), or with shared, geographically dispersed storage provided by EMC or Hitachi.
Mainframes are designed to handle very high volume input and output (I/O) and emphasize throughput computing. Since the late 1950s, mainframe designs have included subsidiary hardware (called channels or peripheral processors) which manage the I/O devices, leaving the CPU free to deal only with high-speed memory. It is common in mainframe shops to deal with massive databases and files. Gigabyte to terabyte-size record files are not unusual. Compared to a typical PC, mainframes commonly have hundreds to thousands of times as much data storage online, and can access it reasonably quickly. Other server families also offload I/O processing and emphasize throughput computing.
Mainframe return on investment (ROI), like any other computing platform, is dependent on its ability to scale, support mixed workloads, reduce labor costs, deliver uninterrupted service for critical business applications, and several other risk-adjusted cost factors.
Mainframes also have execution integrity characteristics for fault tolerant computing. For example, z900, z990, System z9, and System z10 servers effectively execute result-oriented instructions twice, compare results, arbitrate between any differences (through instruction retry and failure isolation), then shift workloads ""in flight"" to functioning processors, including spares, without any impact to operating systems, applications, or users. This hardware-level feature, also found in HP's NonStop systems, is known as lock-stepping, because both processors take their ""steps"" (i.e. instructions) together. Not all applications absolutely need the assured integrity that these systems provide, but many do, such as financial transaction processing.


== Current market ==
IBM, with z Systems, continues to be a major manufacturer in the mainframe market. Unisys manufactures ClearPath Libra mainframes, based on earlier Burroughs MCP products and ClearPath Dorado mainframes based on Sperry Univac OS 1100 product lines. In 2000, Hitachi co-developed the zSeries z900 with IBM to share expenses, but subsequently the two companies have not collaborated on new Hitachi models. Hewlett-Packard sells its unique NonStop systems, which it acquired with Tandem Computers and which some analysts classify as mainframes. Groupe Bull's GCOS, Stratus OpenVOS, Fujitsu (formerly Siemens) BS2000, and Fujitsu-ICL VME mainframes are still available in Europe, and Fujitsu (formerly Amdahl) GS21 mainframes globally. NEC with ACOS and Hitachi with AP10000-VOS3 still maintain mainframe hardware businesses in the Japanese market.
The amount of vendor investment in mainframe development varies with market share. Fujitsu and Hitachi both continue to use custom S/390-compatible processors, as well as other CPUs (including POWER and Xeon) for lower-end systems. Bull uses a mixture of Itanium and Xeon processors. NEC uses Xeon processors for its low-end ACOS-2 line, but develops the custom NOAH-6 processor for its high-end ACOS-4 series. IBM also develops custom processors in-house, such as the zEC12. Unisys produces code compatible mainframe systems that range from laptops to cabinet-sized mainframes that use homegrown CPUs as well as Xeon processors. Furthermore, there exists a market for software applications to manage the performance of mainframe implementations. In addition to IBM, significant players in this market include BMC, Compuware, and CA Technologies.


== History ==

Several manufacturers and their successors produced mainframe computers from the late 1950s until the early 21st Century, with gradually decreasing numbers and a gradual transition to simulation on Intel chips rather than proprietary hardware. The US group of manufacturers was first known as ""IBM and the Seven Dwarfs"": usually Burroughs, UNIVAC, NCR, Control Data, Honeywell, General Electric and RCA, although some lists varied. Later, with the departure of General Electric and RCA, it was referred to as IBM and the BUNCH. IBM's dominance grew out of their 700/7000 series and, later, the development of the 360 series mainframes. The latter architecture has continued to evolve into their current zSeries mainframes which, along with the then Burroughs and Sperry (now Unisys) MCP-based and OS1100 mainframes, are among the few mainframe architectures still extant that can trace their roots to this early period. While IBM's zSeries can still run 24-bit System/360 code, the 64-bit zSeries and System z9 CMOS servers have nothing physically in common with the older systems. Notable manufacturers outside the US were Siemens and Telefunken in Germany, ICL in the United Kingdom, Olivetti in Italy, and Fujitsu, Hitachi, Oki, and NEC in Japan. The Soviet Union and Warsaw Pact countries manufactured close copies of IBM mainframes during the Cold War; the BESM series and Strela are examples of an independently designed Soviet computer.
Shrinking demand and tough competition started a shakeout in the market in the early 1970s—RCA sold out to UNIVAC and GE sold its business to Honeywell; between 1986 and 1990 Honeywell was bought out by Bull; UNIVAC became a division of Sperry, which later merged with Burroughs to form Unisys Corporation in 1986.
In 1984 estimated sales of desktop computers ($11.6 billion) exceeded mainframe computers ($11.4 billion) for the first time. IBM received the vast majority of mainframe revenue. During the 1980s, minicomputer-based systems grew more sophisticated and were able to displace the lower-end of the mainframes. These computers, sometimes called departmental computers were typified by the DEC VAX.
In 1991, AT&T Corporation briefly owned NCR. During the same period, companies found that servers based on microcomputer designs could be deployed at a fraction of the acquisition price and offer local users much greater control over their own systems given the IT policies and practices at that time. Terminals used for interacting with mainframe systems were gradually replaced by personal computers. Consequently, demand plummeted and new mainframe installations were restricted mainly to financial services and government. In the early 1990s, there was a rough consensus among industry analysts that the mainframe was a dying market as mainframe platforms were increasingly replaced by personal computer networks. InfoWorld's Stewart Alsop infamously predicted that the last mainframe would be unplugged in 1996; in 1993, he cited Cheryl Currid, a computer industry analyst as saying that the last mainframe ""will stop working on December 31, 1999"", a reference to the anticipated Year 2000 problem (Y2K).
That trend started to turn around in the late 1990s as corporations found new uses for their existing mainframes and as the price of data networking collapsed in most parts of the world, encouraging trends toward more centralized computing. The growth of e-business also dramatically increased the number of back-end transactions processed by mainframe software as well as the size and throughput of databases. Batch processing, such as billing, became even more important (and larger) with the growth of e-business, and mainframes are particularly adept at large-scale batch computing. Another factor currently increasing mainframe use is the development of the Linux operating system, which arrived on IBM mainframe systems in 1999 and is typically run in scores or up to c. 8,000 virtual machines on a single mainframe. Linux allows users to take advantage of open source software combined with mainframe hardware RAS. Rapid expansion and development in emerging markets, particularly People's Republic of China, is also spurring major mainframe investments to solve exceptionally difficult computing problems, e.g. providing unified, extremely high volume online transaction processing databases for 1 billion consumers across multiple industries (banking, insurance, credit reporting, government services, etc.) In late 2000, IBM introduced 64-bit z/Architecture, acquired numerous software companies such as Cognos and introduced those software products to the mainframe. IBM's quarterly and annual reports in the 2000s usually reported increasing mainframe revenues and capacity shipments. However, IBM's mainframe hardware business has not been immune to the recent overall downturn in the server hardware market or to model cycle effects. For example, in the 4th quarter of 2009, IBM's System z hardware revenues decreased by 27% year over year. But MIPS (millions of instructions per second) shipments increased 4% per year over the past two years. Alsop had himself photographed in 2000, symbolically eating his own words (""death of the mainframe"").In 2012, NASA powered down its last mainframe, an IBM System z9. However, IBM's successor to the z9, the z10, led a New York Times reporter to state four years earlier that ""mainframe technology—hardware, software and services—remains a large and lucrative business for I.B.M., and mainframes are still the back-office engines behind the world's financial markets and much of global commerce"". As of 2010, while mainframe technology represented less than 3% of IBM's revenues, it ""continue[d] to play an outsized role in Big Blue's results"".In 2015, IBM launched the IBM z13, in June 2017 the IBM z14 and in September 2019 IBM launched the latest version of the product, the IBM z15.


== Differences from supercomputers ==
A supercomputer is a computer at the leading edge of data processing capability, with respect to calculation speed. Supercomputers are used for scientific and engineering problems (high-performance computing) which crunch numbers and data, while mainframes focus on transaction processing. The differences are:

Mainframes are built to be reliable for transaction processing (measured by TPC-metrics; not used or helpful for most supercomputing applications) as it is commonly understood in the business world: the commercial exchange of goods, services, or money. A typical transaction, as defined by the Transaction Processing Performance Council, updates a database system for inventory control (goods), airline reservations (services), or banking (money) by adding a record. A transaction may refer to a set of operations including disk read/writes, operating system calls, or some form of data transfer from one subsystem to another which is not measured by the processing speed of the CPU. Transaction processing is not exclusive to mainframes but is also used by microprocessor-based servers and online networks.
Supercomputer performance is measured in floating point operations per second (FLOPS) or in traversed edges per second or TEPS, metrics that are not very meaningful for mainframe applications, while mainframes are sometimes measured in millions of instructions per second (MIPS), although the definition depends on the instruction mix measured. Examples of integer operations measured by MIPS include adding numbers together, checking values or moving data around in memory (while moving information to and from storage, so-called I/O is most helpful for mainframes; and within memory, only helping indirectly). Floating point operations are mostly addition, subtraction, and multiplication (of binary floating point in supercomputers; measured by FLOPS) with enough digits of precision to model continuous phenomena such as weather prediction and nuclear simulations (only recently standardized decimal floating point, not used in supercomputers, are appropriate for monetary values such as those useful for mainframe applications). In terms of computational speed, supercomputers are more powerful.Mainframes and supercomputers cannot always be clearly distinguished; up until the early 1990s, many supercomputers were based on a mainframe architecture with supercomputing extensions. An example of such a system is the HITAC S-3800, which was instruction-set compatible with IBM System/370 mainframes, and could run the Hitachi VOS3 operating system (a fork of IBM MVS). The S-3800 therefore can be seen as being both simultaneously a supercomputer and also an IBM-compatible mainframe. 
In 2007, an amalgamation of the different technologies and architectures for supercomputers and mainframes has led to the so-called gameframe.


== See also ==
Channel I/O
Cloud computing
Computer types
Failover
Gameframe


== Notes ==


== References ==


== External links ==
 Media related to Mainframe computers at Wikimedia Commons

IBM Systems Mainframe Magazine
IBM z Systems mainframes
Mainframe Computer Support Forum since 1998
Univac 9400, a mainframe from the 1960s, still in use in a German computer museum
Lectures in the History of Computing: Mainframes (archived copy from the Internet Archive)"
"A computer network is a group of computers that use a set of common communication protocols over digital interconnections for the purpose of sharing resources located on or provided by the network nodes. The interconnections between nodes are formed from a broad spectrum of telecommunication network technologies, based on physically wired, optical, and wireless radio-frequency methods that may be arranged in a variety of network topologies.
The nodes of a computer network may be classified by many means as personal computers, servers, networking hardware, or general purpose hosts. They are identified by hostnames and network addresses. Hostnames serve as memorable labels for the nodes, rarely changed after initial assignment. Network addresses serve for locating and identifying the nodes by communication protocols such as the Internet Protocol.
Computer networks may be classified by many criteria, for example, the transmission medium used to carry signals,  bandwidth, communications protocols to organize network traffic, the network size, the topology, traffic control mechanism, and organizational intent.
Computer networks support many applications and services, such as access to the World Wide Web, digital video, digital audio, shared use of application and storage servers, printers, and fax machines, and use of email and instant messaging applications.


== History ==
Computer networking may be considered a branch of computer science, computer engineering, and telecommunications, since it relies on the theoretical and practical application of the related disciplines. Computer networking was influenced by a wide array of technology developments and historical milestones.

In the late 1950s, early networks of computers included the U.S. military radar system Semi-Automatic Ground Environment (SAGE).
In 1959, Christopher Strachey filed a patent application for time-sharing and John McCarthy initiated the first project to implement time-sharing of user programs at MIT. Stratchey passed the concept on to J. C. R. Licklider at the inaugural UNESCO Information Processing Conference in Paris that year. McCarthy was instrumental in the creation of three of the earliest time-sharing systems (Compatible Time-Sharing System in 1961, BBN Time-Sharing System in 1962, and Dartmouth Time Sharing System in 1963).
In 1959, Anatolii Ivanovich Kitov proposed to the Central Committee of the Communist Party of the Soviet Union a detailed plan for the re-organisation of the control of the Soviet armed forces and of the Soviet economy on the basis of a network of computing centres, the OGAS.
In 1959, the MOS transistor was invented by Mohamed Atalla and Dawon Kahng at Bell Labs. It later became one of the basic building blocks and ""work horses"" of virtually any element of communications infrastructure.
In 1960, the commercial airline reservation system semi-automatic business research environment (SABRE) went online with two connected mainframes.
In 1963, J. C. R. Licklider sent a memorandum to office colleagues discussing the concept of the ""Intergalactic Computer Network"", a computer network intended to allow general communications among computer users.
Throughout the 1960s, Paul Baran and Donald Davies independently developed the concept of packet switching to transfer information between computers over a network. Davies pioneered the implementation of the concept with the NPL network, a local area network at the National Physical Laboratory (United Kingdom) using a line speed of 768 kbit/s.
In 1965, Western Electric introduced the first widely used telephone switch that implemented computer control in the switching fabric.
In 1969, the first four nodes of the ARPANET were connected using 50 kbit/s circuits between the University of California at Los Angeles, the Stanford Research Institute, the University of California at Santa Barbara, and the University of Utah. In the 1970s, Leonard Kleinrock carried out mathematical work to model the performance of packet-switched networks, which underpinned the development of the ARPANET. His theoretical work on hierarchical routing in the late 1970s with student Farouk Kamoun remains critical to the operation of the Internet today.
In 1972, commercial services using X.25 were deployed, and later used as an underlying infrastructure for expanding TCP/IP networks.
In 1973, the French CYCLADES network was the first to make the hosts responsible for the reliable delivery of data, rather than this being a centralized service of the network itself.
In 1973, Robert Metcalfe wrote a formal memo at Xerox PARC describing Ethernet, a networking system that was based on the Aloha network, developed in the 1960s by Norman Abramson and colleagues at the University of Hawaii. In July 1976, Robert Metcalfe and David Boggs published their paper ""Ethernet: Distributed Packet Switching for Local Computer Networks"" and collaborated on several patents received in 1977 and 1978.
In 1974, Vint Cerf, Yogen Dalal, and Carl Sunshine published the Transmission Control Protocol (TCP) specification, RFC 675, coining the term Internet as a shorthand for internetworking.
In 1976, John Murphy of Datapoint Corporation created ARCNET, a token-passing network first used to share storage devices.
In 1977, the first long-distance fiber network was deployed by GTE in Long Beach, California.
In 1977, Xerox Network Systems (XNS) was developed by Robert Metcalfe and Yogen Dalal at Xerox.
In 1979, Robert Metcalfe pursued making Ethernet an open standard.
In 1980, Ethernet was upgraded from the original 2.94 Mbit/s protocol to the 10 Mbit/s protocol, which was developed by Ron Crane, Bob Garner, Roy Ogus, and Yogen Dalal.
In 1995, the transmission speed capacity for Ethernet increased from 10 Mbit/s to 100 Mbit/s. By 1998, Ethernet supported transmission speeds of a Gigabit. Subsequently, higher speeds of up to 400 Gbit/s were added (as of 2018). The scaling of Ethernet has been a contributing factor to its continued use.


== Use ==
A computer network extends interpersonal communications by electronic means with various technologies, such as email, instant messaging, online chat, voice and video telephone calls, and video conferencing. A network allows sharing of network and computing resources. Users may access and use resources provided by devices on the network, such as printing a document on a shared network printer or use of a shared storage device. A network allows sharing of files, data, and other types of information giving authorized users the ability to access information stored on other computers on the network. Distributed computing uses computing resources across a network to accomplish tasks.


== Network packet ==
Most modern computer networks use protocols based on packet-mode transmission. A network packet is a formatted unit of data carried by a packet-switched network. The physical link technologies of packet network typically limit the size of packets to a certain maximum transmission unit (MTU). A longer message is fragmented before it is transferred and once the packets arrive, they are reassembled to construct the original message.
Packets consist of two types of data: control information and user data (payload). The control information provides data the network needs to deliver the user data, for example, source and destination network addresses, error detection codes, and sequencing information. Typically, control information is found in packet headers and trailers, with payload data in between.
With packets, the bandwidth of the transmission medium can be better shared among users than if the network were circuit switched. When one user is not sending packets, the link can be filled with packets from other users, and so the cost can be shared, with relatively little interference, provided the link isn't overused. Often the route a packet needs to take through a network is not immediately available. In that case, the packet is queued and waits until a link is free.


== Network topology ==

Network topology is the layout, pattern, or organizational hierarchy of the interconnection of network hosts, in contrast to their physical or geographic location. Typically, most diagrams describing networks are arranged by their topology. The network topology can affect throughput, but reliability is often more critical. With many technologies, such as bus networks, a single failure can cause the network to fail entirely. In general, the more interconnections there are, the more robust the network is; but the more expensive it is to install.
Common layouts are:

Bus network: all nodes are connected to a common medium along this medium. This was the layout used in the original Ethernet, called 10BASE5 and 10BASE2. This is still a common topology on the data link layer, although modern physical layer variants use point-to-point links instead.
Star network: all nodes are connected to a special central node. This is the typical layout found in a Wireless LAN, where each wireless client connects to the central Wireless access point.
Ring network: each node is connected to its left and right neighbour node, such that all nodes are connected and that each node can reach each other node by traversing nodes left- or rightwards. The Fiber Distributed Data Interface (FDDI) made use of such a topology.
Mesh network: each node is connected to an arbitrary number of neighbours in such a way that there is at least one traversal from any node to any other.
Fully connected network: each node is connected to every other node in the network.
Tree network: nodes are arranged hierarchically.The physical layout of the nodes in a network may not necessarily reflect the network topology. As an example, with FDDI, the network topology is a ring, but the physical topology is often a star, because all neighboring connections can be routed via a central physical location. Physical layout is not completely irrelevant, however, as common ducting and equipment locations can represent single points of failure due to issues like fires, power failures and flooding.


=== Overlay network ===

An overlay network is a virtual network that is built on top of another network. Nodes in the overlay network are connected by virtual or logical links.  Each link corresponds to a path, perhaps through many physical links, in the underlying network. The topology of the overlay network may (and often does) differ from that of the underlying one. For example, many peer-to-peer networks are overlay networks.  They are organized as nodes of a virtual system of links that run on top of the Internet.Overlay networks have been around since the invention of networking when computer systems were connected over telephone lines using modems, before any data network existed.
The most striking example of an overlay network is the Internet itself. The Internet itself was initially built as an overlay on the telephone network. Even today, each Internet node can communicate with virtually any other through an underlying mesh of sub-networks of wildly different topologies and technologies. Address resolution and routing are the means that allow mapping of a fully connected IP overlay network to its underlying network.
Another example of an overlay network is a distributed hash table, which maps keys to nodes in the network. In this case, the underlying network is an IP network, and the overlay network is a table (actually a map) indexed by keys.
Overlay networks have also been proposed as a way to improve Internet routing, such as through quality of service guarantees to achieve higher-quality streaming media. Previous proposals such as IntServ, DiffServ, and IP Multicast have not seen wide acceptance largely because they require modification of all routers in the network.  On the other hand, an overlay network can be incrementally deployed on end-hosts running the overlay protocol software, without cooperation from Internet service providers.  The overlay network has no control over how packets are routed in the underlying network between two overlay nodes, but it can control, for example, the sequence of overlay nodes that a message traverses before it reaches its destination.
For example, Akamai Technologies manages an overlay network that provides reliable, efficient content delivery (a kind of multicast).  Academic research includes end system multicast, resilient routing and quality of service studies, among others.


== Network links ==

The transmission media (often referred to in the literature as the physical medium) used to link devices to form a computer network include electrical cable, optical fiber, and free space. In the OSI model, the software to handle the media are defined at layers 1 and 2 — the physical layer and the data link layer.
A widely adopted family that uses copper and fiber media in local area network (LAN) technology is collectively known as Ethernet. The media and protocol standards that enable communication between networked devices over Ethernet are defined by IEEE 802.3.  Wireless LAN standards use radio waves, others use infrared signals as a transmission medium. Power line communication uses a building's power cabling to transmit data.


=== Wired technologies ===

The following classes of wired technologies are used in computer networking.

Coaxial cable is widely used for cable television systems, office buildings, and other work-sites for local area networks. Transmission speed ranges from 200 million bits per second to more than 500 million bits per second.
ITU-T G.hn technology uses existing home wiring (coaxial cable, phone lines and power lines) to create a high-speed local area network.
Twisted pair cabling is used for wired Ethernet and other standards. It typically consists of 4 pairs of copper cabling that can be utilized for both voice and data transmission. The use of two wires twisted together helps to reduce crosstalk and electromagnetic induction. The transmission speed ranges from 2 Mbit/s to 10 Gbit/s. Twisted pair cabling comes in two forms: unshielded twisted pair (UTP) and shielded twisted-pair (STP). Each form comes in several category ratings, designed for use in various scenarios.
An optical fiber is a glass fiber. It carries pulses of light that represent data via lasers and optical amplifiers. Some advantages of optical fibers over metal wires are very low transmission loss and immunity to electrical interference. Using dense wave division multiplexing, optical fibers can simultaneously carry multiple streams of data on different wavelengths of light, which greatly increases the rate that data can be sent to up to trillions of bits per second. Optic fibers can be used for long runs of cable carrying very high data rates, and are used for undersea cables to interconnect continents. There are two basic types of fiber optics, single-mode optical fiber (SMF) and multi-mode optical fiber (MMF).  Single-mode fiber has the advantage of being able to sustain a coherent signal for dozens or even a hundred kilometers. Multimode fiber is cheaper to terminate but is limited to a few hundred or even only a few dozens of meters, depending on the data rate and cable grade.


=== Wireless technologies ===

Network connections can be established wirelessly using radio or other electromagnetic means of communication.

Terrestrial microwave – Terrestrial microwave communication uses Earth-based transmitters and receivers resembling satellite dishes. Terrestrial microwaves are in the low gigahertz range, which limits all communications to line-of-sight. Relay stations are spaced approximately 40 miles (64 km) apart.
Communications satellites – Satellites also communicate via microwave. The satellites are stationed in space, typically in geosynchronous orbit 35,400 km (22,000 mi) above the equator. These Earth-orbiting systems are capable of receiving and relaying voice, data, and TV signals.
Cellular networks use several radio communications technologies. The systems divide the region covered into multiple geographic areas. Each area is served by a low-power transceiver.
Radio and spread spectrum technologies – Wireless LANs use a high-frequency radio technology similar to digital cellular. Wireless LANs use spread spectrum technology to enable communication between multiple devices in a limited area. IEEE 802.11 defines a common flavor of open-standards wireless radio-wave technology known as Wi-Fi.
Free-space optical communication uses visible or invisible light for communications. In most cases, line-of-sight propagation is used, which limits the physical positioning of communicating devices.


=== Exotic technologies ===
There have been various attempts at transporting data over exotic media.

IP over Avian Carriers was a humorous April fool's Request for Comments, issued as RFC 1149. It was implemented in real life in 2001.
Extending the Internet to interplanetary dimensions via radio waves, the Interplanetary Internet.Both cases have a large round-trip delay time, which gives slow two-way communication but doesn't prevent sending large amounts of information.


== Network nodes ==

Apart from any physical transmission media, networks are built from additional basic system building blocks, such as network interface controllers (NICs), repeaters, hubs, bridges, switches, routers, modems, and firewalls. Any particular piece of equipment will frequently contain multiple building blocks and so may perform multiple functions.


=== Network interfaces ===

A network interface controller (NIC) is computer hardware that connects the computer to the network media and has the ability to process low-level network information. For example, the NIC may have a connector for accepting a cable, or an aerial for wireless transmission and reception, and the associated circuitry.
In Ethernet networks, each network interface controller has a unique Media Access Control (MAC) address—usually stored in the controller's permanent memory. To avoid address conflicts between network devices, the Institute of Electrical and Electronics Engineers (IEEE) maintains and administers MAC address uniqueness. The size of an Ethernet MAC address is six octets. The three most significant octets are reserved to identify NIC manufacturers. These manufacturers, using only their assigned prefixes, uniquely assign the three least-significant octets of every Ethernet interface they produce.


=== Repeaters and hubs ===
A repeater is an electronic device that receives a network signal, cleans it of unnecessary noise and regenerates it. The signal is retransmitted at a higher power level, or to the other side of an obstruction so that the signal can cover longer distances without degradation. In most twisted pair Ethernet configurations, repeaters are required for cable that runs longer than 100 meters. With fiber optics, repeaters can be tens or even hundreds of kilometers apart.
Repeaters work on the physical layer of the OSI model but still require a small amount of time to regenerate the signal. This can cause a propagation delay that affects network performance and may affect proper function. As a result, many network architectures limit the number of repeaters used in a network, e.g., the Ethernet 5-4-3 rule.
An Ethernet repeater with multiple ports is known as an Ethernet hub. In addition to reconditioning and distributing network signals, a repeater hub assists with collision detection and fault isolation for the network. Hubs and repeaters in LANs have been largely obsoleted by modern network switches.


=== Bridges ===
A network bridge opeates at the data link layer (layer 2) of the OSI model and connects and filters traffic between two network segments to form a single network. This divides the network's collision domain but maintains a single broadcast domain. Network segmentation through bridging breaks down a large, congested network into an aggregation of smaller, more efficient networks.


=== Switches ===
A network switch is a device that forwards and filters OSI layer 2 datagrams (frames) between ports based on the destination MAC address in each frame.
A switch is distinct from a hub in that it only forwards the frames to the physical ports involved in the communication rather than all ports connected. It can be thought of as a multi-port bridge. It learns to associate physical ports to MAC addresses by examining the source addresses of received frames. If an unknown destination is targeted, the switch broadcasts to all ports but the source. Switches normally have numerous ports, facilitating a star topology for devices, and cascading additional switches.


=== Routers ===

A router is an internetworking device that forwards packets between networks by processing the routing information included in the packet or datagram (Internet protocol information from layer 3).  The routing information is often processed in conjunction with the routing table (or forwarding table).  A router uses its routing table to determine where to forward packets. A destination in a routing table can include a ""null"" interface, also known as the ""black hole"" interface because data can go into it, however, no further processing is done for said data, i.e. the packets are dropped.


=== Modems ===
Modems (MOdulator-DEModulator) are used to connect network nodes via wire not originally designed for digital network traffic, or for wireless. To do this one or more carrier signals are modulated by the digital signal to produce an analog signal that can be tailored to give the required properties for transmission. Modems are commonly used for telephone lines, using a digital subscriber line technology.


=== Firewalls ===
A firewall is a network device for controlling network security and access rules. Firewalls are typically configured to reject access requests from unrecognized sources while allowing actions from recognized ones. The vital role firewalls play in network security grows in parallel with the constant increase in cyber attacks.


== Communication protocols ==

A communication protocol is a set of rules for exchanging information over a network. In a protocol stack (also see the OSI model), each protocol leverages the services of the protocol layer below it, until the lowest layer controls the hardware that sends information across the media. The use of protocol layering is today ubiquitous across the field of computer networking. An important example of a protocol stack is HTTP (the World Wide Web protocol) running over TCP over IP (the Internet protocols) over IEEE 802.11 (the Wi-Fi protocol). This stack is used between the wireless router and the home user's personal computer when the user is surfing the web.
Communication protocols have various characteristics.  They may be connection-oriented or connectionless, they may use circuit mode or packet switching, and they may use hierarchical addressing or flat addressing.
There are many communication protocols, a few of which are described below.


=== IEEE 802 ===
IEEE 802 is a family of IEEE standards dealing with local area networks and metropolitan area networks. The complete IEEE 802 protocol suite provides a diverse set of networking capabilities. The protocols have a flat addressing scheme. They operate mostly at levels 1 and 2 of the OSI model.
For example, MAC bridging (IEEE 802.1D) deals with the routing of Ethernet packets using a Spanning Tree Protocol. IEEE 802.1Q describes VLANs, and IEEE 802.1X defines a port-based Network Access Control protocol, which forms the basis for the authentication mechanisms used in VLANs (but it is also found in WLANs) – it is what the home user sees when the user has to enter a ""wireless access key"".


==== Ethernet ====
Ethernet, sometimes simply called LAN, is a family of protocols used in wired LANs, described by a set of standards together called IEEE 802.3 published by the Institute of Electrical and Electronics Engineers.


==== Wireless LAN ====
Wireless LAN, also widely known as WLAN or WiFi, is probably the most well-known member of the IEEE 802 protocol family for home users today. It is standardized by IEEE 802.11 and shares many properties with wired Ethernet.


=== Internet Protocol Suite ===
The Internet Protocol Suite, also called TCP/IP, is the foundation of all modern networking. It offers connection-less as well as connection-oriented services over an inherently unreliable network traversed by datagram transmission at the Internet protocol (IP) level. At its core, the protocol suite defines the addressing, identification, and routing specifications for Internet Protocol Version 4 (IPv4) and for IPv6, the next generation of the protocol with a much enlarged addressing capability.
The Internet Protocol Suite is the defining set of protocols for the Internet. Although many computers communicate via the Internet, it is actually a network of networks, as elaborated by Andrew Tannenbaum.


=== SONET/SDH ===
Synchronous optical networking (SONET) and Synchronous Digital Hierarchy (SDH) are standardized multiplexing protocols that transfer multiple digital bit streams over optical fiber using lasers. They were originally designed to transport circuit mode communications from a variety of different sources, primarily to support real-time, uncompressed, circuit-switched voice encoded in PCM (Pulse-Code Modulation) format. However, due to its protocol neutrality and transport-oriented features, SONET/SDH also was the obvious choice for transporting Asynchronous Transfer Mode (ATM) frames.


=== Asynchronous Transfer Mode ===
Asynchronous Transfer Mode (ATM) is a switching technique for telecommunication networks.  It uses asynchronous time-division multiplexing and encodes data into small, fixed-sized cells. This differs from other protocols such as the Internet Protocol Suite or Ethernet that use variable sized packets or frames. ATM has similarity with both circuit and packet switched networking.  This makes it a good choice for a network that must handle both traditional high-throughput data traffic, and real-time, low-latency content such as voice and video. ATM uses a connection-oriented model in which a virtual circuit must be established between two endpoints before the actual data exchange begins.
While the role of ATM is diminishing in favor of next-generation networks, it still plays a role in the last mile, which is the connection between an Internet service provider and the home user.


=== Cellular standards ===
There are a number of different digital cellular standards, including: Global System for Mobile Communications (GSM), General Packet Radio Service (GPRS), cdmaOne, CDMA2000, Evolution-Data Optimized (EV-DO), Enhanced Data Rates for GSM Evolution (EDGE), Universal Mobile Telecommunications System (UMTS), Digital Enhanced Cordless Telecommunications (DECT), Digital AMPS (IS-136/TDMA), and Integrated Digital Enhanced Network (iDEN).


== Geographic scale ==
Networks may be characterized by many properties or features, such as physical capacity, organizational purpose, user authorization, access rights, and others. Another distinct classification method is that of physical extent, or geographic scale.

Nanoscale networkA nanoscale communication network has key components implemented at the nanoscale including message carriers and leverages physical principles that differ from macroscale communication mechanisms. Nanoscale communication extends communication to very small sensors and actuators such as those found in biological systems and also tends to operate in environments that would be too harsh for classical communication.
Personal area networkA personal area network (PAN) is a computer network used for communication among computer and different information technological devices close to one person. Some examples of devices that are used in a PAN are personal computers, printers, fax machines, telephones, PDAs, scanners, and even video game consoles. A PAN may include wired and wireless devices. The reach of a PAN typically extends to 10 meters. A wired PAN is usually constructed with USB and FireWire connections while technologies such as Bluetooth and infrared communication typically form a wireless PAN.

Local area networkA local area network (LAN) is a network that connects computers and devices in a limited geographical area such as a home, school, office building, or closely positioned group of buildings. Each computer or device on the network is a node.  Wired LANs are most likely based on Ethernet technology.  Newer standards such as ITU-T G.hn also provide a way to create a wired LAN using existing wiring, such as coaxial cables, telephone lines, and power lines.The defining characteristics of a LAN, in contrast to a wide area network (WAN), include higher data transfer rates, limited geographic range, and lack of reliance on leased lines to provide connectivity. Current Ethernet or other IEEE 802.3 LAN technologies operate at data transfer rates up to 100 Gbit/s, standardized by IEEE in 2010. Currently, 400 Gbit/s Ethernet is being developed.
A LAN can be connected to a WAN using a router.

Home area networkA home area network (HAN) is a residential LAN used for communication between digital devices typically deployed in the home, usually a small number of personal computers and accessories, such as printers and mobile computing devices. An important function is the sharing of Internet access, often a broadband service through a cable TV or digital subscriber line (DSL) provider.

Storage area networkA storage area network (SAN) is a dedicated network that provides access to consolidated, block level data storage. SANs are primarily used to make storage devices, such as disk arrays, tape libraries, and optical jukeboxes, accessible to servers so that the devices appear like locally attached devices to the operating system. A SAN typically has its own network of storage devices that are generally not accessible through the local area network by other devices. The cost and complexity of SANs dropped in the early 2000s to levels allowing wider adoption across both enterprise and small to medium-sized business environments.

Campus area networkA campus area network (CAN) is made up of an interconnection of LANs within a limited geographical area. The networking equipment (switches, routers) and transmission media (optical fiber, copper plant, Cat5 cabling, etc.) are almost entirely owned by the campus tenant / owner (an enterprise, university, government, etc.).
For example, a university campus network is likely to link a variety of campus buildings to connect academic colleges or departments, the library, and student residence halls.

Backbone networkA backbone network is part of a computer network infrastructure that provides a path for the exchange of information between different LANs or subnetworks.  A backbone can tie together diverse networks within the same building, across different buildings, or over a wide area.
For example, a large company might implement a backbone network to connect departments that are located around the world. The equipment that ties together the departmental networks constitutes the network backbone.  When designing a network backbone, network performance and network congestion are critical factors to take into account.  Normally, the backbone network's capacity is greater than that of the individual networks connected to it.
Another example of a backbone network is the Internet backbone, which is a massive, global system of fiber-optic cable and optical networking that carry the bulk of data between wide area networks (WANs), metro, regional, national and transoceanic networks.

Metropolitan area networkA Metropolitan area network (MAN) is a large computer network that usually spans a city or a large campus.

Wide area networkA wide area network (WAN) is a computer network that covers a large geographic area such as a city, country, or spans even intercontinental distances.  A WAN uses a communications channel that combines many types of media such as telephone lines, cables, and air waves. A WAN often makes use of transmission facilities provided by common carriers, such as telephone companies. WAN technologies generally function at the lower three layers of the OSI reference model: the physical layer, the data link layer, and the network layer.

Enterprise private networkAn enterprise private network is a network that a single organization builds to interconnect its office locations (e.g., production sites, head offices, remote offices, shops) so they can share computer resources.

Virtual private networkA virtual private network (VPN) is an overlay network in which some of the links between nodes are carried by open connections or virtual circuits in some larger network (e.g., the Internet) instead of by physical wires. The data link layer protocols of the virtual network are said to be tunneled through the larger network when this is the case. One common application is secure communications through the public Internet, but a VPN need not have explicit security features, such as authentication or content encryption. VPNs, for example, can be used to separate the traffic of different user communities over an underlying network with strong security features.
VPN may have best-effort performance, or may have a defined service level agreement (SLA) between the VPN customer and the VPN service provider. Generally, a VPN has a topology more complex than point-to-point.

Global area networkA global area network (GAN) is a network used for supporting mobile across an arbitrary number of wireless LANs, satellite coverage areas, etc. The key challenge in mobile communications is handing off user communications from one local coverage area to the next. In IEEE Project 802, this involves a succession of terrestrial wireless LANs.


== Organizational scope ==
Networks are typically managed by the organizations that own them. Private enterprise networks may use a combination of intranets and extranets. They may also provide network access to the Internet, which has no single owner and permits virtually unlimited global connectivity.


=== Intranet ===
An intranet is a set of networks that are under the control of a single administrative entity.  The intranet uses the IP protocol and IP-based tools such as web browsers and file transfer applications. The administrative entity limits use of the intranet to its authorized users. Most commonly, an intranet is the internal LAN of an organization. A large intranet typically has at least one web server to provide users with organizational information. An intranet is also anything behind the router on a local area network.


=== Extranet ===
An extranet is a network that is also under the administrative control of a single organization, but supports a limited connection to a specific external network.  For example, an organization may provide access to some aspects of its intranet to share data with its business partners or customers.  These other entities are not necessarily trusted from a security standpoint.  Network connection to an extranet is often, but not always, implemented via WAN technology.


=== Internetwork ===
An internetwork is the connection of multiple different types of computer networks to form a single computer network by layering on top of the different networking software and connecting them together using routers.


=== Internet ===

The Internet is the largest example of an internetwork. It is a global system of interconnected governmental, academic, corporate, public, and private computer networks. It is based on the networking technologies of the Internet Protocol Suite. It is the successor of the Advanced Research Projects Agency Network (ARPANET) developed by DARPA of the United States Department of Defense. The Internet utilizes copper communications and the optical networking backbone to enable the World Wide Web (WWW), the Internet of Things, video transfer and a broad range of information services.
Participants in the Internet use a diverse array of methods of several hundred documented, and often standardized, protocols compatible with the Internet Protocol Suite and an addressing system (IP addresses) administered by the Internet Assigned Numbers Authority and address registries. Service providers and large enterprises exchange information about the reachability of their address spaces through the Border Gateway Protocol (BGP), forming a redundant worldwide mesh of transmission paths.


=== Darknet ===
A darknet is an overlay network, typically running on the Internet, that is only accessible through specialized software. A darknet is an anonymizing network where connections are made only between trusted peers — sometimes called ""friends"" (F2F) — using non-standard protocols and ports.
Darknets are distinct from other distributed peer-to-peer networks as sharing is anonymous (that is, IP addresses are not publicly shared), and therefore users can communicate with little fear of governmental or corporate interference.


== Routing ==

Routing is the process of selecting network paths to carry network traffic. Routing is performed for many kinds of networks, including circuit switching networks and packet switched networks.
In packet-switched networks, routing directs packet forwarding (the transit of logically addressed network packets from their source toward their ultimate destination)  through intermediate nodes. Intermediate nodes are typically network hardware devices such as routers, bridges, gateways, firewalls, or switches. General-purpose computers can also forward packets and perform routing, though they are not specialized hardware and may suffer from limited performance. The routing process usually directs forwarding on the basis of routing tables, which maintain a record of the routes to various network destinations. Thus, constructing routing tables, which are held in the router's memory, is very important for efficient routing.
There are usually multiple routes that can be taken, and to choose between them, different elements can be considered to decide which routes get installed into the routing table, such as (sorted by priority):

Prefix-Length: where longer subnet masks are preferred (independent if it is within a routing protocol or over different routing protocol)
Metric: where a lower metric/cost is preferred (only valid within one and the same routing protocol)
Administrative distance: where a lower distance is preferred (only valid between different routing protocols)Most routing algorithms use only one network path at a time. Multipath routing techniques enable the use of multiple alternative paths.
Routing, in a more narrow sense of the term, is often contrasted with bridging in its assumption that network addresses are structured and that similar addresses imply proximity within the network. Structured addresses allow a single routing table entry to represent the route to a group of devices.  In large networks, structured addressing (routing, in the narrow sense) outperforms unstructured addressing (bridging). Routing has become the dominant form of addressing on the Internet. Bridging is still widely used within localized environments.


== Network service ==
Network services are applications hosted by servers on a computer network, to provide some functionality for members or users of the network, or to help the network itself to operate.
The World Wide Web, E-mail, printing and network file sharing are examples of well-known network services. Network services such as DNS (Domain Name System) give names for IP and MAC addresses (people remember names like “nm.lan” better than numbers like “210.121.67.18”), and DHCP to ensure that the equipment on the network has a valid IP address.Services are usually based on a service protocol that defines the format and sequencing of messages between clients and servers of that network service.


== Network performance ==


=== Bandwidth ===

Bandwidth in bit/s may refer to consumed bandwidth, corresponding to achieved throughput or goodput, i.e., the average rate of successful data transfer through a communication path. The throughput is affected by technologies such as bandwidth shaping, bandwidth management, bandwidth throttling, bandwidth cap, bandwidth allocation (for example bandwidth allocation protocol and dynamic bandwidth allocation), etc. A bit stream's bandwidth  is proportional to the average consumed signal bandwidth in hertz (the average spectral bandwidth of the analog signal representing the bit stream) during a studied time interval.


=== Network delay ===

Any data sent across a network requires time to travel from source to destination. Depending on the application, the one-way delay or the round-trip time can have a significant impact on performance.


=== Quality of service ===
Depending on the installation requirements, network performance is usually measured by the quality of service of a telecommunications product. The parameters that affect this typically can include throughput, jitter, bit error rate and latency.
The following list gives examples of network performance measures for a circuit-switched network and one type of packet-switched network, viz. ATM:

Circuit-switched networks: In circuit switched networks, network performance is synonymous with the grade of service. The number of rejected calls is a measure of how well the network is performing under heavy traffic loads. Other types of performance measures can include the level of noise and echo.
ATM: In an Asynchronous Transfer Mode (ATM) network, performance can be measured by line rate, quality of service (QoS), data throughput, connect time, stability, technology, modulation technique and modem enhancements.There are many ways to measure the performance of a network, as each network is different in nature and design. Performance can also be modelled instead of measured. For example, state transition diagrams are often used to model queuing performance in a circuit-switched network. The network planner uses these diagrams to analyze how the network performs in each state, ensuring that the network is optimally designed.


=== Network congestion ===
Network congestion occurs when a link or node is subjected to a greater data load than it is rated for, resulting in a deterioration of its quality of service.  Typical effects include queueing delay, packet loss or the blocking of new connections.  A consequence of these latter two is that incremental increases in offered load lead either to only a small increase in network throughput, or to a reduction in network throughput.
Network protocols that use aggressive retransmissions to compensate for packet loss tend to keep systems in a state of network congestion—even after the initial load is reduced to a level that would not normally induce network congestion. Thus, networks using these protocols can exhibit two stable states under the same level of load. The stable state with low throughput is known as congestive collapse.
Modern networks use congestion control, congestion avoidance and traffic control techniques to try to avoid congestion collapse. These include: exponential backoff in protocols such as 802.11's CSMA/CA and the original Ethernet, window reduction in TCP, and fair queueing in devices such as routers. Another method to avoid the negative effects of network congestion is implementing priority schemes, so that some packets are transmitted with higher priority than others. Priority schemes do not solve network congestion by themselves, but they help to alleviate the effects of congestion for some services. An example of this is 802.1p. A third method to avoid network congestion is the explicit allocation of network resources to specific flows. One example of this is the use of Contention-Free Transmission Opportunities (CFTXOPs) in the ITU-T G.hn standard, which provides high-speed (up to 1 Gbit/s) Local area networking over existing home wires (power lines, phone lines and coaxial cables).
For the Internet, RFC 2914 addresses the subject of congestion control in detail.


=== Network resilience ===
Network resilience is ""the ability to provide and maintain an acceptable level of service in the face of faults and challenges to normal operation.”


== Security ==

Computer networks are also used by security hackers to deploy computer viruses or computer worms on devices connected to the network, or to prevent these devices from accessing the network via a denial-of-service attack.


=== Network security ===
Network security consists of provisions and policies adopted by the network administrator to prevent and monitor unauthorized access, misuse, modification, or denial of the computer network and its network-accessible resources. Network security is the authorization of access to data in a network, which is controlled by the network administrator. Users are assigned an ID and password that allows them access to information and programs within their authority.  Network security is used on a variety of computer networks, both public and private, to secure daily transactions and communications among businesses, government agencies and individuals.


=== Network surveillance ===
Network surveillance is the monitoring of data being transferred over computer networks such as the Internet. The monitoring is often done surreptitiously and may be done by or at the behest of governments, by corporations, criminal organizations, or individuals. It may or may not be legal and may or may not require authorization from a court or other independent agency.
Computer and network surveillance programs are widespread today, and almost all Internet traffic is or could potentially be monitored for clues to illegal activity.
Surveillance is very useful to governments and law enforcement to maintain social control, recognize and monitor threats, and prevent/investigate criminal activity. With the advent of programs such as the Total Information Awareness program, technologies such as high-speed surveillance computers and biometrics software, and laws such as the Communications Assistance For Law Enforcement Act, governments now possess an unprecedented ability to monitor the activities of citizens.However, many civil rights and privacy groups—such as Reporters Without Borders, the Electronic Frontier Foundation, and the American Civil Liberties Union—have expressed concern that increasing surveillance of citizens may lead to a mass surveillance society, with limited political and personal freedoms. Fears such as this have led to numerous lawsuits such as Hepting v. AT&T. The hacktivist group Anonymous has hacked into government websites in protest of what it considers ""draconian surveillance"".


=== End to end encryption ===
End-to-end encryption (E2EE) is a digital communications paradigm of uninterrupted protection of data traveling between two communicating parties. It involves the originating party encrypting data so only the intended recipient can decrypt it, with no dependency on third parties. End-to-end encryption prevents intermediaries, such as Internet providers or application service providers, from discovering or tampering with communications. End-to-end encryption generally protects both confidentiality and integrity.
Examples of end-to-end encryption include HTTPS for web traffic, PGP for email, OTR for instant messaging, ZRTP for telephony, and TETRA for radio.
Typical server-based communications systems do not include end-to-end encryption. These systems can only guarantee protection of communications between clients and servers, not between the communicating parties themselves. Examples of non-E2EE systems are Google Talk, Yahoo Messenger, Facebook, and Dropbox. Some such systems, for example LavaBit and SecretInk, have even described themselves as offering ""end-to-end"" encryption when they do not. Some systems that normally offer end-to-end encryption have turned out to contain a back door that subverts negotiation of the encryption key between the communicating parties, for example Skype or Hushmail.
The end-to-end encryption paradigm does not directly address risks at the communications endpoints themselves, such as the technical exploitation of clients, poor quality random number generators, or key escrow. E2EE also does not address traffic analysis, which relates to things such as the identities of the endpoints and the times and quantities of messages that are sent.


=== SSL/TLS ===
The introduction and rapid growth of e-commerce on the World Wide Web in the mid-1990s made it obvious that some form of authentication and encryption was needed. Netscape took the first shot at a new standard. At the time, the dominant web browser was Netscape Navigator. Netscape created a standard called secure socket layer (SSL). SSL requires a server with a certificate. When a client requests access to an SSL-secured server, the server sends a copy of the certificate to the client. The SSL client checks this certificate (all web browsers come with an exhaustive list of CA root certificates preloaded), and if the certificate checks out, the server is authenticated and the client negotiates a symmetric-key cipher for use in the session. The session is now in a very secure encrypted tunnel between the SSL server and the SSL client.


== Views of networks ==
Users and network administrators typically have different views of their networks. Users can share printers and some servers from a workgroup, which usually means they are in the same geographic location and are on the same LAN, whereas a Network Administrator is responsible to keep that network up and running.  A community of interest has less of a connection of being in a local area, and should be thought of as a set of arbitrarily located users who share a set of servers, and possibly also communicate via peer-to-peer technologies.
Network administrators can see networks from both physical and logical perspectives. The physical perspective involves geographic locations, physical cabling, and the network elements (e.g., routers, bridges and application layer gateways) that interconnect via the transmission media. Logical networks, called, in the TCP/IP architecture, subnets, map onto one or more transmission media. For example, a common practice in a campus of buildings is to make a set of LAN cables in each building appear to be a common subnet, using  virtual LAN (VLAN) technology.
Both users and administrators are aware, to varying extents, of the trust and scope characteristics of a network. Again using TCP/IP architectural terminology, an intranet is a community of interest under private administration usually by an enterprise, and is only accessible by authorized users (e.g. employees).  Intranets do not have to be connected to the Internet, but generally have a limited connection.  An extranet is an extension of an intranet that allows secure communications to users outside of the intranet (e.g. business partners, customers).Unofficially, the Internet is the set of users, enterprises, and content providers that are interconnected by Internet Service Providers (ISP). From an engineering viewpoint, the Internet is the set of subnets, and aggregates of subnets, that share the registered IP address space and exchange information about the reachability of those IP addresses using the Border Gateway Protocol. Typically, the human-readable names of servers are translated to IP addresses, transparently to users, via the directory function of the Domain Name System (DNS).
Over the Internet, there can be  business-to-business (B2B),  business-to-consumer (B2C) and consumer-to-consumer (C2C) communications. When money or sensitive information is exchanged, the communications are apt to be protected by some form of communications security mechanism.  Intranets and extranets can be securely superimposed onto the Internet, without any access by general Internet users and administrators, using secure Virtual Private Network (VPN) technology.


== Journals and newsletters ==
Open Computer Science (open access journal)


== See also ==
Comparison of network diagram software
Cyberspace
History of the Internet
Information Age
Information revolution
Minimum-Pairs Protocol
Network simulation
Network planning and design
Network traffic control


== References ==

 This article incorporates public domain material from the General Services Administration document: ""Federal Standard 1037C"".


== Further reading ==
Shelly, Gary, et al. ""Discovering Computers"" 2003 Edition.
Wendell Odom, Rus Healy, Denise Donohue. (2010) CCIE Routing and Switching. Indianapolis, IN: Cisco Press
Kurose James F and Keith W. Ross : Computer Networking: A Top-Down Approach Featuring the Internet, Pearson Education 2005.
William Stallings, Computer Networking with Internet Protocols and Technology, Pearson Education 2004.
Important publications in computer networks
Network Communication Architecture and Protocols: OSI Network Architecture 7 Layers Model
Dimitri Bertsekas, and Robert Gallager, ""Data Networks,"" Prentice Hall, 1992.


== External links ==
Networking at Curlie
IEEE Ethernet manufacturer information
A computer networking acronym guide"
"Computer programming is the process of designing and building an executable computer program to accomplish a specific computing result or to perform a specific task. Programming involves tasks such as: analysis, generating algorithms, profiling algorithms' accuracy and resource consumption, and the implementation of algorithms in a chosen programming language (commonly referred to as coding). The source code of a program is written in one or more languages that are intelligible to programmers, rather than machine code, which is directly executed by the central processing unit. The purpose of programming is to find a sequence of instructions that will automate the performance of a task (which can be as complex as an operating system) on a computer, often for solving a given problem. Proficient programming thus often requires expertise in several different subjects, including knowledge of the application domain, specialized algorithms, and formal logic.
Tasks accompanying and related to programming include: testing, debugging, source code maintenance, implementation of build systems, and management of derived artifacts, such as the machine code of computer programs. These might be considered part of the programming process, but often the term software development is used for this larger process with the term programming, implementation, or coding reserved for the actual writing of code. Software engineering combines engineering techniques with software development practices. Reverse engineering is the opposite process. A hacker is any skilled computer expert that uses their technical knowledge to overcome a problem, but it can also mean a security hacker in common language.


== History ==

Programmable devices have existed for centuries. As early as the 9th century, a programmable music sequencer was invented by the Persian Banu Musa brothers, who described an automated mechanical flute player in the Book of Ingenious Devices. In 1206, the Arab engineer Al-Jazari invented a programmable drum machine where musical mechanical automaton could be made to play different rhythms and drum patterns, via pegs and cams. In 1801, the Jacquard loom could produce entirely different weaves by changing the ""program"" – a series of pasteboard cards with holes punched in them.
Code-breaking algorithms have also existed for centuries. In the 9th century, the Arab mathematician Al-Kindi described a cryptographic algorithm for deciphering encrypted code, in A Manuscript On Deciphering Cryptographic Messages. He gave the first description of cryptanalysis by frequency analysis, the earliest code-breaking algorithm.The first computer program is generally dated to 1843, when mathematician Ada Lovelace published an algorithm to calculate a sequence of Bernoulli numbers, intended to be carried out by Charles Babbage's Analytical Engine.

In the 1880s Herman Hollerith invented the concept of storing data in machine-readable form. Later a control panel (plugboard) added to his 1906 Type I Tabulator allowed it to be programmed for different jobs, and by the late 1940s, unit record equipment such as the IBM 602 and IBM 604, were programmed by control panels in a similar way; as were the first electronic computers. However, with the concept of the stored-program computers introduced in 1949, both programs and data were stored and manipulated in the same way in computer memory.Machine code was the language of early programs, written in the instruction set of the particular machine, often in binary notation. Assembly languages were soon developed that let the programmer specify instruction in a text format, (e.g., ADD X, TOTAL), with abbreviations for each operation code and meaningful names for specifying addresses. However, because an assembly language is little more than a different notation for a machine language, any two machines with different instruction sets also have different assembly languages.

High-level languages made the process of developing a program simpler and more understandable, and less bound to the underlying hardware. FORTRAN, the first widely used high-level language to have a functional implementation, came out in 1957 and many other languages were soon developed – in particular, COBOL aimed at commercial data processing, and Lisp for computer research.
Programs were mostly still entered using punched cards or paper tape. See computer programming in the punch card era. By the late 1960s, data storage devices and computer terminals became inexpensive enough that programs could be created by typing directly into the computers. Text editors (programs themselves) were developed that allowed changes and corrections to be made much more easily than with punched cards.


== Modern programming ==


=== Quality requirements ===
Whatever the approach to development may be, the final program must satisfy some fundamental properties. The following properties are among the most important:

Reliability: how often the results of a program are correct. This depends on conceptual correctness of algorithms, and minimization of programming mistakes, such as mistakes in resource management (e.g., buffer overflows and race conditions) and logic errors (such as division by zero or off-by-one errors).
Robustness: how well a program anticipates problems due to errors (not bugs). This includes situations such as incorrect, inappropriate or corrupt data, unavailability of needed resources such as memory, operating system services and network connections, user error, and unexpected power outages.
Usability: the ergonomics of a program: the ease with which a person can use the program for its intended purpose or in some cases even unanticipated purposes. Such issues can make or break its success even regardless of other issues. This involves a wide range of textual, graphical and sometimes hardware elements that improve the clarity, intuitiveness, cohesiveness and completeness of a program's user interface.
Portability: the range of computer hardware and operating system platforms on which the source code of a program can be compiled/interpreted and run. This depends on differences in the programming facilities provided by the different platforms, including hardware and operating system resources, expected behavior of the hardware and operating system, and availability of platform specific compilers (and sometimes libraries) for the language of the source code.
Maintainability: the ease with which a program can be modified by its present or future developers in order to make improvements or customisations, fix bugs and security holes, or adapt it to new environments. Good practices during initial development make the difference in this regard. This quality may not be directly apparent to the end user but it can significantly affect the fate of a program over the long term.
Efficiency/performance: Measure of system resources a program consumes (processor time, memory space, slow devices such as disks, network bandwidth and to some extent even user interaction): the less, the better. This also includes careful management of resources, for example cleaning up temporary files and eliminating memory leaks. This is often discussed under the shadow of a chosen programming language. The language certainly effects the performance, but even slower languages such as python can execute programs, from a human perspective, instantly. The speed, resource usage, and performance may be important for some programs which require it, but many programs that are not bottlenecked by speed of hardware, in general, do not require optimization.


=== Readability of source code ===
In computer programming, readability refers to the ease with which a human reader can comprehend the purpose, control flow, and operation of source code. It affects the aspects of quality above, including portability, usability and most importantly maintainability.
Readability is important because programmers spend the majority of their time reading, trying to understand and modifying existing source code, rather than writing new source code. Unreadable code often leads to bugs, inefficiencies, and duplicated code. A study found that a few simple readability transformations made code shorter and drastically reduced the time to understand it.
Following a consistent programming style often helps readability. However, readability is more than just programming style. Many factors, having little or nothing to do with the ability of the computer to efficiently compile and execute the code, contribute to readability. Some of these factors include:

Different indent styles (whitespace)
Comments
Decomposition
Naming conventions for objects (such as variables, classes, procedures, etc.)The presentation aspects of this (such as indents, line breaks, color highlighting, and so on) are often handled by the source code editor, but the content aspects reflect the programmer's talent and skills.
Various visual programming languages have also been developed with the intent to resolve readability concerns by adopting non-traditional approaches to code structure and display. Integrated development environments (IDEs) aim to integrate all such help. Techniques like Code refactoring can enhance readability.


=== Algorithmic complexity ===
The academic field and the engineering practice of computer programming are both largely concerned with discovering and implementing the most efficient algorithms for a given class of problem. For this purpose, algorithms are classified into orders using so-called Big O notation, which expresses resource use, such as execution time or memory consumption, in terms of the size of an input. Expert programmers are familiar with a variety of well-established algorithms and their respective complexities and use this knowledge to choose algorithms that are best suited to the circumstances.


==== Chess algorithms as an example ====
""Programming a Computer for Playing Chess"" was a 1950 paper that evaluated a ""minimax"" algorithm that is part of the history of algorithmic complexity; a course on IBM's Deep Blue (chess computer) is part of the computer science curriculum at Stanford University.


=== Methodologies ===
The first step in most formal software development processes is requirements analysis, followed by testing to determine value modeling, implementation, and failure elimination (debugging). There exist a lot of differing approaches for each of those tasks. One approach popular for requirements analysis is Use Case analysis. Many programmers use forms of Agile software development where the various stages of formal software development are more integrated together into short cycles that take a few weeks rather than years. There are many approaches to the Software development process.
Popular modeling techniques include Object-Oriented Analysis and Design (OOAD) and Model-Driven Architecture (MDA). The Unified Modeling Language (UML) is a notation used for both the OOAD and MDA.
A similar technique used for database design is Entity-Relationship Modeling (ER Modeling).
Implementation techniques include imperative languages (object-oriented or procedural), functional languages, and logic languages.


=== Measuring language usage ===

It is very difficult to determine what are the most popular of modern programming languages. Methods of measuring programming language popularity include: counting the number of job advertisements that mention the language, the number of books sold and courses teaching the language (this overestimates the importance of newer languages), and estimates of the number of existing lines of code written in the language (this underestimates the number of users of business languages such as COBOL).
Some languages are very popular for particular kinds of applications, while some languages are regularly used to write many different kinds of applications. For example, COBOL is still strong in corporate data centers often on large mainframe computers, Fortran in engineering applications, scripting languages in Web development, and C in embedded software. Many applications use a mix of several languages in their construction and use.  New languages are generally designed around the syntax of a prior language with new functionality added, (for example C++ adds object-orientation to C, and Java adds memory management and bytecode to C++, but as a result, loses efficiency and the ability for low-level manipulation).


=== Debugging ===

Debugging is a very important task in the software development process since having defects in a program can have significant consequences for its users. Some languages are more prone to some kinds of faults because their specification does not require compilers to perform as much checking as other languages. Use of a static code analysis tool can help detect some possible problems. Normally the first step in debugging is to attempt to reproduce the problem. This can be a non-trivial task, for example as with parallel processes or some unusual software bugs. Also, specific user environment and usage history can make it difficult to reproduce the problem.
After the bug is reproduced, the input of the program may need to be simplified to make it easier to debug. For example, a bug in a compiler can make it crash when passing some large source file. However, after simplification of the test case, only few lines from the original source file can be sufficient to reproduce the same crash. Such simplification can be done manually, using a divide-and-conquer approach. The programmer will try to remove some parts of original test case and check if the problem still exists. When debugging the problem in a GUI, the programmer can try to skip some user interaction from the original problem description and check if remaining actions are sufficient for bugs to appear.
Debugging is often done with IDEs like Eclipse, Visual Studio, Xcode, Kdevelop, NetBeans and Code::Blocks. Standalone debuggers like GDB are also used, and these often provide less of a visual environment, usually using a command line. Some text editors such as Emacs allow GDB to be invoked through them, to provide a visual environment.


== Programming languages ==

Different programming languages support different styles of programming (called programming paradigms). The choice of language used is subject to many considerations, such as company policy, suitability to task, availability of third-party packages, or individual preference. Ideally, the programming language best suited for the task at hand will be selected. Trade-offs from this ideal involve finding enough programmers who know the language to build a team, the availability of compilers for that language, and the efficiency with which programs written in a given language execute. Languages form an approximate spectrum from ""low-level"" to ""high-level""; ""low-level"" languages are typically more machine-oriented and faster to execute, whereas ""high-level"" languages are more abstract and easier to use but execute less quickly. It is usually easier to code in ""high-level"" languages than in ""low-level"" ones.
Allen Downey, in his book How To Think Like A Computer Scientist, writes:

The details look different in different languages, but a few basic instructions appear in just about every language:
Input: Gather data from the keyboard, a file, or some other device.
Output: Display data on the screen or send data to a file or other device.
Arithmetic: Perform basic arithmetical operations like addition and multiplication.
Conditional Execution: Check for certain conditions and execute the appropriate sequence of statements.
Repetition: Perform some action repeatedly, usually with some variation.Many computer languages provide a mechanism to call functions provided by shared libraries. Provided the functions in a library follow the appropriate run-time conventions (e.g., method of passing arguments), then these functions may be written in any other language.


== Programmers ==

Computer programmers are those who write computer software. Their jobs usually involve:


== See also ==


== References ==


=== Sources ===
Ceruzzi, Paul E. (1998). History of Computing. Cambridge, Massachusetts: MIT Press. ISBN 9780262032551 – via EBSCOhost.CS1 maint: ref=harv (link)
Evans, Claire L. (2018). Broad Band: The Untold Story of the Women Who Made the Internet. New York: Portfolio/Penguin. ISBN 9780735211759.CS1 maint: ref=harv (link)
Gürer, Denise (1995). ""Pioneering Women in Computer Science"" (PDF). Communications of the ACM. 38 (1): 45–54. doi:10.1145/204865.204875. S2CID 6626310.CS1 maint: ref=harv (link)
Smith, Erika E. (2013). ""Recognizing a Collective Inheritance through the History of Women in Computing"". CLCWeb: Comparative Literature & Culture: A WWWeb Journal. 15 (1): 1–9 – via EBSCOhost.CS1 maint: ref=harv (link)


== Further reading ==
A.K. Hartmann, Practical Guide to Computer Simulations, Singapore: World Scientific (2009)
A. Hunt, D. Thomas, and W. Cunningham, The Pragmatic Programmer. From Journeyman to Master, Amsterdam: Addison-Wesley Longman (1999)
Brian W. Kernighan, The Practice of Programming, Pearson (1999)
Weinberg, Gerald M., The Psychology of Computer Programming, New York: Van Nostrand Reinhold (1971)
Edsger W. Dijkstra, A Discipline of Programming, Prentice-Hall (1976)
O.-J. Dahl, E.W.Dijkstra, C.A.R. Hoare, Structured Programming, Academic Press (1972)
David Gries, The Science of Programming, Springer-Verlag (1981)


== External links ==
 Media related to Computer programming at Wikimedia Commons
 Quotations related to Programming at Wikiquote
Software engineering at Curlie"
"A computer keyboard is a typewriter-style device which uses an arrangement of buttons or keys to act as mechanical levers or electronic switches. Following the decline of punch cards and paper tape, interaction via teleprinter-style keyboards became the main input method for computers.
Keyboard keys (buttons) typically have a set of characters engraved or printed on them, and each press of a key typically corresponds to a single written symbol. However, producing some symbols may require pressing and holding several keys simultaneously or in sequence. While most keyboard keys produce letters, numbers or signs (characters), other keys or simultaneous key presses can produce actions or execute computer commands.
In normal usage, the keyboard is used as a text entry interface for typing text, numbers, and symbols into a word processor, text editor or any other program. In a modern computer, the interpretation of key presses is generally left to the software. A computer keyboard distinguishes each physical key from every other key and reports all key presses to the controlling software.
A keyboard is also used to give commands to the operating system of a computer, such as Windows' Control-Alt-Delete combination. Although on Pre-Windows 95 Microsoft operating systems this forced a re-boot, now it brings up a system security options screen.A command-line interface is a type of user interface navigated entirely using a keyboard, or some other similar device that does the job of one.


== History ==
While typewriters are the definitive ancestor of all key-based text entry devices, the computer keyboard as a device for electromechanical data entry and communication derives largely from the utility of two devices: teleprinters (or teletypes) and keypunches. It was through such devices that modern computer keyboards inherited their layouts.
As early as the 1870s, teleprinter-like devices were used to simultaneously type and transmit stock market text data from the keyboard across telegraph lines to stock ticker machines to be immediately copied and displayed onto ticker tape. The teleprinter, in its more contemporary form, was developed from 1907 to 1910 by American mechanical engineer Charles Krum and his son Howard, with early contributions by electrical engineer Frank Pearne. Earlier models were developed separately by individuals such as Royal Earl House and Frederick G. Creed.
Earlier, Herman Hollerith developed the first keypunch devices, which soon evolved to include keys for text and number entry akin to normal typewriters by the 1930s.The keyboard on the teleprinter played a strong role in point-to-point and point-to-multipoint communication for most of the 20th century, while the keyboard on the keypunch device played a strong role in data entry and storage for just as long. The development of the earliest computers incorporated electric typewriter keyboards: the development of the ENIAC computer incorporated a keypunch device as both the input and paper-based output device, while the BINAC computer also made use of an electromechanically controlled typewriter for both data entry onto magnetic tape (instead of paper) and data output.The keyboard remained the primary, most integrated computer peripheral well into the era of personal computing until the introduction of the mouse as a consumer device in 1984. By this time, text-only user interfaces with sparse graphics gave way to comparatively graphics-rich icons on screen. However, keyboards remain central to human-computer interaction to the present, even as mobile personal computing devices such as smartphones and tablets adapt the keyboard as an optional virtual, touchscreen-based means of data entry.


== Types ==
There are different types of keyboards available right now and each of them is designed with a focus on specific features that suit special needs.One factor determining the size of a keyboard is the presence of duplicate keys, such as a separate numeric keyboard or two each of Shift, ALT and CTL  
for convenience.Further, the keyboard size depends on the extent to which a system is used where a single action is produced by a combination of subsequent or simultaneous keystrokes (with modifier keys), or multiple pressing of a single key. A keyboard with few keys is called a keypad.
Another factor determining the size of a keyboard is the size and spacing of the keys. The reduction is limited by the practical consideration that the keys must be large enough to be easily pressed by fingers. Alternatively, a tool is used for pressing small keys.


=== Standard ===

Standard alphanumeric keyboards have keys that are on three-quarter inch centers (0.750 inches, 19.05 mm), and have a key travel of at least 0.150 inches (3.81 mm). Desktop computer keyboards, such as the 101-key US traditional keyboards or the 104-key Windows keyboards, include alphabetic characters, punctuation symbols, numbers and a variety of function keys. The internationally common 102/104 key keyboards have a smaller left shift key and an additional key with some more symbols between that and the letter to its right (usually Z or Y). The enter key is usually shaped differently. Computer keyboards are similar to electric-typewriter keyboards but contain additional keys, such as the command or Windows keys. There is no standard computer keyboard, although many manufacturers imitate the keyboard of PCs. There are actually three different PC keyboards: the original PC keyboard with 84 keys, the AT keyboard also with 84 keys and the enhanced keyboard with 101 keys. The three differ somewhat in the placement of function keys, the control keys, the return key, and the shift key.


=== Laptop-size ===

Keyboards on laptops and notebook computers usually have a shorter travel distance for the keystroke, shorter over travel distance, and a reduced set of keys. They may not have a numeric keypad, and the function keys may be placed in locations that differ from their placement on a standard, full-sized keyboard. The switch mechanism for a laptop keyboard is more likely to be a scissor switch than a rubber dome; this is opposite the trend for full-size keyboards.


=== Flexible keyboards ===
Flexible keyboards are a junction between normal type and laptop type keyboards: normal from the full arrangement of keys, and laptop from the short key distance. Additionally, the flexibility allows the user to fold/roll the keyboard for better storage and transfer. However, for typing the keyboard must be resting on a hard surface. The vast majority of flexible keyboards in the market are made from silicone; this material makes them water- and dust-proof. This is useful in hospitals, where keyboards are subjected to frequent washing,
and other dirty or must-be-clean environments.


=== Handheld ===

Handheld ergonomic keyboards are designed to be held like a game controller, and can be used as such, instead of laid out flat on top of a table surface. 
Typically handheld keyboards hold all the alphanumeric keys and symbols that a standard keyboard would have, yet only be accessed by pressing two sets of keys at once; one acting as a function key similar to a 'Shift' key that would allow for capital letters on a standard keyboard. Handheld keyboards allow the user the ability to move around a room or to lean back on a chair while also being able to type in front or away from the computer. Some variations of handheld ergonomic keyboards also include a trackball mouse that allow mouse movement and typing included in one handheld device.


=== Thumb-sized ===
Smaller external keyboards have been introduced for devices without a built-in keyboard, such as PDAs, and smartphones. Small keyboards are also useful where there is a limited workspace.A thumb keyboard (thumb board) is used in some personal digital assistants such as the Palm Treo and BlackBerry and some Ultra-Mobile PCs such as the OQO.
Numeric keyboards contain only numbers, mathematical symbols for addition, subtraction, multiplication, and division, a decimal point, and several function keys. They are often used to facilitate data entry with smaller keyboards that do not have a numeric keypad, commonly those of laptop computers. These keys are collectively known as a numeric pad, numeric keys, or a numeric keypad, and it can consist of the following types of keys: Arithmetic operators, numbers, arrow keys, Navigation keys, Num Lock and Enter key.


=== Multifunctional ===

Multifunctional keyboards provide additional function beyond the standard keyboard. Many are programmable, configurable computer keyboards and some control multiple PCs, workstations (incl. SUN) and other information sources (incl. Thomson Reuters FXT/Eikon, Bloomberg, EBS, etc.) usually in multi-screen work environments. Users have additional key functions as well as the standard functions and can typically use a single keyboard and mouse to access multiple sources. 

Multifunctional keyboards may feature customised keypads, fully programmable function or soft keys for macros/pre-sets, biometric or smart card readers, trackballs, etc. New generation multifunctional keyboards feature a touchscreen display to stream video, control audio visual media and alarms, execute application inputs, configure individual desktop environments, etc. Multifunctional keyboards may also permit users to share access to PCs and other information sources. Multiple interfaces (serial, USB, audio, Ethernet, etc.) are used to integrate external devices. Some multifunctional keyboards are also used to directly and intuitively control video walls.
Common environments for multifunctional keyboards are complex, high-performance workplaces for financial traders and control room operators (emergency services, security, air traffic management; industry, utilities management, etc.).


== Non-standard layout and special-use types ==


=== Chorded ===

While other keyboards generally associate one action with each key, chorded keyboards associate actions with combinations of key presses. Since there are many combinations available, chorded keyboards can effectively produce more actions on a board with fewer keys. Court reporters' stenotype machines use chorded keyboards to enable them to enter text much faster by typing a syllable with each stroke instead of one letter at a time. The fastest typists (as of 2007) use a stenograph, a kind of chorded keyboard used by most court reporters and closed-caption reporters. Some chorded keyboards are also made for use in situations where fewer keys are preferable, such as on devices that can be used with only one hand, and on small mobile devices that don't have room for larger keyboards. Chorded keyboards are less desirable in many cases because it usually takes practice and memorization of the combinations to become proficient.


=== Software ===
Software keyboards or on-screen keyboards often take the form of computer programs that display an image of a keyboard on the screen. Another input device such as a mouse or a touchscreen can be used to operate each virtual key to enter text. Software keyboards have become very popular in touchscreen enabled cell phones, due to the additional cost and space requirements of other types of hardware keyboards. Microsoft Windows, Mac OS X, and some varieties of Linux include on-screen keyboards that can be controlled with the mouse. In software keyboards, the mouse has to be maneuvered onto the on-screen letters given by the software. On the click of a letter, the software writes the respective letter on the respective spot.


=== Projection ===
Projection keyboards project an image of keys, usually with a laser, onto a flat surface. The device then uses a camera or infrared sensor to ""watch"" where the user's fingers move, and will count a key as being pressed when it ""sees"" the user's finger touch the projected image. Projection keyboards can simulate a full size keyboard from a very small projector. Because the ""keys"" are simply projected images, they cannot be felt when pressed. Users of projected keyboards often experience increased discomfort in their fingertips because of the lack of ""give"" when typing. A flat, non-reflective surface is also required for the keys to be projected. Most projection keyboards are made for use with PDAs and smartphones due to their small form factor.


=== Optical keyboard technology ===

Also known as photo-optical keyboard, light responsive keyboard, photo-electric keyboard and optical key actuation detection technology.
An optical keyboard technology utilizes LEDs and photo sensors to optically detect actuated keys. Most commonly the emitters and sensors are located in the perimeter, mounted on a small PCB. The light is directed from side to side of the keyboard interior and it can only be blocked by the actuated keys. Most optical keyboards require at least 2 beams (most commonly vertical beam and horizontal beam) to determine the actuated key. Some optical keyboards use a special key structure that blocks the light in a certain pattern, allowing only one beam per row of keys (most commonly horizontal beam).


== Layout ==


=== Alphabetic ===

There are a number of different arrangements of alphabetic, numeric, and punctuation symbols on keys. These different keyboard layouts arise mainly because different people need easy access to different symbols, either because they are inputting text in different languages, or because they need a specialized layout for mathematics, accounting, computer programming, or other purposes. The United States keyboard layout is used as default in the currently most popular operating systems: Windows, Mac OS X and Linux. The common QWERTY-based layout was designed early in the era of mechanical typewriters, so its ergonomics were compromised to allow for the mechanical limitations of the typewriter.
As the letter-keys were attached to levers that needed to move freely, inventor Christopher Sholes developed the QWERTY layout to reduce the likelihood of jamming. With the advent of computers, lever jams are no longer an issue, but nevertheless, QWERTY layouts were adopted for electronic keyboards because they were widely used. Alternative layouts such as Dvorak are not in widespread use.
The QWERTZ layout is widely used in Germany and much of Central Europe. The main difference between it and QWERTY is that Y and Z are swapped, and most special characters such as brackets are replaced by diacritical characters.
Another situation takes place with ""national"" layouts. Keyboards designed for typing in Spanish have some characters shifted, to release the space for Ñ ñ; similarly, those for Portuguese, French and other European languages may have a special key for the character Ç ç. The AZERTY layout is used in France, Belgium and some neighbouring countries. It differs from the QWERTY layout in that the A and Q are swapped, the Z and W are swapped, and the M is moved from the right of N to the right of L (where colon/semicolon is on a US keyboard). The digits 0 to 9 are on the same keys, but to be typed the shift key must be pressed. The unshifted positions are used for accented characters.
In bilingual regions of Canada and in the French-speaking province of Québec, keyboards can often be switched between an English and a French-language keyboard; while both keyboards share the same QWERTY alphabetic layout, the French-language keyboard enables the user to type accented vowels such as ""é"" or ""à"" with a single keystroke. Using keyboards for other languages leads to a conflict: the image on the key does not correspond to the character. In such cases, each new language may require an additional label on the keys, because the standard keyboard layouts do not share even similar characters of different languages (see the example in the figure above).
Keyboards in many parts of Asia may have special keys to switch between the Latin character set and a completely different typing system. Japanese layout keyboards can be switched between various Japanese input methods and the Latin alphabet by signaling the operating system's input interpreter of the change, and some operating systems (namely the Windows family) interpret the character ""\"" as ""¥"" for display purposes without changing the bytecode which has led some keyboard makers to mark ""\"" as ""¥"" or both.
Keyboards for other alphabets supported include:

Arabic keyboard – In the Arab world, keyboards can often be switched between Arabic and Latin characters.
Russian keyboard, which uses Cyrillic script
Hebrew keyboard
In Microsoft word, ALT+Shift allows shifting between languages.


=== Key types ===


==== Alphanumeric ====

Alphabetical, numeric, and punctuation keys are used in the same fashion as a typewriter keyboard to enter their respective symbol into a word processing program, text editor, data spreadsheet, or other program. Many of these keys will produce different symbols when modifier keys or shift keys are pressed. The alphabetic characters become uppercase when the shift key or Caps Lock key is depressed. The numeric characters become symbols or punctuation marks when the shift key is depressed. The alphabetical, numeric, and punctuation keys can also have other functions when they are pressed at the same time as some modifier keys.
The Space bar is a horizontal bar in the lowermost row, which is significantly wider than other keys. Like the alphanumeric characters, it is also descended from the mechanical typewriter. Its main purpose is to enter the space between words during typing. It is large enough so that a thumb from either hand can use it easily. Depending on the operating system, when the space bar is used with a modifier key such as the control key, it may have functions such as resizing or closing the current window, half-spacing, or backspacing. In computer games and other applications the key has myriad uses in addition to its normal purpose in typing, such as jumping and adding marks to check boxes. In certain programs for playback of digital video, the space bar is used for pausing and resuming the playback.


==== Modifier keys ====
Modifier keys are special keys that modify the normal action of another key, when the two are pressed in combination. For example, Alt+F4 in Microsoft Windows will close the program in an active window. In contrast, pressing just F4 will probably do nothing, unless assigned a specific function in a particular program. By themselves, modifier keys usually do nothing.
The most widely used modifier keys include the Control key, Shift key and the Alt key. The AltGr key is used to access additional symbols for keys that have three symbols printed on them. On the Macintosh and Apple keyboards, the modifier keys are the Option key and Command key, respectively. On Sun Microsystems and Lisp machine keyboards, the Meta key is used as a modifier and for Windows keyboards, there is a Windows key. Compact keyboard layouts often use a Fn key. ""Dead keys"" allow placement of a diacritic mark, such as an accent, on the following letter (e.g., the Compose key).
The Enter/Return key typically causes a command line, window form or dialog box to operate its default function, which is typically to finish an ""entry"" and begin the desired process. In word processing applications, pressing the enter key ends a paragraph and starts a new one.


==== Cursor keys ====
Navigation keys or cursor keys include a variety of keys which move the cursor to different positions on the screen. Arrow keys are programmed to move the cursor in a specified direction; page scroll keys, such as the Page Up and Page Down keys, scroll the page up and down. The Home key is used to return the cursor to the beginning of the line where the cursor is located; the End key puts the cursor at the end of the line. The Tab key advances the cursor to the next tab stop.
The Insert key is mainly used to switch between overtype mode, in which the cursor overwrites any text that is present on and after its current location, and insert mode, where the cursor inserts a character at its current position, forcing all characters past it one position further. The Delete key discards the character ahead of the cursor's position, moving all following characters one position ""back"" towards the freed place. On many notebook computer keyboards the key labeled Delete (sometimes Delete and Backspace are printed on the same key) serves the same purpose as a Backspace key. The Backspace key deletes the preceding character.
Lock keys lock part of a keyboard, depending on the settings selected. The lock keys are scattered around the keyboard. Most styles of keyboards have three LEDs indicating which locks are enabled, in the upper right corner above the numeric pad. The lock keys include Scroll lock, Num lock (which allows the use of the numeric keypad), and Caps lock.


==== System commands ====

The SysRq and Print screen commands often share the same key. SysRq was used in earlier computers as a ""panic"" button to recover from crashes (and it is still used in this sense to some extent by the Linux kernel; see Magic SysRq key). The Print screen command used to capture the entire screen and send it to the printer, but in the present it usually puts a screenshot in the clipboard.


===== Break key =====
The Break key/Pause key no longer has a well-defined purpose. Its origins go back to teleprinter users, who wanted a key that would temporarily interrupt the communications line. The Break key can be used by software in several different ways, such as to switch between multiple login sessions, to terminate a program, or to interrupt a modem connection.
In programming, especially old DOS-style BASIC, Pascal and C, Break is used (in conjunction with Ctrl) to stop program execution. In addition to this, Linux and variants, as well as many DOS programs, treat this combination the same as Ctrl+C. On modern keyboards, the break key is usually labeled Pause/Break. In most Windows environments, the key combination Windows key+Pause brings up the system properties.


===== Escape key =====
 
The escape key (often abbreviated Esc) ""nearly all of the time"" signals Stop - QUIT - let me ""get out of a dialog"" (or pop-up window): LET ME ESCAPE.
Another common application today of the Esc key is to trigger the Stop button in many web browsers.


====== ESC origins ======
ESC was part of the standard keyboard of the Teletype Model 33 (introduced in 1964 and used with many early minicomputers). The DEC VT50, introduced July 1974, also had an Esc key. The TECO text editor (ca 1963) and its descendant Emacs (ca 1985) use the Esc key extensively.
Historically it also served as a type of shift key, such that one or more following characters were interpreted differently, hence the term escape sequence, which refers to a series of characters, usually preceded by the escape character.On machines running Microsoft Windows, prior to the implementation of the Windows key on keyboards, the typical practice for invoking the ""start"" button was to hold down the control key and press escape. This process still works in Windows 95, 98, Me, NT 4, 2000, XP, Vista, 7, 8, and 10.


===== Enter key =====
The Enter key is located: One in the alphanumeric keys and the other one is in the numeric keys. When one worked something on their computer and wanted to do something with their work, pressing the enter key would do the command they ordered. Another function is to create a space for next paragraph. When one typed and finished typing a paragraph and they wanted to have a second paragraph, they could press enter and it would do spacing.


===== Shift key =====
Shift key: when one presses shift and a letter, it will capitalize the letter pressed with the shift key. Another use is to type more symbols than appear to be available, for instance the apostrophe key is accompanied with a quotation mark on the top. If one wants to type the quotation mark but pressed that key alone, the symbol that would appear would be the apostrophe. The quotation mark will only appear if both the required key and the Shift key are pressed.


===== Menu key =====
The Menu key or Application key is a key found on Windows-oriented computer keyboards. It is used to launch a context menu with the keyboard rather than with the usual right mouse button. The key's symbol is usually a small icon depicting a cursor hovering above a menu. On some Samsung keyboards the cursor in the icon is not present, showing the menu only.  This key was created at the same time as the Windows key. This key is normally used when the right mouse button is not present on the mouse. Some Windows public terminals do not have a Menu key on their keyboard to prevent users from right-clicking (however, in many Windows applications, a similar functionality can be invoked with the Shift+F10 keyboard shortcut).


==== Miscellaneous ====

Many, but not all, computer keyboards have a numeric keypad to the right of the alphabetic keyboard, often separated from the other groups of keys such as the function keys and system command keys, which contains numbers, basic mathematical symbols (e.g., addition, subtraction, etc.), and a few function keys. On Japanese/Korean keyboards, there may be Language input keys for changing the language to use. Some keyboards have power management keys (e.g., power key, sleep key and wake key); Internet keys to access a web browser or E-mail; and/or multimedia keys, such as volume controls; or keys that can be programmed by the user to launch a specified application or a command like minimizing all windows.


=== Numeric keys ===
When we calculate, we use these numeric keys to type numbers. Symbols concerned with calculations such as addition, subtraction, multiplication and division symbols are located in this group of keys. The enter key in this keys indicate the equal sign.


==== Multiple layouts ====
It is possible to install multiple keyboard layouts within an operating system and switch between them, either through features implemented within the OS, or through an external application. Microsoft Windows, Linux, and Mac provide support to add keyboard layouts and choose from them.


==== Layout changing software ====
The character code produced by any key press is determined by the keyboard driver software. A key press generates a scancode which is interpreted as an alphanumeric character or control function. Depending on operating systems, various application programs are available to create, add and switch among keyboard layouts. Many programs are available, some of which are language specific.
The arrangement of symbols of specific language can be customized. An existing keyboard layout can be edited, and a new layout can be created using this type of software.
For example, Ukelele [sic] for Mac, The Microsoft Keyboard Layout Creator and open-source Avro Keyboard for Windows provide the ability to customize the keyboard layout as desired.


== Illumination ==
Keyboards and keypads may be illuminated from inside, especially on equipment for mobile use. Both keyboards built into computers and external ones may support backlighting; external backlit keyboards may have a wired USB connection, or be connected wirelessly and powered by batteries. Illumination facilitates the use of the keyboard or keypad in dark environments. 
For general productivity, only the keys may be uniformly backlit, without distracting light around the keys. 

Many gaming keyboards are designed to have an aesthetic as well as functional appeal, with multiple colours, and colour-coded keys to make it easier for gamers to find command keys while playing in a dark room. Many keyboards not otherwise illuminated may have small LED indicator lights in a few important function keys, or elsewhere on the housing, if their function is activated (see photo).


== Technology ==


=== Key switches ===
In the first electronic keyboards in the early 1970s, the key switches were individual switches inserted into holes in metal frames. These keyboards cost from 80 to 120 USD and were used in mainframe data terminals. The most popular switch types were reed switches (contacts enclosed in a vacuum in a glass capsule, affected by a magnet mounted on the switch plunger).In the mid-1970s, lower-cost direct-contact key switches were introduced, but their life in switch cycles was much shorter (rated ten million cycles) because they were open to the environment. This became more acceptable, however, for use in computer terminals at the time, which began to see increasingly shorter model lifespans as they advanced.In 1978, Key Tronic Corporation introduced keyboards with capacitive-based switches, one of the first keyboard technologies not to use self-contained switches. There was simply a sponge pad with a conductive-coated Mylar plastic sheet on the switch plunger, and two half-moon trace patterns on the printed circuit board below. As the key was depressed, the capacitance between the plunger pad and the patterns on the PCB below changed, which was detected by integrated circuits (IC). These keyboards were claimed to have the same reliability as the other ""solid-state switch"" keyboards such as inductive and Hall-effect, but competitive with direct-contact keyboards. Prices of $60 for keyboards were achieved, and Key Tronic rapidly became the largest independent keyboard manufacturer.
Meanwhile, IBM made their own keyboards, using their own patented technology: Keys on older IBM keyboards were made with a ""buckling spring"" mechanism, in which a coil spring under the key buckles under pressure from the user's finger, triggering a hammer that presses two plastic sheets (membranes) with conductive traces together, completing a circuit. This produces a clicking sound and gives physical feedback for the typist, indicating that the key has been depressed.The first electronic keyboards had a typewriter key travel distance of 0.187 inches (4.75 mm), keytops were a half-inch (12.7 mm) high, and keyboards were about two inches (5 cm) thick. Over time, less key travel was accepted in the market, finally landing on 0.110 inches (2.79 mm). Coincident with this, Key Tronic was the first company to introduce a keyboard that was only about one inch thick. And now keyboards measure only about a half-inch thick.
Keytops are an important element of keyboards. In the beginning, keyboard keytops had a ""dish shape"" on top, like typewriters before them. Keyboard key legends must be extremely durable over tens of millions of depressions, since they are subjected to extreme mechanical wear from fingers and fingernails, and subject to hand oils and creams, so engraving and filling key legends with paint, as was done previously for individual switches, was never acceptable. So, for the first electronic keyboards, the key legends were produced by two-shot (or double-shot, or two-color) molding, where either the key shell or the inside of the key with the key legend was molded first, and then the other color molded second. But, to save cost, other methods were explored, such as sublimation printing and laser engraving, both methods which could be used to print a whole keyboard at the same time.
Initially, sublimation printing, where a special ink is printed onto the keycap surface and the application of heat causes the ink molecules to penetrate and commingle with the plastic modules, had a problem because finger oils caused the molecules to disperse, but then a necessarily very hard clear coating was applied to prevent this. Coincident with sublimation printing, which was first used in high volume by IBM on their keyboards, was the introduction by IBM of single-curved-dish keycaps to facilitate quality printing of key legends by having a consistently curved surface instead of a dish. But one problem with sublimation or laser printing was that the processes took too long and only dark legends could be printed on light-colored keys. On another note, IBM was unique in using separate shells, or ""keycaps"", on keytop bases. This might have made their manufacturing of different keyboard layouts more flexible, but the reason for doing this was that the plastic material that needed to be used for sublimation printing was different from standard ABS keytop plastic material.
Three final mechanical technologies brought keyboards to where they are today, driving the cost well under $10:

""Monoblock"" keyboard designs were developed where individual switch housings were eliminated and a one-piece ""monoblock"" housing used instead. This was possible because of molding techniques that could provide very tight tolerances for the switch-plunger holes and guides across the width of the keyboard so that the key plunger-to-housing clearances were not too tight or too loose, either of which could cause the keys to bind.
The use of contact-switch membrane sheets under the monoblock. This technology came from flat-panel switch membranes, where the switch contacts are printed inside of a top and bottom layer, with a spacer layer in between, so that when pressure is applied to the area above, a direct electrical contact is made.  The membrane layers can be printed by very-high volume, low-cost ""reel-to-reel"" printing machines, with each keyboard membrane cut and punched out afterwards.Plastic materials played a very important part in the development and progress of electronic keyboards. Until ""monoblocks"" came along, GE's ""self-lubricating"" Delrin was the only plastic material for keyboard switch plungers that could withstand the beating over tens of millions of cycles of lifetime use. Greasing or oiling switch plungers was undesirable because it would attract dirt over time which would eventually affect the feel and even bind the key switches (although keyboard manufacturers would sometimes sneak this into their keyboards, especially if they could not control the tolerances of the key plungers and housings well enough to have a smooth key depression feel or prevent binding). But Delrin was only available in black and white, and was not suitable for keytops (too soft), so keytops use ABS plastic.  However, as plastic molding advanced in maintaining tight tolerances, and as key travel length reduced from 0.187-inch to 0.110-inch (4.75 mm to 2.79 mm), single-part keytop/plungers could be made of ABS, with the keyboard monoblocks also made of ABS.
In common use, the term ""mechanical keyboard"" refers to a keyboard with individual mechanical key switches, each of which contains a fully encased plunger with a spring below it and metallic electrical contacts on a side. The plunger sits on the spring and the key will often close the contacts when the plunger is pressed half-way. Other switches require the plunger to be fully pressed down. The depth at which the plunger must be pressed for the contacts to close is known as the activation distance. Analog keyboards with key switches whose activation distance can be reconfigured through software, optical switches that work by blocking laser beams, and Hall Effect keyboards that use key switches that use a magnet to activate a hall sensor, are also available.


=== Control processor ===

Computer keyboards include control circuitry to convert key presses into key codes (usually scancodes) that the computer's electronics can understand. The key switches are connected via the printed circuit board in an electrical X-Y matrix where a voltage is provided sequentially to the Y lines and, when a key is depressed, detected sequentially by scanning the X lines.
The first computer keyboards were for mainframe computer data terminals and used discrete electronic parts. The first keyboard microprocessor was introduced in 1972 by General Instruments, but keyboards have been using the single-chip 8048 microcontroller variant since it became available in 1978. The keyboard switch matrix is wired to its inputs, it converts the keystrokes to key codes, and, for a detached keyboard, sends the codes down a serial cable (the keyboard cord) to the main processor on the computer motherboard. This serial keyboard cable communication is only bi-directional to the extent that the computer's electronics controls the illumination of the caps lock, num lock and scroll lock lights.
One test for whether the computer has crashed is pressing the caps lock key. The keyboard sends the key code to the keyboard driver running in the main computer; if the main computer is operating, it commands the light to turn on. All the other indicator lights work in a similar way. The keyboard driver also tracks the Shift, alt and control state of the keyboard.
Some lower-quality keyboards have multiple or false key entries due to inadequate electrical designs.  These are caused by inadequate keyswitch ""debouncing"" or inadequate keyswitch matrix layout that don't allow multiple keys to be depressed at the same time, both circumstances which are explained below:
When pressing a keyboard key, the key contacts may ""bounce"" against each other for several milliseconds before they settle into firm contact. When released, they bounce some more until they revert to the uncontacted state. If the computer were watching for each pulse, it would see many keystrokes for what the user thought was just one. To resolve this problem, the processor in a keyboard (or computer) ""debounces"" the keystrokes, by aggregating them across time to produce one ""confirmed"" keystroke.
Some low-quality keyboards also suffer problems with rollover (that is, when multiple keys pressed at the same time, or when keys are pressed so fast that multiple keys are down within the same milliseconds). Early ""solid-state"" keyswitch keyboards did not have this problem because the keyswitches are electrically isolated from each other, and early ""direct-contact"" keyswitch keyboards avoided this problem by having isolation diodes for every keyswitch. These early keyboards had ""n-key"" rollover, which means any number of keys can be depressed and the keyboard will still recognize the next key depressed. But when three keys are pressed (electrically closed) at the same time in a ""direct contact"" keyswitch matrix that doesn't have isolation diodes, the keyboard electronics can see a fourth ""phantom"" key which is the intersection of the X and Y lines of the three keys. Some types of keyboard circuitry will register a maximum number of keys at one time. ""Three-key"" rollover, also called ""phantom key blocking"" or ""phantom key lockout"", will only register three keys and ignore all others until one of the three keys is lifted. This is undesirable, especially for fast typing (hitting new keys before the fingers can release previous keys), and games (designed for multiple key presses).
As direct-contact membrane keyboards became popular, the available rollover of keys was optimized by analyzing the most common key sequences and placing these keys so that they do not potentially produce phantom keys in the electrical key matrix (for example, simply placing three or four keys that might be depressed simultaneously on the same X or same Y line, so that a phantom key intersection/short cannot happen), so that blocking a third key usually isn't a problem. But lower-quality keyboard designs and unknowledgeable engineers may not know these tricks, and it can still be a problem in games due to wildly different or configurable layouts in different games.


=== Connection types ===
There are several ways of connecting a keyboard to a system unit (more precisely, to its keyboard controller) using cables, including the standard AT connector commonly found on motherboards, which was eventually replaced by the PS/2 and the USB connection. Prior to the iMac line of systems, Apple used the proprietary Apple Desktop Bus for its keyboard connector.
Wireless keyboards have become popular. A wireless keyboard must have a transmitter built in, and a receiver connected to the computer's keyboard port; it communicates either by radio frequency (RF) or infrared (IR) signals. A wireless keyboard may use industry standard Bluetooth radio communication,  in which case the receiver may be built into the computer. Wireless keyboards need batteries for power, and may be at risk of data eavesdropping. Wireless solar keyboards charge their batteries from small solar panels using natural or artificial light. The 1984 Apricot Portable is an early example of an IR keyboard.


== Alternative text-entering methods ==

Optical character recognition (OCR) is preferable to rekeying for converting existing text that is already written down but not in machine-readable format (for example, a Linotype-composed book from the 1940s). In other words, to convert the text from an image to editable text (that is, a string of character codes), a person could re-type it, or a computer could look at the image and deduce what each character is. OCR technology has already reached an impressive state (for example, Google Book Search) and promises more for the future.
Speech recognition converts speech into machine-readable text (that is, a string of character codes). This technology has also reached an advanced state and is implemented in various software products. For certain uses (e.g., transcription of medical or legal dictation; journalism; writing essays or novels) speech recognition is starting to replace the keyboard.  However, the lack of privacy when issuing voice commands and dictation makes this kind of input unsuitable for many environments.
Pointing devices can be used to enter text or characters in contexts where using a physical keyboard would be inappropriate or impossible. These accessories typically present characters on a display, in a layout that provides fast access to the more frequently used characters or character combinations. Popular examples of this kind of input are Graffiti, Dasher and on-screen virtual keyboards.


== Other issues ==


=== Keystroke logging ===
Unencrypted wireless Bluetooth keyboards are known to be vulnerable to signal theft by placing a covert listening device in the same room as the keyboard to sniff and record Bluetooth packets for the purpose of logging keys typed by the user. Microsoft wireless keyboards 2011 and earlier are documented to have this vulnerability.Keystroke logging (often called keylogging) is a method of capturing and recording user keystrokes. While it is used legally to measure employee productivity on certain clerical tasks, or by law enforcement agencies to find out about illegal activities, it is also used by hackers for various illegal or malicious acts. Hackers use keyloggers as a means to obtain passwords or encryption keys and thus bypass other security measures.
Keystroke logging can be achieved by both hardware and software means. Hardware key loggers are attached to the keyboard cable or installed inside standard keyboards. Software keyloggers work on the target computer's operating system and gain unauthorized access to the hardware, hook into the keyboard with functions provided by the OS, or use remote access software to transmit recorded data out of the target computer to a remote location. Some hackers also use wireless keylogger sniffers to collect packets of data being transferred from a wireless keyboard and its receiver, and then they crack the encryption key being used to secure wireless communications between the two devices.
Anti-spyware applications are able to detect many keyloggers and cleanse them. Responsible vendors of monitoring software support detection by anti-spyware programs, thus preventing abuse of the software. Enabling a firewall does not stop keyloggers per se, but can possibly prevent transmission of the logged material over the net if properly configured. Network monitors (also known as reverse-firewalls) can be used to alert the user whenever an application attempts to make a network connection. This gives the user the chance to prevent the keylogger from ""phoning home"" with his or her typed information. Automatic form-filling programs can prevent keylogging entirely by not using the keyboard at all. Most keyloggers can be fooled by alternating between typing the login credentials and typing characters somewhere else in the focus window.Keyboards are also known to emit electromagnetic signatures that can be detected using special spying equipment to reconstruct the keys pressed on the keyboard. Neal O'Farrell, executive director of the Identity Theft Council, revealed to InformationWeek that ""More than 25 years ago, a couple of former spooks showed me how they could capture a user's ATM PIN, from a van parked across the street, simply by capturing and decoding the electromagnetic signals generated by every keystroke,"" O'Farrell said. ""They could even capture keystrokes from computers in nearby offices, but the technology wasn't sophisticated enough to focus in on any specific computer.""


=== Physical injury ===

The use of any keyboard may cause serious injury (that is, carpal tunnel syndrome or other repetitive strain injury) to hands, wrists, arms, neck or back. The risks of injuries can be reduced by taking frequent short breaks to get up and walk around a couple of times every hour. As well, users should vary tasks throughout the day, to avoid overuse of the hands and wrists. When inputting at the keyboard, a person should keep the shoulders relaxed with the elbows at the side, with the keyboard and mouse positioned so that reaching is not necessary. The chair height and keyboard tray should be adjusted so that the wrists are straight, and the wrists should not be rested on sharp table edges. Wrist or palm rests should not be used while typing.Some adaptive technology ranging from special keyboards, mouse replacements and pen tablet interfaces to speech recognition software can reduce the risk of injury. Pause software reminds the user to pause frequently. Switching to a much more ergonomic mouse, such as a vertical mouse or joystick mouse may provide relief.
By using a touchpad or a stylus pen with a graphic tablet, in place of a mouse, one can lessen the repetitive strain on the arms and hands.


== See also ==
Digital pen
IBM PC keyboard
Keyboard protector
Overlay keyboard
Table of keyboard shortcuts
Dvorak
Maltron


== References ==


== External links ==
How Computer Keyboards Work at HowStuffWorks
""Art of Assembly Language: Chapter Twenty"": The PC Keyboard
Keyboard matrix circuits
PC World. ""The 10 worst PC Keyboards of All Time""."
"Computing is any activity that uses computers to manage, process, and communicate information. It includes development of both  hardware and software. Computing has become a critical, integral component of modern industrial technology. Major computing disciplines include computer engineering, computer science, cybersecurity, data science, information systems, information technology and software engineering.


== Definitions ==
The ACM Computing Curricula 2005 and 2020 defined ""computing"" as follows:

""In a general way, we can define computing to mean any goal-oriented activity requiring, benefiting from, or creating computers. Thus, computing includes designing and building hardware and software systems for a wide range of purposes; processing, structuring, and managing various kinds of information; doing scientific studies using computers; making computer systems behave intelligently; creating and using communications and entertainment media; finding and gathering information relevant to any particular purpose, and so on. The list is virtually endless, and the possibilities are vast.""
ACM also defines seven sub-disciplines of the computing field:
Computer engineering.
Computer science.
Cybersecurity.
Data science.
Information systems.
Information technology.
Software engineering.However, Computing Curricula 2005 also recognizes that the meaning of ""computing"" depends on the context:

Computing also has other meanings that are more specific, based on the context in which the term is used. For example, an information systems specialist will view computing somewhat differently from a software engineer. Regardless of the context, doing computing well can be complicated and difficult. Because society needs people to do computing well, we must think of computing not only as a profession but also as a discipline.
The term ""computing"" has sometimes been narrowly defined, as in a 1989 ACM report on Computing as a Discipline:
The discipline of computing is the systematic study of algorithmic processes that describe and transform information: their theory, analysis, design, efficiency, implementation, and application. The fundamental question underlying all computing is ""What can be (efficiently) automated?"" 
The term ""computing"" is also synonymous with counting and calculating. In earlier times, it was used in reference to the action performed by mechanical computing machines, and before that, to human computers.


== History ==

The history of computing is longer than the history of computing hardware and modern computing technology and includes the history of methods intended for pen and paper or for chalk and slate, with or without the aid of tables.
Computing is intimately tied to the representation of numbers. But long before abstractions like the number arose, there were mathematical concepts to serve the purposes of civilization. These concepts include one-to-one correspondence (the basis of counting), comparison to a standard (used for measurement), and the 3-4-5 right triangle (a device for assuring a right angle).
The earliest known tool for use in computation was the abacus, and it was thought to have been invented in Babylon circa 2400 BC. Its original style of usage was by lines drawn in sand with pebbles. Abaci, of a more modern design, are still used as calculation tools today. This was the first known calculation aid – preceding Greek methods by 2,000 years.
The first recorded idea of using digital electronics for computing was the 1931 paper ""The Use of Thyratrons for High Speed Automatic Counting of Physical Phenomena"" by C. E. Wynn-Williams. Claude Shannon's 1938 paper ""A Symbolic Analysis of Relay and Switching Circuits"" then introduced the idea of using electronics for Boolean algebraic operations.
The concept of a field-effect transistor was proposed by Julius Edgar Lilienfeld in 1925. John Bardeen and Walter Brattain, while working under William Shockley at Bell Labs, built the first working transistor, the point-contact transistor, in 1947. In 1953, the University of Manchester built the first transistorized computer, called the Transistor Computer. However, early junction transistors were relatively bulky devices that were difficult to manufacture on a mass-production basis, which limited them to a number of specialised applications. The metal–oxide–silicon field-effect transistor (MOSFET, or MOS transistor) was invented by Mohamed Atalla and Dawon Kahng at Bell Labs in 1959. It was the first truly compact transistor that could be miniaturised and mass-produced for a wide range of uses. The MOSFET made it possible to build high-density integrated circuit chips, leading to what is known as the computer revolution or microcomputer revolution.


== Computer ==

A computer is a machine that manipulates data according to a set of instructions called a computer program. The program has an executable form that the computer can use directly to execute the instructions. The same program in its human-readable source code form, enables a programmer to study and develop a sequence of steps known as an algorithm. Because the instructions can be carried out in different types of computers, a single set of source instructions converts to machine instructions according to the CPU type.
The execution process carries out the instructions in a computer program. Instructions express the computations performed by the computer. They trigger sequences of simple actions on the executing machine. Those actions produce effects according to the semantics of the instructions.


=== Computer software and hardware ===
Computer software, or just ""software"", is a collection of computer programs and related data that provides the instructions for telling a computer what to do and how to do it. Software refers to one or more computer programs and data held in the storage of the computer for some purposes. In other words, software is a set of programs, procedures, algorithms and its documentation concerned with the operation of a data processing system. Program software performs the function of the program it implements, either by directly providing instructions to the computer hardware or by serving as input to another piece of software. The term was coined to contrast with the old term hardware (meaning physical devices). In contrast to hardware, software is intangible. Software is also sometimes used in a more narrow sense, meaning application software only.


==== Application software ====

Application software, also known as an ""application"" or an ""app"", is a computer software designed to help the user to perform specific tasks. Examples include enterprise software, accounting software, office suites, graphics software and media players. Many application programs deal principally with documents. Apps may be bundled with the computer and its system software, or may be published separately. Some users are satisfied with the bundled apps and need never install additional applications.
Application software is contrasted with system software and middleware, which manage and integrate a computer's capabilities, but typically do not directly apply them in the performance of tasks that benefit the user. The system software serves the application, which in turn serves the user.
Application software applies the power of a particular computing platform or system software to a particular purpose. Some apps such as Microsoft Office are available in versions for several different platforms; others have narrower requirements and are thus called, for example, a Geography application for Windows or an Android application for education or Linux gaming. Sometimes a new and popular application arises that only runs on one platform, increasing the desirability of that platform. This is called a killer application.


==== System software ====

System software, or systems software, is computer software designed to operate and control the computer hardware, and to provide a platform for running application software. System software includes operating systems, utility software, device drivers, window systems, and firmware. Frequently used development tools such as compilers, linkers, and debuggers are classified as system software.


=== Computer network ===

A computer network, often simply referred to as a network, is a collection of hardware components and computers interconnected by communication channels that allow sharing of resources and information. Where at least one process in one device is able to send/receive data to/from at least one process residing in a remote device, then the two devices are said to be in a network.
Networks may be classified according to a wide variety of characteristics such as the medium used to transport the data, communications protocol used, scale, topology, and organizational scope.
Communications protocols define the rules and data formats for exchanging information in a computer network, and provide the basis for network programming. Well-known communications protocols include Ethernet, a hardware and Link Layer standard that is ubiquitous in local area networks, and the Internet Protocol Suite, which defines a set of protocols for internetworking, i.e. for data communication between multiple networks, as well as host-to-host data transfer, and application-specific data transmission formats.
Computer networking is sometimes considered a sub-discipline of electrical engineering, telecommunications, computer science, information technology or computer engineering, since it relies upon the theoretical and practical application of these disciplines.


==== Internet ====

The Internet is a global system of interconnected computer networks that use the standard Internet protocol suite (TCP/IP) to serve billions of users that consists of millions of private, public, academic, business, and government networks, of local to global scope, that are linked by a broad array of electronic, wireless and optical networking technologies. The Internet carries an extensive range of information resources and services, such as the inter-linked hypertext documents of the World Wide Web and the infrastructure to support email.


=== Computer programming ===

Computer programming in general is the process of writing, testing, debugging, and maintaining the source code and documentation of computer programs. This source code is written in a programming language, which is an artificial language often more restrictive or demanding than natural languages, but easily translated by the computer. The purpose of programming is to invoke the desired behavior (customization) from the machine. The process of writing high quality source code requires knowledge of both the application's domain  and the computer science domain. The highest-quality software is thus developed by a team of various domain experts, each person a specialist in some area of development. But the term programmer may apply to a range of program quality, from hacker to open source contributor to professional. And a single programmer could do most or all of the computer programming needed to generate the proof of concept to launch a new ""killer"" application.


==== Computer programmer ====

A programmer, computer programmer, or coder is a person who writes computer software. The term computer programmer can refer to a specialist in one area of computer programming or to a generalist who writes code for many kinds of software. One who practices or professes a formal approach to programming may also be known as a programmer analyst. A programmer's primary computer language (C, C++, Java, Lisp, Python, etc.) is often prefixed to the above titles, and those who work in a web environment often prefix their titles with web. The term programmer can be used to refer to a software developer, software engineer, computer scientist, or software analyst. However, members of these professions typically possess other software engineering skills, beyond programming.


=== Computer industry ===

The computer industry is made up of all of the businesses involved in developing computer software, designing computer hardware and computer networking infrastructures, the manufacture of computer components and the provision of information technology services including system administration and maintenance.


==== Software industry ====

The software industry includes businesses engaged in development, maintenance and publication of software. The industry also includes software services, such as training, documentation, and consulting.


== Sub-disciplines of computing ==


=== Computer engineering ===

Computer engineering is a discipline that integrates several fields of electrical engineering and computer science required to develop computer hardware and software. Computer engineers usually have training in electronic engineering (or electrical engineering), software design, and hardware-software integration instead of only software engineering or electronic engineering. Computer engineers are involved in many hardware and software aspects of computing, from the design of individual microprocessors, personal computers, and supercomputers, to circuit design. This field of engineering not only focuses on the design of hardware within its own domain, but as well the interactions between hardware and the world around it.


=== Software engineering ===

Software engineering (SE) is the application of a systematic, disciplined, quantifiable approach to the design, development, operation, and maintenance of software, and the study of these approaches; that is, the application of engineering to software. In layman's terms, it is the act of using insights to conceive, model and scale a solution to a problem. The first reference to the term is the 1968 NATO Software Engineering Conference and was meant to provoke thought regarding the perceived ""software crisis"" at the time. Software development, a much used and more generic term, does not necessarily subsume the engineering paradigm. The generally accepted concepts of Software Engineering as an engineering discipline have been specified in the Guide to the Software Engineering Body of Knowledge (SWEBOK). The SWEBOK has become an internationally accepted standard ISO/IEC TR 19759:2015.


=== Computer science ===

Computer science or computing science (abbreviated CS or Comp Sci) is the scientific and practical approach to computation and its applications. A computer scientist specializes in the theory of computation and the design of computational systems.Its subfields can be divided into practical techniques for its implementation and application in computer systems and purely theoretical areas. Some, such as computational complexity theory, which studies fundamental properties of computational problems, are highly abstract, while others, such as computer graphics, emphasize real-world applications. Still others focus on the challenges in implementing computations. For example, programming language theory studies approaches to description of computations, while the study of computer programming itself investigates various aspects of the use of programming languages and complex systems, and human–computer interaction focuses on the challenges in making computers and computations useful, usable, and universally accessible to humans.


=== Information systems ===

""Information systems (IS)"" is the study of complementary networks of hardware and software (see information technology) that people and organizations use to collect, filter, process, create, and distribute data. The ACM's Computing Careers website says 

""A majority of IS [degree] programs are located in business schools; however, they may have different names such as management information systems, computer information systems, or business information systems. All IS degrees combine business and computing topics, but the emphasis between technical and organizational issues varies among programs. For example, programs differ substantially in the amount of programming required.""

The study bridges business and computer science using the theoretical foundations of information and computation to study various business models and related algorithmic processes within a computer science discipline.


==== Computer Information System(s) (CIS) ====
This field studies computers and algorithmic processes, including their principles, their software and hardware designs, their applications, and their impact on society while IS emphasizes functionality over design.


=== Information technology ===

Information technology (IT) is the application of computers and telecommunications equipment to store, retrieve, transmit and manipulate data, often in the context of a business or other enterprise. The term is commonly used as a synonym for computers and computer networks, but it also encompasses other information distribution technologies such as television and telephones. Several industries are associated with information technology, such as computer hardware, software, electronics, semiconductors, internet, telecom equipment, e-commerce and computer services.


==== Systems administration ====

A system administrator, IT systems administrator, systems administrator, or sysadmin is a person employed to maintain and operate a computer system or network. The duties of a system administrator are wide-ranging, and may vary substantially from one organization to another. Sysadmins are usually charged with installing, supporting and maintaining servers or other computer systems, and planning for and responding to service outages and other problems. Other duties may include scripting or light programming, project management for systems-related projects, supervising or training computer operators, and being the consultant for computer problems beyond the knowledge of technical support staff.


== Research and emerging technologies ==

DNA-based computing and quantum computing are areas of active research in both hardware and software (such as the development of quantum algorithms). Potential infrastructure for future technologies includes DNA origami on photolithography and quantum antennae for transferring information between ion traps. By 2011, researchers had entangled 14 qubits. Fast digital circuits (including those based on Josephson junctions and rapid single flux quantum technology) are becoming more nearly realizable with the discovery of nanoscale superconductors.Fiber-optic and photonic (optical) devices, which already have been used to transport data over long distances, have started being used by data centers, side by side with CPU and semiconductor memory components. This allows the separation of RAM from CPU by optical interconnects. IBM has created an integrated circuit with both electronic and optical information processing in one chip. This is denoted ""CMOS-integrated nanophotonics"" or (CINP). One benefit of optical interconnects is that motherboards which formerly required a certain kind of system on a chip (SoC) can now move formerly dedicated memory and network controllers off the motherboards, spreading the controllers out onto the rack. This allows standardization of backplane interconnects and motherboards for multiple types of SoCs, which allows more timely upgrades of CPUs.Another field of research is spintronics. Spintronics can provide computing power and storage, without heat buildup. Some research is being done on hybrid chips, which combine photonics and spintronics. There is also research ongoing on combining plasmonics, photonics, and electronics.


=== Cloud Computing ===
Cloud computing is a model that allows for the use of computing resources, such as servers or applications, without the need for much interaction between the owner of these resources and the user using them. It is typically offered as a service, making it another example of Software as a Service, Platforms as a Service, and Infrastructure as a Service depending on the functionality offered. Key characteristics include on-demand access, broad network access, and the capability of rapid scaling. It allows individual users or small business to benefit from economies of scale.
One area of interest in this field is its potential to support energy efficiency. Allowing thousands of instances of computation to occur on one single machine instead of thousands of individual machines could help save energy. It could also ease the transition to more renewable energy, since it would suffice to power one server farm with a set of solar panels or wind turbines rather than millions of peoples' homes.With centralized computing, the field poses several challenges, especially in security and privacy. Current legislation does not sufficiently protect users from companies mishandling their data on the company servers. This suggests potential for further legislative regulations on cloud computing and tech companies.


=== Quantum Computing ===
Quantum computing is an area of research that brings together the disciplines of computer science, information theory, and quantum physics. The idea of information being a basic part of physics is relatively new, but there seems to be a strong tie between information theory and quantum mechanics. Whereas traditional computing operates on a binary system of ones and zeros, quantum computing uses qubits. Qubits are capable of being in a superposition, which means that they are in both states, one and zero, simultaneously. This means the qubit is not somewhere between 1 and 0, but actually the value of the qubit will change depending on when you measure it. This trait of qubits is called quantum entanglement and is the core idea of quantum computing and is what allows quantum computers to do the large scale equations they are used for. Quantum computing is often used for scientific research where a normal computer does not have nearly enough computational power to do the calculations necessary. A good example would be molecular modeling. Large molecules are far too complex for modern computers to calculate what happens to them during a reaction, but the power of quantum computers could open the doors to further understanding these molecules.


== See also ==
Index of history of computing articles
List of computer term etymologies
Lehmer sieve
Scientific computing
Electronic data processing
Creative computing


== References ==


== External links ==

FOLDOC: the Free On-Line Dictionary Of Computing"
"A computer mouse (plural mice or mouses) is a hand-held pointing device that detects two-dimensional motion relative to a surface. This motion is typically translated into the motion of a pointer on a display, which allows a smooth control of the graphical user interface of a computer.
The first public demonstration of a mouse controlling a computer system was in 1968. Mice originally used a ball rolling on a surface to detect motion, but modern mice often have optical sensors that have no moving parts. Originally wired to a computer, many modern mice are cordless, relying on short-range radio communication with the connected system.
In addition to moving a cursor, computer mice have one or more buttons to allow operations such as selection of a menu item on a display. Mice often also feature other elements, such as touch surfaces and scroll wheels, which enable additional control and dimensional input.


== Naming ==

The earliest known publication of the term mouse as referring to a computer pointing device is in Bill English's July 1965 publication, ""Computer-Aided Display Control"" likely originating from its resemblance to the shape and size of a mouse, a rodent, with the cord resembling its tail. The popularity of wireless mice without cords makes the resemblance less obvious.
The plural for the small rodent is always ""mice"" in modern usage. The plural of a computer mouse is either ""mouses"" or ""mice"" according to most dictionaries, with ""mice"" being more common. The first recorded plural usage is ""mice"";  the online Oxford Dictionaries cites a 1984 use, and earlier uses include J. C. R. Licklider's ""The Computer as a Communication Device"" of 1968. The term computer mouses may be used informally in some cases. Although the plural of a mouse (small rodent) is mice, the two words have undergone a differentiation through usage.


== History ==
The trackball, a related pointing device, was invented in 1946 by Ralph Benjamin as part of a post-World War II-era fire-control radar plotting system called the Comprehensive Display System (CDS). Benjamin was then working for the British Royal Navy Scientific Service. Benjamin's project used analog computers to calculate the future position of target aircraft based on several initial input points provided by a user with a joystick. Benjamin felt that a more elegant input device was needed and invented what they called a ""roller ball"" for this purpose.The device was patented in 1947, but only a prototype using a metal ball rolling on two rubber-coated wheels was ever built, and the device was kept as a military secret.Another early trackball was built by Kenyon Taylor, a British electrical engineer working in collaboration with Tom Cranston and Fred Longstaff. Taylor was part of the original Ferranti Canada, working on the Royal Canadian Navy's DATAR (Digital Automated Tracking and Resolving) system in 1952.DATAR was similar in concept to Benjamin's display. The trackball used four disks to pick up motion, two each for the X and Y directions. Several rollers provided mechanical support. When the ball was rolled, the pickup discs spun and contacts on their outer rim made periodic contact with wires, producing pulses of output with each movement of the ball. By counting the pulses, the physical movement of the ball could be determined. A digital computer calculated the tracks and sent the resulting data to other ships in a task force using pulse-code modulation radio signals. This trackball used a standard Canadian five-pin bowling ball. It was not patented, since it was a secret military project.

Douglas Engelbart of the Stanford Research Institute (now SRI International) has been credited in published books by Thierry Bardini, Paul Ceruzzi, Howard Rheingold, and several others as the inventor of the computer mouse. Engelbart was also recognized as such in various obituary titles after his death in July 2013.By 1963, Engelbart had already established a research lab at SRI, the Augmentation Research Center (ARC), to pursue his objective of developing both hardware and software computer technology to ""augment"" human intelligence. That November, while attending a conference on computer graphics in Reno, Nevada, Engelbart began to ponder how to adapt the underlying principles of the planimeter to inputting X- and Y-coordinate data. On November 14, 1963, he first recorded his thoughts in his personal notebook about something he initially called a ""bug,"" which in a ""3-point"" form could have a ""drop point and 2 orthogonal wheels."" He wrote that the ""bug"" would be ""easier"" and ""more natural"" to use, and unlike a stylus, it would stay still when let go, which meant it would be ""much better for coordination with the keyboard.""In 1964, Bill English joined ARC, where he helped Engelbart build the first mouse prototype. They christened the device the mouse as early models had a cord attached to the rear part of the device which looked like a tail, and in turn resembled the common mouse. As noted above, this ""mouse"" was first mentioned in print in a July 1965 report, on which English was the lead author. On 9 December 1968, Engelbart publicly demonstrated the mouse at what would come to be known as The Mother of All Demos. Engelbart never received any royalties for it, as his employer SRI held the patent, which expired before the mouse became widely used in personal computers. In any event, the invention of the mouse was just a small part of Engelbart's much larger project of augmenting human intellect.

Several other experimental pointing-devices developed for Engelbart's oN-Line System (NLS) exploited different body movements – for example, head-mounted devices attached to the chin or nose – but ultimately the mouse won out because of its speed and convenience. The first mouse, a bulky device (pictured) used two potentiometers perpendicular to each other and connected to wheels: the rotation of each wheel translated into motion along one axis. At the time of the ""Mother of All Demos"", Engelbart's group had been using their second generation, 3-button mouse for about a year.
On October 2, 1968, a mouse device named Rollkugel (German for ""rolling ball"") was described as an optional device for its SIG-100 terminal. It was developed by the German company Telefunken. As the name suggests and unlike Engelbart's mouse, the Telefunken model already had a ball. It was based on an earlier trackball-like device (also named Rollkugel) that was embedded into radar flight control desks. This trackball had been developed by a team led by Rainer Mallebrein at Telefunken Konstanz for the German Bundesanstalt für Flugsicherung (Federal Air Traffic Control) as part of their TR 86 process computer system with its SIG 100-86 vector graphics terminal.

When the development for the Telefunken main frame TR 440 began in 1965, Mallebrein and his team came up with the idea of ""reversing"" the existing Rollkugel into a moveable mouse-like device, so that customers did not have to be bothered with mounting holes for the earlier trackball device. Together with light pens and trackballs, it was offered as an optional input device for their system since 1968. Some Rollkugel mouses installed at the Leibniz-Rechenzentrum in Munich in 1972 are well preserved in a museum. Telefunken considered the invention too unimportant to apply for a patent on it.
The Xerox Alto was one of the first computers designed for individual use in 1973 and is regarded as the first modern computer to utilize a mouse. Inspired by PARC's Alto, the Lilith, a computer which had been developed by a team around Niklaus Wirth at ETH Zürich between 1978 and 1980, provided a mouse as well. The third marketed version of an integrated mouse shipped as a part of a computer and intended for personal computer navigation came with the Xerox 8010 Star in 1981.
By 1982, the Xerox 8010 was probably the best-known computer with a mouse. The Sun-1 also came with a mouse, and the forthcoming Apple Lisa was rumored to use one, but the peripheral remained obscure; Jack Hawley of The Mouse House reported that one buyer for a large organization believed at first that his company sold lab mice. Hawley, who manufactured mice for Xerox, stated that ""Practically, I have the market all to myself right now""; a Hawley mouse cost $415. In 1982, Logitech introduced the P4 Mouse at the Comdex trade show in Las Vegas, its first hardware mouse. That same year Microsoft made the decision to make the MS-DOS program Microsoft Word mouse-compatible, and developed the first PC-compatible mouse. Microsoft's mouse shipped in 1983, thus beginning the Microsoft Hardware division of the company. However, the mouse remained relatively obscure until the appearance of the Macintosh 128K (which included an updated version of the single-button Lisa Mouse) in 1984, and of the Amiga 1000 and the Atari ST in 1985.


== Operation ==

A mouse typically controls the motion of a pointer in two dimensions in a graphical user interface (GUI). The mouse turns movements of the hand backward and forward, left and right into equivalent electronic signals that in turn are used to move the pointer.
The relative movements of the mouse on the surface are applied to the position of the pointer on the screen, which signals the point where actions of the user take place, so hand movements are replicated by the pointer. Clicking or hovering (stopping movement while the cursor is within the bounds of an area) can select files, programs or actions from a list of names, or (in graphical interfaces) through small images called ""icons"" and other elements. For example, a text file might be represented by a picture of a paper notebook and clicking while the cursor hovers this icon might cause a text editing program to open the file in a window.
Different ways of operating the mouse cause specific things to happen in the GUI:
Click: pressing and releasing a button.
(left) Single-click: clicking the main button.
(left) Double-click: clicking the button two times in quick succession counts as a different gesture than two separate single clicks.
(left) Triple-click: clicking the button three times in quick succession counts as a different gesture than three separate single clicks. Triple clicks are far less common in traditional navigation.
Right-click: clicking the secondary button, or clicking with two fingers. (This brings a menu with different options depending on the software)
Middle-click: clicking the tertiary button.
Drag and drop: pressing and holding a button, then moving the mouse without releasing. (Using the command ""drag with the right mouse button"" instead of just ""drag"" when one instructs a user to drag an object while holding the right mouse button down instead of the more commonly used left mouse button.)
Mouse button chording (a.k.a. Rocker navigation).
Combination of right-click then left-click.
Combination of left-click then right-click or keyboard letter.
Combination of left or right-click and the mouse wheel.
Clicking while holding down a modifier key.
Moving the pointer a long distance: When a practical limit of mouse movement is reached, one lifts up the mouse, brings it to the opposite edge of the working area while it is held above the surface, and then replaces it down onto the working surface. This is often not necessary, because acceleration software detects fast movement, and moves the pointer significantly faster in proportion than for slow mouse motion.
Multi-touch: this method is similar to a multi-touch trackpad on a laptop with support for tap input for multiple fingers, the most famous example being the Apple Magic Mouse.


=== Gestures ===

Users can also employ mice gesturally; meaning that a stylized motion of the mouse cursor itself, called a ""gesture"", can issue a command or map to a specific action. For example, in a drawing program, moving the mouse in a rapid ""x"" motion over a shape might delete the shape.
Gestural interfaces occur more rarely than plain pointing-and-clicking; and people often find them more difficult to use, because they require finer motor control from the user. However, a few gestural conventions have become widespread, including the drag and drop gesture, in which:

The user presses the mouse button while the mouse cursor hovers over an interface object
The user moves the cursor to a different location while holding the button down
The user releases the mouse buttonFor example, a user might drag-and-drop a picture representing a file onto a picture of a trash can, thus instructing the system to delete the file.
Standard semantic gestures include:

Crossing-based goal
Drag and drop
Menu traversal
Pointing
Rollover (Mouseover)
Selection


=== Specific uses ===
Other uses of the mouse's input occur commonly in special application-domains. In interactive three-dimensional graphics, the mouse's motion often translates directly into changes in the virtual objects' or camera's orientation. For example, in the first-person shooter genre of games (see below), players usually employ the mouse to control the direction in which the virtual player's ""head"" faces: moving the mouse up will cause the player to look up, revealing the view above the player's head. A related function makes an image of an object rotate, so that all sides can be examined. 3D design and animation software often modally chords many different combinations to allow objects and cameras to be rotated and moved through space with the few axes of movement mice can detect.
When mice have more than one button, the software may assign different functions to each button. Often, the primary (leftmost in a right-handed configuration) button on the mouse will select items, and the secondary (rightmost in a right-handed) button will bring up a menu of alternative actions applicable to that item. For example, on platforms with more than one button, the Mozilla web browser will follow a link in response to a primary button click, will bring up a contextual menu of alternative actions for that link in response to a secondary-button click, and will often open the link in a new tab or window in response to a click with the tertiary (middle) mouse button.


== Types ==


=== Mechanical mice ===
The German company Telefunken published on their early ball mouse on 2 October 1968. Telefunken's mouse was sold as optional equipment for their computer systems. Bill English, builder of Engelbart's original mouse, created a ball mouse in 1972 while working for Xerox PARC.The ball mouse replaced the external wheels with a single ball that could rotate in any direction. It came as part of the hardware package of the Xerox Alto computer. Perpendicular chopper wheels housed inside the mouse's body chopped beams of light on the way to light sensors, thus detecting in their turn the motion of the ball. This variant of the mouse resembled an inverted trackball and became the predominant form used with personal computers throughout the 1980s and 1990s. The Xerox PARC group also settled on the modern technique of using both hands to type on a full-size keyboard and grabbing the mouse when required.

The ball mouse has two freely rotating rollers. These are located 90 degrees apart. One roller detects the forward–backward motion of the mouse and other the left–right motion. Opposite the two rollers is a third one (white, in the photo, at 45 degrees) that is spring-loaded to push the ball against the other two rollers. Each roller is on the same shaft as an encoder wheel that has slotted edges; the slots interrupt infrared light beams to generate electrical pulses that represent wheel movement. Each wheel's disc has a pair of light beams, located so that a given beam becomes interrupted or again starts to pass light freely when the other beam of the pair is about halfway between changes.
Simple logic circuits interpret the relative timing to indicate which direction the wheel is rotating. This incremental rotary encoder scheme is sometimes called quadrature encoding of the wheel rotation, as the two optical sensors produce signals that are in approximately quadrature phase. The mouse sends these signals to the computer system via the mouse cable, directly as logic signals in very old mice such as the Xerox mice, and via a data-formatting IC in modern mice. The driver software in the system converts the signals into motion of the mouse cursor along X and Y axes on the computer screen.

The ball is mostly steel, with a precision spherical rubber surface. The weight of the ball, given an appropriate working surface under the mouse, provides a reliable grip so the mouse's movement is transmitted accurately. Ball mice and wheel mice were manufactured for Xerox by Jack Hawley, doing business as The Mouse House in Berkeley, California, starting in 1975. Based on another invention by Jack Hawley, proprietor of the Mouse House, Honeywell produced another type of mechanical mouse. Instead of a ball, it had two wheels rotating at off axes. Key Tronic later produced a similar product.Modern computer mice took form at the École Polytechnique Fédérale de Lausanne (EPFL) under the inspiration of Professor Jean-Daniel Nicoud and at the hands of engineer and watchmaker André Guignard. This new design incorporated a single hard rubber mouseball and three buttons, and remained a common design until the mainstream adoption of the scroll-wheel mouse during the 1990s. In 1985, René Sommer added a microprocessor to Nicoud's and Guignard's design. Through this innovation, Sommer is credited with inventing a significant component of the mouse, which made it more ""intelligent""; though optical mice from Mouse Systems had incorporated microprocessors by 1984.Another type of mechanical mouse, the ""analog mouse"" (now generally regarded as obsolete), uses potentiometers rather than encoder wheels, and is typically designed to be plug compatible with an analog joystick. The ""Color Mouse"", originally marketed by RadioShack for their Color Computer (but also usable on MS-DOS machines equipped with analog joystick ports, provided the software accepted joystick input) was the best-known example.


=== Optical and laser mice ===

Early optical mice relied entirely on one or more light-emitting diodes (LEDs) and an imaging array of photodiodes to detect movement relative to the underlying surface, eschewing the internal moving parts a mechanical mouse uses in addition to its optics. A laser mouse is an optical mouse that uses coherent (laser) light.
The earliest optical mice detected movement on pre-printed mousepad surfaces, whereas the modern LED optical mouse works on most opaque diffuse surfaces; it is usually unable to detect movement on specular surfaces like polished stone. Laser diodes provide good resolution and precision, improving performance on opaque specular surfaces. Later, more surface-independent optical mice use an optoelectronic sensor (essentially, a tiny low-resolution video camera) to take successive images of the surface on which the mouse operates. Battery powered, wireless optical mice flash the LED intermittently to save power, and only glow steadily when movement is detected.


=== Inertial and gyroscopic mice ===
Often called ""air mice"" since they do not require a surface to operate, inertial mice use a tuning fork or other accelerometer (US Patent 4787051) to detect rotary movement for every axis supported. The most common models (manufactured by Logitech and Gyration) work using 2 degrees of rotational freedom and are insensitive to spatial translation. The user requires only small wrist rotations to move the cursor, reducing user fatigue or ""gorilla arm"".
Usually cordless, they often have a switch to deactivate the movement circuitry between use, allowing the user freedom of movement without affecting the cursor position. A patent for an inertial mouse claims that such mice consume less power than optically based mice, and offer increased sensitivity, reduced weight and increased ease-of-use. In combination with a wireless keyboard an inertial mouse can offer alternative ergonomic arrangements which do not require a flat work surface, potentially alleviating some types of repetitive motion injuries related to workstation posture.


=== 3D mice ===
Also known as bats, flying mice, or wands, these devices generally function through ultrasound and provide at least three degrees of freedom. Probably the best known example would be 3Dconnexion (""Logitech's SpaceMouse"") from the early 1990s. In the late 1990s Kantek introduced the 3D RingMouse. This wireless mouse was worn on a ring around a finger, which enabled the thumb to access three buttons. The mouse was tracked in three dimensions by a base station. Despite a certain appeal, it was finally discontinued because it did not provide sufficient resolution.
One example of a 2000s consumer 3D pointing device is the Wii Remote. While primarily a motion-sensing device (that is, it can determine its orientation and direction of movement), Wii Remote can also detect its spatial position by comparing the distance and position of the lights from the IR emitter using its integrated IR camera (since the nunchuk accessory lacks a camera, it can only tell its current heading and orientation). The obvious drawback to this approach is that it can only produce spatial coordinates while its camera can see the sensor bar. More accurate consumer devices have since been released, including the PlayStation Move, the Razer Hydra and the controllers part of the HTC Vive virtual reality system. All of these devices can accurately detect position and orientation in 3D space regardless of angle relative to the sensor station.A mouse-related controller called the SpaceBall has a ball placed above the work surface that can easily be gripped. With spring-loaded centering, it sends both translational as well as angular displacements on all six axes, in both directions for each. In November 2010 a German Company called Axsotic introduced a new concept of 3D mouse called 3D Spheric Mouse. This new concept of a true six degree-of-freedom input device uses a ball to rotate in 3 axes without any limitations.

		
		
		
		


=== Tactile mice ===
In 2000, Logitech introduced a ""tactile mouse"" that contained a small actuator to make the mouse vibrate. Such a mouse can augment user-interfaces with haptic feedback, such as giving feedback when crossing a window boundary. To surf by touch requires the user to be able to feel depth or hardness; this ability was realized with the first electrorheological tactile mice but never marketed.


=== Pucks ===
Tablet digitizers are sometimes used with accessories called pucks, devices which rely on absolute positioning, but can be configured for sufficiently mouse-like relative tracking that they are sometimes marketed as mice.


=== Ergonomic mice ===

As the name suggests, this type of mouse is intended to provide optimum comfort and avoid injuries such as carpal tunnel syndrome, arthritis and other repetitive strain injuries. It is designed to fit natural hand position and movements, to reduce discomfort.
When holding a typical mouse, ulna and radius bones on the arm are crossed. Some designs attempt to place the palm more vertically, so the bones take more natural parallel position. Some limit wrist movement, encouraging arm movement instead, that may be less precise but more optimal from the health point of view. A mouse may be angled from the thumb downward to the opposite side – this is known to reduce wrist pronation. However such optimizations make the mouse right or left hand specific, making more problematic to change the tired hand. Time has criticized manufacturers for offering few or no left-handed ergonomic mice: ""Oftentimes I felt like I was dealing with someone who’d never actually met a left-handed person before.""

Another solution is a pointing bar device. The so-called roller bar mouse is positioned snugly in front of the keyboard, thus allowing bi-manual accessibility.


=== Gaming mice ===

These mice are specifically designed for use in computer games. They typically employ a wider array of controls and buttons and have designs that differ radically from traditional mice. They may also have decorative monochrome or programmable RGB LED lighting. The additional buttons can often be used for changing the sensitivity of the mouse or they can be assigned (programmed) to macros (i.e., for opening a program or for use instead of a key combination) It is also common for game mice, especially those designed for use in real-time strategy games such as StarCraft, or in multiplayer online battle arena games such as Dota 2 to have a relatively high sensitivity, measured in dots per inch (DPI), which can be as high as 20,000. Some advanced mice from gaming manufacturers also allow users to adjust the weight of the mouse by adding or subtracting weights to allow for easier control. Ergonomic quality is also an important factor in gaming mice, as extended gameplay times may render further use of the mouse to be uncomfortable. Some mice have been designed to have adjustable features such as removable and/or elongated palm rests, horizontally adjustable thumb rests and pinky rests. Some mice may include several different rests with their products to ensure comfort for a wider range of target consumers. Gaming mice are held by gamers in three styles of grip:
Palm Grip: the hand rests on the mouse, with extended fingers.
Claw Grip: palm rests on the mouse, bent fingers.
Finger-Tip Grip: bent fingers, palm doesn't touch the mouse.


== Connectivity and communication protocols ==

To transmit their input, typical cabled mice use a thin electrical cord terminating in a standard connector, such as RS-232C, PS/2, ADB or USB. Cordless mice instead transmit data via infrared radiation (see IrDA) or radio (including Bluetooth), although many such cordless interfaces are themselves connected through the aforementioned wired serial buses.
While the electrical interface and the format of the data transmitted by commonly available mice is currently standardized on USB, in the past it varied between different manufacturers. A bus mouse used a dedicated interface card for connection to an IBM PC or compatible computer.
Mouse use in DOS applications became more common after the introduction of the Microsoft Mouse, largely because Microsoft provided an open standard for communication between applications and mouse driver software. Thus, any application written to use the Microsoft standard could use a mouse with a driver that implements the same API, even if the mouse hardware itself was incompatible with Microsoft's. This driver provides the state of the buttons and the distance the mouse has moved in units that its documentation calls ""mickeys"", as does the Allegro library.


=== Early mice ===

In the 1970s, the Xerox Alto mouse, and in the 1980s the Xerox optical mouse, used a quadrature-encoded X and Y interface.  This two-bit encoding per dimension had the property that only one bit of the two would change at a time, like a Gray code or Johnson counter, so that the transitions would not be misinterpreted when asynchronously sampled.The earliest mass-market mice, such as on the original Macintosh, Amiga, and Atari ST mice used a D-subminiature 9-pin connector to send the quadrature-encoded X and Y axis signals directly, plus one pin per mouse button.  The mouse was a simple optomechanical device, and the decoding circuitry was all in the main computer.
The DE-9 connectors were designed to be electrically compatible with the joysticks popular on numerous 8-bit systems, such as the Commodore 64 and the Atari 2600.  Although the ports could be used for both purposes, the signals must be interpreted differently.  As a result, plugging a mouse into a joystick port causes the ""joystick"" to continuously move in some direction, even if the mouse stays still, whereas plugging a joystick into a mouse port causes the ""mouse"" to only be able to move a single pixel in each direction.


=== Serial interface and protocol ===

Because the IBM PC did not have a quadrature decoder built in, early PC mice used the RS-232C serial port to communicate encoded mouse movements, as well as provide power to the mouse's circuits. The Mouse Systems Corporation version used a five-byte protocol and supported three buttons. The Microsoft version used a three-byte protocol and supported two buttons. Due to the incompatibility between the two protocols, some manufacturers sold serial mice with a mode switch: ""PC"" for MSC mode, ""MS"" for Microsoft mode.


=== Apple Desktop Bus ===

In 1986 Apple first implemented the Apple Desktop Bus allowing the daisy-chaining (linking together in series, ie. end to end) of up to 16 devices, including mice and other devices on the same bus with no configuration whatsoever. Featuring only a single data pin, the bus used a purely polled approach to computer/device communications and survived as the standard on mainstream models (including a number of non-Apple workstations) until 1998 when Apple's iMac line of computers joined the industry-wide switch to using USB. Beginning with the Bronze Keyboard PowerBook G3 in May 1999, Apple dropped the external ADB port in favor of USB, but retained an internal ADB connection in the PowerBook G4 for communication with its built-in keyboard and trackpad until early 2005.


=== PS/2 interface and protocol ===

With the arrival of the IBM PS/2 personal-computer series in 1987, IBM introduced the eponymous PS/2 interface for mice and keyboards, which other manufacturers rapidly adopted. The most visible change was the use of a round 6-pin mini-DIN, in lieu of the former 5-pin MIDI style full sized DIN 41524 connector. In default mode (called stream mode) a PS/2 mouse communicates motion, and the state of each button, by means of 3-byte packets. For any motion, button press or button release event, a PS/2 mouse sends, over a bi-directional serial port, a sequence of three bytes, with the following format:

Here, XS and YS represent the sign bits of the movement vectors, XV and YV indicate an overflow in the respective vector component, and LB, MB and RB indicate the status of the left, middle and right mouse buttons (1 = pressed). PS/2 mice also understand several commands for reset and self-test, switching between different operating modes, and changing the resolution of the reported motion vectors.
A Microsoft IntelliMouse relies on an extension of the PS/2 protocol: the ImPS/2 or IMPS/2 protocol (the abbreviation combines the concepts of ""IntelliMouse"" and ""PS/2""). It initially operates in standard PS/2 format, for backwards compatibility. After the host sends a special command sequence, it switches to an extended format in which a fourth byte carries information about wheel movements. The IntelliMouse Explorer works analogously, with the difference that its 4-byte packets also allow for two additional buttons (for a total of five).Mouse vendors also use other extended formats, often without providing public documentation. The Typhoon mouse uses 6-byte packets which can appear as a sequence of two standard 3-byte packets, such that an ordinary PS/2 driver can handle them. For 3-D (or 6-degree-of-freedom) input, vendors have made many extensions both to the hardware and to software. In the late 1990s, Logitech created ultrasound based tracking which gave 3D input to a few millimeters accuracy, which worked well as an input device but failed as a profitable product. In 2008, Motion4U introduced its ""OptiBurst"" system using IR tracking for use as a Maya (graphics software) plugin.


=== USB ===
The industry-standard USB (Universal Serial Bus) protocol and its connector have become widely used for mice; it is among the most popular types.


=== Cordless or wireless ===
Cordless or wireless mice transmit data via infrared radiation (see IrDA) or radio (including Bluetooth and Wi-Fi). The receiver is connected to the computer through a serial or USB port, or can be built in (as is sometimes the case with Bluetooth and WiFi).
Modern non-Bluetooth and non-WiFi wireless mice use USB receivers. Some of these can be stored inside the mouse for safe transport while not in use, while other, newer mice use newer ""nano"" receivers, designed to be small enough to remain plugged into a laptop during transport, while still being large enough to easily remove.

		
		


== Multiple-mouse systems ==
Some systems allow two or more mice to be used at once as input devices. Late-1980s era home computers such as the Amiga used this to allow computer games with two players interacting on the same computer (Lemmings and The Settlers for example). The same idea is sometimes used in collaborative software, e.g. to simulate a whiteboard that multiple users can draw on without passing a single mouse around.
Microsoft Windows, since Windows 98, has supported multiple simultaneous pointing devices. Because Windows only provides a single screen cursor, using more than one device at the same time requires cooperation of users or applications designed for multiple input devices.
Multiple mice are often used in multi-user gaming in addition to specially designed devices that provide several input interfaces.
Windows also has full support for multiple input/mouse configurations for multi-user environments.
Starting with Windows XP, Microsoft introduced an SDK for developing applications that allow multiple input devices to be used at the same time with independent cursors and independent input points. However, it no longer appears to be available.The introduction of Vista and Microsoft Surface (now known as Microsoft PixelSense) introduced a new set of input APIs that were adopted into Windows 7, allowing for 50 points/cursors, all controlled by independent users. The new input points provide traditional mouse input; however, they were designed with other input technologies like touch and image in mind. They inherently offer 3D coordinates along with pressure, size, tilt, angle, mask, and even an image bitmap to see and recognize the input point/object on the screen.
As of 2009, Linux distributions and other operating systems that use X.Org, such as OpenSolaris and FreeBSD, support 255 cursors/input points through Multi-Pointer X. However, currently no window managers support Multi-Pointer X leaving it relegated to custom software usage.
There have also been propositions of having a single operator use two mice simultaneously as a more sophisticated means of controlling various graphics and multimedia applications.


== Buttons ==

Mouse buttons are microswitches which can be pressed to select or interact with an element of a graphical user interface, producing a distinctive clicking sound.
Since around the late 1990s, the three-button scrollmouse has become the de facto standard. Users most commonly employ the second button to invoke a contextual menu in the computer's software user interface, which contains options specifically tailored to the interface element over which the mouse cursor currently sits. By default, the primary mouse button sits located on the left-hand side of the mouse, for the benefit of right-handed users; left-handed users can usually reverse this configuration via software.


== Scrolling ==

Nearly all mice now have an integrated input primarily intended for scrolling on top, usually a single-axis digital wheel or rocker switch which can also be depressed to act as a third button. Though less common, many mice instead have two-axis inputs such as a tiltable wheel, trackball, or touchpad. Those with a trackball may be designed to stay stationary, using the trackball instead of moving the mouse.


== Speed ==
Mickeys per second is a unit of measurement for the speed and movement direction of a computer mouse, where direction is often expressed as ""horizontal"" versus ""vertical"" mickey count. However, speed can also refer to the ratio between how many pixels the cursor moves on the screen and how far the mouse moves on the mouse pad, which may be expressed as pixels per mickey, pixels per inch, or pixels per centimeter.
The computer industry often measures mouse sensitivity in terms of counts per inch (CPI), commonly expressed as dots per inch (DPI) – the number of steps the mouse will report when it moves one inch. In early mice, this specification was called pulses per inch (ppi). The Mickey originally referred to one of these counts, or one resolvable step of motion. If the default mouse-tracking condition involves moving the cursor by one screen-pixel or dot on-screen per reported step, then the CPI does equate to DPI: dots of cursor motion per inch of mouse motion. The CPI or DPI as reported by manufacturers depends on how they make the mouse; the higher the CPI, the faster the cursor moves with mouse movement. However, software can adjust the mouse sensitivity, making the cursor move faster or slower than its CPI. Current software can change the speed of the cursor dynamically, taking into account the mouse's absolute speed and the movement from the last stop-point. In most software, an example being the Windows platforms, this setting is named ""speed,"" referring to ""cursor precision"". However, some operating systems name this setting ""acceleration"", the typical Apple OS designation. This term is incorrect. Mouse acceleration in most mouse software refers to the change in speed of the cursor over time while the mouse movement is constant.For simple software, when the mouse starts to move, the software will count the number of ""counts"" or ""mickeys"" received from the mouse and will move the cursor across the screen by that number of pixels (or multiplied by a rate factor, typically less than 1). The cursor will move slowly on the screen, with good precision. When the movement of the mouse passes the value set for some threshold, the software will start to move the cursor faster, with a greater rate factor. Usually, the user can set the value of the second rate factor by changing the ""acceleration"" setting.
Operating systems sometimes apply acceleration, referred to as ""ballistics"", to the motion reported by the mouse. For example, versions of Windows prior to Windows XP doubled reported values above a configurable threshold, and then optionally doubled them again above a second configurable threshold. These doublings applied separately in the X and Y directions, resulting in very nonlinear response.


== Mousepads ==

Engelbart's original mouse did not require a mousepad; the mouse had two large wheels which could roll on virtually any surface. However, most subsequent mechanical mice starting with the steel roller ball mouse have required a mousepad for optimal performance.
The mousepad, the most common mouse accessory, appears most commonly in conjunction with mechanical mice, because to roll smoothly the ball requires more friction than common desk surfaces usually provide. So-called ""hard mousepads"" for gamers or optical/laser mice also exist.
Most optical and laser mice do not require a pad, the notable exception being early optical mice which relied on a grid on the pad to detect movement (e.g. Mouse Systems). Whether to use a hard or soft mousepad with an optical mouse is largely a matter of personal preference. One exception occurs when the desk surface creates problems for the optical or laser tracking, for example, a transparent or reflective surface, such as glass.


== In the marketplace ==

Around 1981, Xerox included mice with its Xerox Star, based on the mouse used in the 1970s on the Alto computer at Xerox PARC. Sun Microsystems, Symbolics, Lisp Machines Inc., and Tektronix also shipped workstations with mice, starting in about 1981. Later, inspired by the Star, Apple Computer released the Apple Lisa, which also used a mouse. However, none of these products achieved large-scale success. Only with the release of the Apple Macintosh in 1984 did the mouse see widespread use.The Macintosh design, commercially successful and technically influential, led many other vendors to begin producing mice or including them with their other computer products (by 1986, Atari ST, Amiga, Windows 1.0, GEOS for the Commodore 64, and the Apple IIGS).The widespread adoption of graphical user interfaces in the software of the 1980s and 1990s made mice all but indispensable for controlling computers. In November 2008, Logitech built their billionth mouse.


== Use in games ==

The Classic Mac OS Desk Accessory Puzzle in 1984 was the first game designed specifically for a mouse. The device often functions as an interface for PC-based computer games and sometimes for video game consoles.


=== First-person shooters ===
FPSs naturally lend themselves to separate and simultaneous control of the player's movement and aim, and on computers this has traditionally been achieved with a combination of keyboard and mouse. Players use the X-axis of the mouse for looking (or turning) left and right, and the Y-axis for looking up and down; the keyboard is used for movement and supplemental inputs.
Many shooting genre players prefer a mouse over a gamepad analog stick because the wide range of motion offered by a mouse allows for faster and more varied control. Although an analog stick allows the player more granular control, it is poor for certain movements, as the player's input is relayed based on a vector of both the stick
s direction and magnitude. Thus, a small but fast movement (known as ""flick-shotting"") using a gamepad requires the player to quickly move the stick from its rest position to the edge and back again in quick succession, a difficult maneuver. In addition the stick also has a finite magnitude; if the player is currently using the stick to move at a non-zero velocity their ability to increase the rate of movement of the camera is further limited based on the position their displaced stick was already at before executing the maneuver. The effect of this is that a mouse is well suited not only to small, precise movements but also to large, quick movements and immediate, responsive movements; all of which are important in shooter gaming. This advantage also extends in varying degrees to similar game styles such as third-person shooters.
Some incorrectly ported games or game engines have acceleration and interpolation curves which unintentionally produce excessive, irregular, or even negative acceleration when used with a mouse instead of their native platform's non-mouse default input device. Depending on how deeply hardcoded this misbehavior is, internal user patches or external 3rd-party software may be able to fix it.Due to their similarity to the WIMP desktop metaphor interface for which mice were originally designed, and to their own tabletop game origins, computer strategy games are most commonly played with mice. In particular, real-time strategy and MOBA games usually require the use of a mouse.
The left button usually controls primary fire. If the game supports multiple fire modes, the right button often provides secondary fire from the selected weapon. Games with only a single fire mode will generally map secondary fire to ADS. In some games, the right button may also invoke accessories for a particular weapon, such as allowing access to the scope of a sniper rifle or allowing the mounting of a bayonet or silencer.
Players can use a scroll wheel for changing weapons (or for controlling scope-zoom magnification, in older games). On most first person shooter games, programming may also assign more functions to additional buttons on mice with more than three controls. A keyboard usually controls movement (for example, WASD for moving forward, left, backward and right, respectively) and other functions such as changing posture. Since the mouse serves for aiming, a mouse that tracks movement accurately and with less lag (latency) will give a player an advantage over players with less accurate or slower mice. In some cases the right mouse button may be used to move the player forward, either in lieu of, or in conjunction with the typical WASD configuration.
Many games provide players with the option of mapping their own choice of a key or button to a certain control. An early technique of players, circle strafing, saw a player continuously strafing while aiming and shooting at an opponent by walking in circle around the opponent with the opponent at the center of the circle. Players could achieve this by holding down a key for strafing while continuously aiming the mouse towards the opponent.
Games using mice for input are so popular that many manufacturers make mice specifically for gaming. Such mice may feature adjustable weights, high-resolution optical or laser components, additional buttons, ergonomic shape, and other features such as adjustable CPI. Mouse Bungees are typically used with gaming mice because it eliminates the annoyance of the cable.
Many games, such as first- or third-person shooters, have a setting named ""invert mouse"" or similar (not to be confused with ""button inversion"", sometimes performed by left-handed users) which allows the user to look downward by moving the mouse forward and upward by moving the mouse backward (the opposite of non-inverted movement). This control system resembles that of aircraft control sticks, where pulling back causes pitch up and pushing forward causes pitch down; computer joysticks also typically emulate this control-configuration.
After id Software's commercial hit of Doom, which did not support vertical aiming, competitor Bungie's Marathon became the first first-person shooter to support using the mouse to aim up and down. Games using the Build engine had an option to invert the Y-axis. The ""invert"" feature actually made the mouse behave in a manner that users now regard as non-inverted (by default, moving mouse forward resulted in looking down). Soon after, id Software released Quake, which introduced the invert feature as users now know it.


=== Home consoles ===

In 1988, the VTech Socrates educational video game console featured a wireless mouse with an attached mouse pad as an optional controller used for some games. In the early 1990s, the Super Nintendo Entertainment System video game system featured a mouse in addition to its controllers. The Mario Paint game in particular used the mouse's capabilities as did its successor on the N64. Sega released official mice for their Genesis/Mega Drive, Saturn and Dreamcast consoles. NEC sold official mice for its PC Engine and PC-FX consoles. Sony released an official mouse product for the PlayStation console, included one along with the Linux for PlayStation 2 kit, as well as allowing owners to use virtually any USB mouse with the PS2, PS3, and PS4. Nintendo's Wii also had this added on in a later software update, retained on the Wii U.


== See also ==


== References ==


== Further reading ==
Pang, Alex Soojung-Kim, ""Mighty Mouse: In 1980, Apple Computer asked a group of guys fresh from Stanford's product design program to take a $400 device and make it mass-producible, reliable and cheap. Their work transformed personal computing"", Stanford University Alumni Magazine, March/April 2002.
Stanford University MouseSite with stories and annotated archives from Doug Engelbart's work
Doug Engelbart Institute mouse resources page includes stories and links
Fire-Control and Human-Computer Interaction: Towards a History of the Computer Mouse (1940–1965), by Axel Roch
50 Jahre Computer mit der Maus - Öffentliche Veranstaltung am 5. Dezember auf dem Campus Vaihingen (Invitation to a plenum discussion) (in German), Informatik-Forum Stuttgart (infos e.V.), GI- / ACM-Regionalgruppe Stuttgart / Böblingen, Institut für Visualisierung und Interaktive Systeme der Universität Stuttgart and SFB-TRR 161, 2016-11-28, archived from the original on 2017-11-15, retrieved 2017-11-15
Borchers, Detlef (2016-12-10), 50 Jahre Mensch-Maschine-Interaktion: Finger oder Kugel? (in German), Heise Online, archived from the original on 2017-11-15, retrieved 2017-11-15
Yacoub, Mousa; Turfa, Majd; Maurer, Fabian (2016-08-19). Reverse Engineering of the Computer Mouse RKS 100 (PDF). Archived from the original (PDF) on 2017-11-15. Retrieved 2017-11-15. (NB. Contains some historical photos.)


== External links ==
The video segment of The Mother of All Demos with Doug Engelbart showing the device from 1968"
"Information technology (IT) is the use of computers to store, retrieve, transmit, and manipulate data or information. IT is typically used within the context of business operations as opposed to personal or entertainment technologies. IT is considered to be a subset of information and communications technology (ICT). An information technology system (IT system) is generally an information system, a communications system or, more specifically speaking, a computer system – including all hardware, software and peripheral equipment – operated by a limited group of users.
Humans have been storing, retrieving, manipulating, and communicating information since the Sumerians in Mesopotamia developed writing in about 3000 BC, but the term information technology in its modern sense first appeared in a 1958 article published in the Harvard Business Review; authors Harold J. Leavitt and Thomas L. Whisler commented that ""the new technology does not yet have a single established name. We shall call it information technology (IT)."" Their definition consists of three categories: techniques for processing, the application of statistical and mathematical methods to decision-making, and the simulation of higher-order thinking through computer programs.The term is commonly used as a synonym for computers and computer networks, but it also encompasses other information distribution technologies such as television and telephones. Several products or services within an economy are associated with information technology, including computer hardware, software, electronics, semiconductors, internet, telecom equipment, and e-commerce.Based on the storage and processing technologies employed, it is possible to distinguish four distinct phases of IT development: pre-mechanical (3000 BC – 1450 AD), mechanical (1450–1840), electromechanical (1840–1940), and electronic (1940–present). This article focuses on the most recent period (electronic).


== History of computer technology ==

Devices have been used to aid computation for thousands of years, probably initially in the form of a tally stick. The Antikythera mechanism, dating from about the beginning of the first century BC, is generally considered to be the earliest known mechanical analog computer, and the earliest known geared mechanism. Comparable geared devices did not emerge in Europe until the 16th century, and it was not until 1645 that the first mechanical calculator capable of performing the four basic arithmetical operations was developed.Electronic computers, using either relays or valves, began to appear in the early 1940s. The electromechanical Zuse Z3, completed in 1941, was the world's first programmable computer, and by modern standards one of the first machines that could be considered a complete computing machine. Colossus, developed during the Second World War to decrypt German messages, was the first electronic digital computer. Although it was programmable, it was not general-purpose, being designed to perform only a single task. It also lacked the ability to store its program in memory; programming was carried out using plugs and switches to alter the internal wiring. The first recognisably modern electronic digital stored-program computer was the Manchester Baby, which ran its first program on 21 June 1948.The development of transistors in the late 1940s at Bell Laboratories allowed a new generation of computers to be designed with greatly reduced power consumption. The first commercially available stored-program computer, the Ferranti Mark I, contained 4050 valves and had a power consumption of 25 kilowatts. By comparison, the first transistorized computer developed at the University of Manchester and operational by November 1953, consumed only 150 watts in its final version.Several later breakthroughs in semiconductor technology include the integrated circuit (IC) invented by Jack Kilby at Texas Instruments and Robert Noyce at Fairchild Semiconductor in 1959, the metal-oxide-semiconductor field-effect transistor (MOSFET) invented by Mohamed Atalla and Dawon Kahng at Bell Laboratories in 1959, and the microprocessor invented by Ted Hoff, Federico Faggin, Masatoshi Shima and Stanley Mazor at Intel in 1971. These important inventions led to the development of the personal computer (PC) in the 1970s, and the emergence of information and communications technology (ICT).


== Electronic data processing ==


=== Data storage ===

Early electronic computers such as Colossus made use of punched tape, a long strip of paper on which data was represented by a series of holes, a technology now obsolete. Electronic data storage, which is used in modern computers, dates from World War II, when a form of delay line memory was developed to remove the clutter from radar signals, the first practical application of which was the mercury delay line. The first random-access digital storage device was the Williams tube, based on a standard cathode ray tube, but the information stored in it and delay line memory was volatile in that it had to be continuously refreshed, and thus was lost once power was removed. The earliest form of non-volatile computer storage was the magnetic drum, invented in 1932 and used in the Ferranti Mark 1, the world's first commercially available general-purpose electronic computer.IBM introduced the first hard disk drive in 1956, as a component of their 305 RAMAC computer system. Most digital data today is still stored magnetically on hard disks, or optically on media such as CD-ROMs. Until 2002 most information was stored on analog devices, but that year digital storage capacity exceeded analog for the first time. As of 2007 almost 94% of the data stored worldwide was held digitally: 52% on hard disks, 28% on optical devices and 11% on digital magnetic tape. It has been estimated that the worldwide capacity to store information on electronic devices grew from less than 3 exabytes in 1986 to 295 exabytes in 2007, doubling roughly every 3 years.


==== Databases ====

Database Management Systems (DMS) emerged in the 1960s to address the problem of storing and retrieving large amounts of data accurately and quickly. An early such systems was IBM's Information Management System (IMS), which is still widely deployed more than 50 years later. IMS stores data hierarchically, but in the 1970s Ted Codd proposed an alternative relational storage model based on set theory and predicate logic and the familiar concepts of tables, rows and columns. In 1981, the first commercially available relational database management system (RDBMS) was released by Oracle.All DMS consist of components, they allow the data they store to be accessed simultaneously by many users while maintaining its integrity. All databases are common in one point that the structure of the data they contain is defined and stored separately from the data itself, in a database schema.In recent years, the extensible markup language (XML) has become a popular format for data representation. Although XML data can be stored in normal file systems, it is commonly held in relational databases to take advantage of their ""robust implementation verified by years of both theoretical and practical effort"". As an evolution of the Standard Generalized Markup Language (SGML), XML's text-based structure offers the advantage of being both machine and human-readable.


=== Data retrieval ===
The relational database model introduced a programming-language independent Structured Query Language (SQL), based on relational algebra.
The terms ""data"" and ""information"" are not synonymous. Anything stored is data, but it only becomes information when it is organized and presented meaningfully. Most of the world's digital data is unstructured, and stored in a variety of different physical formats even within a single organization. Data warehouses began to be developed in the 1980s to integrate these disparate stores. They typically contain data extracted from various sources, including external sources such as the Internet, organized in such a way as to facilitate decision support systems (DSS).


=== Data transmission ===
Data transmission has three aspects: transmission, propagation, and reception. It can be broadly categorized as broadcasting, in which information is transmitted unidirectionally downstream, or telecommunications, with bidirectional upstream and downstream channels.XML has been increasingly employed as a means of data interchange since the early 2000s, particularly for machine-oriented interactions such as those involved in web-oriented protocols such as SOAP, describing ""data-in-transit rather than ... data-at-rest"".


=== Data manipulation ===
Hilbert and Lopez identify the exponential pace of technological change (a kind of Moore's law): machines' application-specific capacity to compute information per capita roughly doubled every 14 months between 1986 and 2007; the per capita capacity of the world's general-purpose computers doubled every 18 months during the same two decades; the global telecommunication capacity per capita doubled every 34 months; the world's storage capacity per capita required roughly 40 months to double (every 3 years); and per capita broadcast information has doubled every 12.3 years.Massive amounts of data are stored worldwide every day, but unless it can be analysed and presented effectively it essentially resides in what have been called data tombs: ""data archives that are seldom visited"". To address that issue, the field of data mining – ""the process of discovering interesting patterns and knowledge from large amounts of data"" – emerged in the late 1980s.


== Perspectives ==


=== Academic perspective ===
In an academic context, the Association for Computing Machinery defines IT as ""undergraduate degree programs that prepare students to meet the computer technology needs of business, government, healthcare, schools, and other kinds of organizations .... IT specialists assume responsibility for selecting hardware and software products appropriate for an organization, integrating those products with organizational needs and infrastructure, and installing, customizing, and maintaining those applications for the organization’s computer users.""


=== Commercial and employment perspective ===
Companies in the information technology field are often discussed as a group as the ""tech sector"" or the ""tech industry"".Many companies now have IT departments for managing the computers, networks, and other technical areas of their businesses.
In a business context, the Information Technology Association of America has defined information technology as ""the study, design, development, application, implementation, support or management of computer-based information systems"". The responsibilities of those working in the field include network administration, software development and installation, and the planning and management of an organization's technology life cycle, by which hardware and software are maintained, upgraded and replaced.

		
		
		
		


=== Ethical perspectives ===

The field of information ethics was established by mathematician Norbert Wiener in the 1940s. Some of the ethical issues associated with the use of information technology include:
Breaches of copyright by those downloading files stored without the permission of the copyright holders
Employers monitoring their employees' emails and other Internet usage
Unsolicited emails
Hackers accessing online databases
Web sites installing cookies or spyware to monitor a user's online activities


== See also ==
Center for Minorities and People with Disabilities in Information Technology
Computing
Computer science
Data processing
Health information technology
Information and communications technology (ICT)
Information management
Journal of Cases on Information Technology
Knowledge society
List of the largest information technology companies
Outline of information technology
World Information Technology and Services Alliance


== References ==


=== Notes ===


=== Citations ===


=== Bibliography ===


== Further reading ==
Allen, T.; Morton, M. S. Morton, eds. (1994), Information Technology and the Corporation of the 1990s, Oxford University Press
Gitta, Cosmas and South, David (2011). Southern Innovator Magazine Issue 1: Mobile Phones and Information Technology: United Nations Office for South-South Cooperation. ISSN 2222-9280
Gleick, James (2011).The Information: A History, a Theory, a Flood. New York: Pantheon Books.
Price, Wilson T. (1981), Introduction to Computer Data Processing, Holt-Saunders International Editions, ISBN 978-4-8337-0012-2
Shelly, Gary, Cashman, Thomas, Vermaat, Misty, and Walker, Tim. (1999). Discovering Computers 2000: Concepts for a Connected World. Cambridge, Massachusetts: Course Technology.
Webster, Frank, and Robins, Kevin. (1986). Information Technology – A Luddite Analysis. Norwood, NJ: Ablex.


== External links ==
 Learning materials related to Information technology at Wikiversity
 Media related to Information technology at Wikimedia Commons
 Quotations related to Information technology at Wikiquote"
"A video game is an electronic game that involves interaction with a user interface or input device, such as a joystick, controller, keyboard, or motion sensing devices, to generate visual feedback on a two- or three-dimensional video display device such as a TV set, monitor, touchscreen, or virtual reality headset. Video games are augmented with audio feedback from speakers or headphones, and optionally with other types of feedback systems including haptic technology. 
Video games are defined based on their platform, which include arcade games, console games, and PC games. More recently, the industry has expanded onto mobile gaming through smartphones and tablet computers, and remote cloud gaming. Video games are classified into a wide range of genres based on their type of gameplay and purpose.
The first video games were simple extensions of electronic games using video-like output from large room-size computers in the 1950s and 1960s, while the first video games available to consumers appears in 1972 through way of the Magnavox Odyssey home console, and the 1971 release of the arcade game Computer Space, followed the next year by Pong. Today, video game development requires numerous skills to bring a game to market, including developers, publishers, distributors, retailers, console and other third-party manufacturers, and other roles.
Since the 2010s, the commercial importance of the video game industry has been increasing. The emerging Asian markets and mobile games on smartphones in particular are driving the growth of the industry. As of 2018, video games generated sales of US$134.9 billion annually worldwide, and were the third-largest segment in the U.S. entertainment market, behind broadcast and cable TV.


== Origins ==

Early games used interactive electronic devices with various display formats. The earliest example is from 1947—a ""Cathode ray tube Amusement Device"" was filed for a patent on 25 January 1947, by Thomas T. Goldsmith Jr. and Estle Ray Mann, and issued on 14 December 1948, as U.S. Patent 2455992. Inspired by radar display technology, it consisted of an analog device that allowed a user to control a vector-drawn dot on the screen to simulate a missile being fired at targets, which were drawings fixed to the screen. Other early examples include: Christopher Strachey's Draughts game, the Nimrod computer at the 1951 Festival of Britain; OXO a tic-tac-toe Computer game by Alexander S. Douglas for the EDSAC in 1952; Tennis for Two, an electronic interactive game engineered by William Higinbotham in 1958; Spacewar!, written by MIT students Martin Graetz, Steve Russell, and Wayne Wiitanen's on a DEC PDP-1 computer in 1961; and the hit ping pong-style Pong, a 1972 game by Atari. Each game used different means of display: NIMROD used a panel of lights to play the game of Nim, OXO used a graphical display to play tic-tac-toe Tennis for Two used an oscilloscope to display a side view of a tennis court, and Spacewar! used the DEC PDP-1's vector display to have two spaceships battle each other.

These preliminary inventions paved the way for the origins of video games today. Ralph H. Baer, while working at Sanders Associates in 1966, came up with the idea of using a control system to play a rudimentary game of table tennis on a television screen. With Sanders' blessing, Baer build out the prototype ""Brown Box"". Sanders patented Baer's inventions and licensed them to Magnavox, who commercialized it as the first home video game console, the Magnavox Odyssey, released in 1972. Separately, Nolan Bushnell and Ted Dabney, inspired by seeing Spacewar! running at Stanford University, came up with the idea of creating a similar version running in a smaller cabinet using a less expensive computer with a coin-operated feature. This was released as Computer Space, the first arcade game, in 1971.  Bushnell and Dabney went on to form Atari, Inc., and with Allan Alcorn, created their second arcade game Pong in 1972, which was directly inspired by the table tennis game on the Odyssey. Sanders and Magnavox sued Atari on patent infringement over Baer's patents, but Atari settled out of court, paying for perpetual rights to the patents. Following their agreement, Atari went ahead with plans to make a home version of Pong, while was released by Christmas 1975. The success of the Odyssey and Pong, both as an arcade game and home machine, launched the video game industry. Both Baer and Bushnell have been given the title the ""Father of Video Games"" for their contributions.


== Terminology ==
The term ""video game"" was developed to distinguish this class of electronic games that were played to some type of video display rather than those that used the output of a teletype printer or similar device.The first appearance of the term emerged around 1973. The Oxford English Dictionary cited a November 10, 1973 BusinessWeek article as the first printed use of the term. While Bushnell believed the term came out from a vending magazine review of Computer Space in 1971, a review of the major vending magazines Vending Times and Cashbox showed that the term came much earlier, appearing first around March 1973 in these magazines in mass usage including by the arcade game manufacturers. As analyzed by video game historian Keith Smith, the sudden appearance suggested that the term had been suggested and readily adopted by those involved. This appeared to trace to Ed Adlum, who ran Cashbox's coin-operated section until 1972 and then later founded RePlay Magazine, covering the coin-op amusement field, in 1975. In a September 1982 issue of RePlay, Adlum is credited with first naming these games as ""video games"": ""RePlay's Eddie Adlum worked at 'Cash Box' when 'TV games' first came out. The personalities in those days were Bushnell, his sales manager Pat Karns and a handful of other 'TV game' manufacturers like Henry Leyser and the McEwan brothers. It seemed awkward to call their products 'TV games', so borrowing a word from 'Billboard's description of movie jukeboxes, Adlum started to refer to this new breed of amusement machine as 'video games.' The phrase stuck."" In Japan, where consoles like the Odyssey were first imported and then made within the country by the large television manufacturers such as Toshiba and Sharp Corporation, these were also known as ""TV games"", or TV geemu or terebi geemu.


=== Video game terms ===

As every video game is different, the experience of playing every video game is impossible to summarize, but many common elements exist. Most games will launch into a title screen and give the player a chance to review options such as the number of players before starting a game. Most games are divided into levels which the player must work their avatar through, scoring points, collecting power-ups to boost the avatar's innate attributes, all while either using special attacks to defeat enemies or moves to avoid them. Taking damage will deplete their avatar's health, and if that falls to zero or if the avatar otherwise falls into an impossible-to-escape location, the player will lose one of their lifes. Should they lose all their lives without gaining an extra life or ""1-UP"", then the player will reach the ""game over"" screen. Many levels as well as the game's finale end with a type of boss character the player must defeat to continue on. In some games, intermediate points between levels will offer save points where the player can create a saved game on storage media to restart the game should they lose all their lives or need to stop the game and restart at a later time. These also may be in the form of a passage that can be written down and reentered at the title screen.
As games are software products, they may still ship with software bugs. These can manifest as glitches within the game which may be exploited by the player; this is often the foundation of speedrunning a video game. Other times, these bugs, along with cheat codes, Easter eggs, and other hidden secrets that were intentionally added to the game can also be exploited. On some consoles, cheat cartridges allow players to execute these cheat codes, while user-developed trainers allow similar bypassing for computer software games, both which can make the game easier, give the player additional power-ups, or change the appearance of the game.


== Components of a video game ==


=== Platform ===

Video games require a ""platform"", a specific combination of electronic components or computer hardware and associated software, to operate. The term ""system"" is also commonly used. Games are typically designed to be played on one or a limited number of platforms, and exclusivity to a platform is used as a competitive edge in the video game market. The list below is not exhaustive and excludes other electronic devices capable of playing video games such as PDAs and graphing calculators.

Computer game
Most computer games are PC games, referring to those that involve a player interacting with a personal computer (PC) connected to a video monitor. Personal computers are not dedicated game platforms, so there may be differences running the same game on different hardware. Also, the openness allows some features to developers like reduced software cost, increased flexibility, increased innovation, emulation, creation of modifications (""mods""), open hosting for online gaming (in which a person plays a video game with people who are in a different household) and others. A gaming computer is a PC or laptop intended specifically for gaming typically using high-performance, high-cost components. In additional to personal computer gaming, there also exist games that work on mainframe computers and other similarly shared systems, with users logging in remotely to use the computer.Home console
A ""console game"" is played on a specialized electronic device (""home video game console"") that connects to a common television set or composite video monitor, unlike PCs, which can run all sorts of computer programs, a console is a dedicated video game platform manufactured by a specific company. Usually consoles only run games developed for it, or games from other platform made by the same company, but never games developed by its direct competitor, even if the same game is available on different platforms. It often comes with a specific game controller. Major console platforms include Xbox, PlayStation, and Nintendo.Handheld console
A ""handheld"" gaming device is a small, self-contained electronic device that is portable and can be held in a user's hands. It features the console, a small screen, speakers and buttons, joystick or other game controllers in a single unit. Like consoles, handhelds are dedicated platforms, and share almost the same characteristics. Handheld hardware usually is less powerful than PC or console hardware. Some handheld games from the late 1970s and early 1980s could only play one game. In the 1990s and 2000s, a number of handheld games used cartridges, which enabled them to be used to play many different games.
Arcade game
An arcade game  generally refers to a game played on an even more specialized type of electronic device that is typically designed to play only one game and is encased in a special, large coin-operated cabinet which has one built-in console, controllers (joystick, buttons, etc.), a CRT screen, and audio amplifier and speakers. Arcade games often have brightly painted logos and images relating to the theme of the game. While most arcade games are housed in a vertical cabinet, which the user typically stands in front of to play, some arcade games use a tabletop approach, in which the display screen is housed in a table-style cabinet with a see-through table top. With table-top games, the users typically sit to play. In the 1990s and 2000s, some arcade games offered players a choice of multiple games. In the 1980s, video arcades were businesses in which game players could use a number of arcade video games. In the 2010s, there are far fewer video arcades, but some movie theaters and family entertainment centers still have them.Browser game
A browser game takes advantages of standardizations of technologies for the functionality of web browsers across multiple devices providing a cross-platform environment. These games may be identified based on the website that they appear, such as with ""Miniclip"" games. Others are named based on the programming platform used to develop them, such as Java and Flash games.Mobile game
With the introduction of smartphones and tablet computers standardized on the iOS and Android operating systems, mobile gaming has become a significant platform. These games may utilize unique features of mobile devices that are not necessary present on other platforms, such as global positing information and camera devices to support augmented reality gameplay.
Virtual reality
Virtual reality (VR) games generally require players to use a special head-mounted unit that provides stereoscopic screens and motion tracking to immerse a player within virtual environment that responds to their head movements. Some VR systems include control units for the player's hands as to provide a direct way to interact with the virtual world. VR systems generally require a separate computer, console, or other processing device that couples with the head-mounted unit.Emulation
An emulator enables games from a console or otherwise different system to be run in a type of virtual machine on a modern system, simulating the hardware of the original and allows old games to be played. While emulators themselves have been found to be legal in United States case law, the act of obtaining the game software that one does not already own may violate copyrights. However, there are some official releases of emulated software from game manufacturers, such as Nintendo with its Virtual Console or Nintendo Switch Online offerings.


=== Game media ===
Early arcade games, home consoles, and handheld games were dedicated hardware units with the game's logic built into the electronic componentry of the hardware. Since then, most video game platforms have means to use multiple games distributed on different types of media or formats. Physical formats include ROM cartridges, magnetic storage including magnetic tape data storage and floppy discs, optical media formats including CD-ROM and DVDs, and flash memory cards. Furthermore digital distribution over the Internet or other communication methods as well as cloud gaming alleviate the need for any physical media. In some cases, the media serves as the direct read-only memory for the game, or it may be the form of installation media that is used to write the main assets to the player's platform's local storage for faster loading periods and later updates.
Games can be extended with new content and software patches through either expansion packs which are typically available as physical media, or as downloadable content nominally available via digital distribution. These can be offered freely or can be used to monetize a game following its initial release. Several games offer players the ability to create user-generated content to share with others to play. Other games, mostly those on personal computers, can be extended with user-created modifications or mods that alter or add onto the game; these often are unofficial and were developed by players from reverse engineering of the game, but other games provide official support for modding the game.


=== Controller ===

Video game can use several types of input devices to translate human actions to a game. Most common are the use of game controllers like gamepads and joysticks for most consoles. Handheld consoles will have built in buttons and directional pads, similarly arcade games will have controls built into the console unit itself. Many games on personal computers can take advantage of keyboard and mouse controls. Other game controllers are commonly used for specific games like racing wheels, light guns or dance pads. Digital cameras can also be used as game controllers capturing movements of the body of the player.
As technology continues to advance, more can be added onto the controller to give the player a more immersive experience when playing different games. There are some controllers that have presets so that the buttons are mapped a certain way to make playing certain games easier. Along with the presets, a player can sometimes custom map the buttons to better accommodate their play style. On keyboard and mouse, different actions in the game are already preset to keys on the keyboard. Most games allow the player to change that so that the actions are mapped to different keys that are more to their liking. The companies that design the controllers are trying to make the controller visually appealing and also feel comfortable in the hands of the consumer.
An example of a technology that was incorporated into the controller was the touchscreen. It allows the player to be able to interact with the game differently than before. The person could move around in menus easier and they are also able to interact with different objects in the game. They can pick up some objects, equip others, or even just move the objects out of the player's path. Another example is motion sensor where a person's movement is able to be captured and put into a game. Some motion sensor games are based on where the controller is. The reason for that is because there is a signal that is sent from the controller to the console or computer so that the actions being done can create certain movements in the game. Other type of motion sensor games are webcam style where the player moves around in front of it, and the actions are repeated by a game character.


=== Display and output ===

By definition, all video games are intended to output graphics to an external video display, such as cathode-ray tube televisions, newer liquid-crystal display (LCD) televisions and built-in screens, projectors or computer monitors, depending on the type of platform the game is played on. Features such as color depth, refresh rate, frame rate, and screen resolution are a combination of the limitations of the game platform and display device and the program efficiency of the game itself. The game's output can range from fixed displays using LED or LCD elements, text-based games, two-dimensional and three-dimensional graphics, and augmented reality displays. 
The game's graphics are often accompanied by sound produced by internal speakers on the game platform or external speakers attached to the platform, as directed by the game's programming. This often will include sound effects tied to the player's actions to provide audio feedback, as well as background music for the game. 
Some platforms support additional feedback mechanics to the player that a game can take advantage of. This is most commonly haptic technology built into the game controller, such as causing the controller to shake in the player's hands to simulate a shaking earthquake occurring in game.


== Means of classification ==
Video games are frequently classified by a number of factors related to how one plays them.


=== Genres ===

A video game, like most other forms of media, may be categorized into genres. However, unlike film or television which use visual or narrative elements, video games are generally categorized into genres based on their gameplay interaction, since this is the primary means which one interacts with a video game. The narrative setting does not impact gameplay; a shooter game is still a shooter game, regardless of whether it takes place in a fantasy world or in outer space.Genre names are normally self-describing in terms of the type of gameplay, such as action game, role playing game, or shoot 'em up, though some genres have derivations from influential works that have defined that genre, such as roguelikes from Rogue, Grand Theft Auto clones from Grand Theft Auto III, and battle royale game from the film Battle Royale. The names may shift over time as players, developers and the media come up with new terms; for example, first-person shooters were originally called ""Doom clones"" based on the 1993 game. A hierarchy of game genres exist, with top-level genres like ""shooter game"" and ""action game"" that broadly capture the game's main gameplay style, and several subgenres of specific implementation, such as within the shooter game first-person shooter and third-person shooter. Some cross-genre types also exist that fall until multiple top-level genres such as action-adventure game.


=== Mode ===

A video game's mode describes how many players can use the game at the same type. This is primarily distinguished by single-player video games and multiplayer video games. Within the latter category, multiplayer games can be played in a variety of ways, including locally at the same device, on separate devices connected through a local network such as LAN parties, or online via separate Internet connections. Most multiplayer games are based on competitive gameplay, but many offer cooperative and team-based options as well as asymmetric gameplay. Online games use server structures that can also enable massively multiplayer online games to support hundreds of players at the same time.


=== Intent ===
Most video games are created for entertainment purposes, but there are a small subset of games developed for additional purposes beyond entertainment. These include: 

Casual games
Casual games are designed for easy of accessibility, simple to understand gameplay and quick to grasp rule sets, and aimed at mass market audience, as opposed to a hardcore game. They frequently support the ability to jump in and out of play on demand, such during commuting or lunch breaks. Numerous browser and mobile games fall into the casual game area, and casual games often are from genres with low intensity game elements such as match three, hidden object, time management, and puzzle games. Causal games frequently use social-network game mechanics, where players can enlist the help of friends on their social media networks for extra turns or moves each day. More recent are hyper-casual games which use even more simplistic rules for shore but infinitely replayable games.Educational games
Education software has been used in homes and classrooms to help teach children and students, and video games have been similarly adapted for these reasons, all designed to provide a form of interactivity and entertainment tied to game design elements. There are a variety of differences in their designs and how they educate the user. These are broadly split between edutainment games that tend to focus on the entertainment value and rote learning but are unlikely to engage in critical thinking, and educational video games that are geared towards problem solving through motivation and positive reinforcement while downplaying the entertainment value. Further, games not initially developed for educational purposes have found their way into the classroom after release, often those that feature open worlds or virtual sandboxes, such as Minecraft.
Serious games
Further extending from educational games, serious games are those where the entertainment factor may be augmented, overshadowed, or even eliminated by other purposes for the game. Game design is used to reinforce the non-entertainment purpose of the game, such as using video game technology for the game's interactive world, or gamification for reinforcement training. Educational games are a form of serious games, but other types of serious games include fitness games that incorporate significant physical exercise to help keep the player fit, flight simulators that simulate piloting commercial and military aircraft, advergames that are built around the advertising of a product, and newsgames aimed at conveying a specific advocacy message.


=== Content ratings ===

Video games can be subject to national and international content rating requirements. Like with film content ratings, video game ratings typing identify the target age group that the national or regional ratings board believes is appropriate for the player, ranging from all-ages, to a teenager-or-older, to mature, to the infrequently seen adults-only titles. Most content review is based on the level of violence, both in the type of violence and how graphic it may be represented, and sexual content, but other themes such as drug and alcohol use and gambling that can influence children may also be identified. A primary identifier based on a minimum age is used by nearly all systems, along with additional descriptors to identify specific content that players and parents should be aware of. 
The regulations vary from country to country but generally are voluntary systems upheld by vendor practices, with penalty and fines issued by the ratings body on the video game publisher for misuse of the ratings. Among the major content rating systems include:

Entertainment Software Rating Board (ESRB) that oversees games released in the United States. ESRB ratings are voluntary and rated along a E (Everyone), E10+ (Everyone 10 and older), T (Teen), M (Mature), and AO (Adults Only). Attempts to mandate video games ratings in the U.S. subsequently led to the landmark Supreme Court case, Brown v. Entertainment Merchants Association in 2011 which ruled video games were a protected form of art, a key victory for the video game industry.
Pan European Game Information (PEGI) covering the United Kingdom, most of the European Union and other European countries, replacing previous national-based systems. The PEGI system uses content rated based on minimum recommended ages, which include 3+, 8+, 12+, 16+, and 18+.
Australian Classification Board (ACB) oversees the ratings of games and other works in Australia, using ratings of G (General), PG (Parental Guidance), M (Mature), MA15+ (Mature Accompanied), R18+ (Restricted), and X (Restricted for pornographic material). ACB can also deny to give a rating to game (RC - Refused Classification). The ACB's ratings are enforceable by law, and importantly, games cannot be imported or purchased digitally in Australia if they have failed to gain a rating or were given the RC rating, leading to a number of notable banned games.
Computer Entertainment Rating Organization (CERO) rates games for Japan. Their ratings include A (all ages), B (12 and older), C (15 and over), D (17 and over), and Z (18 and over).Additionally, the major content system provides have worked to create the International Age Rating Coalition (IARC), a means to streamline and align the content ratings system between different region, so that a publisher would only need to complete the content ratings review for one provider, and use the IARC transition to affirm the content rating for all other regions.
Certain nations have even more restrictive rules related to political or ideological content. Notably, China's video game segment is mostly isolated from the rest of the world due to the government's censorship, and all games published there must adhere to strict government review, disallowing content such as smearing the image of the Chinese Communist Party. Foreign games published in China often require modification by developers and publishers to meet these requirements.


== Development ==

Video game development and authorship, much like any other form of entertainment, is frequently a cross-disciplinary field. Video game developers, as employees within this industry are commonly referred, primarily include programmers and graphic designers. Over the years this has expanded to include almost every type of skill that one might see prevalent in the creation of any movie or television program, including sound designers, musicians, and other technicians; as well as skills that are specific to video games, such as the game designer. All of these are managed by producers.
In the early days of the industry, it was more common for a single person to manage all of the roles needed to create a video game. As platforms have become more complex and powerful in the type of material they can present, larger teams have been needed to generate all of the art, programming, cinematography, and more. This is not to say that the age of the ""one-man shop"" is gone, as this is still sometimes found in the casual gaming and handheld markets, where smaller games are prevalent due to technical limitations such as limited RAM or lack of dedicated 3D graphics rendering capabilities on the target platform (e.g., some PDAs).With the growth of the size of development teams in the industry, the problem of cost has increased. Development studios need to be able to pay their staff a competitive wage in order to attract and retain the best talent, while publishers are constantly looking to keep costs down in order to maintain profitability on their investment. Typically, a video game console development team can range in sizes of anywhere from 5 to 50 people, with some teams exceeding 100. In May 2009, one game project was reported to have a development staff of 450. The growth of team size combined with greater pressure to get completed projects into the market to begin recouping production costs has led to a greater occurrence of missed deadlines, rushed games and the release of unfinished products.A newer trend since the mid-2000s is indie game development, small teams outside any direct publisher control, typically making games that are smaller in scope than those from the larger ""AAA"" game studios and more experiment in style. Indie game development are aided by larger availability of digital distribution, including the newer mobile gaming marker, and readily-available development tools for these games.


== Industry ==

Video games have a large network effect that draw on many different sectors that tie into the larger video game industry. While video game developers are a significant portion of the industry, other key participants in the market include:
Publishers: Companies generally that oversee bringing the game from the developer to market. This often includes performing the marketing, public relations, and advertising of the game. Publishers frequently pay the developers ahead of time to make their games and will be involved in critical decisions about the direction of the game's progress, and then pay the developers additional royalties or bonuses based on sales performances. Other smaller, boutique publishers may simply offer to perform the publishing of a game for a small fee and a portion of the sales, and otherwise leave the developer with the creative freedom to proceed. A range of other publisher-developer relationships exist between these points.
Distributors: Publishers often are able to produce their own game media and take the role of distributor, but there are also third-party distributors that can mass produce game media and distribute to retailers. Digital storefronts like Steam and the iOS App Store also serve as distributors and retailers in the digital space.
Retailers: Physical storefronts, which include large online retailers, department and electronic stores, and specialty video game stores, sell games, consoles, and other accessories to consumers. This has also including a trade-in market in certain regions, allowing players to turn in used games for partial refunds or credit towards other games.
Hardware manufacturers: The video game console manufacturers typically require a license to develop for their platform and may control the production of some games, such as Nintendo does with the use of game cartridges for its systems. In exchange, the manufacturers may help promote titles for their system and may seek console exclusivity for certain games. For games on personal computers, a number of manufacturers are devoted to high-performance ""gaming computer"" hardware, particularly in the graphics card area. A range of third-party manufacturers also exist to provide equipment and gear for the console hardware makers, such as additional controllers for console or carrying cases and gear for handheld devices.
Journalism: While journalism around video games used to be primarily print-based, and focused more on post-release reviews and gameplay strategy, the Internet has brought a more proactive press that use web journalism, covering games in the months prior to release as well as beyond, helping to build excitement for games ahead of release.
Influencers: With the rising importance of social media, video game companies have found that the opinions of influencers using streaming media to play through their games has had a significant impact on game sales, and have turned to use influencers alongside traditional journalism as a means to build up attention to their game before release.
Esports: Esports is a major function of several multiplayer games with numerous professional leagues established since the 2000s, with large viewership numbers, particularly out of southeast Asia since the 2010s.
Trade and advocacy groups: Trade groups like the Entertainment Software Association were established to provide a common voice for the industry in response to governmental and other advocacy concerns. They frequently set up the major trade events and conventions for the industry such as E3.
Gamers: The players and consumers of video games, broadly. While their representation in the industry is primarily seen through game sales, many companies follow gamers' comments on social media or on user reviews and engage with them to work to improve their products in addition to other feedback from other parts of the industry.


=== Game sales ===

According to the market research firm SuperData, as of May 2015, the global games market was worth US$74.2 billion. By region, North America accounted for $23.6 billion, Asia for $23.1 billion, Europe for $22.1 billion and South America for $4.5 billion. By market segment, mobile games were worth $22.3 billion, retail games 19.7 billion, free-to-play MMOs 8.7 billion, social games $7.9 billion, PC DLC 7.5 billion, and other categories $3 billion or less each.In the United States, also according to SuperData, the share of video games in the entertainment market grew from 5% in 1985 to 13% in 2015, becoming the third-largest market segment behind broadcast and cable television. The research firm anticipated that Asia would soon overtake North America as the largest video game market due to the strong growth of free-to-play and mobile games.Sales of different types of games vary widely between countries due to local preferences. Japanese consumers tend to purchase much more handheld games than console games and especially PC games, with a strong preference for games catering to local tastes. Another key difference is that, despite the decline of arcades in the West, arcade games remain an important sector of the Japanese gaming industry. In South Korea, computer games are generally preferred over console games, especially MMORPG games and real-time strategy games. Computer games are also popular in China.


=== Copyright of video games ===

Creators will nearly always copyright their games. Laws that define copyright, and the rights that are conveyed over a video game vary from country to country. Usually a fair use copyright clause allows consumers some ancillary rights, such as for a player of the game to stream a game online. This is a vague area in copyright law, as these laws predate the advent of video games. This means that rightsholders often must define what they will allow a consumer to do with the video game.


== Theory ==

Although departments of computer science have been studying the technical aspects of video games for years, theories that examine games as an artistic medium are a relatively recent development in the humanities. The two most visible schools in this emerging field are ludology and narratology. Narrativists approach video games in the context of what Janet Murray calls ""Cyberdrama"". That is to say, their major concern is with video games as a storytelling medium, one that arises out of interactive fiction. Murray puts video games in the context of the Holodeck, a fictional piece of technology from Star Trek, arguing for the video game as a medium in which the player is allowed to become another person, and to act out in another world. This image of video games received early widespread popular support, and forms the basis of films such as Tron, eXistenZ and The Last Starfighter.
Ludologists break sharply and radically from this idea. They argue that a video game is first and foremost a game, which must be understood in terms of its rules, interface, and the concept of play that it deploys. Espen J. Aarseth argues that, although games certainly have plots, characters, and aspects of traditional narratives, these aspects are incidental to gameplay. For example, Aarseth is critical of the widespread attention that narrativists have given to the heroine of the game Tomb Raider, saying that ""the dimensions of Lara Croft's body, already analyzed to death by film theorists, are irrelevant to me as a player, because a different-looking body would not make me play differently... When I play, I don't even see her body, but see through it and past it."" Simply put, ludologists reject traditional theories of art because they claim that the artistic and socially relevant qualities of a video game are primarily determined by the underlying set of rules, demands, and expectations imposed on the player.
While many games rely on emergent principles, video games commonly present simulated story worlds where emergent behavior occurs within the context of the game. The term ""emergent narrative"" has been used to describe how, in a simulated environment, storyline can be created simply by ""what happens to the player."" However, emergent behavior is not limited to sophisticated games. In general, any place where event-driven instructions occur for AI in a game, emergent behavior will exist. For instance, take a racing game in which cars are programmed to avoid crashing, and they encounter an obstacle in the track: the cars might then maneuver to avoid the obstacle causing the cars behind them to slow and/or maneuver to accommodate the cars in front of them and the obstacle. The programmer never wrote code to specifically create a traffic jam, yet one now exists in the game.


== Effects on society ==


=== Culture ===

Video game culture is a worldwide new media subculture formed around video games and game playing. As computer and video games have increased in popularity over time, they have had a significant influence on popular culture. Video game culture has also evolved over time hand in hand with internet culture as well as the increasing popularity of mobile games. Many people who play video games identify as gamers, which can mean anything from someone who enjoys games to someone who is passionate about it. As video games become more social with multiplayer and online capability, gamers find themselves in growing social networks. Gaming can both be entertainment as well as competition, as a new trend known as electronic sports is becoming more widely accepted. In the 2010s, video games and discussions of video game trends and topics can be seen in social media, politics, television, film and music. 

Since the mid-2000s there has been debate whether video games qualify as art, primarily as the form's interactivity interfered with the artistic intent of the work and that they are designed for commercial appeal. A significant debate on the matter came after film critic Roger Ebert published an essay ""Video Games can never be art"", which challenged the industry to prove him and other critics wrong. The view that video games were an art form was cemented in 2011 when the U.S. Supreme Court ruled in the landmark case Brown v. Entertainment Merchants Association that video games were a protected form of speech with artistic merit. Since then, video game developers have come to use the form more for artistic expression, including the development of art games, and the cultural heritage of video games as works of arts, beyond their technical capabilities, have been part of major museum exhibits, including The Art of Video Games at the Smithsonian American Art Museum and toured at other museums from 2012−2016.


=== Beneficial uses of video games ===

Besides their entertainment value, appropriately-designed video games have been seen to provide value in education across several ages and comprehension levels. Learning principles found in video games have been identified as possible techniques with which to reform the U.S. education system. It has been noticed that gamers adopt an attitude while playing that is of such high concentration, they do not realize they are learning, and that if the same attitude could be adopted at school, education would enjoy significant benefits. Students are found to be ""learning by doing"" while playing video games while fostering creative thinking.Video games are also believed to be beneficial to the mind and body. It has been shown that action video game players have better hand–eye coordination and visuo-motor skills, such as their resistance to distraction, their sensitivity to information in the peripheral vision and their ability to count briefly presented objects, than nonplayers. Researchers found that such enhanced abilities could be acquired by training with action games, involving challenges that switch attention between different locations, but not with games requiring concentration on single objects.


=== Controversies surrounding video games ===

Video games have not been without controversy since the 1970s. Parents and children's advocates have raised concerns that violent video games can influence young players into performing those violent acts in real life, and events such as the Columbine High School massacre in 1999 in which the perpetrators specifically alluded to using video games to plot out their attack, raised further fears. Medical experts and mental health professionals have also raised concerned that video games may be addictive, and the World Health Organization has included ""gaming disorder"" in the 11th revision of its International Statistical Classification of Diseases. Other health experts, including the American Psychiatric Association, have stated that there is insufficient evidence that video games can can create violent tendiencies or lead to addictive behavior, though agree that video games typically use a compulsion loop in their core design that can create dopamine that can help reinforce the desire to continue to play through that compulsion loop and potentially lead into violent or addictive behavior. Even with case law establishing that video games qualify as a protected art form, there has been pressure on the video game industry to keep their products in check to avoid over-excessive violence particularly for games aimed at younger children.
Numerous other controversies around video games and its industry have arisen over the years, among the more notable incidents include the 1993 United State Congressional hearings on games like Mortal Kombat which lead to the formation of the ESRB ratings system, numerous legal actions taken by attoney Jack Thompson over violent games such as Grand Theft Auto III and Manhunt from 2003 to 2007, the outrage over the ""No Russian"" level from Call of Duty: Modern Warfare 2 in 2009, and the Gamergate movement in 2014.


== Collecting and preservation ==

Players of video games often maintain collections of games. More recently there has been interest in retrogaming, focusing on games from the first decades. Games in retail packaging in good shape have become collectors items for the early days of the industry, with some rare publications having gone for over US$100,000 as of 2020. Separately, there is also concern about the preservation of video games, as both game media and the hardware to play them degrade over time. Further, many of the game developers and publishers from the first decades no longer exist, so records of their games have disappeared. Archivists and preservations have worked within the scope of copyright law to save these games as part of the cultural history of the industry.

There are many video game museums around the world, including the National Videogame Museum in Frisco, Texas, which serves as the largest museum wholly dedicated to the display and preservation of the industry's most important artifacts. Europe hosts video game museums such as the Computer Games Museum in Berlin and the Museum of Soviet Arcade Machines in Moscow and Saint-Petersburg. The Museum of Art and Digital Entertainment in Oakland, California is a dedicated video game museum focusing on playable exhibits of console and computer games. The Video Game Museum of Rome is also dedicated to preserving video games and their history. The International Center for the History of Electronic Games at The Strong in Rochester, New York contains one of the largest collections of electronic games and game-related historical materials in the world, including a 5,000-square-foot (460 m2) exhibit which allows guests to play their way through the history of video games. The Smithsonian Institution in Washington, DC has three video games on permanent display: Pac-Man, Dragon's Lair, and Pong.The Museum of Modern Art has added a total of 20 video games and one video game console to its permanent Architecture and Design Collection since 2012. In 2012, the Smithsonian American Art Museum ran an exhibition on ""The Art of Video Games"". However, the reviews of the exhibit were mixed, including questioning whether video games belong in an art museum.


== See also ==

Lists of video games
List of accessories to video games by system
Outline of video games


== Notes ==


== References ==


== External links ==

Video games bibliography by the French video game research association Ludoscience
The Virtual Museum of Computing (VMoC)"
"An analog computer or analogue computer is a type of computer that uses the continuously changeable aspects of physical phenomena such as electrical, mechanical, or hydraulic quantities to model the problem being solved. In contrast, digital computers represent varying quantities symbolically and by discrete values of both time and amplitude.
Analog computers can have a very wide range of complexity. Slide rules and nomograms are the simplest, while naval gunfire control computers and large hybrid digital/analog computers were among the most complicated. Systems for process control and protective relays used analog computation to perform control and protective functions.
Analog computers were widely used in scientific and industrial applications even after the advent of digital computers, because at the time they were typically much faster, but they started to become obsolete as early as the 1950s and 1960s, although they remained in use in some specific applications, such as aircraft flight simulators, the flight computer in aircraft, and for teaching control systems in universities. More complex applications, such as aircraft flight simulators and synthetic-aperture radar, remained the domain of analog computing (and hybrid computing) well into the 1980s, since digital computers were insufficient for the task.


== Timeline of analog computers ==


=== Precursors ===

This is a list of examples of early computation devices considered precursors of the modern computers. Some of them may even have been dubbed as 'computers' by the press, though they may fail to fit modern definitions.

The Antikythera mechanism was an orrery and is considered an early mechanical analog computer, according to Derek J. de Solla Price. It was designed to calculate astronomical positions. It was discovered in 1901 in the Antikythera wreck off the Greek island of Antikythera, between Kythera and Crete, and has been dated to c. 100 BC during the Hellenistic period of Greece. Devices of a level of complexity comparable to that of the Antikythera mechanism would not reappear until a thousand years later.
Many mechanical aids to calculation and measurement were constructed for astronomical and navigation use.
The planisphere was first described by Ptolemy in the 2nd century AD. The astrolabe was invented in the Hellenistic world in either the 1st or 2nd centuries BC and is often attributed to Hipparchus. A combination of the planisphere and dioptra, the astrolabe was effectively an analog computer capable of working out several different kinds of problems in spherical astronomy. An astrolabe incorporating a mechanical calendar computer and gear-wheels was invented by Abi Bakr of Isfahan, Persia in 1235. Abū Rayhān al-Bīrūnī invented the first mechanical geared lunisolar calendar astrolabe, an early fixed-wired knowledge processing machine with a gear train and gear-wheels, c. AD 1000. The castle clock, a hydropowered mechanical astronomical clock invented by Al-Jazari in 1206, was the first programmable analog computer.The sector, a calculating instrument used for solving problems in proportion, trigonometry, multiplication and division, and for various functions, such as squares and cube roots, was developed in the late 16th century and found application in gunnery, surveying and navigation.
The planimeter was a manual instrument to calculate the area of a closed figure by tracing over it with a mechanical linkage.

The slide rule was invented around 1620–1630, shortly after the publication of the concept of the logarithm.  It is a hand-operated analog computer for doing multiplication and division. As slide rule development progressed, added scales provided reciprocals, squares and square roots, cubes and cube roots, as well as transcendental functions such as logarithms and exponentials, circular and hyperbolic trigonometry and other functions. Aviation is one of the few fields where slide rules are still in widespread use, particularly for solving time–distance problems in light aircraft.
In 1831–1835, mathematician and engineer Giovanni Plana devised a Perpetual Calendar machine, which, though a system of pulleys and cylinders and over, could predict the perpetual calendar for every year from AD 0 (that is, 1 BC) to AD 4000, keeping track of leap years and varying day length.
The tide-predicting machine invented by Sir William Thomson in 1872 was of great utility to navigation in shallow waters. It used a system of pulleys and wires to automatically calculate predicted tide levels for a set period at a particular location.
The differential analyser, a mechanical analog computer designed to solve differential equations by integration, used wheel-and-disc mechanisms to perform the integration. In 1876 James Thomson had already discussed the possible construction of such calculators, but he had been stymied by the limited output torque of the ball-and-disk integrators. In a differential analyzer, the output of one integrator drove the input of the next integrator, or a graphing output. The torque amplifier was the advance that allowed these machines to work. Starting in the 1920s, Vannevar Bush and others developed mechanical differential analyzers.


=== Modern era ===

The Dumaresq was a mechanical calculating device invented around 1902 by Lieutenant John Dumaresq of the Royal Navy.  It was an analog computer that related vital variables of the fire control problem to the movement of one's own ship and that of a target ship.  It was often used with other devices, such as a Vickers range clock to generate range and deflection data so the gun sights of the ship could be continuously set. A number of versions of the Dumaresq were produced of increasing complexity as development proceeded.
By 1912 Arthur Pollen had developed an electrically driven mechanical analog computer for fire-control systems, based on the differential analyser. It was used by the Imperial Russian Navy in World War I.Starting in 1929, AC network analyzers were constructed to solve calculation problems related to electrical power systems that were too large to solve with numerical methods at the time. These were essentially scale models of the electrical properties of the full-size system. Since network analyzers could handle problems too large for analytic methods or hand computation, they were also used to solve problems in nuclear physics and in the design of structures. More than 50 large network analyzers were built by the end of the 1950s.
World War II era gun directors, gun data computers, and bomb sights used mechanical analog computers. In 1942 Helmut Hölzer built a fully electronic analog computer at Peenemünde Army Research Center as an embedded control system (mixing device) to calculate V-2 rocket trajectories from the accelerations and orientations (measured by gyroscopes) and to stabilize and guide the missile. Mechanical analog computers were very important in gun fire control in World War II, The Korean War and well past the Vietnam War; they were made in significant numbers.
In the period 1930–1945 in the Netherlands Johan van Veen developed an analogue computer to calculate and predict tidal currents when the geometry of the channels are changed. Around 1950 this idea was developed into the Deltar, an analogue computer supporting the closure of estuaries in the southwest of the Netherlands (the Delta Works).
The FERMIAC was an analog computer invented by physicist Enrico Fermi in 1947 to aid in his studies of neutron transport. Project Cyclone was an analog computer developed by Reeves in 1950 for the analysis and design of dynamic systems. Project Typhoon was an analog computer developed by RCA in 1952. It consisted of over 4000 electron tubes and used 100 dials and 6000 plug-in connectors to program. The MONIAC Computer was a hydraulic model of a national economy first unveiled in 1949.Computer Engineering Associates was spun out of Caltech in 1950 to provide commercial services using the ""Direct Analogy Electric Analog Computer"" (""the largest and most impressive general-purpose analyzer facility for the solution of field problems"") developed there by Gilbert D. McCann, Charles H. Wilts, and Bart Locanthi.Educational analog computers illustrated the principles of analog calculation. The Heathkit EC-1, a $199 educational analog computer, was made by the Heath Company, US c. 1960. It was programmed using patch cords that connected nine operational amplifiers and other components. General Electric also marketed an ""educational"" analog computer kit of a simple design in the early 1960s consisting of a two transistor tone generators and three potentiometers wired such that the frequency of the oscillator was nulled when the potentiometer dials were positioned by hand to satisfy an equation. The relative resistance of the potentiometer was then equivalent to the formula of the equation being solved. Multiplication or division could be performed, depending on which dials were inputs and which was the output. Accuracy and resolution was limited and a simple slide rule was more accurate—however, the unit did demonstrate the basic principle.
Analog computer designs were published in electronics magazines. One example is the PE Analogue Computer, published in Practical Electronics in the September 1978 edition. Another more modern hybrid computer design was published in Everyday Practical Electronics in 2002. An example described in the EPE Hybrid Computer was the flight of a VTOL aircraft like the Harrier jump jet. The altitude and speed of the aircraft were calculated by the analog part of the computer and sent to a PC via a digital microprocessor and displayed on the PC screen.
In industrial process control, analog loop controllers were used to automatically regulate temperature, flow, pressure, or other process conditions. The technology of these controllers ranged from purely mechanical integrators, through vacuum-tube and solid-state devices, to emulation of analog controllers by microprocessors.


== Electronic analog computers ==

The similarity between linear mechanical components, such as springs and dashpots (viscous-fluid dampers), and electrical components, such as capacitors, inductors, and resistors is striking in terms of mathematics. They can be modeled using equations of the same form.
However, the difference between these systems is what makes analog computing useful. If one considers a simple mass–spring system, constructing the physical system would require making or modifying the springs and masses. This would be followed by attaching them to each other and an appropriate anchor, collecting test equipment with the appropriate input range, and finally, taking measurements. In more complicated cases, such as suspensions for racing cars, experimental construction, modification, and testing is both complicated and expensive.
The electrical equivalent can be constructed with a few operational amplifiers (op amps) and some passive linear components; all measurements can be taken directly with an oscilloscope. In the circuit, the (simulated) 'stiffness of the spring', for instance, can be changed by adjusting the parameters of a capacitor. The electrical system is an analogy to the physical system, hence the name, but it is less expensive to construct, generally safer, and typically much easier to modify.
As well, an electronic circuit can typically operate at higher frequencies than the system being simulated. This allows the simulation to run faster than real time (which could, in some instances, be hours, weeks, or longer). Experienced users of electronic analog computers said that they offered a comparatively intimate control and understanding of the problem, relative to digital simulations.
The drawback of the mechanical-electrical analogy is that electronics are limited by the range over which the variables may vary due to the fixed supply voltage. Therefore, each problem must be scaled to its parameters and dimensions—e.g., the expected magnitudes of the velocity and the position of a spring pendulum. Improperly scaled problems might suffer from higher noise levels. Floating-point digital calculations have a huge dynamic range but might also suffer from imprecision if tiny differences of huge values lead to numerical instability.
These electric circuits can also easily perform a wide variety of simulations. For example, voltage can simulate water pressure and electric current can simulate rate of flow in terms of cubic metres per second. An integrator can provide the total accumulated volume of liquid, using an input current proportional to the (possibly varying) flow rate.

Analog computers are especially well-suited to representing situations described by differential equations. Occasionally, they were used when a system of differential equations proved very difficult to solve by traditional means. As a simple example, the dynamics of a spring-mass system can be described by the equation 
  
    
      
        m
        
          
            
              y
              ¨
            
          
        
        +
        d
        
          
            
              y
              ˙
            
          
        
        +
        c
        y
        =
        m
        g
      
    
    {\displaystyle m{\ddot {y}}+d{\dot {y}}+cy=mg}
  , with 
  
    
      
        y
      
    
    {\displaystyle y}
   as the vertical position of a mass 
  
    
      
        m
      
    
    {\displaystyle m}
  , 
  
    
      
        d
      
    
    {\displaystyle d}
   the damping coefficient, 
  
    
      
        c
      
    
    {\displaystyle c}
   the spring constant and 
  
    
      
        g
      
    
    {\displaystyle g}
   the gravity of Earth. For analog computing, the equation is programmed as 
  
    
      
        
          
            
              y
              ¨
            
          
        
        =
        −
        
          
            
              d
              m
            
          
        
        
          
            
              y
              ˙
            
          
        
        −
        
          
            
              c
              m
            
          
        
        y
        −
        g
      
    
    {\displaystyle {\ddot {y}}=-{\tfrac {d}{m}}{\dot {y}}-{\tfrac {c}{m}}y-g}
  . The equivalent analog circuit consists of two integrators for the state variables 
  
    
      
        −
        
          
            
              y
              ˙
            
          
        
      
    
    {\displaystyle -{\dot {y}}}
   (speed) and 
  
    
      
        y
      
    
    {\displaystyle y}
   (position), one inverter, and three potentiometers. The circuit has to consider that both integration and addition units invert the signal polarity.
The accuracy of an analog computer is limited by its computing elements as well as quality of the internal power and electrical interconnections. The precision of the analog computer readout was limited chiefly by the precision of the readout equipment used, generally three or four significant figures. The precision of a digital computer is limited by the word size; arbitrary-precision arithmetic, while relatively slow, provides any practical degree of precision that might be needed. However, in most cases the precision of an analog computer is absolutely sufficient given the uncertainty of the model characteristics and its technical parameters.
Many small computers dedicated to specific computations are still part of industrial regulation equipment, but from the 1950s to the 1970s, general-purpose analog computers were the only systems fast enough for real time simulation of dynamic systems, especially in the aircraft, military and aerospace field.
In the 1960s, the major manufacturer was Electronic Associates of Princeton, New Jersey, with its 231R Analog Computer (vacuum tubes, 20 integrators) and subsequently its EAI 8800 Analog Computer (solid state operational amplifiers, 64 integrators). Its challenger was Applied Dynamics of Ann Arbor, Michigan.
Although the basic technology for analog computers is usually operational amplifiers (also called ""continuous current amplifiers"" because they have no low frequency limitation), in the 1960s an attempt was made in the French ANALAC computer to use an alternative technology: medium frequency carrier and non dissipative reversible circuits.
In the 1970s every big company and administration concerned with problems in dynamics had a big analog computing center, for example:

In the US: NASA (Huntsville, Houston), Martin Marietta (Orlando), Lockheed, Westinghouse, Hughes Aircraft
In Europe: CEA (French Atomic Energy Commission), MATRA, Aérospatiale, BAC (British Aircraft Corporation).


== Analog–digital hybrids ==
Analog computing devices are fast, digital computing devices are more versatile and accurate, so the idea is to combine the two processes for the best efficiency. An example of such hybrid elementary device is the hybrid multiplier where one input is an analog signal, the other input is a digital signal and the output is analog. It acts as an analog potentiometer upgradable digitally.  This kind of hybrid technique is mainly used for fast dedicated real time computation when computing time is very critical as signal processing for radars and generally for controllers in embedded systems.
In the early 1970s analog computer manufacturers tried to tie together their analog computer with a digital computer to get the advantages of the two techniques.  In such systems, the digital computer controlled the analog computer, providing initial set-up, initiating multiple analog runs, and automatically feeding and collecting data. The digital computer may also participate to the calculation itself using analog-to-digital and digital-to-analog converters.
The largest manufacturer of hybrid computers was Electronics Associates. Their hybrid computer model 8900 was made of a digital computer and one or more analog consoles. These systems were mainly dedicated to large projects such as the Apollo program and Space Shuttle at NASA, or Ariane in Europe, especially during the integration step where at the beginning everything is simulated, and progressively real components replace their simulated part.Only one company was known as offering general commercial computing services on its hybrid computers, CISI of France, in the 1970s.
The best reference in this field is the 100,000 simulations runs for each certification of the automatic landing systems of Airbus and Concorde aircraft.After 1980, purely digital computers progressed more and more rapidly and were fast enough to compete with analog computers.
One key to the speed of analog computers was their fully parallel computation, but this was also a limitation. The more equations required for a problem, the more analog components were needed, even when the problem wasn't time critical. ""Programming"" a problem meant interconnecting the analog operators; even with a removable wiring panel this was not very versatile. Today there are no more big hybrid computers, but only hybrid components.


== Implementations ==


=== Mechanical analog computers ===

While a wide variety of mechanisms have been developed throughout history, some stand out because of their theoretical importance, or because they were manufactured in significant quantities.
Most practical mechanical analog computers of any significant complexity used rotating shafts to carry variables from one mechanism to another. Cables and pulleys were used in a Fourier synthesizer, a tide-predicting machine, which summed the individual harmonic components. Another category, not nearly as well known, used rotating shafts only for input and output, with precision racks and pinions. The racks were connected to linkages that performed the computation. At least one US Naval sonar fire control computer of the later 1950s, made by Librascope, was of this type, as was the principal computer in the Mk. 56 Gun Fire Control System.
Online, there is a remarkably clear illustrated reference (OP 1140) that describes the fire control computer mechanisms.
For adding and subtracting, precision miter-gear differentials were in common use in some computers; the Ford Instrument Mark I Fire Control Computer contained about 160 of them.
Integration with respect to another variable was done by a rotating disc driven by one variable. Output came from a pickoff device (such as a wheel) positioned at a radius on the disc proportional to the second variable. (A carrier with a pair of steel balls supported by small rollers worked especially well. A roller, its axis parallel to the disc's surface, provided the output. It was held against the pair of balls by a spring.)
Arbitrary functions of one variable were provided by cams, with gearing to convert follower movement to shaft rotation.
Functions of two variables were provided by three-dimensional cams. In one good design, one of the variables rotated the cam. A hemispherical follower moved its carrier on a pivot axis parallel to that of the cam's rotating axis. Pivoting motion was the output. The second variable moved the follower along the axis of the cam. One practical application was ballistics in gunnery.
Coordinate conversion from polar to rectangular was done by a mechanical resolver (called a ""component solver"" in US Navy fire control computers). Two discs on a common axis positioned a sliding block with pin (stubby shaft) on it. One disc was a face cam, and a follower on the block in the face cam's groove set the radius. The other disc, closer to the pin, contained a straight slot in which the block moved. The input angle rotated the latter disc (the face cam disc, for an unchanging radius, rotated with the other (angle) disc; a differential and a few gears did this correction).
Referring to the mechanism's frame, the location of the pin corresponded to the tip of the vector represented by the angle and magnitude inputs. Mounted on that pin was a square block.
Rectilinear-coordinate outputs (both sine and cosine, typically) came from two slotted plates, each slot fitting on the block just mentioned. The plates moved in straight lines, the movement of one plate at right angles to that of the other. The slots were at right angles to the direction of movement. Each plate, by itself, was like a Scotch yoke, known to steam engine enthusiasts.
During World War II, a similar mechanism converted rectilinear to polar coordinates, but it was not particularly successful and was eliminated in a significant redesign (USN, Mk. 1 to Mk. 1A).
Multiplication was done by mechanisms based on the geometry of similar right triangles. Using the trigonometric terms for a right triangle, specifically opposite, adjacent, and hypotenuse, the adjacent side was fixed by construction. One variable changed the magnitude of the opposite side. In many cases, this variable changed sign; the hypotenuse could coincide with the adjacent side (a zero input), or move beyond the adjacent side, representing a sign change.
Typically, a pinion-operated rack moving parallel to the (trig.-defined) opposite side would position a slide with a slot coincident with the hypotenuse. A pivot on the rack let the slide's angle change freely. At the other end of the slide (the angle, in trig, terms), a block on a pin fixed to the frame defined the vertex between the hypotenuse and the adjacent side.
At any distance along the adjacent side, a line perpendicular to it intersects the hypotenuse at a particular point. The distance between that point and the adjacent side is some fraction that is the product of 1 the distance from the vertex, and 2 the magnitude of the opposite side.
The second input variable in this type of multiplier positions a slotted plate perpendicular to the adjacent side. That slot contains a block, and that block's position in its slot is determined by another block right next to it. The latter slides along the hypotenuse, so the two blocks are positioned at a distance from the (trig.) adjacent side by an amount proportional to the product.
To provide the product as an output, a third element, another slotted plate, also moves parallel to the (trig.) opposite side of the theoretical triangle. As usual, the slot is perpendicular to the direction of movement. A block in its slot, pivoted to the hypotenuse block positions it.
A special type of integrator, used at a point where only moderate accuracy was needed, was based on a steel ball, instead of a disc. It had two inputs, one to rotate the ball, and the other to define the angle of the ball's rotating axis. That axis was always in a plane that contained the axes of two movement-pickoff rollers, quite similar to the mechanism of a rolling-ball computer mouse (in this mechanism, the pickoff rollers were roughly the same diameter as the ball). The pickoff roller axes were at right angles.
A pair of rollers ""above"" and ""below"" the pickoff plane were mounted in rotating holders that were geared together. That gearing was driven by the angle input, and established the rotating axis of the ball. The other input rotated the ""bottom"" roller to make the ball rotate.
Essentially, the whole mechanism, called a component integrator, was a variable-speed drive with one motion input and two outputs, as well as an angle input. The angle input varied the ratio (and direction) of coupling between the ""motion"" input and the outputs according to the sine and cosine of the input angle.
Although they did not accomplish any computation, electromechanical position servos were essential in mechanical analog computers of the ""rotating-shaft"" type for providing operating torque to the inputs of subsequent computing mechanisms, as well as driving output data-transmission devices such as large torque-transmitter synchros in naval computers.
Other non-computational mechanisms included internal odometer-style counters with interpolating drum dials for indicating internal variables, and mechanical multi-turn limit stops.
Considering that accurately controlled rotational speed in analog fire-control computers was a basic element of their accuracy, there was a motor with its average speed controlled by a balance wheel, hairspring, jeweled-bearing differential, a twin-lobe cam, and spring-loaded contacts (ship's AC power frequency was not necessarily accurate, nor dependable enough, when these computers were designed).


=== Electronic analog computers ===

Electronic analog computers typically have front panels with numerous jacks (single-contact sockets) that permit patch cords (flexible wires with plugs at both ends) to create the interconnections that define the problem setup. In addition, there are precision high-resolution potentiometers (variable resistors) for setting up (and, when needed, varying) scale factors. In addition, there is usually a zero-center analog pointer-type meter for modest-accuracy voltage measurement. Stable, accurate voltage sources provide known magnitudes.
Typical electronic analog computers contain anywhere from a few to a hundred or more operational amplifiers (""op amps""), named because they perform mathematical operations. Op amps are a particular type of feedback amplifier with very high gain and stable input (low and stable offset). They are always used with precision feedback components that, in operation, all but cancel out the currents arriving from input components. The majority of op amps in a representative setup are summing amplifiers, which add and subtract analog voltages, providing the result at their output jacks. As well, op amps with capacitor feedback are usually included in a setup; they integrate the sum of their inputs with respect to time.
Integrating with respect to another variable is the nearly exclusive province of mechanical analog integrators; it is almost never done in electronic analog computers. However, given that a problem solution does not change with time, time can serve as one of the variables.
Other computing elements include analog multipliers, nonlinear function generators, and analog comparators.
Electrical elements such as inductors and capacitors used in electrical analog computers had to be carefully manufactured to reduce non-ideal effects.  For example, in the construction of AC power network analyzers, one motive for using higher frequencies for the calculator (instead of the actual power frequency) was that higher-quality inductors could be more easily made. Many general-purpose analog computers avoided the use of inductors entirely, re-casting the problem in a form that could be solved using only resistive and capacitive elements, since high-quality capacitors are relatively easy to make.
The use of electrical properties in analog computers means that calculations are normally performed in real time (or faster), at a speed determined mostly by the frequency response of the operational amplifiers and other computing elements. In the history of electronic analog computers, there were some special high-speed types.
Nonlinear functions and calculations can be constructed to a limited precision (three or four digits) by designing function generators—special circuits of various combinations of resistors and diodes to provide the nonlinearity. Typically, as the input voltage increases, progressively more diodes conduct.
When compensated for temperature, the forward voltage drop of a transistor's base-emitter junction can provide a usably accurate logarithmic or exponential function. Op amps scale the output voltage so that it is usable with the rest of the computer.
Any physical process that models some computation can be interpreted as an analog computer. Some examples, invented for the purpose of illustrating the concept of analog computation, include using a bundle of spaghetti as a model of sorting numbers; a board, a set of nails, and a rubber band as a model of finding the convex hull of a set of points; and strings tied together as a model of finding the shortest path in a network. These are all described in Dewdney (1984).


== Components ==

Analog computers often have a complicated framework, but they have, at their core, a set of key components that perform the calculations. The operator manipulates these through the computer's framework.
Key hydraulic components might include pipes, valves and containers.
Key mechanical components might include rotating shafts for carrying data within the computer, miter gear differentials, disc/ball/roller integrators, cams (2-D and 3-D), mechanical resolvers and multipliers, and torque servos.
Key electrical/electronic components might include:

Precision resistors and capacitors
operational amplifiers
Multipliers
potentiometers
fixed-function generatorsThe core mathematical operations used in an electric analog computer are:

addition
integration with respect to time
inversion
multiplication
exponentiation
logarithm
divisionIn some analog computer designs, multiplication is much preferred to division. Division is carried out with a multiplier in the feedback path of an Operational Amplifier.
Differentiation with respect to time is not frequently used, and in practice is avoided by redefining the problem when possible. It corresponds in the frequency domain to a high-pass filter, which means that high-frequency noise is amplified; differentiation also risks instability.


== Limitations ==
In general, analog computers are limited by non-ideal effects. An analog signal is composed of four basic components: DC and AC magnitudes, frequency, and phase. The real limits of range on these characteristics limit analog computers. Some of these limits include the operational amplifier offset, finite gain, and frequency response, noise floor, non-linearities, temperature coefficient, and parasitic effects within semiconductor devices. For commercially available electronic components, ranges of these aspects of input and output signals are always figures of merit.


== Decline ==
In the 1950s to 1970s, digital computers based on first vacuum tubes, transistors, integrated circuits and then micro-processors became more economical and precise. This led digital computers to largely replace analog computers. Even so, some research in analog computation is still being done. A few universities still use analog computers to teach control system theory. The American company Comdyna manufactured small analog computers. At Indiana University Bloomington, Jonathan Mills has developed the Extended Analog Computer based on sampling voltages in a foam sheet. At the Harvard Robotics Laboratory, analog computation is a research topic. Lyric Semiconductor's error correction circuits use analog probabilistic signals. Slide rules are still popular among aircraft personnel.


== Resurgence ==
With the development of very-large-scale integration (VLSI) technology, Yannis Tsividis' group at Columbia University has been revisiting analog/hybrid computers design in standard CMOS process. Two VLSI chips have been developed, an 80th-order analog computer (250 nm) by Glenn Cowan in 2005 and a 4th-order hybrid computer (65 nm) developed by Ning Guo in 2015, both targeting at energy-efficient ODE/PDE applications. Glenn's chip contains 16 macros, in which there are 25 analog computing blocks, namely integrators, multipliers, fanouts, few nonlinear blocks. Ning's chip contains one macro block, in which there are 26 computing blocks including integrators, multipliers, fanouts, ADCs, SRAMs and DACs. Arbitrary nonlinear function generation is made possible by the ADC+SRAM+DAC chain, where the SRAM block stores the nonlinear function data. The experiments from the related publications revealed that VLSI analog/hybrid computers demonstrated about 1–2 orders magnitude of advantage in both solution time and energy while achieving accuracy within 5%, which points to the promise of using analog/hybrid computing techniques in the area of energy-efficient approximate computing. In 2016, a team of researchers developed a compiler to solve differential equations using analog circuits.


== Practical examples ==

These are examples of analog computers that have been constructed or practically used:

Analog (audio) synthesizers can also be viewed as a form of analog computer, and their technology was originally based in part on electronic analog computer technology. The ARP 2600's Ring Modulator was actually a moderate-accuracy analog multiplier.
The Simulation Council (or Simulations Council) was an association of analog computer users in US. It is now known as The Society for Modeling and Simulation International. The Simulation Council newsletters from 1952 to 1963 are available online and show the concerns and technologies at the time, and the common use of analog computers for missilry.


== See also ==
Analog neural network
Analogical models
Chaos theory
Differential equation
Dynamical system
Field-programmable analog array
General purpose analog computer
Lotfernrohr 7 series of WW II German bombsights
Signal (electrical engineering)
Voskhod Spacecraft ""Globus"" IMP navigation instrument
XY-writer


== Notes ==


== References ==
A.K. Dewdney. ""On the Spaghetti Computer and Other Analog Gadgets for Problem Solving"", Scientific American, 250(6):19–26, June 1984. Reprinted in The Armchair Universe, by A.K. Dewdney, published by W.H. Freeman & Company (1988), ISBN 0-7167-1939-8.
Universiteit van Amsterdam Computer Museum. (2007). Analog Computers.
Jackson, Albert S., ""Analog Computation"". London & New York: McGraw-Hill, 1960. OCLC 230146450


== External links ==
Biruni's eight-geared lunisolar calendar in ""Archaeology: High tech from Ancient Greece"", François Charette, Nature 444, 551–552(30 November 2006), doi:10.1038/444551a
The first computers
Large collection of electronic analog computers with lots of pictures, documentation and samples of implementations (some in German)
Large collection of old analog and digital computers at Old Computer Museum
A great disappearing act: the electronic analogue computer Chris Bissell, The Open University, Milton Keynes, UK Accessed February 2007
German computer museum with still runnable analog computers
Analog computer basics
Analog computer trumps Turing model
Jonathan W. Mills's Analog Notebook
Harvard Robotics Laboratory Analog Computation
The Enns Power Network Computer – an analog computer for the analysis of electric power systems (advertisement from 1955)
Librascope Development Company – Type LC-1 WWII Navy PV-1 ""Balance Computor""
– Kronis Technology More information on Analog and Hybrid computers"
"Computer security, cybersecurity or information technology security (IT security) is the protection of computer systems and networks from the theft of or damage to their hardware, software, or electronic data, as well as from the disruption or misdirection of the services they provide.
The field is becoming more important due to increased reliance on computer systems, the Internet and wireless network standards such as Bluetooth and Wi-Fi, and due to the growth of ""smart"" devices, including smartphones, televisions, and the various devices that constitute the ""Internet of things"". Owing to its complexity, both in terms of politics and technology, cybersecurity is also one of the major challenges in the contemporary world.


== Vulnerabilities and attacks ==

A vulnerability is a weakness in design, implementation, operation, or internal control. Most of the vulnerabilities that have been discovered are documented in the Common Vulnerabilities and Exposures (CVE) database. An exploitable vulnerability is one for which at least one working attack or ""exploit"" exists. Vulnerabilities can be researched, reverse-engineered, hunted, or exploited using automated tools or customized scripts. To secure a computer system, it is important to understand the attacks that can be made against it, and these threats can typically be classified into one of these categories below:


=== Backdoor ===
A backdoor in a computer system, a cryptosystem or an algorithm, is any secret method of bypassing normal authentication or security controls. They may exist for a number of reasons, including by original design or from poor configuration. They may have been added by an authorised party to allow some legitimate access, or by an attacker for malicious reasons; but regardless of the motives for their existence, they create a vulnerability.  Backdoors can be very hard to detect, and detection of backdoors are usually discovered by someone who has access to application source code or intimate knowledge of the computer's Operating System.


=== Denial-of-service attack ===
Denial of service attacks (DoS) are designed to make a machine or network resource unavailable to its intended users. Attackers can deny service to individual victims, such as by deliberately entering a wrong password enough consecutive times to cause the victim's account to be locked, or they may overload the capabilities of a machine or network and block all users at once. While a network attack from a single IP address can be blocked by adding a new firewall rule, many forms of Distributed denial of service (DDoS) attacks are possible, where the attack comes from a large number of points – and defending is much more difficult. Such attacks can originate from the zombie computers of a botnet or from a range of other possible techniques, including reflection and amplification attacks, where innocent systems are fooled into sending traffic to the victim.


=== Direct-access attacks ===
An unauthorized user gaining physical access to a computer is most likely able to directly copy data from it. They may also compromise security by making operating system modifications, installing software worms, keyloggers, covert listening devices or using wireless mice. Even when the system is protected by standard security measures, these may be able to be by-passed by booting another operating system or tool from a CD-ROM or other bootable media. Disk encryption and Trusted Platform Module are designed to prevent these attacks.


=== Eavesdropping ===
Eavesdropping is the act of surreptitiously listening to a private computer ""conversation"" (communication), typically between hosts on a network. For instance, programs such as Carnivore and NarusInSight have been used by the FBI and NSA to eavesdrop on the systems of internet service providers. Even machines that operate as a closed system (i.e., with no contact to the outside world) can be eavesdropped upon via monitoring the faint electromagnetic transmissions generated by the hardware; TEMPEST is a specification by the NSA referring to these attacks.


=== Multi-vector, polymorphic attacks ===
Surfacing in 2017, a new class of multi-vector, polymorphic cyber threats surfaced that combined several types of attacks and changed form to avoid cybersecurity controls as they spread. These threats have been classified as fifth-generation cyberattacks.


=== Phishing ===

Phishing is the attempt to acquire sensitive information such as usernames, passwords, and credit card details directly from users by deceiving the users. Phishing is typically carried out by email spoofing or instant messaging, and it often directs users to enter details at a fake website whose ""look"" and ""feel"" are almost identical to the legitimate one. The fake website often asks for personal information, such as log-in details and passwords. This information can then be used to gain access to the individual's real account on the real website. Preying on a victim's trust, phishing can be classified as a form of social engineering.  Attackers are using creative ways to gain access to real accounts.  A common scam is for attackers to send fake electronic invoices to individuals showing that they recently purchased music, apps, or other, and instructing them to click on a link if the purchases were not authorized.


=== Privilege escalation ===
Privilege escalation describes a situation where an attacker with some level of restricted access is able to, without authorization, elevate their privileges or access level. For example, a standard computer user may be able to exploit a vulnerability in the system to gain access to restricted data; or even become ""root"" and have full unrestricted access to a system.


=== Reverse engineering ===
Reverse engineering is the process by which a man-made object is deconstructed to reveal its designs, code, architecture, or to extract knowledge from the object; similar to scientific research, the only difference being that scientific research is about a natural phenomenon.


=== Social engineering ===
Social engineering, insofar as computer security is concerned, aims to convince a user to disclose secrets such as passwords, card numbers, etc. by, for example, impersonating a bank, a contractor, or a customer.Social engineering, in the context of information security, is the psychological manipulation of people into performing actions or divulging confidential information.
A common scam involves fake CEO emails sent to accounting and finance departments. In early 2016, the FBI reported that the scam has cost US businesses more than $2 billion in about two years.In May 2016, the Milwaukee Bucks NBA team was the victim of this type of cyber scam with a perpetrator impersonating the team's president Peter Feigin, resulting in the handover of all the team's employees' 2015 W-2 tax forms.


=== Spoofing ===

Spoofing is the act of masquerading as a valid entity through falsification of data (such as an IP address or username), in order to gain access to information or resources that one is otherwise unauthorized to obtain. There are several types of spoofing, including:

Email spoofing, where an attacker forges the sending (From, or source) address of an email.
IP address spoofing, where an attacker alters the source IP address in a network packet to hide their identity or impersonate another computing system.
MAC spoofing, where an attacker modifies the Media Access Control (MAC) address of their network interface to pose as a valid user on a network.
Biometric spoofing, where an attacker produces a fake biometric sample to pose as another user.


=== Tampering ===
Tampering describes a malicious modification or alteration of data. So-called Evil Maid attacks and security services planting of surveillance capability into routers are examples.


== Information security culture ==
Employee behavior can have a big impact on information security in organizations. Cultural concepts can help different segments of the organization work effectively or work against effectiveness towards information security within an organization. Information security culture is the ""...totality of patterns of behavior in an organization that contributes to the protection of information of all kinds.″Andersson and Reimers (2014) found that employees often do not see themselves as part of their organization's information security effort and often take actions that impede organizational changes. Research shows information security culture needs to be improved continuously. In ″Information Security Culture from Analysis to Change″, authors commented, ″It's a never-ending process, a cycle of evaluation and change or maintenance.″ To manage the information security culture, five steps should be taken: pre-evaluation, strategic planning, operative planning, implementation, and post-evaluation.
Pre-Evaluation: to identify the awareness of information security within employees and to analyze the current security policy.
Strategic Planning: to come up with a better awareness program, clear targets need to be set. Assembling a team of skilled professionals is helpful to achieve it.
Operative Planning: a good security culture can be established based on internal communication, management-buy-in, and security awareness and a training program.
Implementation: four stages should be used to implement the information security culture. They are:Commitment of the management
Communication with organizational members
Courses for all organizational members
Commitment of the employeesPost-Evaluation: to assess the success of the planning and implementation, and to identify unresolved areas of concern.


== Systems at risk ==
The growth in the number of computer systems and the increasing reliance upon them by individuals, businesses, industries, and governments means that there is an increasing number of systems at risk.


=== Financial systems ===
The computer systems of financial regulators and financial institutions like the U.S. Securities and Exchange Commission, SWIFT, investment banks, and commercial banks are prominent hacking targets for cybercriminals interested in manipulating markets and making illicit gains. Web sites and apps that accept or store credit card numbers, brokerage accounts, and bank account information are also prominent hacking targets, because of the potential for immediate financial gain from transferring money, making purchases, or selling the information on the black market. In-store payment systems and ATMs have also been tampered with in order to gather customer account data and PINs.


=== Utilities and industrial equipment ===
Computers control functions at many utilities, including coordination of telecommunications, the power grid, nuclear power plants, and valve opening and closing in water and gas networks. The Internet is a potential attack vector for such machines if connected, but the Stuxnet worm demonstrated that even equipment controlled by computers not connected to the Internet can be vulnerable. In 2014, the Computer Emergency Readiness Team, a division of the Department of Homeland Security, investigated 79 hacking incidents at energy companies. Vulnerabilities in smart meters (many of which use local radio or cellular communications) can cause problems with billing fraud.


=== Aviation ===
The aviation industry is very reliant on a series of complex systems which could be attacked. A simple power outage at one airport can cause repercussions worldwide, much of the system relies on radio transmissions which could be disrupted, and controlling aircraft over oceans is especially dangerous because radar surveillance only extends 175 to 225 miles offshore. There is also potential for attack from within an aircraft.In Europe, with the (Pan-European Network Service) and NewPENS, and in the US with the NextGen program, air navigation service providers are moving to create their own dedicated networks.
The consequences of a successful attack range from loss of confidentiality to loss of system integrity, air traffic control outages, loss of aircraft, and even loss of life.


=== Consumer devices ===
Desktop computers and laptops are commonly targeted to gather passwords or financial account information, or to construct a botnet to attack another target. Smartphones, tablet computers, smart watches, and other mobile devices such as quantified self devices like activity trackers have sensors such as cameras, microphones, GPS receivers, compasses, and accelerometers which could be exploited, and may collect personal information, including sensitive health information. WiFi, Bluetooth, and cell phone networks on any of these devices could be used as attack vectors, and sensors might be remotely activated after a successful breach.The increasing number of home automation devices such as the Nest thermostat are also potential targets.


=== Large corporations ===
Large corporations are common targets. In many cases attacks are aimed at financial gain through identity theft and involve data breaches. Examples include loss of millions of clients' credit card details by Home Depot, Staples, Target Corporation, and the most recent breach of Equifax.Some cyberattacks are ordered by foreign governments, which engage in cyberwarfare with the intent to spread their propaganda, sabotage, or spy on their targets. Many people believe the Russian government played a major role in the US presidential election of 2016 by using Twitter and Facebook to affect the results of the election.Medical records have been targeted in general identify theft, health insurance fraud, and impersonating patients to obtain prescription drugs for recreational purposes or resale. Although cyber threats continue to increase, 62% of all organizations did not increase security training for their business in 2015.Not all attacks are financially motivated, however: security firm HBGary Federal suffered a serious series of attacks in 2011 from hacktivist group Anonymous in retaliation for the firm's CEO claiming to have infiltrated their group, and Sony Pictures was hacked in 2014 with the apparent dual motive of embarrassing the company through data leaks and crippling the company by wiping workstations and servers.


=== Automobiles ===

Vehicles are increasingly computerized, with engine timing, cruise control, anti-lock brakes, seat belt tensioners, door locks, airbags and advanced driver-assistance systems on many models. Additionally, connected cars may use WiFi and Bluetooth to communicate with onboard consumer devices and the cell phone network. Self-driving cars are expected to be even more complex.
All of these systems carry some security risk, and such issues have gained wide attention. Simple examples of risk include a malicious compact disc being used as an attack vector, and the car's onboard microphones being used for eavesdropping. However, if access is gained to a car's internal controller area network, the danger is much greater – and in a widely publicized 2015 test, hackers remotely carjacked a vehicle from 10 miles away and drove it into a ditch.Manufacturers are reacting in a number of ways, with Tesla in 2016 pushing out some security fixes ""over the air"" into its cars' computer systems.In the area of autonomous vehicles, in September 2016 the United States Department of Transportation announced some initial safety standards, and called for states to come up with uniform policies.


=== Government ===
Government and military computer systems are commonly attacked by activists and foreign powers. Local and regional government infrastructure such as traffic light controls, police and intelligence agency communications, personnel records, student records, and financial systems are also potential targets as they are now all largely computerized. Passports and government ID cards that control access to facilities which use RFID can be vulnerable to cloning.


=== Internet of things and physical vulnerabilities ===
The Internet of things (IoT) is the network of physical objects such as devices, vehicles, and buildings that are embedded with electronics, software, sensors, and network connectivity that enables them to collect and exchange data – and concerns have been raised that this is being developed without appropriate consideration of the security challenges involved.While the IoT creates opportunities for more direct integration of the physical world into computer-based systems,
it also provides opportunities for misuse. In particular, as the Internet of Things spreads widely, cyberattacks are likely to become an increasingly physical (rather than simply virtual) threat. If a front door's lock is connected to the Internet, and can be locked/unlocked from a phone, then a criminal could enter the home at the press of a button from a stolen or hacked phone. People could stand to lose much more than their credit card numbers in a world controlled by IoT-enabled devices. Thieves have also used electronic means to circumvent non-Internet-connected hotel door locks.An attack that targets physical infrastructure and/or human lives is classified as a Cyber-kinetic attack. As IoT devices and appliances gain currency, cyber-kinetic attacks can become pervasive and significantly damaging.


==== Medical systems ====

Medical devices have either been successfully attacked or had potentially deadly vulnerabilities demonstrated, including both in-hospital diagnostic equipment and implanted devices including pacemakers and insulin pumps. There are many reports of hospitals and hospital organizations getting hacked, including ransomware attacks, Windows XP exploits, viruses, and data breaches of sensitive data stored on hospital servers. On 28 December 2016 the US Food and Drug Administration released its recommendations for how medical device manufacturers should maintain the security of Internet-connected devices – but no structure for enforcement.


=== Energy sector ===
In distributed generation systems, the risk of a cyber attack is real, according to Daily Energy Insider. An attack could cause a loss of power in a large area for a long period of time, and such an attack could have just as severe consequences as a natural disaster. The District of Columbia is considering creating a Distributed Energy Resources (DER) Authority within the city, with the goal being for customers to have more insight into their own energy use and giving the local electric utility, Pepco, the chance to better estimate energy demand. The D.C. proposal, however, would ""allow third-party vendors to create numerous points of energy distribution, which could potentially create more opportunities for cyber attackers to threaten the electric grid.""


== Impact of security breaches ==
Serious financial damage has been caused by security breaches, but because there is no standard model for estimating the cost of an incident, the only data available is that which is made public by the organizations involved. ""Several computer security consulting firms produce estimates of total worldwide losses attributable to virus and worm attacks and to hostile digital acts in general. The 2003 loss estimates by these firms range from $13 billion (worms and viruses only) to $226 billion (for all forms of covert attacks). The reliability of these estimates is often challenged; the underlying methodology is basically anecdotal."" Security breaches continue to cost businesses billions of dollars but a survey revealed that 66% of security staffs do not believe senior leadership takes cyber precautions as a strategic priority.However, reasonable estimates of the financial cost of security breaches can actually help organizations make rational investment decisions. According to the classic Gordon-Loeb Model analyzing the optimal investment level in information security, one can conclude that the amount a firm spends to protect information should generally be only a small fraction of the expected loss (i.e., the expected value of the loss resulting from a cyber/information security breach).


== Attacker motivation ==
As with physical security, the motivations for breaches of computer security vary between attackers. Some are thrill-seekers or vandals, some are activists, others are criminals looking for financial gain. State-sponsored attackers are now common and well resourced but started with amateurs such as Markus Hess who hacked for the KGB, as recounted by Clifford Stoll in The Cuckoo's Egg.
Additionally, recent attacker motivations can be traced back to extremist organizations seeking to gain political advantage or disrupt social agendas. The growth of the internet, mobile technologies, and inexpensive computing devices have led to a rise in capabilities but also to the risk to environments that are deemed as vital to operations. All critical targeted environments are susceptible to compromise and this has led to a series of proactive studies on how to migrate the risk by taking into consideration motivations by these types of actors. Several stark differences exist between the hacker motivation and that of nation state actors seeking to attack based an ideological preference.A standard part of threat modeling for any particular system is to identify what might motivate an attack on that system, and who might be motivated to breach it. The level and detail of precautions will vary depending on the system to be secured. A home personal computer, bank, and classified military network face very different threats, even when the underlying technologies in use are similar.


== Computer protection (countermeasures) ==
In computer security a countermeasure is an action, device, procedure or technique that reduces a threat, a vulnerability, or an attack by eliminating or preventing it, by minimizing the harm it can cause, or by discovering and reporting it so that corrective action can be taken.Some common countermeasures are listed in the following sections:


=== Security by design ===

Security by design, or alternately secure by design, means that the software has been designed from the ground up to be secure. In this case, security is considered as a main feature.
Some of the techniques in this approach include:

The principle of least privilege, where each part of the system has only the privileges that are needed for its function. That way even if an attacker gains access to that part, they have only limited access to the whole system.
Automated theorem proving to prove the correctness of crucial software subsystems.
Code reviews and unit testing, approaches to make modules more secure where formal correctness proofs are not possible.
Defense in depth, where the design is such that more than one subsystem needs to be violated to compromise the integrity of the system and the information it holds.
Default secure settings, and design to ""fail secure"" rather than ""fail insecure"" (see fail-safe for the equivalent in safety engineering). Ideally, a secure system should require a deliberate, conscious, knowledgeable and free decision on the part of legitimate authorities in order to make it insecure.
Audit trails tracking system activity, so that when a security breach occurs, the mechanism and extent of the breach can be determined. Storing audit trails remotely, where they can only be appended to, can keep intruders from covering their tracks.
Full disclosure of all vulnerabilities, to ensure that the ""window of vulnerability"" is kept as short as possible when bugs are discovered.


=== Security architecture ===
The Open Security Architecture organization defines IT security architecture as ""the design artifacts that describe how the security controls (security countermeasures) are positioned, and how they relate to the overall information technology architecture. These controls serve the purpose to maintain the system's quality attributes: confidentiality, integrity, availability, accountability and assurance services"".Techopedia defines security architecture as ""a unified security design that addresses the necessities and potential risks involved in a certain scenario or environment. It also specifies when and where to apply security controls. The design process is generally reproducible."" The key attributes of security architecture are:
the relationship of different components and how they depend on each other.
the determination of controls based on risk assessment, good practice, finances, and legal matters.
the standardization of controls.Practicing security architecture provides the right foundation to systematically address business, IT and security concerns in an organization.


=== Security measures ===
A state of computer ""security"" is the conceptual ideal, attained by the use of the three processes: threat prevention, detection, and response. These processes are based on various policies and system components, which include the following:

User account access controls and cryptography can protect systems files and data, respectively.
Firewalls are by far the most common prevention systems from a network security perspective as they can (if properly configured) shield access to internal network services, and block certain kinds of attacks through packet filtering. Firewalls can be both hardware- or software-based.
Intrusion Detection System (IDS) products are designed to detect network attacks in-progress and assist in post-attack forensics, while audit trails and logs serve a similar function for individual systems.
""Response"" is necessarily defined by the assessed security requirements of an individual system and may cover the range from simple upgrade of protections to notification of legal authorities, counter-attacks, and the like. In some special cases, the complete destruction of the compromised system is favored, as it may happen that not all the compromised resources are detected.Today, computer security comprises mainly ""preventive"" measures, like firewalls or an exit procedure. A firewall can be defined as a way of filtering network data between a host or a network and another network, such as the Internet, and can be implemented as software running on the machine, hooking into the network stack (or, in the case of most UNIX-based operating systems such as Linux, built into the operating system kernel) to provide real-time filtering and blocking. Another implementation is a so-called ""physical firewall"", which consists of a separate machine filtering network traffic. Firewalls are common amongst machines that are permanently connected to the Internet.
Some organizations are turning to big data platforms, such as Apache Hadoop, to extend data accessibility and machine learning to detect advanced persistent threats.However, relatively few organizations maintain computer systems with effective detection systems, and fewer still have organized response mechanisms in place. As a result, as Reuters points out: ""Companies for the first time report they are losing more through electronic theft of data than physical stealing of assets"". The primary obstacle to effective eradication of cybercrime could be traced to excessive reliance on firewalls and other automated ""detection"" systems. Yet it is basic evidence gathering by using packet capture appliances that puts criminals behind bars.
In order to ensure adequate security, the confidentiality, integrity and availability of a network, better known as the CIA triad, must be protected and is considered the foundation to information security. To achieve those objectives, administrative, physical and technical security measures should be employed. The amount of security afforded to an asset can only be determined when its value is known.


=== Vulnerability management ===

Vulnerability management is the cycle of identifying, and remediating or mitigating vulnerabilities, especially in software and firmware. Vulnerability management is integral to computer security and network security.  
Vulnerabilities can be discovered with a vulnerability scanner, which analyzes a computer system in search of known vulnerabilities, such as open ports, insecure software configuration, and susceptibility to malware.  In order for these tools to be effective, they must be kept up to date with every new update the vendors release.  Typically, these updates will scan for the new vulnerabilities that were introduced recently.  
Beyond vulnerability scanning, many organizations contract outside security auditors to run regular penetration tests against their systems to identify vulnerabilities. In some sectors, this is a contractual requirement.


=== Reducing vulnerabilities ===
While formal verification of the correctness of computer systems is possible, it is not yet common. Operating systems formally verified include seL4, and SYSGO's PikeOS – but these make up a very small percentage of the market.
Two factor authentication is a method for mitigating unauthorized access to a system or sensitive information. It requires ""something you know""; a password or PIN, and ""something you have""; a card, dongle, cellphone, or another piece of hardware. This increases security as an unauthorized person needs both of these to gain access.
Social engineering and direct computer access (physical) attacks can only be prevented by non-computer means, which can be difficult to enforce, relative to the sensitivity of the information. Training is often involved to help mitigate this risk, but even in highly disciplined environments (e.g. military organizations), social engineering attacks can still be difficult to foresee and prevent.
Inoculation, derived from inoculation theory, seeks to prevent social engineering and other fraudulent tricks or traps by instilling a resistance to persuasion attempts through exposure to similar or related attempts.It is possible to reduce an attacker's chances by keeping systems up to date with security patches and updates, using a security scanner and/or hiring people with expertise in security, though none of these guarantee the prevention of an attack. The effects of data loss/damage can be reduced by careful backing up and insurance.


=== Hardware protection mechanisms ===

While hardware may be a source of insecurity, such as with microchip vulnerabilities maliciously introduced during the manufacturing process, hardware-based or assisted computer security also offers an alternative to software-only computer security. Using devices and methods such as dongles, trusted platform modules, intrusion-aware cases, drive locks, disabling USB ports, and mobile-enabled access may be considered more secure due to the physical access (or sophisticated backdoor access) required in order to be compromised. Each of these is covered in more detail below.

USB dongles are typically used in software licensing schemes to unlock software capabilities, but they can also be seen as a way to prevent unauthorized access to a computer or other device's software. The dongle, or key, essentially creates a secure encrypted tunnel between the software application and the key. The principle is that an encryption scheme on the dongle, such as Advanced Encryption Standard (AES) provides a stronger measure of security since it is harder to hack and replicate the dongle than to simply copy the native software to another machine and use it. Another security application for dongles is to use them for accessing web-based content such as cloud software or Virtual Private Networks (VPNs). In addition, a USB dongle can be configured to lock or unlock a computer.
Trusted platform modules (TPMs) secure devices by integrating cryptographic capabilities onto access devices, through the use of microprocessors, or so-called computers-on-a-chip. TPMs used in conjunction with server-side software offer a way to detect and authenticate hardware devices, preventing unauthorized network and data access.
Computer case intrusion detection refers to a device, typically a push-button switch, which detects when a computer case is opened. The firmware or BIOS is programmed to show an alert to the operator when the computer is booted up the next time.
Drive locks are essentially software tools to encrypt hard drives, making them inaccessible to thieves. Tools exist specifically for encrypting external drives as well.
Disabling USB ports is a security option for preventing unauthorized and malicious access to an otherwise secure computer. Infected USB dongles connected to a network from a computer inside the firewall are considered by the magazine Network World as the most common hardware threat facing computer networks.
Disconnecting or disabling peripheral devices ( like camera, GPS, removable storage etc.), that are not in use.
Mobile-enabled access devices are growing in popularity due to the ubiquitous nature of cell phones. Built-in capabilities such as Bluetooth, the newer Bluetooth low energy (LE), Near field communication (NFC) on non-iOS devices and biometric validation such as thumb print readers, as well as QR code reader software designed for mobile devices, offer new, secure ways for mobile phones to connect to access control systems. These control systems provide computer security and can also be used for controlling access to secure buildings.


=== Secure operating systems ===

One use of the term ""computer security"" refers to technology that is used to implement secure operating systems. In the 1980s the United States Department of Defense (DoD) used the ""Orange Book"" standards, but the current international standard ISO/IEC 15408, ""Common Criteria"" defines a number of progressively more stringent Evaluation Assurance Levels. Many common operating systems meet the EAL4 standard of being ""Methodically Designed, Tested and Reviewed"", but the formal verification required for the highest levels means that they are uncommon. An example of an EAL6 (""Semiformally Verified Design and Tested"") system is Integrity-178B, which is used in the Airbus A380
and several military jets.


=== Secure coding ===

In software engineering, secure coding aims to guard against the accidental introduction of security vulnerabilities. It is also possible to create software designed from the ground up to be secure. Such systems are ""secure by design"". Beyond this, formal verification aims to prove the correctness of the algorithms underlying a system;
important for cryptographic protocols for example.


=== Capabilities and access control lists ===

Within computer systems, two of many security models capable of enforcing privilege separation are access control lists (ACLs) and capability-based security. Using ACLs to confine programs has been proven to be insecure in many situations, such as if the host computer can be tricked into indirectly allowing restricted file access, an issue known as the confused deputy problem. It has also been shown that the promise of ACLs of giving access to an object to only one person can never be guaranteed in practice. Both of these problems are resolved by capabilities. This does not mean practical flaws exist in all ACL-based systems, but only that the designers of certain utilities must take responsibility to ensure that they do not introduce flaws.Capabilities have been mostly restricted to research operating systems, while commercial OSs still use ACLs. Capabilities can, however, also be implemented at the language level, leading to a style of programming that is essentially a refinement of standard object-oriented design. An open-source project in the area is the E language.


=== End user security training ===
The end-user is widely recognized as the weakest link in the security chain and it is estimated that more than 90% of security incidents and breaches involve some kind of human error. Among the most commonly recorded forms of errors and misjudgment are poor password management, sending emails containing sensitive data and attachments to the wrong recipient, the inability to recognize misleading URLs and to identify fake websites and dangerous email attachments.  A common mistake that users make is saving their userid/password in their browsers to make it easier to log in to banking sites.  This is a gift to attackers who have obtained access to a machine by some means.  The risk may be mitigated by the use of two-factor authentication.As the human component of cyber risk is particularly relevant in determining the global cyber risk an organization is facing, security awareness training, at all levels, not only provides formal compliance with regulatory and industry mandates but is considered essential in reducing cyber risk and protecting individuals and companies from the great majority of cyber threats.
The focus on the end-user represents a profound cultural change for many security practitioners, who have traditionally approached cybersecurity exclusively from a technical perspective, and moves along the lines suggested by major security centers to develop a culture of cyber awareness within the organization, recognizing that a security-aware user provides an important line of defense against cyber attacks.


=== Digital hygiene ===
Related to end-user training, digital hygiene or cyber hygiene is a fundamental principle relating to information security and, as the analogy with personal hygiene shows, is the equivalent of establishing simple routine measures to minimize the risks from cyber threats. The assumption is that good cyber hygiene practices can give networked users another layer of protection, reducing the risk that one vulnerable node will be used to either mount attacks or compromise another node or network, especially from common cyberattacks.As opposed to a purely technology-based defense against threats, cyber hygiene mostly regards routine measures that are technically simple to implement and mostly dependent on discipline or education. It can be thought of as an abstract list of tips or measures that have been demonstrated as having a positive effect on personal and/or collective digital security. As such, these measures can be performed by laypeople, not just security experts. 
Cyber hygiene relates to personal hygiene as computer viruses relate to biological viruses (or pathogens). However, while the term computer virus was coined almost simultaneously with the creation of the first working computer viruses, the term cyber hygiene is a much later invention, perhaps as late as 2000 by Internet pioneer Vint Cerf. It has since been adopted by the Congress and Senate of the United States, the FBI, EU institutions and heads of state.Cyber hygiene should also not be mistaken for proactive cyber defence, a military term.


=== Response to breaches ===
Responding forcefully to attempted security breaches (in the manner that one would for attempted physical security breaches) is often very difficult for a variety of reasons:

Identifying attackers is difficult, as they are often in a different jurisdiction to the systems they attempt to breach and operate through proxies, temporary anonymous dial-up accounts, wireless connections, and other anonymizing procedures which make backtracing difficult and are often located in yet another jurisdiction. If they successfully breach security, they are often able to delete logs to cover their tracks.
The sheer number of attempted attacks is so large that organizations cannot spend time pursuing each attacker (a typical home user with a permanent (e.g., cable modem) connection will be attacked at least several times per day, so more attractive targets could be presumed to see many more). Note, however, that most of the sheer bulk of these attacks are made by automated vulnerability scanners and computer worms.
Law enforcement officers are often unfamiliar with information technology, and so lack the skills and interest in pursuing attackers. There are also budgetary constraints. It has been argued that the high cost of technology, such as DNA testing and improved forensics, mean less money for other kinds of law enforcement, so the overall rate of criminals not getting dealt with goes up as the cost of the technology increases. In addition, the identification of attackers across a network may require logs from various points in the network and in many countries, the release of these records to law enforcement (with the exception of being voluntarily surrendered by a network administrator or a system administrator) requires a search warrant and, depending on the circumstances, the legal proceedings required can be drawn out to the point where the records are either regularly destroyed, or the information is no longer relevant.
The United States government spends the largest amount of money every year on cybersecurity. The United States has a yearly budget of 28 billion dollars. Canada has the 2nd highest annual budget at 1 billion dollars. Australia has the third-highest budget with only 70 million dollars.


=== Types of security and privacy ===


== Incident response planning ==
Incident response is an organized approach to addressing and managing the aftermath of a computer security incident or compromise with the goal of preventing a breach or thwarting a cyberattack. An incident that is not identified and managed at the time of intrusion typically escalates to a more damaging event such as a data breach or system failure. The intended outcome of a computer security incident response plan is to limit damage and reduce recovery time and costs. Responding to compromises quickly can mitigate exploited vulnerabilities, restore services and processes and minimize losses.
Incident response planning allows an organization to establish a series of best practices to stop an intrusion before it causes damage. Typical incident response plans contain a set of written instructions that outline the organization's response to a cyberattack. Without a documented plan in place, an organization may not successfully detect an intrusion or compromise and stakeholders may not understand their roles, processes and procedures during an escalation, slowing the organization's response and resolution.
There are four key components of a computer security incident response plan:

Preparation: Preparing stakeholders on the procedures for handling computer security incidents or compromises
Detection & Analysis: Identifying and investigating suspicious activity to confirm a security incident, prioritizing the response based on impact and coordinating notification of the incident
Containment, Eradication & Recovery: Isolating affected systems to prevent escalation and limit impact, pinpointing the genesis of the incident, removing malware, affected systems and bad actors from the environment and restoring systems and data when a threat no longer remains
Post Incident Activity: Post mortem analysis of the incident, its root cause and the organization's response with the intent of improving the incident response plan and future response efforts


== Notable attacks and breaches ==

Some illustrative examples of different types of computer security breaches are given below.


=== Robert Morris and the first computer worm ===

In 1988, only 60,000 computers were connected to the Internet, and most were mainframes, minicomputers and professional workstations. On 2 November 1988, many started to slow down, because they were running a malicious code that demanded processor time and that spread itself to other computers – the first internet ""computer worm"". The software was traced back to 23-year-old Cornell University graduate student Robert Tappan Morris, Jr. who said ""he wanted to count how many machines were connected to the Internet"".


=== Rome Laboratory ===
In 1994, over a hundred intrusions were made by unidentified crackers into the Rome Laboratory, the US Air Force's main command and research facility. Using trojan horses, hackers were able to obtain unrestricted access to Rome's networking systems and remove traces of their activities. The intruders were able to obtain classified files, such as air tasking order systems data and furthermore able to penetrate connected networks of National Aeronautics and Space Administration's Goddard Space Flight Center, Wright-Patterson Air Force Base, some Defense contractors, and other private sector organizations, by posing as
a trusted Rome center user.


=== TJX customer credit card details ===
In early 2007, American apparel and home goods company TJX announced that it was the victim of an unauthorized computer systems intrusion and that the hackers had accessed a system that stored data on credit card, debit card, check, and merchandise return transactions.


=== Stuxnet attack ===
In 2010 the computer worm known as Stuxnet reportedly ruined almost one-fifth of Iran's nuclear centrifuges. It did so by disrupting industrial programmable logic controllers (PLCs) in a targeted attack. This is generally believed to have been launched by Israel and the United States to disrupt Iranian's nuclear program – although neither has publicly admitted this.


=== Global surveillance disclosures ===

In early 2013, documents provided by Edward Snowden were published by The Washington Post and The Guardian exposing the massive scale of NSA global surveillance. There were also indications that the NSA may have inserted a backdoor in a NIST standard for encryption. This standard was later withdrawn due to widespread criticism. The NSA additionally were revealed to have tapped the links between Google's data centres.


=== Target and Home Depot breaches ===
In 2013 and 2014, a Russian/Ukrainian hacking ring known as ""Rescator"" broke into Target Corporation computers in 2013, stealing roughly 40 million credit cards, and then Home Depot computers in 2014, stealing between 53 and 56 million credit card numbers. Warnings were delivered at both corporations, but ignored; physical security breaches using self checkout machines are believed to have played a large role. ""The malware utilized is absolutely unsophisticated and uninteresting,"" says Jim Walter, director of threat intelligence operations at security technology company McAfee – meaning that the heists could have easily been stopped by existing antivirus software had administrators responded to the warnings. The size of the thefts has resulted in major attention from state and Federal United States authorities and the investigation is ongoing.


=== Office of Personnel Management data breach ===
In April 2015, the Office of Personnel Management discovered it had been hacked more than a year earlier in a data breach, resulting in the theft of approximately 21.5 million personnel records handled by the office. The Office of Personnel Management hack has been described by federal officials as among the largest breaches of government data in the history of the United States. Data targeted in the breach included personally identifiable information such as Social Security Numbers, names, dates and places of birth, addresses, and fingerprints of current and former government employees as well as anyone who had undergone a government background check. It is believed the hack was perpetrated by Chinese hackers.


=== Ashley Madison breach ===

In July 2015, a hacker group known as ""The Impact Team"" successfully breached the extramarital relationship website Ashley Madison, created by Avid Life Media. The group claimed that they had taken not only company data but user data as well. After the breach, The Impact Team dumped emails from the company's CEO, to prove their point, and threatened to dump customer data unless the website was taken down permanently."" When Avid Life Media did not take the site offline the group released two more compressed files, one 9.7GB and the second 20GB. After the second data dump, Avid Life Media CEO Noel Biderman resigned; but the website remained functioning.


== Legal issues and global regulation ==
International legal issues of cyber attacks are complicated in nature. There is no global base of common rules to judge, and eventually punish, cybercrimes and cybercriminals - and where security firms or agencies do locate the cybercriminal behind the creation of a particular piece of malware or form of cyber attack, often the local authorities cannot take action due to lack of laws under which to prosecute. Proving attribution for cybercrimes and cyberattacks is also a major problem for all law enforcement agencies. ""Computer viruses switch from one country to another, from one jurisdiction to another – moving around the world, using the fact that we don't have the capability to globally police operations like this. So the Internet is as if someone [had] given free plane tickets to all the online criminals of the world."" The use of techniques such as dynamic DNS, fast flux and bullet proof servers add to the difficulty of investigation and enforcement.


== Role of government ==
The role of the government is to make regulations to force companies and organizations to protect their systems, infrastructure and information from any cyberattacks, but also to protect its own national infrastructure such as the national power-grid.The government's regulatory role in cyberspace is complicated. For some, cyberspace was seen virtual space that was to remain free of government intervention, as can be seen in many of today's libertarian blockchain and bitcoin discussions.Many government officials and experts think that the government should do more and that there is a crucial need for improved regulation, mainly due to the failure of the private sector to solve efficiently the cybersecurity problem. R. Clarke said during a panel discussion at the RSA Security Conference in San Francisco, he believes that the ""industry only responds when you threaten regulation. If the industry doesn't respond (to the threat), you have to follow through.""
On the other hand, executives from the private sector agree that improvements are necessary, but think that government intervention would affect their ability to innovate efficiently. Daniel R. McCarthy analyzed this public-private partnership in cybersecurity and reflected on the role of cybersecurity in the broader constitution of political order.On May 22, 2020, the UN Security Council held its second ever informal meeting on cybersecurity to focus on cyber challenges to international peace. According to UN Secretary-General António Guterres, new technologies are too often used to violate rights.


== International actions ==
Many different teams and organisations exist, including:

The Forum of Incident Response and Security Teams (FIRST) is the global association of CSIRTs. The US-CERT, AT&T, Apple, Cisco, McAfee, Microsoft are all members of this international team.
The Council of Europe helps protect societies worldwide from the threat of cybercrime through the Convention on Cybercrime.
The purpose of the Messaging Anti-Abuse Working Group (MAAWG) is to bring the messaging industry together to work collaboratively and to successfully address the various forms of messaging abuse, such as spam, viruses, denial-of-service attacks and other messaging exploitations. France Telecom, Facebook, AT&T, Apple, Cisco, Sprint are some of the members of the MAAWG.
ENISA : The European Network and Information Security Agency (ENISA) is an agency of the European Union with the objective to improve network and information security in the European Union.


=== Europe ===
On 14 April 2016 the European Parliament and Council of the European Union adopted The General Data Protection Regulation (GDPR) (EU) 2016/679. GDPR, which became enforceable beginning 25 May 2018, provides for data protection and privacy for all individuals within the European Union (EU) and the European Economic Area (EEA). GDPR requires that business processes that handle personal data be built with data protection by design and by default. GDPR also requires that certain organizations appoint a Data Protection Officer (DPO).


== National actions ==


=== Computer emergency response teams ===

Most countries have their own computer emergency response team to protect network security.


==== Canada ====
Since 2010, Canada has had a cybersecurity strategy. This functions as a counterpart document to the National Strategy and Action Plan for Critical Infrastructure. The strategy has three main pillars: securing government systems, securing vital private cyber systems, and helping Canadians to be secure online. There is also a Cyber Incident Management Framework to provide a coordinated response in the event of a cyber incident.The Canadian Cyber Incident Response Centre (CCIRC) is responsible for mitigating and responding to threats to Canada's critical infrastructure and cyber systems. It provides support to mitigate cyber threats, technical support to respond and recover from targeted cyber attacks, and provides online tools for members of Canada's critical infrastructure sectors. It posts regular cybersecurity bulletins and operates an online reporting tool where individuals and organizations can report a cyber incident.To inform the general public on how to protect themselves online, Public Safety Canada has partnered with STOP.THINK.CONNECT, a coalition of non-profit, private sector, and government organizations, and launched the Cyber Security Cooperation Program. They also run the GetCyberSafe portal for Canadian citizens, and Cyber Security Awareness Month during October.Public Safety Canada aims to begin an evaluation of Canada's cybersecurity strategy in early 2015.


==== China ====
China's Central Leading Group for Internet Security and Informatization (Chinese: 中央网络安全和信息化领导小组) was established on 27 February 2014. This Leading Small Group (LSG) of the Communist Party of China is headed by General Secretary Xi Jinping himself and is staffed with relevant Party and state decision-makers. The LSG was created to overcome the incoherent policies and overlapping responsibilities that characterized China's former cyberspace decision-making mechanisms. The LSG oversees policy-making in the economic, political, cultural, social and military fields as they relate to network security and IT strategy. This LSG also coordinates major policy initiatives in the international arena that promote norms and standards favored by the Chinese government and that emphasizes the principle of national sovereignty in cyberspace.


==== Germany ====
Berlin starts National Cyber Defense Initiative:
On 16 June 2011, the German Minister for Home Affairs, officially opened the new German NCAZ (National Center for Cyber Defense) Nationales Cyber-Abwehrzentrum located in Bonn. The NCAZ closely cooperates with BSI (Federal Office for Information Security) Bundesamt für Sicherheit in der Informationstechnik, BKA (Federal Police Organisation) Bundeskriminalamt (Deutschland), BND (Federal Intelligence Service) Bundesnachrichtendienst, MAD (Military Intelligence Service) Amt für den Militärischen Abschirmdienst and other national organizations in Germany taking care of national security aspects. According to the Minister the primary task of the new organization founded on 23 February 2011, is to detect and prevent attacks against the national infrastructure and mentioned incidents like Stuxnet. Germany has also established the largest research institution for IT security in Europe, the Center for Research in Security and Privacy (CRISP) in Darmstadt.


==== India ====
Some provisions for cybersecurity have been incorporated into rules framed under the Information Technology Act 2000.The National Cyber Security Policy 2013 is a policy framework by Ministry of Electronics and Information Technology (MeitY) which aims to protect the public and private infrastructure from cyberattacks, and safeguard ""information, such as personal information (of web users), financial and banking information and sovereign data"". CERT- In is the nodal agency which monitors the cyber threats in the country. The post of National Cyber Security Coordinator has also been created in the Prime Minister's Office (PMO).
The Indian Companies Act 2013 has also introduced cyber law and cybersecurity obligations on the part of Indian directors.
Some provisions for cybersecurity have been incorporated into rules framed under the Information Technology Act 2000 Update in 2013.


==== South Korea ====
Following cyber attacks in the first half of 2013, when the government, news media, television station, and bank websites were compromised, the national government committed to the training of 5,000 new cybersecurity experts by 2017. The South Korean government blamed its northern counterpart for these attacks, as well as incidents that occurred in 2009, 2011, and 2012, but Pyongyang denies the accusations.


==== United States ====


===== Legislation =====
The 1986 18 U.S.C. § 1030, the Computer Fraud and Abuse Act is the key legislation. It prohibits unauthorized access or damage of ""protected computers"" as defined in 18 U.S.C. § 1030(e)(2). Although various other measures have been proposed – none has succeeded.
In 2013, executive order 13636 Improving Critical Infrastructure Cybersecurity was signed, which prompted the creation of the NIST Cybersecurity Framework
Standardized Government Testing Services
The General Services Administration (GSA) has standardized the ""penetration test"" service as a pre-vetted support service, to rapidly address potential vulnerabilities, and stop adversaries before they impact US federal, state and local governments. These services are commonly referred to as Highly Adaptive Cybersecurity Services (HACS) and are listed at the US GSA Advantage website. See more information here: Penetration test: Standardized government penetration test services.


===== Agencies =====
The Department of Homeland Security has a dedicated division responsible for the response system, risk management program and requirements for cybersecurity in the United States called the National Cyber Security Division. The division is home to US-CERT operations and the National Cyber Alert System. The National Cybersecurity and Communications Integration Center brings together government organizations responsible for protecting computer networks and networked infrastructure.The third priority of the Federal Bureau of Investigation (FBI) is to: ""Protect the United States against cyber-based attacks and high-technology crimes"", and they, along with the National White Collar Crime Center (NW3C), and the Bureau of Justice Assistance (BJA) are part of the multi-agency task force, The Internet Crime Complaint Center, also known as IC3.In addition to its own specific duties, the FBI participates alongside non-profit organizations such as InfraGard.In the criminal division of the United States Department of Justice operates a section called the Computer Crime and Intellectual Property Section. The CCIPS is in charge of investigating computer crime and intellectual property crime and is specialized in the search and seizure of digital evidence in computers and networks. In 2017, CCIPS published A Framework for a Vulnerability Disclosure Program for Online Systems to help organizations ""clearly describe authorized vulnerability disclosure and discovery conduct, thereby
substantially reducing the likelihood that such described activities will result in a civil or criminal violation of law under the Computer Fraud and Abuse Act (18 U.S.C. § 1030).""The United States Cyber Command, also known as USCYBERCOM, ""has the mission to direct, synchronize, and coordinate cyberspace planning and operations to defend and advance national interests in collaboration with domestic and international partners."" It has no role in the protection of civilian networks.The U.S. Federal Communications Commission's role in cybersecurity is to strengthen the protection of critical communications infrastructure, to assist in maintaining the reliability of networks during disasters, to aid in swift recovery after, and to ensure that first responders have access to effective communications services.The Food and Drug Administration has issued guidance for medical devices, and the National Highway Traffic Safety Administration is concerned with automotive cybersecurity. After being criticized by the Government Accountability Office, and following successful attacks on airports and claimed attacks on airplanes, the Federal Aviation Administration has devoted funding to securing systems on board the planes of private manufacturers, and the Aircraft Communications Addressing and Reporting System. Concerns have also been raised about the future Next Generation Air Transportation System.


===== Computer emergency readiness team =====
""Computer emergency response team"" is a name given to expert groups that handle computer security incidents. In the US, two distinct organization exist, although they do work closely together.

US-CERT: part of the National Cyber Security Division of the United States Department of Homeland Security.
CERT/CC: created by the Defense Advanced Research Projects Agency (DARPA) and run by the Software Engineering Institute (SEI).


== Modern warfare ==

There is growing concern that cyberspace will become the next theater of warfare. As Mark Clayton from the Christian Science Monitor described in an article titled ""The New Cyber Arms Race"":

In the future, wars will not just be fought by soldiers with guns or with planes that drop bombs. They will also be fought with the click of a mouse a half a world away that unleashes carefully weaponized computer programs that disrupt or destroy critical industries like utilities, transportation, communications, and energy. Such attacks could also disable military networks that control the movement of troops, the path of jet fighters, the command and control of warships.
This has led to new terms such as cyberwarfare and cyberterrorism. The United States Cyber Command was created in 2009 and many other countries have similar forces.
There are a few critical voices that question whether cybersecurity is as significant a threat as it is made out to be.


== Careers ==
Cybersecurity is a fast-growing field of IT concerned with reducing organizations' risk of hack or data breach. According to research from the Enterprise Strategy Group, 46% of organizations say that they have a ""problematic shortage"" of cybersecurity skills in 2016, up from 28% in 2015. Commercial, government and non-governmental organizations all employ cybersecurity professionals. The fastest increases in demand for cybersecurity workers are in industries managing increasing volumes of consumer data such as finance, health care, and retail. However, the use of the term ""cybersecurity"" is more prevalent in government job descriptions.Typical cybersecurity job titles and descriptions include:


=== Security analyst ===
Analyzes and assesses vulnerabilities in the infrastructure (software, hardware, networks), investigates using available tools and countermeasures to remedy the detected vulnerabilities and recommends solutions and best practices. Analyzes and assesses damage to the data/infrastructure as a result of security incidents, examines available recovery tools and processes, and recommends solutions. Tests for compliance with security policies and procedures. May assist in the creation, implementation, or management of security solutions.


=== Security engineer ===
Performs security monitoring, security and data/logs analysis, and forensic analysis, to detect security incidents, and mounts the incident response. Investigates and utilizes new technologies and processes to enhance security capabilities and implement improvements. May also review code or perform other security engineering methodologies.


=== Security architect ===
Designs a security system or major components of a security system, and may head a security design team building a new security system.


=== Security administrator ===
Installs and manages organization-wide security systems. This position may also include taking on some of the tasks of a security analyst in smaller organizations.


=== Chief Information Security Officer (CISO) ===
A high-level management position responsible for the entire information security division/staff. The position may include hands-on technical work.


=== Chief Security Officer (CSO) ===
A high-level management position responsible for the entire security division/staff. A newer position now deemed needed as security risks grow.


=== Security Consultant/Specialist/Intelligence ===
Broad titles that encompass any one or all of the other roles or titles tasked with protecting computers, networks, software, data or information systems against viruses, worms, spyware, malware, intrusion detection, unauthorized access, denial-of-service attacks, and an ever-increasing list of attacks by hackers acting as individuals or as part of organized crime or foreign governments.Student programs are also available to people interested in beginning a career in cybersecurity. Meanwhile, a flexible and effective option for information security professionals of all experience levels to keep studying is online security training, including webcasts. A wide range of certified courses are also available.In the United Kingdom, a nationwide set of cybersecurity forums, known as the U.K Cyber Security Forum, were established supported by the Government's cybersecurity strategy in order to encourage start-ups and innovation and to address the skills gap identified by the U.K Government.


== Terminology ==
The following terms used with regards to computer security are explained below:

Access authorization restricts access to a computer to a group of users through the use of authentication systems. These systems can protect either the whole computer, such as through an interactive login screen, or individual services, such as a FTP server. There are many methods for identifying and authenticating users, such as passwords, identification cards, smart cards, and biometric systems.
Anti-virus software consists of computer programs that attempt to identify, thwart, and eliminate computer viruses and other malicious software (malware).
Applications are executable code, so general practice is to disallow users the power to install them; to install only those which are known to be reputable – and to reduce the attack surface by installing as few as possible. They are typically run with least privilege, with a robust process in place to identify, test and install any released security patches or updates for them.
Authentication techniques can be used to ensure that communication end-points are who they say they are.
Automated theorem proving and other verification tools can enable critical algorithms and code used in secure systems to be mathematically proven to meet their specifications.
Backups are one or more copies kept of important computer files. Typically, multiple copies will be kept at different locations so that if a copy is stolen or damaged, other copies will still exist.
Capability and access control list techniques can be used to ensure privilege separation and mandatory access control. Capabilities vs. ACLs discusses their use.
Chain of trust techniques can be used to attempt to ensure that all software loaded has been certified as authentic by the system's designers.
Confidentiality is the nondisclosure of information except to another authorized person.
Cryptographic techniques can be used to defend data in transit between systems, reducing the probability that data exchanged between systems can be intercepted or modified.
Cyberwarfare is an Internet-based conflict that involves politically motivated attacks on information and information systems. Such attacks can, for example, disable official websites and networks, disrupt or disable essential services, steal or alter classified data, and cripple financial systems.
Data integrity is the accuracy and consistency of stored data, indicated by an absence of any alteration in data between two updates of a data record.
Encryption is used to protect the confidentiality of a message. Cryptographically secure ciphers are designed to make any practical attempt of breaking them infeasible. Symmetric-key ciphers are suitable for bulk encryption using shared keys, and public-key encryption using digital certificates can provide a practical solution for the problem of securely communicating when no key is shared in advance.
Endpoint security software aids networks in preventing malware infection and data theft at network entry points made vulnerable by the prevalence of potentially infected devices such as laptops, mobile devices, and USB drives.
Firewalls serve as a gatekeeper system between networks, allowing only traffic that matches defined rules. They often include detailed logging, and may include intrusion detection and intrusion prevention features. They are near-universal between company local area networks and the Internet, but can also be used internally to impose traffic rules between networks if network segmentation is configured.
A hacker is someone who seeks to breach defenses and exploit weaknesses in a computer system or network.
Honey pots are computers that are intentionally left vulnerable to attack by crackers. They can be used to catch crackers and to identify their techniques.
Intrusion-detection systems are devices or software applications that monitor networks or systems for malicious activity or policy violations.
A microkernel is an approach to operating system design which has only the near-minimum amount of code running at the most privileged level – and runs other elements of the operating system such as device drivers, protocol stacks and file systems, in the safer, less privileged user space.
Pinging. The standard ""ping"" application can be used to test if an IP address is in use. If it is, attackers may then try a port scan to detect which services are exposed.
A port scan is used to probe an IP address for open ports to identify accessible network services and applications.
A Key logger is spyware silently captures and stores each keystroke that a user types on the computer's keyboard.
Social engineering is the use of deception to manipulate individuals to breach security.
Logic bombs is a type of malware added to a legitimate program that lies dormant until it is triggered by a specific event.


== Scholars ==


== See also ==


== References ==


== Further reading ==
Costigan, Sean; Hennessy, Michael (2016). Cybersecurity: A Generic Reference Curriculum. NATO. ISBN 978-9284501960. https://www.nato.int/nato_static_fl2014/assets/pdf/pdf_2016_10/20161025_1610-cybersecurity-curriculum.pdf
Fuller, Christopher J. “The Roots of the United States’ Cyber (In)Security,” Diplomatic History"" 43:1 (2019): 157-185. online
Kim, Peter (2014). The Hacker Playbook: Practical Guide To Penetration Testing. Seattle: CreateSpace Independent Publishing Platform. ISBN 978-1494932633.
Lee, Newton (2015). Counterterrorism and Cybersecurity: Total Information Awareness (2nd ed.). Springer. ISBN 978-3-319-17243-9.
Montagnani, Maria Lillà and Cavallo, Mirta Antonella (July 26, 2018). ""Cybersecurity and Liability in a Big Data World"". SSRN.
Singer, P. W.; Friedman, Allan (2014). Cybersecurity and Cyberwar: What Everyone Needs to Know. Oxford University Press. ISBN 978-0199918119.
Wu, Chwan-Hwa (John); Irwin, J. David (2013). Introduction to Computer Networks and Cybersecurity. Boca Raton: CRC Press. ISBN 978-1466572133.
M. Shariati et al. / Procedia Computer Science 3 (2011) 537–543. Enterprise information security, a review of architectures and frameworks from interoperability perspective


== External links ==
Computer security at Curlie
Cybersecurity Websites"
"A central processing unit (CPU), also called a central processor, main processor or just processor, is the electronic circuitry within a computer that executes instructions that make up a computer program. The CPU performs basic arithmetic, logic, controlling, and input/output (I/O) operations specified by the instructions in the program. The computer industry used the term ""central processing unit"" as early as 1955. Traditionally, the term ""CPU"" refers to a processor, more specifically to its processing unit and control unit (CU), distinguishing these core elements of a computer from external components such as main memory and I/O circuitry.The form, design, and implementation of CPUs have changed over the course of their history, but their fundamental operation remains almost unchanged. Principal components of a CPU include the arithmetic logic unit (ALU) that performs arithmetic and logic operations, processor registers that supply operands to the ALU and store the results of ALU operations, and a control unit that orchestrates the fetching (from memory) and execution of instructions by directing the coordinated operations of the ALU, registers and other components.
Most modern CPUs are microprocessors, where the CPU is contained on a single metal-oxide-semiconductor (MOS) integrated circuit (IC) chip. An IC that contains a CPU may also contain memory, peripheral interfaces, and other components of a computer; such integrated devices are variously called microcontrollers or systems on a chip (SoC). Some computers employ a multi-core processor, which is a single chip or ""socket"" containing two or more CPUs called ""cores"".Array processors or vector processors have multiple processors that operate in parallel, with no unit considered central. Virtual CPUs are an abstraction of dynamical aggregated computational resources.


== History ==

Early computers such as the ENIAC had to be physically rewired to perform different tasks, which caused these machines to be called ""fixed-program computers"". Since the term ""CPU"" is generally defined as a device for software (computer program) execution, the earliest devices that could rightly be called CPUs came with the advent of the stored-program computer.
The idea of a stored-program computer had been already present in the design of J. Presper Eckert and John William Mauchly's ENIAC, but was initially omitted so that it could be finished sooner. On June 30, 1945, before ENIAC was made, mathematician John von Neumann distributed the paper entitled First Draft of a Report on the EDVAC. It was the outline of a stored-program computer that would eventually be completed in August 1949. EDVAC was designed to perform a certain number of instructions (or operations) of various types. Significantly, the programs written for EDVAC were to be stored in high-speed computer memory rather than specified by the physical wiring of the computer. This overcame a severe limitation of ENIAC, which was the considerable time and effort required to reconfigure the computer to perform a new task. With von Neumann's design, the program that EDVAC ran could be changed simply by changing the contents of the memory. EDVAC, however, was not the first stored-program computer; the Manchester Baby, a small-scale experimental stored-program computer, ran its first program on 21 June 1948 and the Manchester Mark 1 ran its first program during the night of 16–17 June 1949.Early CPUs were custom designs used as part of a larger and sometimes distinctive computer. However, this method of designing custom CPUs for a particular application has largely given way to the development of multi-purpose processors produced in large quantities. This standardization began in the era of discrete transistor mainframes and minicomputers and has rapidly accelerated with the popularization of the integrated circuit (IC). The IC has allowed increasingly complex CPUs to be designed and manufactured to tolerances on the order of nanometers. Both the miniaturization and standardization of CPUs have increased the presence of digital devices in modern life far beyond the limited application of dedicated computing machines. Modern microprocessors appear in electronic devices ranging from automobiles to cellphones, and sometimes even in toys.While von Neumann is most often credited with the design of the stored-program computer because of his design of EDVAC, and the design became known as the von Neumann architecture, others before him, such as Konrad Zuse, had suggested and implemented similar ideas. The so-called Harvard architecture of the Harvard Mark I, which was completed before EDVAC, also used a stored-program design using punched paper tape rather than electronic memory. The key difference between the von Neumann and Harvard architectures is that the latter separates the storage and treatment of CPU instructions and data, while the former uses the same memory space for both. Most modern CPUs are primarily von Neumann in design, but CPUs with the Harvard architecture are seen as well, especially in embedded applications; for instance, the Atmel AVR microcontrollers are Harvard architecture processors.Relays and vacuum tubes (thermionic tubes) were commonly used as switching elements; a useful computer requires thousands or tens of thousands of switching devices. The overall speed of a system is dependent on the speed of the switches. Tube computers like EDVAC tended to average eight hours between failures, whereas relay computers like the (slower, but earlier) Harvard Mark I failed very rarely. In the end, tube-based CPUs became dominant because the significant speed advantages afforded generally outweighed the reliability problems. Most of these early synchronous CPUs ran at low clock rates compared to modern microelectronic designs. Clock signal frequencies ranging from 100 kHz to 4 MHz were very common at this time, limited largely by the speed of the switching devices they were built with.


=== Transistor CPUs ===

The design complexity of CPUs increased as various technologies facilitated building smaller and more reliable electronic devices. The first such improvement came with the advent of the transistor. Transistorized CPUs during the 1950s and 1960s no longer had to be built out of bulky, unreliable and fragile switching elements like vacuum tubes and relays. With this improvement more complex and reliable CPUs were built onto one or several printed circuit boards containing discrete (individual) components.
In 1964, IBM introduced its IBM System/360 computer architecture that was used in a series of computers capable of running the same programs with different speed and performance. This was significant at a time when most electronic computers were incompatible with one another, even those made by the same manufacturer. To facilitate this improvement, IBM used the concept of a microprogram (often called ""microcode""), which still sees widespread usage in modern CPUs. The System/360 architecture was so popular that it dominated the mainframe computer market for decades and left a legacy that is still continued by similar modern computers like the IBM zSeries. In 1965, Digital Equipment Corporation (DEC) introduced another influential computer aimed at the scientific and research markets, the PDP-8.

Transistor-based computers had several distinct advantages over their predecessors. Aside from facilitating increased reliability and lower power consumption, transistors also allowed CPUs to operate at much higher speeds because of the short switching time of a transistor in comparison to a tube or relay. The increased reliability and dramatically increased speed of the switching elements (which were almost exclusively transistors by this time), CPU clock rates in the tens of megahertz were easily obtained during this period. Additionally while discrete transistor and IC CPUs were in heavy usage, new high-performance designs like SIMD (Single Instruction Multiple Data) vector processors began to appear. These early experimental designs later gave rise to the era of specialized supercomputers like those made by Cray Inc and Fujitsu Ltd.


=== Small-scale integration CPUs ===

During this period, a method of manufacturing many interconnected transistors in a compact space was developed. The integrated circuit (IC) allowed a large number of transistors to be manufactured on a single semiconductor-based die, or ""chip"". At first, only very basic non-specialized digital circuits such as NOR gates were miniaturized into ICs. CPUs based on these ""building block"" ICs are generally referred to as ""small-scale integration"" (SSI) devices. SSI ICs, such as the ones used in the Apollo Guidance Computer, usually contained up to a few dozen transistors. To build an entire CPU out of SSI ICs required thousands of individual chips, but still consumed much less space and power than earlier discrete transistor designs.IBM's System/370, follow-on to the System/360, used SSI ICs rather than Solid Logic Technology discrete-transistor modules. DEC's PDP-8/I and KI10 PDP-10 also switched from the individual transistors used by the PDP-8 and PDP-10 to SSI ICs, and their extremely popular PDP-11 line was originally built with SSI ICs but was eventually implemented with LSI components once these became practical.


=== Large-scale integration CPUs ===
The MOSFET (metal-oxide-semiconductor field-effect transistor), also known as the MOS transistor, was invented by Mohamed Atalla and Dawon Kahng at Bell Labs in 1959, and demonstrated in 1960. This led to the development of the MOS (metal-oxide-semiconductor) integrated circuit, proposed by Atalla in 1960 and Kahng in 1961, and then fabricated by Fred Heiman and Steven Hofstein at RCA in 1962. With its high scalability, and much lower power consumption and higher density than bipolar junction transistors, the MOSFET made it possible to build high-density integrated circuits.Lee Boysel published influential articles, including a 1967 ""manifesto"", which described how to build the equivalent of a 32-bit mainframe computer from a relatively small number of large-scale integration circuits (LSI). The only way to build LSI chips, which are chips with a hundred or more gates, was to build them using a MOS semiconductor manufacturing process (either PMOS logic, NMOS logic, or CMOS logic). However, some companies continued to build processors out of bipolar transistor–transistor logic (TTL) chips because bipolar junction transistors were faster than MOS chips up until the 1970s (a few companies such as Datapoint continued to build processors out of TTL chips until the early 1980s). In the 1960s, MOS ICs were slower and initially considered useful only in applications that required low power. Following the development of silicon-gate MOS technology by Federico Faggin at Fairchild Semiconductor in 1968, MOS ICs largely replaced bipolar TTL as the standard chip technology in the early 1970s.As the microelectronic technology advanced, an increasing number of transistors were placed on ICs, decreasing the number of individual ICs needed for a complete CPU. MSI and LSI ICs increased transistor counts to hundreds, and then thousands. By 1968, the number of ICs required to build a complete CPU had been reduced to 24 ICs of eight different types, with each IC containing roughly 1000 MOSFETs. In stark contrast with its SSI and MSI predecessors, the first LSI implementation of the PDP-11 contained a CPU composed of only four LSI integrated circuits.


=== Microprocessors ===

Advances in MOS IC technology led to the invention of the microprocessor in the early 1970s. Since the introduction of the first commercially available microprocessor, the Intel 4004 in 1971, and the first widely used microprocessor, the Intel 8080 in 1974, this class of CPUs has almost completely overtaken all other central processing unit implementation methods. Mainframe and minicomputer manufacturers of the time launched proprietary IC development programs to upgrade their older computer architectures, and eventually produced instruction set compatible microprocessors that were backward-compatible with their older hardware and software. Combined with the advent and eventual success of the ubiquitous personal computer, the term CPU is now applied almost exclusively to microprocessors. Several CPUs (denoted cores) can be combined in a single processing chip.
Previous generations of CPUs were implemented as discrete components and numerous small integrated circuits (ICs) on one or more circuit boards. Microprocessors, on the other hand, are CPUs manufactured on a very small number of ICs; usually just one. The overall smaller CPU size, as a result of being implemented on a single die, means faster switching time because of physical factors like decreased gate parasitic capacitance. This has allowed synchronous microprocessors to have clock rates ranging from tens of megahertz to several gigahertz. Additionally, the ability to construct exceedingly small transistors on an IC has increased the complexity and number of transistors in a single CPU many fold. This widely observed trend is described by Moore's law, which had proven to be a fairly accurate predictor of the growth of CPU (and other IC) complexity until 2016.While the complexity, size, construction and general form of CPUs have changed enormously since 1950, the basic design and function has not changed much at all. Almost all common CPUs today can be very accurately described as von Neumann stored-program machines. As Moore's law no longer holds, concerns have arisen about the limits of integrated circuit transistor technology. Extreme miniaturization of electronic gates is causing the effects of phenomena like electromigration and subthreshold leakage to become much more significant. These newer concerns are among the many factors causing researchers to investigate new methods of computing such as the quantum computer, as well as to expand the usage of parallelism and other methods that extend the usefulness of the classical von Neumann model.


== Operation ==
The fundamental operation of most CPUs, regardless of the physical form they take, is to execute a sequence of stored instructions that is called a program. The instructions to be executed are kept in some kind of computer memory. Nearly all CPUs follow the fetch, decode and execute steps in their operation, which are collectively known as the instruction cycle.
After the execution of an instruction, the entire process repeats, with the next instruction cycle normally fetching the next-in-sequence instruction because of the incremented value in the program counter. If a jump instruction was executed, the program counter will be modified to contain the address of the instruction that was jumped to and program execution continues normally. In more complex CPUs, multiple instructions can be fetched, decoded and executed simultaneously. This section describes what is generally referred to as the ""classic RISC pipeline"", which is quite common among the simple CPUs used in many electronic devices (often called microcontroller). It largely ignores the important role of CPU cache, and therefore the access stage of the pipeline.
Some instructions manipulate the program counter rather than producing result data directly; such instructions are generally called ""jumps"" and facilitate program behavior like loops, conditional program execution (through the use of a conditional jump), and existence of functions. In some processors, some other instructions change the state of bits in a ""flags"" register. These flags can be used to influence how a program behaves, since they often indicate the outcome of various operations. For example, in such processors a ""compare"" instruction evaluates two values and sets or clears bits in the flags register to indicate which one is greater or whether they are equal; one of these flags could then be used by a later jump instruction to determine program flow.


=== Fetch ===
The first step, fetch, involves retrieving an instruction (which is represented by a number or sequence of numbers) from program memory. The instruction's location (address) in program memory is determined by a program counter (PC), which stores a number that identifies the address of the next instruction to be fetched. After an instruction is fetched, the PC is incremented by the length of the instruction so that it will contain the address of the next instruction in the sequence. Often, the instruction to be fetched must be retrieved from relatively slow memory, causing the CPU to stall while waiting for the instruction to be returned. This issue is largely addressed in modern processors by caches and pipeline architectures (see below).


=== Decode ===
The instruction that the CPU fetches from memory determines what the CPU will do. In the decode step, performed by the circuitry known as the instruction decoder, the instruction is converted into signals that control other parts of the CPU.
The way in which the instruction is interpreted is defined by the CPU's instruction set architecture (ISA). Often, one group of bits (that is, a ""field"") within the instruction, called the opcode, indicates which operation is to be performed, while the remaining fields usually provide supplemental information required for the operation, such as the operands. Those operands may be specified as a constant value (called an immediate value), or as the location of a value that may be a processor register or a memory address, as determined by some addressing mode.
In some CPU designs the instruction decoder is implemented as a hardwired, unchangeable circuit. In others, a microprogram is used to translate instructions into sets of CPU configuration signals that are applied sequentially over multiple clock pulses. In some cases the memory that stores the microprogram is rewritable, making it possible to change the way in which the CPU decodes instructions.


=== Execute ===
After the fetch and decode steps, the execute step is performed. Depending on the CPU architecture, this may consist of a single action or a sequence of actions. During each action, various parts of the CPU are electrically connected so they can perform all or part of the desired operation and then the action is completed, typically in response to a clock pulse. Very often the results are written to an internal CPU register for quick access by subsequent instructions. In other cases results may be written to slower, but less expensive and higher capacity main memory.
For example, if an addition instruction is to be executed, the arithmetic logic unit (ALU) inputs are connected to a pair of operand sources (numbers to be summed), the ALU is configured to perform an addition operation so that the sum of its operand inputs will appear at its output, and the ALU output is connected to storage (e.g., a register or memory) that will receive the sum. When the clock pulse occurs, the sum will be transferred to storage and, if the resulting sum is too large (i.e., it is larger than the ALU's output word size), an arithmetic overflow flag will be set.


== Structure and implementation ==

Hardwired into a CPU's circuitry is a set of basic operations it can perform, called an instruction set. Such operations may involve, for example, adding or subtracting two numbers, comparing two numbers, or jumping to a different part of a program. Each basic operation is represented by a particular combination of bits, known as the machine language opcode; while executing instructions in a machine language program, the CPU decides which operation to perform by ""decoding"" the opcode. A complete machine language instruction consists of an opcode and, in many cases, additional bits that specify arguments for the operation (for example, the numbers to be summed in the case of an addition operation). Going up the complexity scale, a machine language program is a collection of machine language instructions that the CPU executes.
The actual mathematical operation for each instruction is performed by a combinational logic circuit within the CPU's processor known as the arithmetic logic unit or ALU. In general, a CPU executes an instruction by fetching it from memory, using its ALU to perform an operation, and then storing the result to memory. Beside the instructions for integer mathematics and logic operations, various other machine instructions exist, such as those for loading data from memory and storing it back, branching operations, and mathematical operations on floating-point numbers performed by the CPU's floating-point unit (FPU).


=== Control unit ===

The control unit (CU) is a component of the CPU that directs the operation of the processor. It tells the computer's memory, arithmetic and logic unit and input and output devices how to respond to the instructions that have been sent to the processor.
It directs the operation of the other units by providing timing and control signals. Most computer resources are managed by the CU. It directs the flow of data between the CPU and the other devices. John von Neumann included the control unit as part of the von Neumann architecture. In modern computer designs, the control unit is typically an internal part of the CPU with its overall role and operation unchanged since its introduction.


=== Arithmetic logic unit ===

The arithmetic logic unit (ALU) is a digital circuit within the processor that performs integer arithmetic and bitwise logic operations. The inputs to the ALU are the data words to be operated on (called operands), status information from previous operations, and a code from the control unit indicating which operation to perform. Depending on the instruction being executed, the operands may come from internal CPU registers or external memory, or they may be constants generated by the ALU itself.
When all input signals have settled and propagated through the ALU circuitry, the result of the performed operation appears at the ALU's outputs. The result consists of both a data word, which may be stored in a register or memory, and status information that is typically stored in a special, internal CPU register reserved for this purpose.


=== Address generation unit ===

Address generation unit (AGU), sometimes also called address computation unit (ACU), is an execution unit inside the CPU that calculates addresses used by the CPU to access main memory. By having address calculations handled by separate circuitry that operates in parallel with the rest of the CPU, the number of CPU cycles required for executing various machine instructions can be reduced, bringing performance improvements.
While performing various operations, CPUs need to calculate memory addresses required for fetching data from the memory; for example, in-memory positions of array elements must be calculated before the CPU can fetch the data from actual memory locations. Those address-generation calculations involve different integer arithmetic operations, such as addition, subtraction, modulo operations, or bit shifts. Often, calculating a memory address involves more than one general-purpose machine instruction, which do not necessarily decode and execute quickly. By incorporating an AGU into a CPU design, together with introducing specialized instructions that use the AGU, various address-generation calculations can be offloaded from the rest of the CPU, and can often be executed quickly in a single CPU cycle.
Capabilities of an AGU depend on a particular CPU and its architecture. Thus, some AGUs implement and expose more address-calculation operations, while some also include more advanced specialized instructions that can operate on multiple operands at a time. Furthermore, some CPU architectures include multiple AGUs so more than one address-calculation operation can be executed simultaneously, bringing further performance improvements by capitalizing on the superscalar nature of advanced CPU designs. For example, Intel incorporates multiple AGUs into its Sandy Bridge and Haswell microarchitectures, which increase bandwidth of the CPU memory subsystem by allowing multiple memory-access instructions to be executed in parallel.


=== Memory management unit (MMU) ===

Most high-end microprocessors (in desktop, laptop, server computers) have a memory management unit, translating logical addresses into physical RAM addresses, providing memory protection and paging abilities, useful for virtual memory. Simpler processors, especially microcontrollers, usually don't include an MMU.


=== Cache ===
A CPU cache is a hardware cache used by the central processing unit (CPU) of a computer to reduce the average cost (time or energy) to access data from the main memory. A cache is a smaller, faster memory, closer to a processor core, which stores copies of the data from frequently used main memory locations. Most CPUs have different independent caches, including instruction and data caches, where the data cache is usually organized as a hierarchy of more cache levels (L1, L2, L3, L4, etc.).
All modern (fast) CPUs (with few specialized exceptions) have multiple levels of CPU caches. The first CPUs that used a cache had only one level of cache; unlike later level 1 caches, it was not split into L1d (for data) and L1i (for instructions). Almost all current CPUs with caches have a split L1 cache. They also have L2 caches and, for larger processors, L3 caches as well. The L2 cache is usually not split and acts as a common repository for the already split L1 cache. Every core of a multi-core processor has a dedicated L2 cache and is usually not shared between the cores. The L3 cache, and higher-level caches, are shared between the cores and are not split. An L4 cache is currently uncommon, and is generally on dynamic random-access memory (DRAM), rather than on static random-access memory (SRAM), on a separate die or chip. That was also the case historically with L1, while bigger chips have allowed integration of it and generally all cache levels, with the possible exception of the last level. Each extra level of cache tends to be bigger and be optimized differently.
Other types of caches exist (that are not counted towards the ""cache size"" of the most important caches mentioned above), such as the translation lookaside buffer (TLB) that is part of the memory management unit (MMU) that most CPUs have.
Caches are generally sized in powers of two: 4, 8, 16 etc. KiB or MiB (for larger non-L1) sizes, although the IBM z13 has a 96 KiB L1 instruction cache.


=== Clock rate ===

Most CPUs are synchronous circuits, which means they employ a clock signal to pace their sequential operations. The clock signal is produced by an external oscillator circuit that generates a consistent number of pulses each second in the form of a periodic square wave. The frequency of the clock pulses determines the rate at which a CPU executes instructions and, consequently, the faster the clock, the more instructions the CPU will execute each second.
To ensure proper operation of the CPU, the clock period is longer than the maximum time needed for all signals to propagate (move) through the CPU. In setting the clock period to a value well above the worst-case propagation delay, it is possible to design the entire CPU and the way it moves data around the ""edges"" of the rising and falling clock signal. This has the advantage of simplifying the CPU significantly, both from a design perspective and a component-count perspective. However, it also carries the disadvantage that the entire CPU must wait on its slowest elements, even though some portions of it are much faster. This limitation has largely been compensated for by various methods of increasing CPU parallelism (see below).
However, architectural improvements alone do not solve all of the drawbacks of globally synchronous CPUs. For example, a clock signal is subject to the delays of any other electrical signal. Higher clock rates in increasingly complex CPUs make it more difficult to keep the clock signal in phase (synchronized) throughout the entire unit. This has led many modern CPUs to require multiple identical clock signals to be provided to avoid delaying a single signal significantly enough to cause the CPU to malfunction. Another major issue, as clock rates increase dramatically, is the amount of heat that is dissipated by the CPU. The constantly changing clock causes many components to switch regardless of whether they are being used at that time. In general, a component that is switching uses more energy than an element in a static state. Therefore, as clock rate increases, so does energy consumption, causing the CPU to require more heat dissipation in the form of CPU cooling solutions.
One method of dealing with the switching of unneeded components is called clock gating, which involves turning off the clock signal to unneeded components (effectively disabling them). However, this is often regarded as difficult to implement and therefore does not see common usage outside of very low-power designs. One notable recent CPU design that uses extensive clock gating is the IBM PowerPC-based Xenon used in the Xbox 360; that way, power requirements of the Xbox 360 are greatly reduced. Another method of addressing some of the problems with a global clock signal is the removal of the clock signal altogether. While removing the global clock signal makes the design process considerably more complex in many ways, asynchronous (or clockless) designs carry marked advantages in power consumption and heat dissipation in comparison with similar synchronous designs. While somewhat uncommon, entire asynchronous CPUs have been built without using a global clock signal. Two notable examples of this are the ARM compliant AMULET and the MIPS R3000 compatible MiniMIPS.
Rather than totally removing the clock signal, some CPU designs allow certain portions of the device to be asynchronous, such as using asynchronous ALUs in conjunction with superscalar pipelining to achieve some arithmetic performance gains. While it is not altogether clear whether totally asynchronous designs can perform at a comparable or better level than their synchronous counterparts, it is evident that they do at least excel in simpler math operations. This, combined with their excellent power consumption and heat dissipation properties, makes them very suitable for embedded computers.


=== Voltage regulator module ===

Many modern CPUs have a die-integrated power managing module which regulates on-demand voltage supply to the CPU circuitry allowing it to keep balance between performance and power consumption.


=== Integer range ===
Every CPU represents numerical values in a specific way. For example, some early digital computers represented numbers as familiar decimal (base 10) numeral system values, and others have employed more unusual representations such as ternary (base three). Nearly all modern CPUs represent numbers in binary form, with each digit being represented by some two-valued physical quantity such as a ""high"" or ""low"" voltage.

Related to numeric representation is the size and precision of integer numbers that a CPU can represent. In the case of a binary CPU, this is measured by the number of bits (significant digits of a binary encoded integer) that the CPU can process in one operation, which is commonly called word size, bit width, data path width, integer precision, or integer size. A CPU's integer size determines the range of integer values it can directly operate on. For example, an 8-bit CPU can directly manipulate integers represented by eight bits, which have a range of 256 (28) discrete integer values.
Integer range can also affect the number of memory locations the CPU can directly address (an address is an integer value representing a specific memory location). For example, if a binary CPU uses 32 bits to represent a memory address then it can directly address 232 memory locations. To circumvent this limitation and for various other reasons, some CPUs use mechanisms (such as bank switching) that allow additional memory to be addressed.
CPUs with larger word sizes require more circuitry and consequently are physically larger, cost more and consume more power (and therefore generate more heat). As a result, smaller 4- or 8-bit microcontrollers are commonly used in modern applications even though CPUs with much larger word sizes (such as 16, 32, 64, even 128-bit) are available. When higher performance is required, however, the benefits of a larger word size (larger data ranges and address spaces) may outweigh the disadvantages. A CPU can have internal data paths shorter than the word size to reduce size and cost. For example, even though the IBM System/360 instruction set was a 32-bit instruction set, the System/360 Model 30 and Model 40 had 8-bit data paths in the arithmetic logical unit, so that a 32-bit add required four cycles, one for each 8 bits of the operands, and, even though the Motorola 68000 series instruction set was a 32-bit instruction set, the Motorola 68000 and Motorola 68010 had 16-bit data paths in the arithmetic logical unit, so that a 32-bit add required two cycles.
To gain some of the advantages afforded by both lower and higher bit lengths, many instruction sets have different bit widths for integer and floating-point data, allowing CPUs implementing that instruction set to have different bit widths for different portions of the device. For example, the IBM System/360 instruction set was primarily 32 bit, but supported 64-bit floating point values to facilitate greater accuracy and range in floating point numbers. The System/360 Model 65 had an 8-bit adder for decimal and fixed-point binary arithmetic and a 60-bit adder for floating-point arithmetic. Many later CPU designs use similar mixed bit width, especially when the processor is meant for general-purpose usage where a reasonable balance of integer and floating point capability is required.


=== Parallelism ===

The description of the basic operation of a CPU offered in the previous section describes the simplest form that a CPU can take. This type of CPU, usually referred to as subscalar, operates on and executes one instruction on one or two pieces of data at a time, that is less than one instruction per clock cycle (IPC < 1).
This process gives rise to an inherent inefficiency in subscalar CPUs. Since only one instruction is executed at a time, the entire CPU must wait for that instruction to complete before proceeding to the next instruction. As a result, the subscalar CPU gets ""hung up"" on instructions which take more than one clock cycle to complete execution. Even adding a second execution unit (see below) does not improve performance much; rather than one pathway being hung up, now two pathways are hung up and the number of unused transistors is increased. This design, wherein the CPU's execution resources can operate on only one instruction at a time, can only possibly reach scalar performance (one instruction per clock cycle, IPC = 1). However, the performance is nearly always subscalar (less than one instruction per clock cycle, IPC < 1).
Attempts to achieve scalar and better performance have resulted in a variety of design methodologies that cause the CPU to behave less linearly and more in parallel. When referring to parallelism in CPUs, two terms are generally used to classify these design techniques:

instruction-level parallelism (ILP), which seeks to increase the rate at which instructions are executed within a CPU (that is, to increase the use of on-die execution resources);
task-level parallelism (TLP), which purposes to increase the number of threads or processes that a CPU can execute simultaneously.Each methodology differs both in the ways in which they are implemented, as well as the relative effectiveness they afford in increasing the CPU's performance for an application.


==== Instruction-level parallelism ====

One of the simplest methods used to accomplish increased parallelism is to begin the first steps of instruction fetching and decoding before the prior instruction finishes executing. This is the simplest form of a technique known as instruction pipelining, and is used in almost all modern general-purpose CPUs. Pipelining allows more than one instruction to be executed at any given time by breaking down the execution pathway into discrete stages. This separation can be compared to an assembly line, in which an instruction is made more complete at each stage until it exits the execution pipeline and is retired.
Pipelining does, however, introduce the possibility for a situation where the result of the previous operation is needed to complete the next operation; a condition often termed data dependency conflict. To cope with this, additional care must be taken to check for these sorts of conditions and delay a portion of the instruction pipeline if this occurs. Naturally, accomplishing this requires additional circuitry, so pipelined processors are more complex than subscalar ones (though not very significantly so). A pipelined processor can become very nearly scalar, inhibited only by pipeline stalls (an instruction spending more than one clock cycle in a stage).

Further improvement upon the idea of instruction pipelining led to the development of a method that decreases the idle time of CPU components even further. Designs that are said to be superscalar include a long instruction pipeline and multiple identical execution units, such as load-store units, arithmetic-logic units, floating-point units and address generation units. In a superscalar pipeline, multiple instructions are read and passed to a dispatcher, which decides whether or not the instructions can be executed in parallel (simultaneously). If so they are dispatched to available execution units, resulting in the ability for several instructions to be executed simultaneously. In general, the more instructions a superscalar CPU is able to dispatch simultaneously to waiting execution units, the more instructions will be completed in a given cycle.
Most of the difficulty in the design of a superscalar CPU architecture lies in creating an effective dispatcher. The dispatcher needs to be able to quickly and correctly determine whether instructions can be executed in parallel, as well as dispatch them in such a way as to keep as many execution units busy as possible. This requires that the instruction pipeline is filled as often as possible and gives rise to the need in superscalar architectures for significant amounts of CPU cache. It also makes hazard-avoiding techniques like branch prediction, speculative execution, register renaming, out-of-order execution and transactional memory crucial to maintaining high levels of performance. By attempting to predict which branch (or path) a conditional instruction will take, the CPU can minimize the number of times that the entire pipeline must wait until a conditional instruction is completed. Speculative execution often provides modest performance increases by executing portions of code that may not be needed after a conditional operation completes. Out-of-order execution somewhat rearranges the order in which instructions are executed to reduce delays due to data dependencies. Also in case of single instruction stream, multiple data stream—a case when a lot of data from the same type has to be processed—, modern processors can disable parts of the pipeline so that when a single instruction is executed many times, the CPU skips the fetch and decode phases and thus greatly increases performance on certain occasions, especially in highly monotonous program engines such as video creation software and photo processing.
In the case where a portion of the CPU is superscalar and part is not, the part which is not suffers a performance penalty due to scheduling stalls. The Intel P5 Pentium had two superscalar ALUs which could accept one instruction per clock cycle each, but its FPU could not accept one instruction per clock cycle. Thus the P5 was integer superscalar but not floating point superscalar. Intel's successor to the P5 architecture, P6, added superscalar capabilities to its floating point features, and therefore afforded a significant increase in floating point instruction performance.
Both simple pipelining and superscalar design increase a CPU's ILP by allowing a single processor to complete execution of instructions at rates surpassing one instruction per clock cycle. Most modern CPU designs are at least somewhat superscalar, and nearly all general purpose CPUs designed in the last decade are superscalar. In later years some of the emphasis in designing high-ILP computers has been moved out of the CPU's hardware and into its software interface, or ISA. The strategy of the very long instruction word (VLIW) causes some ILP to become implied directly by the software, reducing the amount of work the CPU must perform to boost ILP and thereby reducing the design's complexity.


==== Task-level parallelism ====

Another strategy of achieving performance is to execute multiple threads or processes in parallel. This area of research is known as parallel computing. In Flynn's taxonomy, this strategy is known as multiple instruction stream, multiple data stream (MIMD).One technology used for this purpose was multiprocessing (MP). The initial flavor of this technology is known as symmetric multiprocessing (SMP), where a small number of CPUs share a coherent view of their memory system. In this scheme, each CPU has additional hardware to maintain a constantly up-to-date view of memory. By avoiding stale views of memory, the CPUs can cooperate on the same program and programs can migrate from one CPU to another. To increase the number of cooperating CPUs beyond a handful, schemes such as non-uniform memory access (NUMA) and directory-based coherence protocols were introduced in the 1990s. SMP systems are limited to a small number of CPUs while NUMA systems have been built with thousands of processors. Initially, multiprocessing was built using multiple discrete CPUs and boards to implement the interconnect between the processors. When the processors and their interconnect are all implemented on a single chip, the technology is known as chip-level multiprocessing (CMP) and the single chip as a multi-core processor.
It was later recognized that finer-grain parallelism existed with a single program. A single program might have several threads (or functions) that could be executed separately or in parallel. Some of the earliest examples of this technology implemented input/output processing such as direct memory access as a separate thread from the computation thread. A more general approach to this technology was introduced in the 1970s when systems were designed to run multiple computation threads in parallel. This technology is known as multi-threading (MT). This approach is considered more cost-effective than multiprocessing, as only a small number of components within a CPU is replicated to support MT as opposed to the entire CPU in the case of MP. In MT, the execution units and the memory system including the caches are shared among multiple threads. The downside of MT is that the hardware support for multithreading is more visible to software than that of MP and thus supervisor software like operating systems have to undergo larger changes to support MT. One type of MT that was implemented is known as temporal multithreading, where one thread is executed until it is stalled waiting for data to return from external memory. In this scheme, the CPU would then quickly context switch to another thread which is ready to run, the switch often done in one CPU clock cycle, such as the UltraSPARC T1. Another type of MT is simultaneous multithreading, where instructions from multiple threads are executed in parallel within one CPU clock cycle.
For several decades from the 1970s to early 2000s, the focus in designing high performance general purpose CPUs was largely on achieving high ILP through technologies such as pipelining, caches, superscalar execution, out-of-order execution, etc. This trend culminated in large, power-hungry CPUs such as the Intel Pentium 4. By the early 2000s, CPU designers were thwarted from achieving higher performance from ILP techniques due to the growing disparity between CPU operating frequencies and main memory operating frequencies as well as escalating CPU power dissipation owing to more esoteric ILP techniques.
CPU designers then borrowed ideas from commercial computing markets such as transaction processing, where the aggregate performance of multiple programs, also known as throughput computing, was more important than the performance of a single thread or process.
This reversal of emphasis is evidenced by the proliferation of dual and more core processor designs and notably, Intel's newer designs resembling its less superscalar P6 architecture. Late designs in several processor families exhibit CMP, including the x86-64 Opteron and Athlon 64 X2, the SPARC UltraSPARC T1, IBM POWER4 and POWER5, as well as several video game console CPUs like the Xbox 360's triple-core PowerPC design, and the PlayStation 3's 7-core Cell microprocessor.


==== Data parallelism ====

A less common but increasingly important paradigm of processors (and indeed, computing in general) deals with data parallelism. The processors discussed earlier are all referred to as some type of scalar device. As the name implies, vector processors deal with multiple pieces of data in the context of one instruction. This contrasts with scalar processors, which deal with one piece of data for every instruction. Using Flynn's taxonomy, these two schemes of dealing with data are generally referred to as single instruction stream, multiple data stream (SIMD) and single instruction stream, single data stream (SISD), respectively. The great utility in creating processors that deal with vectors of data lies in optimizing tasks that tend to require the same operation (for example, a sum or a dot product) to be performed on a large set of data. Some classic examples of these types of tasks include multimedia applications (images, video and sound), as well as many types of scientific and engineering tasks. Whereas a scalar processor must complete the entire process of fetching, decoding and executing each instruction and value in a set of data, a vector processor can perform a single operation on a comparatively large set of data with one instruction. This is only possible when the application tends to require many steps which apply one operation to a large set of data.
Most early vector processors, such as the Cray-1, were associated almost exclusively with scientific research and cryptography applications. However, as multimedia has largely shifted to digital media, the need for some form of SIMD in general-purpose processors has become significant. Shortly after inclusion of floating-point units started to become commonplace in general-purpose processors, specifications for and implementations of SIMD execution units also began to appear for general-purpose processors. Some of these early SIMD specifications - like HP's Multimedia Acceleration eXtensions (MAX) and Intel's MMX - were integer-only. This proved to be a significant impediment for some software developers, since many of the applications that benefit from SIMD primarily deal with floating-point numbers. Progressively, developers refined and remade these early designs into some of the common modern SIMD specifications, which are usually associated with one ISA. Some notable modern examples include Intel's SSE and the PowerPC-related AltiVec (also known as VMX).


== Virtual CPUs ==
Cloud computing can involve subdividing CPU operation into virtual central processing units (vCPUs).
A host is the virtual equivalent of a physical machine, on which a virtual system is operating. When there are several physical machines operating in tandem and managed as a whole, the grouped computing and memory resources form a cluster. In some systems, it is possible to dynamically add and remove from a cluster. Resources available at a host and cluster level can be partitioned out into resources pools with fine granularity.


== Performance ==

The performance or speed of a processor depends on, among many other factors, the clock rate (generally given in multiples of hertz) and the instructions per clock (IPC), which together are the factors for the instructions per second (IPS) that the CPU can perform.
Many reported IPS values have represented ""peak"" execution rates on artificial instruction sequences with few branches, whereas realistic workloads consist of a mix of instructions and applications, some of which take longer to execute than others. The performance of the memory hierarchy also greatly affects processor performance, an issue barely considered in MIPS calculations. Because of these problems, various standardized tests, often called ""benchmarks"" for this purpose‍—‌such as SPECint‍—‌have been developed to attempt to measure the real effective performance in commonly used applications.
Processing performance of computers is increased by using multi-core processors, which essentially is plugging two or more individual processors (called cores in this sense) into one integrated circuit. Ideally, a dual core processor would be nearly twice as powerful as a single core processor. In practice, the performance gain is far smaller, only about 50%, due to imperfect software algorithms and implementation. Increasing the number of cores in a processor (i.e. dual-core, quad-core, etc.) increases the workload that can be handled. This means that the processor can now handle numerous asynchronous events, interrupts, etc. which can take a toll on the CPU when overwhelmed. These cores can be thought of as different floors in a processing plant, with each floor handling a different task. Sometimes, these cores will handle the same tasks as cores adjacent to them if a single core is not enough to handle the information.
Due to specific capabilities of modern CPUs, such as simultaneous multithreading and uncore, which involve sharing of actual CPU resources while aiming at increased utilization, monitoring performance levels and hardware use gradually became a more complex task. As a response, some CPUs implement additional hardware logic that monitors actual use of various parts of a CPU and provides various counters accessible to software; an example is Intel's Performance Counter Monitor technology.


== See also ==


== Notes ==


== References ==


== External links ==

How Microprocessors Work at HowStuffWorks.
25 Microchips that shook the world – an article by the Institute of Electrical and Electronics Engineers."
"A computer worm is a standalone malware computer program that replicates itself in order to spread to other computers. It often uses a computer network to spread itself, relying on security failures on the target computer to access it. It will use this machine as a host to scan and infect other computers. When these new worm-invaded computers are controlled, the worm will continue to scan and infect other computers using these computers as hosts, and this behavior will continue. Computer worms use recursive method to copy themselves without host program and distribute themselves based on the law of exponential growth, and then controlling and infecting more and more computers in a short time. Worms almost always cause at least some harm to the network, even if only by consuming bandwidth, whereas viruses almost always corrupt or modify files on a targeted computer.
Many worms are designed only to spread, and do not attempt to change the systems they pass through. However, as the Morris worm and Mydoom showed, even these ""payload-free"" worms can cause major disruption by increasing network traffic and other unintended effects.


== History ==

The actual term ""worm"" was first used in John Brunner's 1975 novel, The Shockwave Rider. In that novel, Nichlas Haflinger designs and sets off a data-gathering worm in an act of revenge against the powerful men who run a national electronic information web that induces mass conformity. ""You have the biggest-ever worm loose in the net, and it automatically sabotages any attempt to monitor it. There's never been a worm with that tough a head or that long a tail!""On November 2, 1988, Robert Tappan Morris, a Cornell University computer science graduate student, unleashed what became known as the Morris worm, disrupting many computers then on the Internet, guessed at the time to be one tenth of all those connected. During the Morris appeal process, the U.S. Court of Appeals estimated the cost of removing the worm from each installation at between $200 and $53,000; this work prompted the formation of the CERT Coordination Center and Phage mailing list. Morris himself became the first person tried and convicted under the 1986 Computer Fraud and Abuse Act.


== Features ==
Independence
Computer viruses generally require a host program. The virus writes its own code into the host program. When the program runs, the written virus program is executed first, causing infection and damage. A worm does not need a host program, as it is an independent program or code chunk. Therefore, it is not restricted by the host program, but can run independently and actively carry out attacks.Exploit attacks
Because a worm is not limited by the host program, worms can take advantage of various operating system vulnerabilities to carry out active attacks. For example, the ""Nimda"" virus exploits vulnerabilities to attack.
Complexity
Some worms are combined with web page scripts, and are hidden in HTML pages using VBScript, ActiveX and other technologies. When a user accesses a webpage containing a virus, the virus automatically resides in memory and waits to be triggered. There are also some worms that are combined with backdoor programs or Trojan horses, such as ""Code Red"".Contagiousness
Worms are more infectious than traditional viruses. They not only infect local computers, but also all servers and clients on the network based on the local computer. Worms can easily spread through shared folders, e-mails, malicious web pages, and servers with a large number of vulnerabilities in the network.


== Harm ==
Any code designed to do more than spread the worm is typically referred to as the ""payload"". Typical malicious payloads might delete files on a host system (e.g., the ExploreZip worm), encrypt files in a ransomware attack, or exfiltrate data such as confidential documents or passwords.Probably the most common payload for worms is to install a backdoor. This allows the computer to be remotely controlled by the worm author as a ""zombie"". Networks of such machines are often referred to as botnets and are very commonly used for a range of malicious purposes, including sending spam or performing DoS attacks.Some special worms attack industrial systems in a targeted manner. Stuxnet was primarily transmitted through LANs and infected thumb-drives, as its targets were never connected to untrusted networks, like the internet.  This virus can destroy the core production control computer software used by chemical, power generation and power transmission companies in various countries around the world - in Stuxnet's case, Iran, Indonesia and India were hardest hit - it was used ""issue orders"" to other equipment in the factory, and to hide those commands from being detected.  Stuxnet used multiple vulnerabilities and four different zero-day exploits (eg: [1]) in Windows systems and Siemens SIMATICWinCC systems to attack the embedded programmable logic controllers of industrial machines.  Although these systems operate independently from the network, if the operator inserts a virus-infected disk into the system's USB interface, the virus will be able to gain control of the system without any other operational requirements or prompts.


== Countermeasures ==
Worms spread by exploiting vulnerabilities in operating systems.
Vendors with security problems supply regular security updates (see ""Patch Tuesday""), and if these are installed to a machine, then the majority of worms are unable to spread to it. If a vulnerability is disclosed before the security patch released by the vendor, a zero-day attack is possible.
Users need to be wary of opening unexpected email, and should not run attached files or programs, or visit web sites that are linked to such emails. However, as with the ILOVEYOU worm, and with the increased growth and efficiency of phishing attacks, it remains possible to trick the end-user into running malicious code.
Anti-virus and anti-spyware software are helpful, but must be kept up-to-date with new pattern files at least every few days. The use of a firewall is also recommended.
Users can minimize the threat posed by worms by keeping their computers' operating system and other software up to date, avoiding opening unrecognized or unexpected emails and running firewall and antivirus software.Mitigation techniques include:

ACLs in routers and switches
Packet-filters
TCP Wrapper/ACL enabled network service daemons
NullrouteInfections can sometimes be detected by their behavior - typically scanning the Internet randomly, looking for vulnerable hosts to infect. In addition, machine learning techniques can be used to detect new worms, by analyzing the behavior of the suspected computer.


== Worms with good intent ==
A helpful worm or anti-worm is a worm designed to do something that its author feels is helpful, though not necessarily with the permission of the executing computer's owner. Beginning with the very first research into worms at Xerox PARC, there have been attempts to create useful worms. Those worms allowed John Shoch and Jon Hupp to test the Ethernet principles on their network of Xerox Alto computers. Similarly, the Nachi family of worms tried to download and install patches from Microsoft's website to fix vulnerabilities in the host system by exploiting those same vulnerabilities. In practice, although this may have made these systems more secure, it generated considerable network traffic, rebooted the machine in the course of patching it, and did its work without the consent of the computer's owner or user. Regardless of their payload or their writers' intentions, most security experts regard all worms as malware.
Several worms, including some XSS worms, have been written to research how worms spread, such as the effects of changes in social activity or user behavior. One study proposed what seems to be the first computer worm that operates on the second layer of the OSI model (Data link Layer), utilizing topology information such as Content-addressable memory (CAM) tables and Spanning Tree information stored in switches to propagate and probe for vulnerable nodes until the enterprise network is covered.Anti-worms have been used to combat the effects of the Code Red, Blaster, and Santy worms.  Welchia is an example of a helpful worm.  Utilizing the same deficiencies exploited by the Blaster worm, Welchia infected computers and automatically began downloading Microsoft security updates for Windows without the users' consent. Welchia automatically reboots the computers it infects after installing the updates. One of these updates was the patch that fixed the exploit.Other examples of helpful worms are ""Den_Zuko"", ""Cheeze"", ""CodeGreen"", and ""Millenium"".


== See also ==
BlueKeep
Botnet
Code Shikara (Worm)
Computer and network surveillance
Computer virus
Email spam
Father Christmas (computer worm)
Self-replicating machine
Technical support scam – unsolicited phone calls from a fake ""tech support"" person, claiming that the computer has a virus or other problems
Timeline of computer viruses and worms
Trojan horse (computing)
XSS worm
Zombie (computer science)


== References ==


== External links ==
Malware Guide – Guide for understanding, removing and preventing worm infections on Vernalex.com.
""The 'Worm' Programs – Early Experience with a Distributed Computation"", John Shoch and Jon Hupp, Communications of the ACM, Volume 25 Issue 3 (March 1982), pages 172–180.
""The Case for Using Layered Defenses to Stop Worms"", Unclassified report from the U.S. National Security Agency (NSA), 18 June 2004.
Worm Evolution, paper by Jago Maniscalchi on Digital Threat, 31 May 2009."
"Home computers were a class of microcomputers that entered the market in 1977 and became common during the 1980s. They were marketed to consumers as affordable and accessible computers that, for the first time, were intended for the use of a single nontechnical user. These computers were a distinct market segment that typically cost much less than business, scientific or engineering-oriented computers of the time such as those running CP/M or the IBM PC, and were generally less powerful in terms of memory and expandability. However, a home computer often had better graphics and sound than contemporary business computers. Their most common uses were playing video games, but they were also regularly used for word processing, doing homework, and programming.
Home computers were usually not electronic kits; home computers were sold already manufactured in stylish metal or plastic enclosures. There were, however, commercial kits like the Sinclair ZX80 which were both home and home-built computers since the purchaser could assemble the unit from a kit.
Advertisements in the popular press for early home computers were rife with possibilities for their practical use in the home, from cataloging recipes to personal finance to home automation, but these were seldom realized in practice. For example, using a typical 1980s home computer as a home automation appliance would require the computer to be kept powered on at all times and dedicated to this task. Personal finance and database use required tedious data entry.
By contrast, advertisements in the specialty computer press often simply listed specifications, assuming a knowledgable user who already had applications in mind. If no packaged software was available for a particular application, the  home computer user could program one—provided they had invested the requisite hours to learn computer programming, as well as the idiosyncrasies of their system.  Since most systems shipped with the BASIC programming language included on the system ROM, it was easy for users to get started creating their own simple applications.  Many users found programming to be a fun and rewarding experience, and an excellent introduction to the world of digital technology.The line between 'business' and 'home' computer market segments vanished completely once IBM PC compatibles became commonly used in the home, since now both categories of computers typically use the same processor architectures, peripherals, operating systems, and applications. Often the only difference may be the sales outlet through which they are purchased. Another change from the home computer era is that the once-common endeavour of writing one's own software programs has almost vanished from home computer use.


== Background ==

As early as 1965, some experimental projects, such as Jim Sutherland's ECHO IV, explored the possible utility of a computer in the home. In 1969, the Honeywell Kitchen Computer was marketed as a luxury gift item, and would have inaugurated the era of home computing, but none was sold.Computers became affordable for the general public in the 1970s due to the mass production of the microprocessor starting in 1971. Early microcomputers such as the Altair 8800 had front-mounted switches and diagnostic lights (nicknamed ""blinkenlights"") to control and indicate internal system status, and were often sold in kit form to hobbyists. These kits would contain an empty printed circuit board which the buyer would fill with the integrated circuits, other individual electronic components, wires and connectors, and then hand-solder all the connections.While two early home computers (Sinclair ZX80 and Acorn Atom) could be bought either in kit form or assembled, most home computers were only sold pre-assembled. They were enclosed in plastic or metal cases similar in appearance to typewriter or hi-fi equipment enclosures, which were more familiar and attractive to consumers than the industrial metal card-cage enclosures used by the Altair and similar computers. The keyboard - a feature lacking on the Altair - was usually built into the same case as the motherboard. Ports for plug-in peripheral devices such as a video display, cassette tape recorders, joysticks, and (later) disk drives were either built-in or available on expansion cards. Although the Apple II series had internal expansion slots, most other home computer models' expansion arrangements were through externally accessible 'expansion ports' that also served as a place to plug in cartridge-based games. Usually the manufacturer would sell peripheral devices designed to be compatible with their computers as extra cost accessories. Peripherals and software were not often interchangeable between different brands of home computer, or even between successive models of the same brand.
To save the cost of a dedicated monitor, the home computer would often connect through an RF modulator to the family TV set, which served as both video display and sound system.By 1982, an estimated 621,000 home computers were in American households, at an average sales price of US$530 (equivalent to $1,404 in 2019). After the success of the Radio Shack TRS-80, the Commodore PET and the Apple II in 1977, almost every manufacturer of consumer electronics rushed to introduce a home computer. Large numbers of new machines of all types began to appear during the late 1970s and early 1980s. Mattel, Coleco, Texas Instruments and Timex, none of which had any prior connection to the computer industry, all had short-lived home computer lines in the early 1980s. Some home computers were more successful – the BBC Micro, Sinclair ZX Spectrum, Atari 800XL and Commodore 64 sold many units over several years and attracted third-party software development.
Almost universally, home computers had a BASIC interpreter combined with a line editor in permanent read-only memory which one could use to type in BASIC programs and execute them immediately or save them to tape or disk. In direct mode, the BASIC interpreter was also used as the user interface, and given tasks such as loading, saving, managing, and running files. One exception was the Jupiter Ace, which had a Forth interpreter instead of BASIC. A built-in programming language was seen as a requirement for any computer of the era, and was the main feature setting home computers apart from video game consoles.
Still, home computers competed in the same market as the consoles. A home computer was often seen as simply as a higher end purchase than a console, adding abilities and productivity potential to what would still be mainly a gaming device. A common marketing tactic was to show a computer system and console playing games side by side, then emphasizing the computer's greater ability by showing it running user-created programs, education software, word processing, spreadsheet and other applications while the game console showed a blank screen or continued playing the same repetitive game. Another capability home computers had that game consoles of the time lacked was the ability to access remote services over telephone lines by adding a serial port interface, a modem, and communication software. Though it could be costly, it permitted the computer user to access services like Compuserve and private or corporate bulletin board systems to post or read messages, or to download or upload software. Some enthusiasts with computers equipped with large storage capacity and a dedicated phone line operated bulletin boards of their own. This capability anticipated the internet by nearly twenty years.
Some game consoles offered ""programming packs"" consisting of a version of BASIC in a ROM cartridge. Atari's BASIC Programming for the Atari 2600 was one of these. For the ColecoVision console, Coleco even announced an expansion module which would convert it into a full-fledged computer system. The Magnavox Odyssey² game console had a built-in keyboard to support its C7420 Home Computer Module.
Books of type-in program listings like BASIC Computer Games were available dedicated for the BASICs of most models of computer with titles along the lines of 64 Amazing BASIC Games for the Commodore 64. While most of the programs in these books were short and simple games or demos, some titles such as Compute!'s SpeedScript series, contained productivity software that rivaled commercial packages. To avoid the tedious process of typing in a program listing from a book, these books would sometimes include a mail-in offer from the author to obtain the programs on disk or cassette for a few dollars. Before the Internet, and before most computer owners had a modem, books were a popular and low-cost means of software distribution—one that had the advantage of incorporating its own documentation. These books also served a role in familiarizing new computer owners with the concepts of programming; some titles added suggested modifications to the program listings for the user to carry out. Applying a patch to modify software to be compatible with one's system or writing a utility program to fit one's needs was a skill every advanced computer owner was expected to have.During the peak years of the home computer market, scores of models were produced, usually as individual design projects with little or no thought given to compatibility between different manufacturers or even within product lines of the same manufacturer. Except for the Japanese MSX standard, the concept of a computer platform was still forming, with most companies considering rudimentary BASIC language and disk format compatibility sufficient to claim a model as ""compatible"". Things were different in the business world, where cost-conscious small business owners had been using CP/M running on Z80 based computers from Osborne, Kaypro, Morrow Designs and a host of other manufacturers. For many of these businesses, the development of the microcomputer made computing and business software affordable where they had not been before.
Introduced in August 1981, the IBM Personal Computer would eventually supplant CP/M as the standard platform used in business. This was largely due to the IBM name and the system's 16 bit open architecture, which expanded maximum memory tenfold, and also encouraged production of third-party clones. In the late 1970s, the 6502-based Apple II series had carved out a niche for itself in business, thanks to the industry's first killer app, VisiCalc, released in 1979. However the Apple II would quickly be displaced for office use by IBM PC compatibles running Lotus 1-2-3. Apple Computer's 1980 Apple III was underwhelming, and although the 1984 release of the Apple Macintosh introduced the modern GUI to the market, it wasn't common until IBM-compatible computers adopted it. Throughout the 1980s, businesses large and small adopted the PC platform, leading, by the end of the decade, to sub-US$1000 IBM PC XT-class white box machines, usually built in Asia and sold by US companies like PCs Limited.
In 1980 Wayne Green, the publisher of Kilobaud Microcomputing, recommended that companies avoid the term ""home computer"" in their advertising as ""I feel is self-limiting for sales ... I prefer the term ""microcomputers"" since it doesn't limit the uses of the equipment in the imagination of the prospective customers"". With the exception of Tandy, most computer companies – even those with a majority of sales to home users – agreed, avoiding the term ""home computer"" because of its association with the image of, as Compute! wrote, ""a low-powered, low-end machine primarily suited for playing games"". Apple consistently avoided stating that it was a home-computer company, and described the IIc as ""a serious computer for the serious home user"" despite competing against IBM's PCjr home computer. John Sculley denied that his company sold home computers; rather, he said, Apple sold ""computers for use in the home"". In 1990 the company reportedly refused to support joysticks on its low-cost Macintosh LC and IIsi computers to prevent customers from considering them as ""game machines"".Although the Apple II and Atari computers are functionally similar, Atari's home-oriented marketing resulted in a game-heavy library with much less business software. By the late 1980s, many mass merchants sold video game consoles like the Nintendo Entertainment System, but no longer sold home computers.Toward the end of the 1980s, clones also became popular with non-corporate customers. Inexpensive, highly compatible clones succeeded where the PCjr had failed. Replacing the hobbyists who had made up the majority of the home computer market were, as Compute! described them, ""people who want to take work home from the office now and then, play a game now and then, learn more about computers, and help educate their children"". By 1986 industry experts predicted an ""MS-DOS Christmas"", and the magazine stated that clones threatened Commodore, Atari, and Apple's domination of the home-computer market.The declining cost of IBM compatibles on the one hand, and the greatly increased graphics, sound, and storage abilities of fourth generation video game consoles such as the Sega Genesis and Super Nintendo Entertainment System on the other, combined to cause the market segment for home computers to vanish by the early 1990s in the US. In Europe, the home computer remained a distinct presence for a few years more, with the low-end models of the 16-bit Amiga and Atari ST families being the dominant players, but by the mid-1990s even the European market had dwindled. The Dutch government even ran a program that allowed businesses to sell computers tax-free to its employees, often accompanied by home training programs. Naturally, these businesses chose to equip their employees with the same systems they themselves were using. Today a computer bought for home use anywhere will be very similar to those used in offices – made by the same manufacturers, with compatible peripherals, operating systems, and application software.


== Technology ==

Many home computers were superficially similar. Most had a keyboard integrated into the same case as the motherboard, or, more frequently, a mainboard—while the expandable home computers appeared from the very start (the Apple II offered as many as seven expansion slots), as the whole segment was generally aimed downmarket, few offers were priced or positioned high enough to allow for such expandability. Some systems have only one expansion port, often realized in the form of cumbersome ""sidecar"" system, such as on the TI-99/4, or required finicky and unwieldy ribbon cables to connect the expansion modules.
Sometimes they were equipped with a cheap membrane or chiclet keyboard in the early days, although full-travel keyboards quickly became universal due to overwhelming consumer preference. Most systems could use an RF modulator to display 20–40 column text output on a home television. Indeed, the use of a television set as a display almost defines the pre-PC home computer. Although dedicated composite or ""green screen"" computer displays were available for this market segment and offered a sharper display, a monitor was often a later purchase made only after users had bought a floppy disk drive, printer, modem, and the other pieces of a full system. The reason for this was that while those TV-monitors had difficulty displaying the clear and readable 80-column text that became the industry standard at the time, the only consumers who really needed that were the power users utilizing the machine for business purposes, while the average casual consumer would use the system for games only and was content with the lower resolution for which a TV worked fine. An important exception was the Radio Shack TRS-80, the first mass-marketed computer for home use, which included its own 64-column display monitor and full-travel keyboard as standard features.
This ""peripherals sold separately"" approach is another defining characteristic of the home computer era. A first time computer buyer who brought a base C-64 system home and hooked it up to their TV would find they needed to buy a disk drive (the Commodore 1541 was the only fully compatible model) or Datasette before they could make use of it as anything but a game machine or TV Typewriter.
In the early part of the 1980s, the dominant microprocessors used in home computers were the 8-bit MOS Technology 6502 (Apple, Commodore, Atari, BBC Micro) and Zilog Z80 (TRS-80, ZX81, ZX Spectrum, Commodore 128, Amstrad CPC). One exception was the TI-99 series, announced in 1979 with a 16-bit TMS9900 CPU. The TI was originally to use the 8-bit 9985 processor designed especially for it, but this project was cancelled. However, the glue logic needed to retrofit the 16-bit CPU to an 8-bit 9985 system negated the advantages of the more powerful CPU. Another exception was the Soviet Elektronika BK series of 1984, which used the fully 16-bit and powerful for the time 1801 series CPU, offering a full PDP-11 compatibility and a fully functional Q-Bus slot, though at the cost of very anemic RAM and graphics. The Motorola 6809 was used by the Radio Shack TRS-80 Color Computer, the Fujitsu FM-7, and Dragon 32/64.
Processor clock rates were typically 1–2 MHz for 6502 and 6809 based CPU's and 2–4 MHz for Z80 based systems (yielding roughly equal performance), but this aspect was not emphasized by users or manufacturers, as the systems' limited RAM capacity, graphics abilities and storage options had a more perceivable effect on performance than CPU speed. For low-price computers the cost of RAM memory chips contributed greatly to the final product price to the consumer, and fast CPUs demanded expensive, fast memory. So designers kept clock rates only adequate; in some cases like the Atari and Commodore 8-bit machines, coprocessors were added to speed processing of graphics and audio data. For these computers clock rate was considered a technical detail of interest only to users needing accurate timing for their own programs. To economize on component cost, often the same crystal used to produce color television compatible signals was also divided down and used for the processor clock. This meant processors rarely operated at their full rated speed, and had the side-effect that European and North American versions of the same home computer operated at slightly different speeds and different video resolution due to different television standards.
Initially, many home computers used the then-ubiquitous compact audio cassette as a storage mechanism. A rough analogy to how this worked would be to place a recorder on the phone line as a file was uploaded by modem to ""save"" it, and playing the recording back through the modem to ""load"". Most cassette implementations were notoriously slow and unreliable, but 8"" drives were too bulky for home use, and early 5.25"" form factor drives were priced for business use, out of reach of most home buyers. An innovative alternative was the Exatron Stringy Floppy, a continuous loop tape drive which was much faster than a datacassette drive and could perform much like a floppy disk drive. It was available for the TRS-80 and some others. A closely related technology was the ZX Microdrive developed by Sinclair Research in the UK for their ZX Spectrum and QL home computers.
Eventually mass production of 5.25"" drives resulted in lower prices, and after about 1984 they pushed cassette drives out of the US home computer market. 5.25"" floppy disk drives would remain standard until the end of the 8-bit era. Though external 3.5"" drives were made available for home computer systems toward the latter part of the 1980s, almost all software sold for 8-bit home computers remained on 5.25"" disks; 3.5"" drives were used for data storage, with the exception of the Japanese MSX standard, on which 5.25"" floppies were never popular. Standardization of disk formats was not common; sometimes even different models from the same manufacturer used different disk formats. Almost universally the floppy disk drives available for 8-bit home computers were housed in external cases with their own controller boards and power supplies contained within. Only the later, advanced 8-bit home computers housed their drives within the main unit; these included the TRS-80 Model III, TRS-80 Model 4, Apple IIc, MSX2, and Commodore 128D. The later 16-bit machines such as the Atari 1040ST (not the 520ST), the Commodore Amigas, and the Tandy 1000s did house floppy drive(s) internally. At any rate, to expand any computer with additional floppy drives external units would have to be plugged in.
Toward the end of the home computer era, drives for a number of home computer models appeared offering disk-format compatibility with the IBM PC. The disk drives sold with the Commodore 128, Amiga and Atari ST were all able to read and write PC disks, which themselves were undergoing the transition from 5.25"" to 3.5"" format at the time (though 5.25"" drives remained common on PCs until the late 1990s, due to existence of the large software and data archives on five-inch floppies). 5.25"" drives were made available for the ST, Amiga and Macintosh, otherwise 3.5"" based systems with no other use for a 5.25"" format. Hard drives were never popular on home computers, remaining an expensive, niche product mainly for BBS sysops and the few business users.
Various copy protection schemes were developed for floppy disks; most were broken in short order.  Many users would only tolerate copy protection for games, as wear and tear on disks was a significant issue in an entirely floppy-based system. The ability to make a ""working backup"" disk of vital application software was seen as important. Copy programs that advertised their ability to copy or even remove common protection schemes were a common category of utility software in this pre-DMCA era.
In another defining characteristic of the home computer, instead of a command line, the BASIC interpreter served double duty as a user interface. Coupled to a character-based screen or line editor, BASIC's file management commands could be entered in direct mode. In contrast to modern computers, home computers most often had their operating system (OS) stored in ROM chips. This made startup times very fast – no more than a few seconds – but made OS upgrades difficult or impossible without buying a new unit. Usually only the most severe bugs were fixed by issuing new ROMs to replace the old ones at the user's cost. Also, the small size and limited scope of home computer ""operating systems"" (really little more than what today would be called a kernel) left little room for bugs to hide.
Although modern operating systems include extensive programming libraries to ease development and promote standardization, home computer operating systems provided little support to application programs. Professionally written software often switched out the ROM based OS anyway to free the address space it occupied and maximize RAM capacity. This gave the program full control of the hardware and allowed the programmer to optimize performance for a specific task. Games would often turn off unused I/O ports, as well as the interrupts that served them. As multitasking was never common on home computers, this practice went largely unnoticed by users. Most software even lacked an exit command, requiring a reboot to use the system for something else.
In an enduring reflection of their early cassette-oriented nature, most home computers loaded their disk operating system (DOS) separately from the main OS. The DOS was only used for disk and file related commands and was not required to perform other computing functions. One exception was Commodore DOS, which was not loaded into the computer's main memory at all – Commodore disk drives contained a 6502 processor and ran DOS from internal ROM. While this gave Commodore systems some advanced capabilities – a utility program could sideload a disk copy routine onto the drive and return control to the user while the drive copied the disk on its own – it also made Commodore drives more expensive and difficult to clone.
Many home computers had a cartridge interface which accepted ROM-based software. This was also used for expansion or upgrades such as fast loaders.  Application software on cartridge did exist, which loaded instantly and eliminated the need for disk swapping on single drive setups, but the vast majority of cartridges were games.


=== PCs at home ===
From the introduction of the IBM Personal Computer (ubiquitously known as the PC) in 1981, the market for computers meant for the corporate, business, and government sectors came to be dominated by the new machine and its MS-DOS operating system. Even basic PCs cost thousands of dollars and were far out of reach for typical home computerists. However, in the following years technological advances and improved manufacturing capabilities (mainly greater use of robotics and relocation of production plants to lower-wage locations in Asia) permitted several computer companies to offer lower-cost PC style machines that would become competitive with many 8-bit home-market pioneers like Radio Shack, Commodore, Atari, Texas Instruments, and Sinclair. PCs could never become as affordable as these because the same price-reducing measures were available to all computer makers. Furthermore, software and peripherals for PC style computers tended to cost more than those for 8-bit computers because of the anchoring effect caused by the pricey IBM PC. As well, PCs were inherently more expensive since they could not use the home TV set as a video display. Nonetheless, the overall reduction in manufacturing costs narrowed the price difference between old 8-bit technology and new PCs. Despite their higher absolute prices PCs were perceived by many to be better values for their utility as superior productivity tools and their access to industry-standard software. Another advantage was the 8088/8086's wide, 20-bit address bus: the PC could access more than 64 kilobytes of memory relatively inexpensively (8-bit CPUs, which generally had multiplexed 16-bit address buses, required complicated, tricky memory management techniques like bank-switching). Similarly, the default PC floppy was double-sided with about twice the storage capacity of floppy disks used by 8-bit home computers. PC drives tended to cost less because they were most often built-in, requiring no external case, controller, and power supply. The faster clock rates and wider buses available to later Intel CPUs compensated somewhat for the custom graphics and sound chips of the Commodores and Ataris. In time the growing popularity of home PCs spurred many software publishers to offer gaming and children's software titles.Many decision makers in the computer industry believed there could be a viable market for office workers who used PC/DOS computers at their jobs and would appreciate an ability to bring diskettes of data home on weeknights and weekends to continue work after-hours on their ""home"" computers. So the ability to run industry-standard MS-DOS software on affordable, user-friendly PCs was anticipated as a source of new sales. Furthermore, many in the industry felt that MS-DOS would eventually (inevitably, it seemed) come to dominate the computer business entirely, and some manufacturers felt the need to offer individual customers PC-style products suitable for the home market.
In early 1984 market colossus IBM produced the PCjr as a PC/DOS-compatible machine aimed squarely at the home user. It proved a spectacular failure because IBM deliberately limited its capabilities and expansion possibilities in order to avoid cannibalizing sales of the profitable PC. IBM management believed that if they made the PCjr too powerful too many buyers would prefer it over the bigger, more expensive PC. Poor reviews in the computer press and poor sales doomed the PCjr.
Tandy Corporation capitalized on IBM's blunder with its PCjr-compatible Tandy 1000 in November. Like the PCjr it was pitched as a home, education, and small-business computer featuring joystick ports, better sound and graphics (same as the PCjr but with enhancements), combined with near-PC/DOS compatibility (unlike Tandy's earlier Tandy 2000). The improved Tandy 1000 video hardware became a standard of its own, known as Tandy Graphics Adapter or TGA. Later Tandy produced Tandy 1000 variants in form factors and price-points even more suited to the home computer market, comprised particularly by the Tandy 1000 EX and HX models (later supplanted by the 1000 RL), which came in cases resembling the original Apple IIs (CPU, keyboard, expansion slots, and power supply in a slimline cabinet) but also included floppy disk drives. The proprietary Deskmate productivity suite came bundled with the Tandy 1000s. Deskmate was suited to use by computer novices with its point-and-click (though not graphical) user interface. From the launch of the Tandy 1000 series, their manufacture were price-competitive because of Tandy's use of high-density ASIC chip technology, which allowed their engineers to integrate many hardware features into the motherboard (obviating the need for circuit cards in expansion slots as with other brands of PC). Tandy never transferred its manufacturing operation to Asia; all Tandy desktop computers were built in the USA (this was not true of the laptop and pocket computers, nor peripherals).
In 1985 the Epson corporation, a popular and respected producer of inexpensive dot-matrix printers and business computers (the QX-10 and QX-16), introduced its low-cost Epson Equity PC. Its designers took minor shortcuts such as few expansion slots and a lack of a socket for an 8087 math chip, but Epson did bundle some utility programs that offered decent turnkey functionality for novice users. While not a high performer, the Equity was a reliable and compatible design for half the price of a similarly-configured IBM PC. Epson often promoted sales by bundling one of their printers with it at cost. The Equity I sold well enough to warrant the furtherance of the Equity line with the follow-on Equity II and Equity III.
In 1986 UK home computer maker Amstrad began producing their PC1512 PC-compatible for sale in the UK. Later they would market the machine in the US as the PC6400. In June 1987 an improved model was produced as the PC1640. These machines had fast 8086 CPUs, enhanced CGA graphics, and were feature-laden for their modest prices.  They had joystick adapters built into their keyboards and shipped with a licensed version of the Digital Research's GEM, a GUI for the MS-DOS operating system. They became marginal successes in the home market.
In 1987 longtime small computer maker Zenith introduced a low-cost PC they called the EaZy PC. This was positioned as an ""appliance"" computer much like the original Apple Macintosh: turnkey startup, built-in monochrome video monitor, and lacking expansion slots requiring proprietary add-ons available only from Zenith, but instead with the traditional MS-DOS Command-line interface. The EaZy PC used a turbo NEC V40 CPU (uprated 8088) which was rather slow for its time, but the video monitor did feature 400 pixel vertical resolution. This unique computer failed for the same reasons as did IBM's PCjr: poor performance and expandability, and a price too high for the home market.
Another company that offered low-cost PCs for home use was Leading Edge with their Model M and Model D computers. These were configured like full-featured business PCs yet still could compete in the home market on price because Leading Edge had access to low-cost hardware from their Asian manufacturing partners Mitsubishi with the Model M and Daewoo with the Model D. The LEWP was bundled with the Model D. It was favorably reviewed by the computer press and sold very well.By the mid-80s the market for inexpensive PCs for use in the home market was expanding at a rate such that the two leaders in the US, Commodore and Atari, themselves felt compelled to enter the market with their own lines. They were only marginally successful compared to other companies that made only PCs.Still later prices of white box PC clone computers by various manufacturers became competitive with the higher-end home computers (see below). Throughout the 1980s costs and prices continued to be driven down by: advanced circuit design and manufacturing, multifunction expansion cards, shareware applications such as PC-Talk, PC-Write, and PC-File, greater hardware reliability, and more user-friendly software that demanded less customer support services.  The increasing availability of faster processor and memory chips, inexpensive EGA and VGA video cards, sound cards, and joystick adapters also bolstered the viability of PC/DOS computers as alternatives to specially-made computers and game consoles for the home.


=== High performance ===
From about 1985 the high end of the home computer market began to be dominated by ""next generation"" home computers using the 16-bit Motorola 68000 chip, which enabled the greatly increased abilities of the Amiga and Atari ST series (in the UK the Sinclair QL was built around the Motorola 68008 with its external 8-bit bus). Graphics resolutions approximately doubled to give roughly NTSC-class resolution, and color palettes increased from dozens to hundreds or thousands of colors available. The Amiga was built with a custom chipset with dedicated graphics and sound coprocessors for high performance video and audio. The Amiga found use as a workstation for desktop video, a first for a standalone computer costing far less than dedicated motion-video processing equipment costing many thousands of dollars. Stereo sound became standard for the first time; the Atari ST gained popularity as an affordable alternative for MIDI equipment for the production of music.
Clock rates on the 68000-based systems were approximately 8 MHz with RAM capacities of 256 KB (for the base Amiga 1000) up to 1024 KB (1 megabyte, a milestone, first seen on the Atari 1040ST). These systems used 3.5"" floppy disks from the beginning but 5.25"" drives were made available to facilitate data exchange with IBM PC compatibles. The Amiga and ST both had GUIs with windowing technology. These were inspired by the Apple Macintosh, but at a list price of US$2495 (equivalent to $5,900 in 2019), the Macintosh itself was too expensive for most households. The Commodore Amiga in particular had true multitasking capability and unlike all other low-cost computers of the era could run multiple applications in their own windows.


=== MSX ===
MSX was a standard for a home computing architecture that was intended and hoped to become a universal platform for home computing. It was conceived, engineered and marketed by Microsoft Japan with ASCII Corporation. Computers conforming to the MSX standard were produced by most all major Japanese electronics manufacturers, as well as two Korean ones and several others in Europe and South America. Some 5 million units are known to have been sold in Japan alone. They sold in smaller numbers throughout the world. Due to the ""price wars"" being waged in the USA home computer market during the 1983-85 period, MSX computers were never marketed to any great extent in the USA. Eventually more advanced mainstream home computers and game consoles obsoleted the MSX machines.
The MSX computers were built around the Zilog Z80 8-bit processor, assisted with dedicated video graphics and audio coprocessors supplied by Intel, Texas Instruments, and General Instrument. MSX computers received a great deal of software support from the traditional Japanese publishers of game software, but never garnered such support from publishers of productivity applications. Microsoft did, however, produce a special version of the BASIC programming language that ran under MSX.


== Radio frequency interference ==
After the first wave of game consoles and computers landed in American homes, the United States Federal Communications Commission (FCC) began receiving complaints of electromagnetic interference to television reception. By 1979 the FCC demanded that home computer makers submit samples for radio frequency interference testing. It was found that ""first generation"" home computers emitted too much radio frequency noise for household use. The Atari 400 and 800 were designed with heavy RF shielding to meet the new requirements. Between 1980 and 1982 regulations governing RF emittance from home computers were phased in. Some companies appealed to the FCC to waive the requirements for home computers, while others (with compliant designs) objected to the waiver. Eventually techniques to suppress interference became standardized.


== Reception and sociological impact ==

In 1977, referring to computers used in home automation at the dawn of the home computer era, Digital Equipment Corporation CEO Ken Olsen is quoted as saying ""There is no reason for any individual to have a computer in his home."" Despite Olsen's warning, in the late 1970s and early 1980s, from about 1977 to 1983, it was widely predicted that computers would soon revolutionize many aspects of home and family life as they had business practices in the previous decades. Mothers would keep their recipe catalog in ""kitchen computer"" databases and turn to a medical database for help with child care, fathers would use the family's computer to manage family finances and track automobile maintenance. Children would use online encyclopedias for school work and would be avid video gamers. The computer would even be tasked with babysitting younger children. Home automation would bring about the intelligent home of the 1980s. Using Videotex, NAPLPS or some sort of vaguely conceptualized computer technology, television would gain interactivity. It would be possible to do the week's grocery shopping through the television. The ""personalized newspaper"" (to be displayed on the television screen)  was another commonly predicted application. Morning coffee would be brewed automatically under computer control. The same household computer would control the home's lighting and temperature. Robots would take the garbage out, and be programmed to perform new tasks via the home computer. Electronics were expensive, so it was generally assumed that each home would have only one computer for the entire family to use. Home control would be performed in a multitasking time-sharing arrangement, with interfaces to the various devices it was expected to control.

As an industry we haven't found any compelling reason to buy a computer for the home.
When the computer revolution was unofficially announced in the early 1980s, all indications were that it would change the world. Experts predicted that within five years, every household would have a computer. Dad would run his business on it. Mom would store her recipes on it. The kids would do their homework on it. Today only 15% of American homes have a computer – and the other 85% don't seem the least bit interested. There is a general feeling that the home computer was a fad and that there is really no practical purpose for a computer in the home.
All this was predicted to be commonplace by the end of the 1980s, but by 1987 Dan Gutman wrote that the predicted revolution was ""in shambles"", with only 15% of American homes owning a computer. Virtually every aspect that was foreseen would be delayed to later years or would be entirely surpassed by later technological developments. The home computers of the early 1980s could not multitask, which meant that using one as a home automation or entertainment appliance would require it be kept powered on at all times and dedicated exclusively for this use. Even if the computers could be used for multiple purposes simultaneously as today, other technical limitations predominated; memory capacities were too small to hold entire encyclopedias or databases of financial records; floppy disk-based storage was inadequate in both capacity and speed for multimedia work; and the home computers' graphics chips could only display blocky, unrealistic images and blurry, jagged text that would be difficult to read a newspaper from. Although CD-ROM technology was introduced in 1985 with much promise for its future use, the drives were prohibitively expensive and only interfaced with IBM PCs and compatibles.The Boston Phoenix stated in 1983 that ""people are catching on to the fact that 'applications' like balancing your checkbook and filing kitchen recipes are actually faster and easier to do with a pocket calculator and a box of index cards"". inCider observed that ""companies cannot live by dilettantes alone"". Gutman wrote that when the first computer boom ended in 1984, ""Suddenly, everybody was saying that the home computer was a fad, just another hula hoop"". Robert Lydon, publisher of Personal Computing, stated in 1985 that the home market ""never really existed. It was a fad. Just about everyone who was going to buy a computer for their home has done it"", and predicted that Apple would cease to exist within two years.A backlash set in; computer users were ""geeks"", ""nerds"" or worse, ""hackers"". The North American video game crash of 1983 soured many on home computer technology as users saw large investments in 'the technology of the future' turn into dead-ends when manufacturers pulled out of the market or went out of business. The computers that were bought for use in the family room were either forgotten in closets or relegated to basements and children's bedrooms to be used exclusively for games and the occasional book report. Home computers of the 1980s have been called ""a technology in search of a use"". In 1984 Tandy executive Steve Leininger, designer of the TRS-80 Model I, admitted that ""As an industry we haven't found any compelling reason to buy a computer for the home"" other than for word processing. A 1985 study found that, during a typical week, 40% of adult computer owners did not use their computers at all. Usage rates among children were higher, with households reporting that only 16-20% of children aged 6––17 did not use the computer during a typical week.It would take another 10 years for technology to mature, for the graphical user interface to make the computer approachable for non-technical users, and for the World Wide Web to provide a compelling reason for most people to want a computer in their homes. Separate 1998 studies found that 75% of Americans with Internet access accessed primarily from home and that not having Internet access at home inhibited Internet use. Predicted aspects of the revolution were left by the wayside or modified in the face of an emerging reality. The cost of electronics dropped precipitously and today many families have a computer for each family member, although shared desktop machines are still common. Encyclopedias, recipe catalogs and medical databases are kept online and accessed over the World Wide Web – not stored locally on floppy disks or CD-ROM. TV has yet to gain substantial interactivity; instead, the web has evolved alongside television, giving rise to the second screen concept. The HTPC and services like Netflix, Google TV or Apple TV, along with internet video sites such as YouTube and Hulu, may one day replace traditional broadcast and cable television. Our coffee may be brewed automatically every morning, but the computer is a simple one embedded in the coffee maker, not under external control. As of 2008, robots are just beginning to make an impact in the home, with Roomba and Aibo leading the charge.
This delay wasn't out of keeping with other technologies newly introduced to an unprepared public. Early motorists were widely derided with the cry of ""Get a horse!"" until the automobile was accepted. Television languished in research labs for decades before regular public broadcasts began. In an example of changing applications for technology, before the invention of radio, the telephone was used to distribute opera and news reports, whose subscribers were denounced as ""illiterate, blind, bedridden and incurably lazy people"". Likewise, the acceptance of computers into daily life today is a product of continuing refinement of both technology and perception.


== Use in the 21st century ==
Retrocomputing is the use of vintage hardware, possibly performing modern tasks such as surfing the web and email. As programming techniques evolved and these systems were well-understood after decades of use, it became possible to write software giving home computers capabilities undreamed of by their designers. The Contiki OS implements a GUI and TCP/IP stack on the Apple II, Commodore 8-bit and Atari ST (16-bit) platforms, allowing these home computers to function as both internet clients and servers.The Commodore 64 has been repackaged as the C-One and C64 Direct-to-TV, both designed by Jeri Ellsworth with modern enhancements.Throughout the 1990s and 1st decade of the 21st century, many home computer systems were available inexpensively at garage sales and on eBay. Many enthusiasts started to collect home computers, with older and rarer systems being much sought after. Sometimes the collections turned into a virtual museum presented on web sites.As their often-inexpensively manufactured hardware ages and the supply of replacement parts dwindles, it has become popular among enthusiasts to emulate these machines, recreating their software environments on modern computers. One of the more well-known emulators is the Multi Emulator Super System (MESS) which can emulate most of the better-known home computers. A more or less complete list of home computer emulators can be found in the List of computer system emulators article. Games for many 8 and 16 bit home computers are becoming available for the Wii Virtual Console.


== Notable home computers ==

The time line below describes many of the most popular or significant home computers of the late 1970s and of the 1980s.
The most popular home computers in the USA up to 1985 were: the TRS-80 (1977), various models of the Apple II family (first introduced in 1977), the Atari 400/800 (1979) along with its follow up models the 800XL and 130XE, and the Commodore VIC-20 (1980) and the Commodore 64 (1982). The VIC was the first computer of any type to sell over one million units, and the 64 is still the highest-selling single model of personal computer ever, with over 17 million produced before production stopped in 1994 – a 12-year run with only minor changes. At one point in 1983 Commodore was selling as many 64s as the rest of the industry's computers combined.The British market was different, as relatively high prices and lower disposable incomes reduced the appeal of most American products. New Scientist stated in 1977 that ""the price of an American kit in dollars rapidly translates into the same figure in pounds sterling by the time it has reached the shores of Britain"". The Commodore 64 was also popular, but a BYTE columnist stated in 1985:
It's not easy for a U.K. citizen to write about home computers for an American magazine. We use the term to refer to an altogether different object on our side of the Atlantic.
In the U.S.A., an Apple II is a home computer; the IBM PC in its smaller configurations is a home computer; the Macintosh is a home computer. Home computers use floppy disks for mass storage and perform useful functions like word processing and income tax preparation as well as playing games.

In the U.K., those computers would be considered rather expensive as business computers, let alone for home use. Home computers typically cost less than £200 (about $250) and use cassette tape recorders for mass storage. We have various manufacturers of our own, some unheard of in the U.S.A. ... Even when we do have machines in common (the Commodore 64), I suspect that the vast majority of U.S. users buy the disk drive, while the majority of U.K. users have only the cassette deck.
Many of the British-made systems like Sinclair's ZX81 and Spectrum, and later the Amstrad/Schneider CPC were much more widely used in Europe than US systems. A few low-cost British Sinclair models were sold in the US by Timex Corporation as the Timex Sinclair 1000 and the ill-fated Timex Sinclair 2068, but neither established a strong following. The only transatlantic success was the Commodore 64, which competed favorably price-wise with the British systems, and was the most popular system in Europe as in the USA.Until the introduction of the IBM PC in 1981, computers such as the Apple II and TRS 80 also found considerable use in office work. In 1983 IBM introduced the PCjr in an attempt to continue their business computer success in the home computer market, but incompatibilities between it and the standard PC kept users away. Assisted by a large public domain software library and promotional offers from Commodore, the PET had a sizable presence in the North American education market until that segment was largely ceded to the Apple II as Commodore focused on the C-64's success in the mass retail market.


=== 1970s ===
Three microcomputers were the prototypes for what would later become the home computer market segment; but when introduced they sold as much to hobbyists and small businesses as to the home.

June 1977: Apple II (North America), color graphics, eight expansion slots; one of the first computers to use a typewriter-like plastic case design.
August 1977: Tandy Radio Shack TRS-80 (N. Am.), first home computer for less than US$600, used a dedicated monitor for US Federal Communications Commission (FCC) rules compliance.
October 1977: Commodore PET (N. Am.), first all-in-one computer: keyboard/screen/tape storage built into stamped sheet metal enclosure.
In 1977 Compucolor II, although shipments did not start until the next year. The Compucolor II was smaller, less expensive than first model which was an upgrade kit for the company's color computer terminal, turning the Intercolor 8001 into the Compucolor 8001 and used the newly-introduced 5.25-inch floppy disks instead of the former 8-inch models.The following computers also introduced significant advancements to the home computer segment:

1979: TI-99/4, first home computer with a 16-bit processor and first to add sprite graphics
1979: Atari 400/800 (N. Am.), first computer with custom chip set and programmable video chip and built-in audio output


=== 1980s ===

January 1980: Sinclair ZX80, available in the United Kingdom for less than a hundred pounds
1980: Commodore VIC-20 (N. Am.), under US$300; first computer of any kind to pass one million sold.
1980: TRS-80 Color Computer (N. Am.), Motorola 6809, optional OS-9 multi-user multi-tasking.
July 1980: TRS-80 Model III (N. Am.), essentially a TRS-80 Model I repackaged in an all-in-one cabinet, to comply with FCC regulations for radiofrequency interference, to eliminate cable clutter, and use only one electrical outlet. Some enhancements like extended character set, repeating keys, and real time clock.
June 1981: Texas Instruments TI-99/4A, based on the less successful TI-99/4.
1981: Sinclair ZX81 (Europe), £49.95 in kit form; £69.95 pre-built, released as Timex Sinclair 1000 in US in 1982.
1981: BBC Micro (Europe), premier educational computer in the UK for a decade; advanced BBC BASIC with integrated 6502 machine code assembler, and a large number of I/O ports, ~ 1.5 million sold.
April 1982: Sinclair ZX Spectrum (Europe), best-selling British home computer; catalysed the UK software industry, widely cloned by the Soviet Union.
June 1982: MicroBee (Australia), initially as a kit, then as a finished unit.
August 1982: Dragon 32 (UK) became, for a short time, the best-selling home micro in the United Kingdom.
August 1982: Commodore 64 (N. Am.), custom graphic & synthesizer chipset, best-selling computer model of all time: ~ 17 million sold.
Jan. 1983: Apple IIe, Apple II enhanced. Reduced component count and production costs enabled high-volume production, until 1993.
April 1983: TRS-80 Model 4, major upgrade compatible with Model III. Ran industry-standard CP/M, updated TRSDOS 6, 4 MHz speed, 128KB RAM max, 80x24 screen, 640x240 high-res option. In September the transportable ""luggable"" Model 4P unveiled.
1983: Acorn Electron A stripped down 'sibling' of the BBC microcomputer with limited functionality. The Electron recovered from a slow start to become one of the more popular home computers of that era in the UK.
1983: Sanyo PHC-25, with 16k of RAM, one of a number of Sanyo models
1983: Coleco Adam, one of the few home computers to be sold only as a complete system with storage device and printer; cousin to the ColecoVision game console.
1983: MSX (Japan, Korea, the Arab League, Europe, N+S. Am., USSR), a computer 'reference design' by ASCII and Microsoft, produced by several companies: ~ 5 million sold.
1983: VTech Laser 200, entry level computer aimed at being the cheapest on market, also sold as Salora Fellow, Texet TX8000 & Dick Smith VZ 200.
1983: Oric 1 and Oric Atmos, a home computer equipped with a full travel keyboard and an extended version of Microsoft BASIC in ROM.
January 1984: The Apple Macintosh is introduced, providing many consumers their first look at a graphical user interface, which would eventually replace the home computer as it was known.
April 1984: Apple IIc, Apple II compact. No expansion slots, and built-in ports for pseudo-plug and play ease of use. The Apple II most geared to home use, to complement the Apple IIe's dominant education market share.
1984: Tiki 100 (Norway), Zilog Z80-based home/educational computer made by Tiki Data.
1984: Amstrad/Schneider, CPC, PCW ranges (Europe), British standard before IBM PC; German sales next to C64.
1985: TRS-80 Model 4D: updated Model 4 with double-sided drives and Deskmate productivity suite.
1985: Elektronika BK-0010, one of the first 16-bit home computers; made in USSR.
1985: Robotron KC 85/1 (Europe), one of the few home computers produced by the East German VEB Robotron-Meßelektronik ""Otto Schön"" Dresden.
1985: Atari ST (N. Am.), first with a graphical user interface (GEM) for less than US$1000; first with built-in MIDI interface; also 1 MB RAM and 16-bit Motorola 68000 processor for under US$1000.
June 1985: Commodore 128 (N. Am.) Final, most advanced 8-bit Commodore, retained full C64 compatibility while adding CP/M in a complex multi-mode architecture
July 1985: Commodore Amiga 1000 (N. Am.), custom chip set for graphics and digital audio; multitasking OS with both GUI and CLI interfaces; 16-bit Motorola 68000 processor. Initially designed as a game console but repositioned as a home computer.
1986: Apple IIGS, Fifth and final model in the Apple II series, with greatly enhanced graphics and sound abilities. Used a 16-bit 65C816 CPU, the same as used in the Super Nintendo Entertainment System.
June 1987: Acorn Archimedes (Europe), launched with an 8 MHz 32-bit ARM2 microprocessor, with between 512 KB and 4 MB of RAM, and an optional 20 or 40 MB hard drive.
October 1987: Commodore Amiga 500 (N. Am.), Amiga 1000 repackaged into a C64-like housing with keyboard and motherboard in the same enclosure, along with a 3.5"" floppy disk drive. Introduced at the same time as the more expandable Amiga 2000.
1989: SAM Coupé (Europe), based on 6 MHz Z80 microprocessor; marketed as a logical upgrade from the Sinclair ZX Spectrum.


== See also ==


== References ==


== External links ==
Rune's PC Museum
Home of the home computer
Collection of old analog and digital computers at Old Computer Museum
Computer History Museum – An online museum of home computing and gaming
HCM - Home Computer Museum
""Total share: 30 years of personal computer market share figures"" – From Ars Technica
article on computing in the 1980s
Google Books link to A history of the personal computer: the people and the technology by Roy A. Allan
Home computer simulation written in Python"
"A computer monitor is an output device that displays information in pictorial form. A monitor usually comprises the visual display, circuitry, casing, and power supply. The display device in modern monitors is typically a thin film transistor liquid crystal display (TFT-LCD) with LED backlighting having replaced cold-cathode fluorescent lamp (CCFL) backlighting. Older monitors used a cathode ray tube (CRT). Monitors are connected to the computer via VGA, Digital Visual Interface (DVI), HDMI, DisplayPort, Thunderbolt, low-voltage differential signaling (LVDS) or other proprietary connectors and signals.
Originally, computer monitors were used for data processing while television sets were used for entertainment. From the 1980s onwards, computers (and their monitors) have been used for both data processing and entertainment, while televisions have implemented some computer functionality. The common aspect ratio of televisions, and computer monitors, has changed from 4:3 to 16:10, to 16:9.
Modern computer monitors are easily interchangeable with conventional television sets and viceversa. However, as computer monitors do not necessarily include integrated speakers nor TV tuners (such as Digital television adapters), it may not be possible to use a computer monitor as a TV set without external components.


== History ==
Early electronic computers were fitted with a panel of light bulbs where the state of each particular bulb would indicate the on/off state of a particular register bit inside the computer.  This allowed the engineers operating the computer to monitor the internal state of the machine, so this panel of lights came to be known as the 'monitor'.  As early monitors were only capable of displaying a very limited amount of information and were very transient, they were rarely considered for program output. Instead, a line printer was the primary output device, while the monitor was limited to keeping track of the program's operation.As technology developed engineers realized that the output of a CRT display was more flexible than a panel of light bulbs and eventually, by giving control of what was displayed in the program itself, the monitor itself became a powerful output device in its own right.Computer monitors were formerly known as visual display units (VDU), but this term had mostly fallen out of use by the 1990s.


== Technologies ==

Multiple technologies have been used for computer monitors. Until the 21st century most used cathode ray tubes but they have largely been superseded by LCD monitors.


=== Cathode ray tube ===

The first computer monitors used cathode ray tubes (CRTs). Prior to the advent of home computers in the late 1970s, it was common for a video display terminal (VDT) using a CRT to be physically integrated with a keyboard and other components of the system in a single large chassis. The display was monochrome and far less sharp and detailed than on a modern flat-panel monitor, necessitating the use of relatively large text and severely limiting the amount of information that could be displayed at one time. High-resolution CRT displays were developed for the specialized military, industrial and scientific applications but they were far too costly for general use.
Some of the earliest home computers (such as the TRS-80 and Commodore PET) were limited to monochrome CRT displays, but color display capability was already a standard feature of the pioneering Apple II, introduced in 1977, and the specialty of the more graphically sophisticated Atari 800, introduced in 1979. Either computer could be connected to the antenna terminals of an ordinary color TV set or used with a purpose-made CRT color monitor for optimum resolution and color quality. Lagging several years behind, in 1981 IBM introduced the Color Graphics Adapter, which could display four colors with a resolution of 320 x 200 pixels, or it could produce 640 x 200 pixels with two colors. In 1984 IBM introduced the Enhanced Graphics Adapter which was capable of producing 16 colors and had a resolution of 640 x 350.By the end of the 1980s color CRT monitors that could clearly display 1024 x 768 pixels were widely available and increasingly affordable. During the following decade, maximum display resolutions gradually increased and prices continued to fall. CRT technology remained dominant in the PC monitor market into the new millennium partly because it was cheaper to produce and offered to view angles close to 180 degrees. CRTs still offer some image quality advantages over LCDs but improvements to the latter have made them much less obvious. The dynamic range of early LCD panels was very poor, and although text and other motionless graphics were sharper than on a CRT, an LCD characteristic known as pixel lag caused moving graphics to appear noticeably smeared and blurry.


=== Liquid crystal display ===

There are multiple technologies that have been used to implement liquid crystal displays (LCD). Throughout the 1990s, the primary use of LCD technology as computer monitors was in laptops where the lower power consumption, lighter weight, and smaller physical size of LCDs justified the higher price versus a CRT. Commonly, the same laptop would be offered with an assortment of display options at increasing price points: (active or passive) monochrome, passive color, or active matrix color (TFT). As volume and manufacturing capability have improved, the monochrome and passive color technologies were dropped from most product lines.
TFT-LCD is a variant of LCD which is now the dominant technology used for computer monitors.The first standalone LCDs appeared in the mid-1990s selling for high prices. As prices declined over a period of years they became more popular, and by 1997 were competing with CRT monitors. Among the first desktop LCD computer monitors was the Eizo L66 in the mid-1990s, the Apple Studio Display in 1998, and the Apple Cinema Display in 1999. In 2003, TFT-LCDs outsold CRTs for the first time, becoming the primary technology used for computer monitors. The main advantages of LCDs over CRT displays are that LCDs consume less power, take up much less space, and are considerably lighter. The now common active matrix TFT-LCD technology also has less flickering than CRTs, which reduces eye strain. On the other hand, CRT monitors have superior contrast, have a superior response time, are able to use multiple screen resolutions natively, and there is no discernible flicker if the refresh rate is set to a sufficiently high value. LCD monitors have now very high temporal accuracy and can be used for vision research.High dynamic range (HDR) has been implemented into high-end LCD monitors to improve color accuracy. Since around the late 2000s, widescreen LCD monitors have become popular, in part due to television series, motion pictures and video games transitioning to high-definition (HD), which makes standard-width monitors unable to display them correctly as they either stretch or crop HD content. These types of monitors may also display it in the proper width, however they usually fill the extra space at the top and bottom of the image with black bars. Other advantages of widescreen monitors over standard-width monitors is that they make work more productive by displaying more of a user's documents and images, and allow displaying toolbars with documents. They also have a larger viewing area, with a typical widescreen monitor having a 16:9 aspect ratio, compared to the 4:3 aspect ratio of a typical standard-width monitor.


=== Organic light-emitting diode ===

Organic light-emitting diode (OLED) monitors provide higher contrast and better viewing angles than LCDs but they require more power when displaying documents with white or bright backgrounds and have a severe problem known as burn-in. They are less common than LCD monitors and are often more expensive.


== Measurements of performance ==
The performance of a monitor is measured by the following parameters:

Luminance is measured in candelas per square meter (cd/m2 also called a Nit).
Color depth is measured in bits per primary color or bits for all colors.
Gamut is measured as coordinates in the CIE 1931 color space. The names sRGB or AdobeRGB are shorthand notations.
Aspect ratio is the ratio of the horizontal length to the vertical length. Monitors usually have the aspect ratio 4:3, 5:4, 16:10 or 16:9.
Viewable image size is usually measured diagonally, but the actual widths and heights are more informative since they are not affected by the aspect ratio in the same way. For CRTs, the viewable size is typically 1 in (25 mm) smaller than the tube itself.
Display resolution is the number of distinct pixels in each dimension that can be displayed. For a given display size, maximum resolution is limited by dot pitch.
Dot pitch is the distance between sub-pixels of the same color in millimeters. In general, the smaller the dot pitch, the sharper the picture will appear.
Refresh rate is the number of times in a second that a display is illuminated. Maximum refresh rate is limited by response time.
Response time is the time a pixel in a monitor takes to go from active (white) to inactive (black) and back to active (white) again, measured in milliseconds. Lower numbers mean faster transitions and therefore fewer visible image artifacts.
Contrast ratio is the ratio of the luminosity of the brightest color (white) to that of the darkest color (black) that the monitor is capable of producing.
Power consumption is measured in watts.
Delta-E: Color accuracy is measured in delta-E; the lower the delta-E, the more accurate the color representation. A delta-E of below 1 is imperceptible to the human eye. Delta-Es of 2 to 4 are considered good and require a sensitive eye to spot the difference.
Viewing angle is the maximum angle at which images on the monitor can be viewed, without excessive degradation to the image. It is measured in degrees horizontally and vertically.


=== Size ===

On two-dimensional display devices such as computer monitors the display size or view able image size is the actual amount of screen space that is available to display a picture, video or working space, without obstruction from the case or other aspects of the unit's design. The main measurements for display devices are: width, height, total area and the diagonal.
The size of a display is usually by monitor manufacturers given by the diagonal, i.e. the distance between two opposite screen corners. This method of measurement is inherited from the method used for the first generation of CRT television, when picture tubes with circular faces were in common use. Being circular, it was the external diameter of the glass envelope that described their size. Since these circular tubes were used to display rectangular images, the diagonal measurement of the rectangular image was smaller than the diameter of the tube's face (due to the thickness of the glass). This method continued even when cathode ray tubes were manufactured as rounded rectangles; it had the advantage of being a single number specifying the size, and was not confusing when the aspect ratio was universally 4:3.
With the introduction of flat panel technology, the diagonal measurement became the actual diagonal of the visible display.  This meant that an eighteen-inch LCD had a larger visible area than an eighteen-inch cathode ray tube.
The estimation of the monitor size by the distance between opposite corners does not take into account the display aspect ratio, so that for example a 16:9 21-inch (53 cm) widescreen display has less area, than a 21-inch (53 cm) 4:3 screen. The 4:3 screen has dimensions of 16.8 in × 12.6 in (43 cm × 32 cm) and area 211 sq in (1,360 cm2), while the widescreen is 18.3 in × 10.3 in (46 cm × 26 cm), 188 sq in (1,210 cm2).


=== Aspect ratio ===

Until about 2003, most computer monitors had a 4:3 aspect ratio and some had 5:4. Between 2003 and 2006, monitors with 16:9 and mostly 16:10 (8:5) aspect ratios became commonly available, first in laptops and later also in standalone monitors. Reasons for this transition was productive uses for such monitors, i.e. besides widescreen computer game play and movie viewing, are the word processor display of two standard letter pages side by side, as well as CAD displays of large-size drawings and CAD application menus at the same time. In 2008 16:10 became the most common sold aspect ratio for LCD monitors and the same year 16:10 was the mainstream standard for laptops and notebook computers.In 2010 the computer industry started to move over from 16:10 to 16:9 because 16:9 was chosen to be the standard high-definition television display size, and because they were cheaper to manufacture.
In 2011 non-widescreen displays with 4:3 aspect ratios were only being manufactured in small quantities. According to Samsung this was because the ""Demand for the old 'Square monitors' has decreased rapidly over the last couple of years,"" and ""I predict that by the end of 2011, production on all 4:3 or similar panels will be halted due to a lack of demand.""


=== Resolution ===

The resolution for computer monitors has increased over time. From 320x200 during the early 1980s, to 1024x768 during the late 1990s. Since 2009, the most commonly sold resolution for computer monitors is 1920x1080. Before 2013 top-end consumer LCD monitors were limited to 2560x1600 at 30 in (76 cm), excluding Apple products and CRT monitors. Apple introduced 2880x1800 with Retina MacBook Pro at 15.4 in (39 cm) on June 12, 2012, and introduced a 5120x2880 Retina iMac at 27 in (69 cm) on October 16, 2014.  By 2015 most major display manufacturers had released 3840x2160 resolution displays.


=== Gamut ===

Every RGB monitor has its own color gamut, bounded in chromaticity by a color triangle. Some of these triangles are smaller than the sRGB triangle, some are larger. Colors are typically encoded by 8 bits per primary color. The RGB value [255, 0, 0] represents red, but slightly different colors in different color spaces such as AdobeRGB and sRGB. Displaying sRGB-encoded data on wide-gamut devices can give an unrealistic result. The gamut is a property of the monitor; the image color space can be forwarded as Exif metadata in the picture. As long as the monitor gamut is wider than the color space gamut, correct display is possible, if the monitor is calibrated. A picture that uses colors that are outside the sRGB color space will display on an sRGB color space monitor with limitations. Still today, many monitors that can display the sRGB color space are not factory adjusted to display it correctly. Color management is needed both in electronic publishing (via the Internet for display in browsers) and in desktop publishing targeted to print.


== Additional features ==


=== Power saving ===
Most modern monitors will switch to a power-saving mode if no video-input signal is received. This allows modern operating systems to turn off a monitor after a specified period of inactivity. This also extends the monitor's service life. Some monitors will also switch themselves off after a time period on standby.
Most modern laptops provide a method of screen dimming after periods of inactivity or when the battery is in use. This extends battery life and reduces wear.


=== Integrated accessories ===
Many monitors have other accessories (or connections for them) integrated. This places standard ports within easy reach and eliminates the need for another separate hub, camera, microphone, or set of speakers. These monitors have advanced microprocessors which contain codec information, Windows Interface drivers and other small software which help in proper functioning of these functions.


=== Glossy screen ===

Some displays, especially newer LCD monitors, replace the traditional anti-glare matte finish with a glossy one. This increases color saturation and sharpness but reflections from lights and windows are very visible. Anti-reflective coatings are sometimes applied to help reduce reflections, although this only mitigates the effect.


=== Curved designs ===
In about 2009, NEC/Alienware together with Ostendo Technologies (based in Carlsbad, CA) were offering a curved (concave) 43-inch (110 cm) monitor that allows better viewing angles near the edges, covering 75% of peripheral vision in the horizontal direction. This monitor had 2880x900 resolution, LED backlight and was marketed as suitable both for gaming and office work, while for $6499 it was rather expensive. While this particular monitor is no longer in production, most PC manufacturers now offer some sort of curved desktop display.


=== Directional screen ===
Narrow viewing angle screens are used in some security conscious applications.


=== 3D ===

Newer monitors are able to display a different image for each eye, often with the help of special glasses, giving the perception of depth.  An autostereoscopic screen can generate 3D images without headgear.


=== Touch screen ===

These monitors use touching of the screen as an input method. Items can be selected or moved with a finger, and finger gestures may be used to convey commands. The screen will need frequent cleaning due to image degradation from fingerprints.


=== Tablet screens ===

A combination of a monitor with a graphics tablet. Such devices are typically unresponsive to touch without the use of one or more special tools' pressure. Newer models however are now able to detect touch from any pressure and often have the ability to detect tilt and rotation as well.
Touch and tablet screens are used on LCDs as a substitute for the light pen, which can only work on CRTs.


=== Ultrawide screens ===

Monitors that feature an aspect ratio of 21:9 as opposed to the more common 16:9.


== Mounting ==
Computer monitors are provided with a variety of methods for mounting them depending on the application and environment.


=== Desktop ===
A desktop monitor is typically provided with a stand from the manufacturer which lifts the monitor up to a more ergonomic viewing height. The stand may be attached to the monitor using a proprietary method or may use, or be adaptable to, a Video Electronics Standards Association, VESA, standard mount. Using a VESA standard mount allows the monitor to be used with an after-market stand once the original stand is removed. Stands may be fixed or offer a variety of features such as height adjustment, horizontal swivel, and landscape or portrait screen orientation.


=== VESA mount ===
The Flat Display Mounting Interface (FDMI), also known as VESA Mounting Interface Standard (MIS) or colloquially as a VESA mount, is a family of standards defined by the Video Electronics Standards Association for mounting flat panel monitors, TVs, and other displays to stands or wall mounts. It is implemented on most modern flat-panel monitors and TVs.
For Computer Monitors, the VESA Mount typically consists of four threaded holes on the rear of the display that will mate with an adapter bracket.


=== Rack mount ===
Rack mount computer monitors are available in two styles and are intended to be mounted into a 19-inch rack:

FixedA fixed rack mount monitor is mounted directly to the rack with the LCD visible at all times. The height of the unit is measured in rack units (RU) and 8U or 9U are most common to fit 17-inch or 19-inch LCDs.  The front sides of the unit are provided with flanges to mount to the rack, providing appropriately spaced holes or slots for the rack mounting screws.  A 19-inch diagonal LCD is the largest size that will fit within the rails of a 19-inch rack.  Larger LCDs may be accommodated but are 'mount-on-rack' and extend forward of the rack.  There are smaller display units, typically used in broadcast environments, which fit multiple smaller LCDs side by side into one rack mount.

StowableA stowable rack mount monitor is 1U, 2U or 3U high and is mounted on rack slides allowing the display to be folded down and the unit slid into the rack for storage.  The display is visible only when the display is pulled out of the rack and deployed.  These units may include only a display or may be equipped with a keyboard creating a KVM (Keyboard Video Monitor).  Most common are systems with a single LCD but there are systems providing two or three displays in a single rack mount system.


=== Panel mount ===
A panel mount computer monitor is intended for mounting into a flat surface with the front of the display unit protruding just slightly.  They may also be mounted to the rear of the panel.  A flange is provided around the LCD, sides, top and bottom, to allow mounting.  This contrasts with a rack mount display where the flanges are only on the sides.  The flanges will be provided with holes for thru-bolts or may have studs welded to the rear surface to secure the unit in the hole in the panel.  Often a gasket is provided to provide a water-tight seal to the panel and the front of the LCD will be sealed to the back of the front panel to prevent water and dirt contamination.


=== Open frame ===
An open frame monitor provides the LCD monitor and enough supporting structure to hold associated electronics and to minimally support the LCD.  Provision will be made for attaching the unit to some external structure for support and protection.  Open frame LCDs are intended to be built into some other piece of equipment.  An arcade video game would be a good example with the display mounted inside the cabinet.  There is usually an open frame display inside all end-use displays with the end-use display simply providing an attractive protective enclosure.  Some rack mount LCD manufacturers will purchase desktop displays, take them apart, and discard the outer plastic parts, keeping the inner open-frame LCD for inclusion into their product.


== Security vulnerabilities ==
According to an NSA document leaked to Der Spiegel, the NSA sometimes swaps the monitor cables on targeted computers with a bugged monitor cable in order to allow the NSA to remotely see what is being displayed on the targeted computer monitor.Van Eck phreaking is the process of remotely displaying the contents of a CRT or LCD by detecting its electromagnetic emissions. It is named after Dutch computer researcher Wim van Eck, who in 1985 published the first paper on it, including proof of concept. Phreaking more generally is the process of exploiting telephone networks.


== See also ==
History of display technology
Flat panel display
Multi-monitor
Vector monitor
Virtual desktop


== References ==


== External links =="
"Computer vision is an interdisciplinary scientific field that deals with how computers can gain high-level understanding from digital images or videos. From the perspective of engineering, it seeks to understand and automate tasks that the human visual system can do.Computer vision tasks include methods for acquiring, processing, analyzing and understanding digital images, and extraction of high-dimensional data from the real world in order to produce numerical or symbolic information, e.g. in the forms of decisions. Understanding in this context means the transformation of visual images (the input of the retina) into descriptions of the world that make sense to thought processes and can elicit appropriate action. This image understanding can be seen as the disentangling of symbolic information from image data using models constructed with the aid of geometry, physics, statistics, and learning theory.The scientific discipline of computer vision is concerned with the theory behind artificial systems that extract information from images. The image data can take many forms, such as video sequences, views from multiple cameras, multi-dimensional data from a 3D scanner or medical scanning device. The technological discipline of computer vision seeks to apply its theories and models to the construction of computer vision systems.
Sub-domains of computer vision include scene reconstruction, event detection, video tracking, object recognition, 3D pose estimation, learning, indexing, motion estimation, visual servoing, 3D scene modeling, and image restoration.


== Definition ==
Computer vision is an interdisciplinary field that deals with how computers can be made to gain high-level understanding from digital images or videos. From the perspective of engineering, it seeks to automate tasks that the human visual system can do. ""Computer vision is concerned with the automatic extraction, analysis and understanding of useful information from a single image or a sequence of images. It involves the development of a theoretical and algorithmic basis to achieve automatic visual understanding."" As a scientific discipline, computer vision is concerned with the theory behind artificial systems that extract information from images. The image data can take many forms, such as video sequences, views from multiple cameras, or multi-dimensional data from a medical scanner. As a technological discipline, computer vision seeks to apply its theories and models for the construction of computer vision systems.


== History ==
In the late 1960s, computer vision began at universities which were pioneering artificial intelligence. It was meant to mimic the human visual system, as a stepping stone to endowing robots with intelligent behavior. In 1966, it was believed that this could be achieved through a summer project, by attaching a camera to a computer and having it ""describe what it saw"".What distinguished computer vision from the prevalent field of digital image processing at that time was a desire to extract three-dimensional structure from images with the goal of achieving full scene understanding. Studies in the 1970s formed the early foundations for many of the computer vision algorithms that exist today, including extraction of edges from images, labeling of lines, non-polyhedral and polyhedral modeling, representation of objects as interconnections of smaller structures, optical flow, and motion estimation.The next decade saw studies based on more rigorous mathematical analysis and quantitative aspects of computer vision. These include the concept of scale-space, the inference of shape from various cues such as shading, texture and focus, and contour models known as snakes. Researchers also realized that many of these mathematical concepts could be treated within the same optimization framework as regularization and Markov random fields.
By the 1990s, some of the previous research topics became more active than the others. Research in projective 3-D reconstructions led to better understanding of camera calibration. With the advent of optimization methods for camera calibration, it was realized that a lot of the ideas were already explored in bundle adjustment theory from the field of photogrammetry. This led to methods for sparse 3-D reconstructions of scenes from multiple images. Progress was made on the dense stereo correspondence problem and further multi-view stereo techniques. At the same time, variations of graph cut were used to solve image segmentation. This decade also marked the first time statistical learning techniques were used in practice to recognize faces in images (see Eigenface). Toward the end of the 1990s, a significant change came about with the increased interaction between the fields of computer graphics and computer vision. This included image-based rendering, image morphing, view interpolation, panoramic image stitching and early light-field rendering.Recent work has seen the resurgence of feature-based methods, used in conjunction with machine learning techniques and complex optimization frameworks. 
The advancement of Deep Learning techniques has brought further life to the field of computer vision. The accuracy of deep learning algorithms on several benchmark computer vision data sets for tasks ranging from classification, segmentation and optical flow has surpassed prior methods.


== Related fields ==


=== Artificial intelligence ===
Areas of artificial intelligence deal with autonomous planning or deliberation for robotic systems to navigate through an environment. A detailed understanding of these environments is required to navigate through them. Information about the environment could be provided by a computer vision system, acting as a vision sensor and providing high-level information about the environment and the robot.
Artificial intelligence and computer vision share other topics such as pattern recognition and learning techniques. Consequently, computer vision is sometimes seen as a part of the artificial intelligence field or the computer science field in general.


=== Information engineering ===
Computer vision is often considered to be part of information engineering.


=== Solid-state physics ===
Solid-state physics is another field that is closely related to computer vision. Most computer vision systems rely on image sensors, which detect electromagnetic radiation, which is typically in the form of either visible or infra-red light. The sensors are designed using quantum physics. The process by which light interacts with surfaces is explained using physics. Physics explains the behavior of optics which are a core part of most imaging systems. Sophisticated image sensors even require quantum mechanics to provide a complete understanding of the image formation process. Also, various measurement problems in physics can be addressed using computer vision, for example motion in fluids.


=== Neurobiology ===
A third field which plays an important role is neurobiology, specifically the study of the biological vision system. Over the last century, there has been an extensive study of eyes, neurons, and the brain structures devoted to processing of visual stimuli in both humans and various animals. This has led to a coarse, yet complicated, description of how ""real"" vision systems operate in order to solve certain vision-related tasks. These results have led to a sub-field within computer vision where artificial systems are designed to mimic the processing and behavior of biological systems, at different levels of complexity. Also, some of the learning-based methods developed within computer vision (e.g. neural net and deep learning based image and feature analysis and classification) have their background in biology.
Some strands of computer vision research are closely related to the study of biological vision – indeed, just as many strands of AI research are closely tied with research into human consciousness, and the use of stored knowledge to interpret, integrate and utilize visual information. The field of biological vision studies and models the physiological processes behind visual perception in humans and other animals. Computer vision, on the other hand, studies and describes the processes implemented in software and hardware behind artificial vision systems. Interdisciplinary exchange between biological and computer vision has proven fruitful for both fields.


=== Signal processing ===
Yet another field related to computer vision is signal processing. Many methods for processing of one-variable signals, typically temporal signals, can be extended in a natural way to processing of two-variable signals or multi-variable signals in computer vision. However, because of the specific nature of images there are many methods developed within computer vision which have no counterpart in processing of one-variable signals. Together with the multi-dimensionality of the signal, this defines a subfield in signal processing as a part of computer vision.


=== Other fields ===
Beside the above-mentioned views on computer vision, many of the related research topics can also be studied from a purely mathematical point of view. For example, many methods in computer vision are based on statistics, optimization or geometry. Finally, a significant part of the field is devoted to the implementation aspect of computer vision; how existing methods can be realized in various combinations of software and hardware, or how these methods can be modified in order to gain processing speed without losing too much performance. Computer vision is also used in fashion ecommerce, inventory management, patent search, furniture, and the beauty industry.


=== Distinctions ===
The fields most closely related to computer vision are image processing, image analysis and machine vision. There is a significant overlap in the range of techniques and applications that these cover. This implies that the basic techniques that are used and developed in these fields are similar, something which can be interpreted as there is only one field with different names. On the other hand, it appears to be necessary for research groups, scientific journals, conferences and companies to present or market themselves as belonging specifically to one of these fields and, hence, various characterizations which distinguish each of the fields from the others have been presented.
Computer graphics produces image data from 3D models, computer vision often produces 3D models from image data. There is also a trend towards a combination of the two disciplines, e.g., as explored in augmented reality.
The following characterizations appear relevant but should not be taken as universally accepted::

Image processing and image analysis tend to focus on 2D images, how to transform one image to another, e.g., by pixel-wise operations such as contrast enhancement, local operations such as edge extraction or noise removal, or geometrical transformations such as rotating the image. This characterization implies that image processing/analysis neither require assumptions nor produce interpretations about the image content.
Computer vision includes 3D analysis from 2D images. This analyzes the 3D scene projected onto one or several images, e.g., how to reconstruct structure or other information about the 3D scene from one or several images. Computer vision often relies on more or less complex assumptions about the scene depicted in an image.
Machine vision is the process of applying a range of technologies & methods to provide imaging-based automatic inspection, process control and robot guidance in industrial applications. Machine vision tends to focus on applications, mainly in manufacturing, e.g., vision-based robots and systems for vision-based inspection, measurement, or picking (such as bin picking). This implies that image sensor technologies and control theory often are integrated with the processing of image data to control a robot and that real-time processing is emphasised by means of efficient implementations in hardware and software. It also implies that the external conditions such as lighting can be and are often more controlled in machine vision than they are in general computer vision, which can enable the use of different algorithms.
There is also a field called imaging which primarily focuses on the process of producing images, but sometimes also deals with processing and analysis of images. For example, medical imaging includes substantial work on the analysis of image data in medical applications.
Finally, pattern recognition is a field which uses various methods to extract information from signals in general, mainly based on statistical approaches and artificial neural networks. A significant part of this field is devoted to applying these methods to image data.Photogrammetry also overlaps with computer vision, e.g., stereophotogrammetry vs. computer stereo vision.


== Applications ==
Applications range from tasks such as industrial machine vision systems which, say, inspect bottles speeding by on a production line, to research into artificial intelligence and computers or robots that can comprehend the world around them. The computer vision and machine vision fields have significant overlap. Computer vision covers the core technology of automated image analysis which is used in many fields. Machine vision usually refers to a process of combining automated image analysis with other methods and technologies to provide automated inspection and robot guidance in industrial applications. In many computer-vision applications, the computers are pre-programmed to solve a particular task, but methods based on learning are now becoming increasingly common. Examples of applications of computer vision include systems for:

Automatic inspection, e.g., in manufacturing applications;
Assisting humans in identification tasks, e.g., a species identification system;
Controlling processes, e.g., an industrial robot;
Detecting events, e.g., for visual surveillance or people counting, e.g., in the restaurant industry;
Interaction, e.g., as the input to a device for computer-human interaction;
Modeling objects or environments, e.g., medical image analysis or topographical modeling;
Navigation, e.g., by an autonomous vehicle or mobile robot; and
Organizing information, e.g., for indexing databases of images and image sequences.


=== Medicine ===

One of the most prominent application fields is medical computer vision, or medical image processing, characterized by the extraction of information from image data to diagnose a patient. An example of this is detection of tumours, arteriosclerosis or other malign changes; measurements of organ dimensions, blood flow, etc. are another example. It also supports medical research by providing new information: e.g., about the structure of the brain, or about the quality of medical treatments. Applications of computer vision in the medical area also includes enhancement of images interpreted by humans—ultrasonic images or X-ray images for example—to reduce the influence of noise.


=== Machine Vision ===
A second application area in computer vision is in industry, sometimes called machine vision, where information is extracted for the purpose of supporting a manufacturing process. One example is quality control where details or final products are being automatically inspected in order to find defects. Another example is measurement of position and orientation of details to be picked up by a robot arm. Machine vision is also heavily used in agricultural process to remove undesirable food stuff from bulk material, a process called optical sorting.


=== Military ===
Military applications are probably one of the largest areas for computer vision. The obvious examples are detection of enemy soldiers or vehicles and missile guidance. More advanced systems for missile guidance send the missile to an area rather than a specific target, and target selection is made when the missile reaches the area based on locally acquired image data. Modern military concepts, such as ""battlefield awareness"", imply that various sensors, including image sensors, provide a rich set of information about a combat scene which can be used to support strategic decisions. In this case, automatic processing of the data is used to reduce complexity and to fuse information from multiple sensors to increase reliability.


=== Autonomous vehicles ===

One of the newer application areas is autonomous vehicles, which include submersibles, land-based vehicles (small robots with wheels, cars or trucks), aerial vehicles, and unmanned aerial vehicles (UAV). The level of autonomy ranges from fully autonomous (unmanned) vehicles to vehicles where computer-vision-based systems support a driver or a pilot in various situations. Fully autonomous vehicles typically use computer vision for navigation, e.g. for knowing where it is, or for producing a map of its environment (SLAM) and for detecting obstacles. It can also be used for detecting certain task specific events, e.g., a UAV looking for forest fires. Examples of supporting systems are obstacle warning systems in cars, and systems for autonomous landing of aircraft. Several car manufacturers have demonstrated systems for autonomous driving of cars, but this technology has still not reached a level where it can be put on the market. There are ample examples of military autonomous vehicles ranging from advanced missiles to UAVs for recon missions or missile guidance. Space exploration is already being made with autonomous vehicles using computer vision, e.g., NASA's Curiosity and CNSA's Yutu-2 rover.


=== Tactile Feedback ===

Materials such as rubber and silicon are being used to create sensors that allow for applications such as detecting micro undulations and calibrating robotic hands. Rubber can be used in order to create a mold that can be placed over a finger, inside of this mold would be multiple strain gauges. The finger mold and sensors could then be placed on top of a small sheet of rubber containing an array of rubber pins. A user can then wear the finger mold and trace a surface. A computer can then read the data from the strain gauges and measure if one or more of the pins is being pushed upward. If a pin is being pushed upward then the computer can recognize this as an imperfection in the surface. This sort of technology is useful in order to receive accurate data of the imperfections on a very large surface. Another variation of this finger mold sensor are sensors that contain a camera suspended in silicon. The silicon forms a dome around the outside of the camera and embedded in the silicon are point markers that are equally spaced. These cameras can then be placed on devices such as robotic hands in order to allow the computer to receive highly accurate tactile data.Other application areas include:

Support of visual effects creation for cinema and broadcast, e.g., camera tracking (matchmoving).
Surveillance.
Driver drowsiness detection
Tracking and counting organisms in the biological sciences


== Typical tasks ==
Each of the application areas described above employ a range of computer vision tasks; more or less well-defined measurement problems or processing problems, which can be solved using a variety of methods. Some examples of typical computer vision tasks are presented below.
Computer vision tasks include methods for acquiring, processing, analyzing and understanding digital images, and extraction of high-dimensional data from the real world in order to produce numerical or symbolic information, e.g., in the forms of decisions. Understanding in this context means the transformation of visual images (the input of the retina) into descriptions of the world that can interface with other thought processes and elicit appropriate action. This image understanding can be seen as the disentangling of symbolic information from image data using models constructed with the aid of geometry, physics, statistics, and learning theory.


=== Recognition ===
The classical problem in computer vision, image processing, and machine vision is that of determining whether or not the image data contains some specific object, feature, or activity. Different varieties of the recognition problem are described in the literature:
Object recognition (also called object classification) – one or several pre-specified or learned objects or object classes can be recognized, usually together with their 2D positions in the image or 3D poses in the scene. Blippar, Google Goggles and LikeThat provide stand-alone programs that illustrate this functionality.
Identification – an individual instance of an object is recognized. Examples include identification of a specific person's face or fingerprint, identification of handwritten digits, or identification of a specific vehicle.
Detection – the image data are scanned for a specific condition. Examples include detection of possible abnormal cells or tissues in medical images or detection of a vehicle in an automatic road toll system. Detection based on relatively simple and fast computations is sometimes used for finding smaller regions of interesting image data which can be further analyzed by more computationally demanding techniques to produce a correct interpretation.Currently, the best algorithms for such tasks are based on convolutional neural networks. An illustration of their capabilities is given by the ImageNet Large Scale Visual Recognition Challenge; this is a benchmark in object classification and detection, with millions of images and hundreds of object classes. Performance of convolutional neural networks, on the ImageNet tests, is now close to that of humans. The best algorithms still struggle with objects that are small or thin, such as a small ant on a stem of a flower or a person holding a quill in their hand. They also have trouble with images that have been distorted with filters (an increasingly common phenomenon with modern digital cameras). By contrast, those kinds of images rarely trouble humans. Humans, however, tend to have trouble with other issues. For example, they are not good at classifying objects into fine-grained classes, such as the particular breed of dog or species of bird, whereas convolutional neural networks handle this with ease.
Several specialized tasks based on recognition exist, such as:

Content-based image retrieval – finding all images in a larger set of images which have a specific content. The content can be specified in different ways, for example in terms of similarity relative a target image (give me all images similar to image X), or in terms of high-level search criteria given as text input (give me all images which contain many houses, are taken during winter, and have no cars in them).
Pose estimation – estimating the position or orientation of a specific object relative to the camera. An example application for this technique would be assisting a robot arm in retrieving objects from a conveyor belt in an assembly line situation or picking parts from a bin.
Optical character recognition (OCR) – identifying characters in images of printed or handwritten text, usually with a view to encoding the text in a format more amenable to editing or indexing (e.g. ASCII).
2D code reading – reading of 2D codes such as data matrix and QR codes.
Facial recognition
 Shape Recognition Technology (SRT) in people counter systems differentiating human beings (head and shoulder patterns) from objects


=== Motion analysis ===
Several tasks relate to motion estimation where an image sequence is processed to produce an estimate of the velocity either at each points in the image or in the 3D scene, or even of the camera that produces the images . Examples of such tasks are:

Egomotion – determining the 3D rigid motion (rotation and translation) of the camera from an image sequence produced by the camera.
Tracking – following the movements of a (usually) smaller set of interest points or objects (e.g., vehicles, humans or other organisms) in the image sequence.
Optical flow – to determine, for each point in the image, how that point is moving relative to the image plane, i.e., its apparent motion. This motion is a result both of how the corresponding 3D point is moving in the scene and how the camera is moving relative to the scene.


=== Scene reconstruction ===
Given one or (typically) more images of a scene, or a video, scene reconstruction aims at computing a 3D model of the scene. In the simplest case the model can be a set of 3D points. More sophisticated methods produce a complete 3D surface model. The advent of 3D imaging not requiring motion or scanning, and related processing algorithms is enabling rapid advances in this field. Grid-based 3D sensing can be used to acquire 3D images from multiple angles. Algorithms are now available to stitch multiple 3D images together into point clouds and 3D models.


=== Image restoration ===
The aim of image restoration is the removal of noise (sensor noise, motion blur, etc.) from images. The simplest possible approach for noise removal is various types of filters such as low-pass filters or median filters. More sophisticated methods assume a model of how the local image structures look, to distinguish them from noise. By first analysing the image data in terms of the local image structures, such as lines or edges, and then controlling the filtering based on local information from the analysis step, a better level of noise removal is usually obtained compared to the simpler approaches.
An example in this field is inpainting.


== System methods ==
The organization of a computer vision system is highly application-dependent. Some systems are stand-alone applications that solve a specific measurement or detection problem, while others constitute a sub-system of a larger design which, for example, also contains sub-systems for control of mechanical actuators, planning, information databases, man-machine interfaces, etc. The specific implementation of a computer vision system also depends on whether its functionality is pre-specified or if some part of it can be learned or modified during operation. Many functions are unique to the application. There are, however, typical functions that are found in many computer vision systems.

Image acquisition – A digital image is produced by one or several image sensors, which, besides various types of light-sensitive cameras, include range sensors, tomography devices, radar, ultra-sonic cameras, etc. Depending on the type of sensor, the resulting image data is an ordinary 2D image, a 3D volume, or an image sequence. The pixel values typically correspond to light intensity in one or several spectral bands (gray images or colour images), but can also be related to various physical measures, such as depth, absorption or reflectance of sonic or electromagnetic waves, or nuclear magnetic resonance.
Pre-processing – Before a computer vision method can be applied to image data in order to extract some specific piece of information, it is usually necessary to process the data in order to assure that it satisfies certain assumptions implied by the method. Examples are:
Re-sampling to assure that the image coordinate system is correct.
Noise reduction to assure that sensor noise does not introduce false information.
Contrast enhancement to assure that relevant information can be detected.
Scale space representation to enhance image structures at locally appropriate scales.
Feature extraction – Image features at various levels of complexity are extracted from the image data. Typical examples of such features are:
Lines, edges and ridges.
Localized interest points such as corners, blobs or points.More complex features may be related to texture, shape or motion.Detection/segmentation – At some point in the processing a decision is made about which image points or regions of the image are relevant for further processing. Examples are:
Selection of a specific set of interest points.
Segmentation of one or multiple image regions that contain a specific object of interest.
Segmentation of image into nested scene architecture comprising foreground, object groups, single objects or salient object parts (also referred to as spatial-taxon scene hierarchy), while the visual salience is often implemented as spatial and temporal attention.
Segmentation or co-segmentation of one or multiple videos into a series of per-frame foreground masks, while maintaining its temporal semantic continuity.
High-level processing – At this step the input is typically a small set of data, for example a set of points or an image region which is assumed to contain a specific object. The remaining processing deals with, for example:
Verification that the data satisfy model-based and application-specific assumptions.
Estimation of application-specific parameters, such as object pose or object size.
Image recognition – classifying a detected object into different categories.
Image registration – comparing and combining two different views of the same object.
Decision making Making the final decision required for the application, for example:
Pass/fail on automatic inspection applications.
Match/no-match in recognition applications.
Flag for further human review in medical, military, security and recognition applications.


=== Image-understanding systems ===
Image-understanding systems (IUS) include three levels of abstraction as follows: low level includes image primitives such as edges, texture elements, or regions; intermediate level includes boundaries, surfaces and volumes; and high level includes objects, scenes, or events. Many of these requirements are entirely topics for further research.
The representational requirements in the designing of IUS for these levels are: representation of prototypical concepts, concept organization, spatial knowledge, temporal knowledge, scaling, and description by comparison and differentiation.
While inference refers to the process of deriving new, not explicitly represented facts from currently known facts, control refers to the process that selects which of the many inference, search, and matching techniques should be applied at a particular stage of processing. Inference and control requirements for IUS are: search and hypothesis activation, matching and hypothesis testing, generation and use of expectations, change and focus of attention, certainty and strength of belief, inference and goal satisfaction.


== Hardware ==

There are many kinds of computer vision systems; however, all of them contain these basic elements: a power source, at least one image acquisition device (camera, ccd, etc.), a processor, and control and communication cables or some kind of wireless interconnection mechanism. In addition, a practical vision system contains software, as well as a display in order to monitor the system. Vision systems for inner spaces, as most industrial ones, contain an illumination system and may be placed in a controlled environment. Furthermore, a completed system includes many accessories such as camera supports, cables and connectors.
Most computer vision systems use visible-light cameras passively viewing a scene at frame rates of at most 60 frames per second (usually far slower).
A few computer vision systems use image-acquisition hardware with active illumination or something other than visible light or both, such as structured-light 3D scanners, thermographic cameras, hyperspectral imagers, radar imaging, lidar scanners, magnetic resonance images, side-scan sonar, synthetic aperture sonar, etc. Such hardware captures ""images"" that are then processed often using the same computer vision algorithms used to process visible-light images.
While traditional broadcast and consumer video systems operate at a rate of 30 frames per second, advances in digital signal processing and consumer graphics hardware has made high-speed image acquisition, processing, and display possible for real-time systems on the order of hundreds to thousands of frames per second. For applications in robotics, fast, real-time video systems are critically important and often can simplify the processing needed for certain algorithms. When combined with a high-speed projector, fast image acquisition allows 3D measurement and feature tracking to be realised.Egocentric vision systems are composed of a wearable camera that automatically take pictures from a first-person perspective.
As of 2016, vision processing units are emerging as a new class of processor, to complement CPUs and graphics processing units (GPUs) in this role.


== See also ==
Computational imaging
Computational photography
Machine vision glossary
Space mapping
Teknomo–Fernandez algorithm
Visual system
Visual perception
Vision science
Egocentric vision
Visual agnosia


=== Lists ===
List of computer vision topics
List of emerging technologies
Outline of artificial intelligence
Outline of computer vision


== References ==


== Further reading ==
David Marr (1982). Vision. W. H. Freeman and Company. ISBN 978-0-7167-1284-8.
Azriel Rosenfeld; Avinash Kak (1982). Digital Picture Processing. Academic Press. ISBN 978-0-12-597301-4.
Barghout, Lauren; Lawrence W. Lee (2003). Perceptual information processing system. U.S. Patent Application 10/618,543. ISBN 978-0-262-08159-7.
Berthold K.P. Horn (1986). Robot Vision. MIT Press. ISBN 978-0-262-08159-7.
Michael C. Fairhurst (1988). Computer Vision for robotic systems. Prentice Hall. ISBN 978-0-13-166919-2.
Olivier Faugeras (1993). Three-Dimensional Computer Vision, A Geometric Viewpoint. MIT Press. ISBN 978-0-262-06158-2.
Tony Lindeberg (1994). Scale-Space Theory in Computer Vision. Springer. ISBN 978-0-7923-9418-1.
James L. Crowley and Henrik I. Christensen (Eds.) (1995). Vision as Process. Springer-Verlag. ISBN 978-3-540-58143-7.CS1 maint: extra text: authors list (link)
Gösta H. Granlund; Hans Knutsson (1995). Signal Processing for Computer Vision. Kluwer Academic Publisher. ISBN 978-0-7923-9530-0.
Reinhard Klette; Karsten Schluens; Andreas Koschan (1998). Computer Vision – Three-Dimensional Data from Images. Springer, Singapore. ISBN 978-981-3083-71-4.
Emanuele Trucco; Alessandro Verri (1998). Introductory Techniques for 3-D Computer Vision. Prentice Hall. ISBN 978-0-13-261108-4.
Bernd Jähne (2002). Digital Image Processing. Springer. ISBN 978-3-540-67754-3.
Richard Hartley and Andrew Zisserman (2003). Multiple View Geometry in Computer Vision. Cambridge University Press. ISBN 978-0-521-54051-3.
Gérard Medioni; Sing Bing Kang (2004). Emerging Topics in Computer Vision. Prentice Hall. ISBN 978-0-13-101366-7.
R. Fisher; K Dawson-Howe; A. Fitzgibbon; C. Robertson; E. Trucco (2005). Dictionary of Computer Vision and Image Processing. John Wiley. ISBN 978-0-470-01526-1.
Nikos Paragios and Yunmei Chen and Olivier Faugeras (2005). Handbook of Mathematical Models in Computer Vision. Springer. ISBN 978-0-387-26371-7.
Wilhelm Burger; Mark J. Burge (2007). Digital Image Processing: An Algorithmic Approach Using Java. Springer. ISBN 978-1-84628-379-6.
Pedram Azad; Tilo Gockel; Rüdiger Dillmann (2008). Computer Vision – Principles and Practice. Elektor International Media BV. ISBN 978-0-905705-71-2.
Richard Szeliski (2010). Computer Vision: Algorithms and Applications. Springer-Verlag. ISBN 978-1848829343.
J. R. Parker (2011). Algorithms for Image Processing and Computer Vision (2nd ed.). Wiley. ISBN 978-0470643853.
Richard J. Radke (2013). Computer Vision for Visual Effects. Cambridge University Press. ISBN 978-0-521-76687-6.
Nixon, Mark; Aguado, Alberto (2019). Feature Extraction and Image Processing for Computer Vision (4th ed.). Academic Press. ISBN 978-0128149768.


== External links ==
USC Iris computer vision conference list
Computer vision papers on the web A complete list of papers of the most relevant computer vision conferences.
Computer Vision Online News, source code, datasets and job offers related to computer vision.
Keith Price's Annotated Computer Vision Bibliography
CVonline Bob Fisher's Compendium of Computer Vision.
British Machine Vision Association Supporting computer vision research within the UK via the BMVC and MIUA conferences, Annals of the BMVA (open-source journal), BMVA Summer School and one-day meetings
Computer Vision Container, Joe Hoeller GitHub:  Widely adopted open-source container for GPU accelerated computer vision applications. Used by researchers, universities, private companies as well as the U.S. Gov't."
"A computer lab is a space which provides computer services to a defined community. Computer labs are typically provided by libraries to the public, by academic institutions to students who attend the institution, or by other institutions to the public or to people affiliated with that institution. Users typically must follow a certain user policy to retain access to the computers. This generally consists of the user not engaging in illegal activities or attempting to circumvent any security or content-control software while using the computers. In public settings, computer lab users are often subject to time limits, in order to allow more people a chance to use the lab, whereas in other institutions, computer access typically requires valid personal login credentials, which may also allow the institution to track the user's activities. Computers in computer labs are typically equipped with internet access, while scanners and printers may augment the lab setup. Computers in computer labs are typically arranged either in rows, so that every workstation has a similar view of one end of the room to facilitate lecturing or presentations, or in clusters, to facilitate small group work. In some cases, generally in academic institutions, student laptops or laptop carts take the place of dedicated computer labs, although computer labs still have a place in applications requiring special software or hardware not practically implementable in personal computers.


== Purposes ==

While computer labs are generally multipurpose, some labs may contain computers with hardware or software optimized for certain tasks or processes, depending on the needs of the institution operating the lab. These specialized purposes may include video editing, stock trading, 3-D computer-aided design, programming, and GIS. Increasingly, these have become the main purposes for the existence of traditional desktop-style computer labs, due to rising ownership of inexpensive personal computers making use of the lab only necessary when the expensive, specialized software and more powerful computers needed to run it are required.


== Arrangements ==

		
		


== Alternatives ==

In some settings, traditional desktop computer labs are impractical due to the requirement of a dedicated space. Because of this, some labs use laptop carts instead of desktop setups, in order to both save space and give the lab some degree of mobility.
In the context of academic institutions, some traditional desktop computer labs are being phased out in favor of other solutions judged to be more efficient given that most students own personal laptops. One of these solutions is a virtual lab, which can allow users to install software from the lab server onto their own laptops or log into virtual machines remotely, essentially turning their own laptops into lab machines.


== Similar spaces ==


=== Media lab ===
A media lab (often referred to as ""new media lab"" or ""media research lab"") is a term used for interdisciplinary organizations, collectives or spaces with the main focus on new media, digital culture and technology.  The MIT Media Lab is a well-known example of a media lab.


=== Internet café ===

An Internet café differs from a computer lab in that usage of a computer lab is generally free for those with access, while Internet cafés charge for computer use. The term 'Internet café' is often used interchangeably with 'computer lab' but may differ from a computer lab in that users can also connect to the Internet using their own computer or device, and users of a computer lab generally do not need any equipment of their own.


== See also ==
Computer science
School library
Kiosk software
Public computer
LAN gaming center


== References =="
"A laptop (also laptop computer), is a small, portable personal computer (PC) with a ""clamshell"" form factor, typically having a thin LCD or LED computer screen mounted on the inside of the upper lid of the clamshell and an alphanumeric keyboard on the inside of the lower lid. The clamshell is opened up to use the computer. Laptops are folded shut for transportation, and thus are suitable for mobile use. Its name comes from lap, as it was deemed to be placed on a person's lap when being used. Although originally there was a distinction between laptops and notebooks (the former being bigger and heavier than the latter), as of 2014, there is often no longer any difference. Today, laptops are commonly used in a variety of settings, such as at work, in education, for playing games, web browsing, for personal multimedia, and general home computer use.
Laptops combine all the input/output components and capabilities of a desktop computer, including the display screen, speakers, a keyboard, data storage device, sometimes an optical disc drive, pointing devices (such as a touchpad or trackpad), with an operating system, a processor and memory into a single unit. Most modern laptops feature integrated webcams and built-in microphones, while many also have touchscreens. Laptops can be powered either from an internal battery or by an external power supply from an AC adapter. Hardware specifications, such as the processor speed and memory capacity, significantly vary between different types, makes, models and price points.
Design elements, form factor and construction can also vary significantly between models depending on intended use. Examples of specialized models of laptops include rugged notebooks for use in construction or military applications, as well as low production cost laptops such as those from the One Laptop per Child (OLPC) organization, which incorporate features like solar charging and semi-flexible components not found on most laptop computers. Portable computers, which later developed into modern laptops, were originally considered to be a small niche market, mostly for specialized field applications, such as in the military, for accountants, or for traveling sales representatives. As the portable computers evolved into the modern laptop, they became widely used for a variety of purposes.


== Terminology variants ==
The terms laptop and notebook are used interchangeably to describe a portable computer in English, although in some parts of the world one or the other may be preferred.  There is some question as to the original etymology and specificity of either term—the term laptop appears to have been coined in the early 1980s to describe a mobile computer which could be used on one's lap, and to distinguish these devices from earlier, much heavier, portable computers (informally called ""luggables""). The term ""notebook"" appears to have gained currency somewhat later as manufacturers started producing even smaller portable devices, further reducing their weight and size and incorporating a display roughly the size of A4 paper; these were marketed as notebooks to distinguish them from bulkier laptops. Regardless of the etymology, by the late 1990s and towards the 2000s, the terms were interchangeable.


== History ==

As the personal computer (PC) became feasible in 1971, the idea of a portable personal computer soon followed. A ""personal, portable information manipulator"" was imagined by Alan Kay at Xerox PARC in 1968, and described in his 1972 paper as the ""Dynabook"". The IBM Special Computer APL Machine Portable (SCAMP) was demonstrated in 1973. This prototype was based on the IBM PALM processor. The IBM 5100, the first commercially available portable computer, appeared in September 1975, and was based on the SCAMP prototype.As 8-bit CPU machines became widely accepted, the number of portables increased rapidly. The first ""laptop-sized notebook computer"" was the Epson HX-20, invented (patented) by Suwa Seikosha's Yukio Yokozawa in July 1980, introduced at the COMDEX computer show in Las Vegas by Japanese company Seiko Epson in 1981, and released in July 1982. It had an LCD screen, a rechargeable battery, and a calculator-size printer, in a 1.6 kg (3.5 lb) chassis, the size of an A4 notebook. It was described as a ""laptop"" and ""notebook"" computer in its patent.The portable micro computer Portal of the French company R2E Micral CCMC officially appeared in September 1980 at the Sicob show in Paris. It was a portable microcomputer designed and marketed by the studies and developments department of R2E Micral at the request of company CCMC specializing in payroll and accounting. It was based on an Intel 8085 processor, 8-bit, clocked at 2 MHz. It was equipped with a central 64 KB RAM, a keyboard with 58 alpha numeric keys and 11 numeric keys (separate blocks), a 32-character screen, a floppy disk : capacity = 140,000 characters, of a thermal printer : speed = 28 characters / second, an asynchronous channel, a synchronous channel, a 220 V power supply. It weighed 12 kg and its dimensions were 45 x 45 x 15 cm. It provided total mobility. Its operating system was the aptly named Prologue.

The Osborne 1, released in 1981, was a luggable computer that used the Zilog Z80 and weighed 24.5 pounds (11.1 kg). It had no battery, a 5 in (13 cm) cathode ray tube (CRT) screen, and dual 5.25 in (13.3 cm) single-density floppy drives. Both Tandy/RadioShack and Hewlett Packard (HP) also produced portable computers of varying designs during this period. The first laptops using the flip form factor appeared in the early 1980s. The Dulmont Magnum was released in Australia in 1981–82, but was not marketed internationally until 1984–85. The US$8,150 (US$21,590 today) GRiD Compass 1101, released in 1982, was used at NASA and by the military, among others. The Sharp PC-5000, Ampere and Gavilan SC released in 1983. The Gavilan SC was described as a ""laptop"" by its manufacturer, while the Ampere had a modern clamshell design. The Toshiba T1100 won acceptance not only among PC experts but the mass market as a way to have PC portability.From 1983 onward, several new input techniques were developed and included in laptops, including the touchpad (Gavilan SC, 1983), the pointing stick (IBM ThinkPad 700, 1992), and handwriting recognition (Linus Write-Top, 1987). Some CPUs, such as the 1990 Intel i386SL, were designed to use minimum power to increase battery life of portable computers and were supported by dynamic power management features such as Intel SpeedStep and AMD PowerNow! in some designs.
Displays reached 640x480 (VGA) resolution by 1988 (Compaq SLT/286), and color screens started becoming a common upgrade in 1991, with increases in resolution and screen size occurring frequently until the introduction of 17"" screen laptops in 2003. Hard drives started to be used in portables, encouraged by the introduction of 3.5"" drives in the late 1980s, and became common in laptops starting with the introduction of 2.5"" and smaller drives around 1990; capacities have typically lagged behind physically larger desktop drives. Optical storage, read-only CD-ROM followed by writeable CD and later read-only or writeable DVD and Blu-ray players, became common in laptops early in the 2000s.


== Types ==

Since the introduction of portable computers during the late 1970s, their form has changed significantly, spawning a variety of visually and technologically differing subclasses.  Except where there is a distinct legal trademark around a term (notably Ultrabook), there are rarely hard distinctions between these classes and their usage has varied over time and between different sources.


=== Traditional laptop ===
The form of the traditional laptop computer is a clamshell, with a screen on one of its inner sides and a keyboard on the opposite, facing the screen. It can be easily folded to conserve space while traveling. The screen and keyboard are inaccessible while closed. Devices of this form are commonly called a 'traditional laptop' or notebook, particularly if they have a screen size of 11 to 17 inches measured diagonally and run a full-featured operating system like Windows, macOS, or Linux. Traditional laptops are the most common form of laptops, although Chromebooks, Ultrabooks, convertibles and 2-in-1s (described below) are becoming more common, with similar performance being achieved in their more portable or affordable forms.


=== Subnotebook ===

A subnotebook or an ultraportable, is a laptop designed and marketed with an emphasis on portability (small size, low weight, and often longer battery life). Subnotebooks are usually smaller and lighter than standard laptops, weighing between 0.8 and 2 kg (2-5 lb), with a battery life exceeding 10 hours. Since the introduction of netbooks and ultrabooks, the line between subnotebooks and either category has blurred. Netbooks are a more basic and cheaper type of subnotebook, and while some ultrabooks have a screen size too large to qualify as subnotebooks, certain ultrabooks fit in the subnotebook category. One notable example of a subnotebook is the Apple MacBook Air.


=== Netbook ===

The netbook is an inexpensive, light-weight, energy-efficient form of laptop, especially suited for wireless communication and Internet access. Netbooks first became commercially available around 2008, weighing under 1 kg, with a display size of under 9"". Netbooks sold for around $300-$500, whereas some notebook models would sell for $1000 or more. This prompted the use of netbooks for education in school systems across the world. The name netbook (with net short for Internet) is used as ""the device excels in web-based computing performance"". Netbooks were initially sold with light-weight variants of the GNU operating system (with Linux kernel), although later versions often have the Windows XP or Windows 7 operating systems. The term ""netbook"" is largely obsolete, although machines that would have once been called netbooks—small, inexpensive, and low powered—never ceased being sold, in particular the smaller Chromebook models.


=== Convertible, hybrid, 2-in-1 ===

The latest trend of technological convergence in the portable computer industry spawned a broad range of devices, which combined features of several previously separate device types. The hybrids, convertibles and 2-in-1s emerged as crossover devices, which share traits of both tablets and laptops. All such devices have a touchscreen display designed to allow users to work in a tablet mode, using either multi-touch gestures or a stylus/digital pen.
Convertibles are devices with the ability to conceal a hardware keyboard. Keyboards on such devices can be flipped, rotated, or slid behind the back of the chassis, thus transforming from a laptop into a tablet. Hybrids have a keyboard detachment mechanism, and due to this feature, all critical components are situated in the part with the display. 2-in-1s can have a hybrid or a convertible form, often dubbed 2-in-1 detachables and 2-in-1 convertibles respectively, but are distinguished by the ability to run a desktop OS, such as Windows 10. 2-in-1s are often marketed as laptop replacement tablets.2-in-1s are often very thin, around 10 millimetres (0.39 in), and light devices with a long battery life. 2-in-1s are distinguished from mainstream tablets as they feature an x86-architecture CPU (typically a low- or ultra-low-voltage model), such as the Intel Core i5, run a full-featured desktop OS like Windows 10, and have a number of typical laptop I/O ports, such as USB 3 and Mini DisplayPort.
2-in-1s are designed to be used not only as a media consumption device, but also as valid desktop or laptop replacements, due to their ability to run desktop applications, such as Adobe Photoshop. It is possible to connect multiple peripheral devices, such as a mouse, keyboard and a number of external displays to a modern 2-in-1.
Microsoft Surface Pro-series devices and Surface Book are examples of modern 2-in-1 detachables, whereas Lenovo Yoga-series computers are a variant of 2-in-1 convertibles. While the older Surface RT and Surface 2 have the same chassis design as the Surface Pro, their use of ARM processors and Windows RT do not classify them as 2-in-1s, but as hybrid tablets. Similarly, a number of hybrid laptops run a mobile operating system, such as Android. These include Asus's Transformer Pad devices, examples of hybrids with a detachable keyboard design, which do not fall in the category of 2-in-1s.


=== Desktop replacement ===

A desktop-replacement laptop is a class of large device which is not intended primarily for mobile use. These devices are bulkier and not as portable as other laptops, and are intended for use as compact and transportable alternatives to a desktop computer. Desktop replacements are larger and typically heavier than other classes of laptops. They are capable of containing more powerful components and have a 15-inch or larger display. Desktop replacement laptops' operation time on batteries is typically shorter than other laptops; in rare cases they have no battery at all. In the past, some laptops in this class used a limited range of desktop components to provide better performance for the same price at the expense of battery life, although this practice has largely died out. The names Media Center Laptops and Gaming Laptops are used to describe specialized notebook computers, often overlapping with the desktop replacement form factor.


=== Rugged laptop ===

A rugged laptop is designed to reliably operate in harsh usage conditions such as strong vibrations, extreme temperatures, and wet or dusty environments. Rugged laptops are usually designed from scratch, rather than adapted from regular consumer laptop models. Rugged laptops are bulkier, heavier, and much more expensive than regular laptops, and thus are seldom seen in regular consumer use.
The design features found in rugged laptops include a rubber sheeting under the keyboard keys, sealed port and connector covers, passive cooling, very bright displays easily readable in daylight, cases and frames made of lightweight magnesium alloys that are much stronger than plastics found in commercial laptops, and solid-state storage devices or hard disk drives that are shock mounted to withstand constant vibrations. Rugged laptops are commonly used by public safety services (police, fire, and medical emergency), military, utilities, field service technicians, construction, mining, and oil drilling personnel. Rugged laptops are usually sold to organizations rather than individuals, and are rarely marketed via retail channels.


=== Business laptop ===
A business laptop is a laptop designed for those in a workplace i.e, while in office or travel. Typically, it is ruggedised, with consumer-facing features, like high resolution sound, removed to allow the device to be used for pure productivity. It may sometimes include business-oriented features like Trusted Platform Module, fingerprint scanner, smart card reader and/or a pointing stick.


== Hardware ==

The basic components of laptops function identically to their desktop counterparts. Traditionally they were miniaturized and adapted to mobile use, although desktop systems increasingly use the same smaller, lower-power parts which were originally developed for mobile use. The design restrictions on power, size, and cooling of laptops limit the maximum performance of laptop parts compared to that of desktop components, although that difference has increasingly narrowed.In general, laptop components are not intended to be replaceable or upgradable, with the exception of components which can be detached, such as a battery or CD/CDR/DVD drive. This restriction is one of the major differences between laptops and desktop computers, because the large ""tower"" cases used in desktop computers are designed so that new motherboards, hard disks, sound cards, RAM, and other components can be added. In a very compact laptop, such as laplets, there may be no upgradeable components at all.Intel, Asus, Compal, Quanta, and some other laptop manufacturers have created the Common Building Block standard for laptop parts to address some of the inefficiencies caused by the lack of standards and inability to upgrade components.The following sections summarizes the differences and distinguishing features of laptop components in comparison to desktop personal computer parts.


=== Display ===
Internally, a display is an LCD panel which could be CCFL or LED backlit which interfaces to the laptop using the LVDS protocol, while externally, it can be a glossy screen or a matte screen. Most modern laptops feature a 13 inches (33 cm) VIS or larger color active matrix display based on LED lighting with resolutions of 1280×800 (16:10) or 1366×768 (16:9) pixels and above. Models with LED-based lighting offer lower power consumption and often increased brightness. Netbooks with a 10 inches (25 cm) or smaller screen typically use a resolution of 1024×600, while netbooks and subnotebooks with an 11.6 inches (29 cm) or 12 inches (30 cm) screen use standard notebook resolutions. Having a higher resolution display allows more items to fit onscreen at a time, improving the user's ability to multitask, although at the higher resolutions on smaller screens, the resolution may only serve to display sharper graphics and text rather than increasing the usable area. Since the introduction of the MacBook Pro with Retina display in 2012, there has been an increase in the availability of very-high-resolution (1920×1080 and higher) displays, even in relatively small systems, and in typical 15-inch screens resolutions as high as 3200×1800 are available. External displays can be connected to most laptops, and models with a Mini DisplayPort can handle up to three.


=== Central processing unit ===
A laptop's central processing unit (CPU) has advanced power-saving features and produces less heat than one intended purely for desktop use. Typically, laptop CPUs made after 2018 have four processor cores, although 6-core and 8-core models are also available. For low price and mainstream performance, there is no longer a significant performance difference between laptop and desktop CPUs, but at the high end, the fastest desktop CPUs still substantially outperform the fastest laptop processors, at the expense of massively higher power consumption and heat generation; the fastest laptop processors top out at 56 watts of heat, while the fastest desktop processors top out at 150 watts.
There have been a wide range of CPUs designed for laptops available from both Intel, AMD, and other manufacturers. On non-x86 architectures, Motorola and IBM produced the chips for the former PowerPC-based Apple laptops (iBook and PowerBook). Many laptops have removable CPUs, although this has become less common in the past few years as the trend has been towards thinner and lighter models. In other laptops the CPU is soldered on the motherboard and is non-replaceable; this is nearly universal in ultrabooks.
In the past, some laptops have used a desktop processor instead of the laptop version and have had high performance gains at the cost of greater weight, heat, and limited battery life, but the practice was largely extinct as of 2013. Unlike their desktop counterparts, laptop CPUs are nearly impossible to overclock. A thermal operating mode of laptops is very close to its limits and there is almost no headroom for an overclocking–related operating temperature increase. The possibility of improving a cooling system of a laptop to allow overclocking is extremely difficult to implement.


=== Graphical processing unit ===
On most laptops a graphical processing unit (GPU) is integrated into the CPU to conserve power and space. This was introduced by Intel with the Core i-series of mobile processors in 2010, and similar accelerated processing unit (APU) processors by AMD later that year. Prior to that, lower-end machines tended to use graphics processors integrated into the system chipset, while higher end machines had a separate graphics processor. In the past, laptops lacking a separate graphics processor were limited in their utility for gaming and professional applications involving 3D graphics, but the capabilities of CPU-integrated graphics have converged with the low-end of dedicated graphics processors in the past few years. Higher-end laptops intended for gaming or professional 3D work still come with dedicated, and in some cases even dual, graphics processors on the motherboard or as an internal expansion card. Since 2011, these almost always involve switchable graphics so that when there is no demand for the higher performance dedicated graphics processor, the more power-efficient integrated graphics processor will be used. Nvidia Optimus and AMD Hybrid Graphics are examples of this sort of system of switchable graphics.


=== Memory ===
Most laptops use SO-DIMM (small outline dual in-line memory module) memory modules, as they are about half the size of desktop DIMMs. They are sometimes accessible from the bottom of the laptop for ease of upgrading, or placed in locations not intended for user replacement. Most laptops have two memory slots, although some of the lowest-end models will have only one, and some high end models (usually mobile engineering workstations and a few high-end models intended for gaming) have four slots. Most mid-range laptops are factory equipped with 4-8 GB of RAM. with higher-end laptops containing 16 GB of RAM or more. Netbooks are commonly equipped with only 1–2 GB of RAM and are generally only expandable to 2 GB, if at all. Laptops may have memory soldered to the motherboard to conserve space, which allows the laptop to have a thinner chassis design. Soldered memory cannot be easily upgraded.


=== Internal storage ===
Traditionally, laptops had a hard disk drive (HDD) as a main non-volatile storage, but these proved inefficient for use in mobile devices due to high power consumption, heat production, and a presence of moving parts, which can cause damage to both the drive itself and the data stored when a laptop is unstable physically, e.g. during its use while transporting it or after its accidental drop. With the advent of flash memory technology, most mid- to high-end laptops opted for more compact, power efficient, and fast solid-state drives (SSD), which eliminated the hazard of drive and data corruption caused by a laptop's physical impacts.  Most laptops use 2.5-inch drives, which are a smaller version of a 3.5-inch desktop drive form factor. 2.5-inch HDDs are more compact, power efficient, and produce less heat, while at the same time have a smaller capacity and a slower data transfer rate. Some very compact laptops support even smaller 1.8-inch HDDs. For SSDs, however, these miniaturization-related trade-offs are nonexistent, because SSDs were designed to have a very small footprint. SSDs feature a traditional 2.5- or 1.8-inch or a laptop-specific mSATA or M.2 card's form factor. SSDs have a higher data transfer rate, lower power consumption, lower failure rate, and a larger capacity compared to HDDs. However, HDDs have a significantly lower cost.
Most laptops can contain a single 2.5-inch drive, but a small number of laptops with a screen wider than 15 inches can house two drives. Some laptops support a hybrid mode, combining a 2.5-inch drive, typically a spacious HDD for data, with an mSATA or M.2 SDD drive, typically having less capacity, but a significantly faster read/write speed. The operating system partition would be located on the SSD to increase laptop I/O performance. Another way to increase performance is to use a smaller SSD of 16-32 GB as a cache drive with a compatible OS. Some laptops may have very limited drive upgradeability when the SSD used has a non-standard shape or requires a proprietary daughter card. Some laptops have very limited space on the installed SSD, instead relying on availability of cloud storage services for storing of user data; Chromebooks are a prominent example of this approach. A variety of external HDDs or NAS data storage servers with support of RAID technology can be attached to virtually any laptop over such interfaces as USB, FireWire, eSATA, or Thunderbolt, or over a wired or wireless network to further increase space for the storage of data. Many laptops also incorporate a card reader which allows for use of memory cards, such as those used for digital cameras, which are typically SD or microSD cards. This enables users to download digital pictures from an SD card onto a laptop, thus enabling them to delete the SD card's contents to free up space for taking new pictures.


=== Removable media drive ===
Optical disc drives capable of playing CD-ROMs, compact discs (CD), DVDs, and in some cases, Blu-ray discs (BD),  were nearly universal on full-sized models by the early 2010s. A disc drive remains fairly common in laptops with a screen wider than 15 inches (38 cm), although the trend towards thinner and lighter machines is gradually eliminating these drives and players; these drives are uncommon in compact laptops, such as subnotebooks and netbooks. Laptop optical drives tend to follow a standard form factor, and usually have a standard mSATA connector. It is often possible to replace an optical drive with a newer model. In certain laptop models there is a possibility to replace an optical drive with a second hard drive, using a caddy that fills the extra space the optical drive would have occupied.


=== Inputs ===

An alphanumeric keyboard is used to enter text and data and make other commands (e.g., function keys). A touchpad (also called a trackpad), a pointing stick, or both, are used to control the position of the cursor on the screen, and an integrated keyboard is used for typing. An external keyboard and mouse may be connected using a USB port or wirelessly, via Bluetooth or similar technology. With the advent of ultrabooks and support of touch input on screens by 2010-era operating systems, such as Windows 8.1, multitouch touchscreen displays are used in many models. Some models have webcams and microphones, which can be used to communicate with other people with both moving images and sound, via Skype, Google chat and similar software.
Laptops typically have USB ports and a microphone jack, for use with an external mic. Some laptops have a card reader for reading digital camera SD cards.


=== Input/output (I/O) ports ===
On a typical laptop there are several USB ports, an external monitor port (VGA, DVI, HDMI or Mini DisplayPort), an audio in/out port (often in form of a single socket) is common. It is possible to connect up to three external displays to a 2014-era laptop via a single Mini DisplayPort, utilizing multi-stream transport technology. Apple, in a 2015 version of its MacBook, transitioned from a number of different I/O ports to a single USB-C port. This port can be used both for charging and connecting a variety of devices through the use of aftermarket adapters. Google, with its updated version of Chromebook Pixel, shows a similar transition trend towards USB-C, although keeping older USB Type-A ports for a better compatibility with older devices. Although being common until the end of the 2000s decade, Ethernet network port are rarely found on modern laptops, due to widespread use of wireless networking, such as Wi-Fi. Legacy ports such as a PS/2 keyboard/mouse port, serial port, parallel port, or FireWire are provided on some models, but they are increasingly rare. On Apple's systems, and on a handful of other laptops, there are also Thunderbolt ports, but Thunderbolt 3 uses USB-C. Laptops typically have a headphone jack, so that the user can connect external headphones or amplified speaker systems for listening to music or other audio.


=== Expansion cards ===
In the past, a PC Card (formerly PCMCIA) or ExpressCard slot for expansion was often present on laptops to allow adding and removing functionality, even when the laptop is powered on; these are becoming increasingly rare since the introduction of USB 3.0. Some internal subsystems such as: Ethernet, Wi-Fi, or a wireless cellular modem can be implemented as replaceable internal expansion cards, usually accessible under an access cover on the bottom of the laptop. The standard for such cards is PCI Express, which comes in both mini and even smaller M.2 sizes. In newer laptops, it is not uncommon to also see Micro SATA (mSATA) functionality on PCI Express Mini or M.2 card slots allowing the use of those slots for SATA-based solid state drives.


=== Battery and power supply ===

2016-era laptops use lithium ion batteries, with some thinner models using the flatter lithium polymer technology. These two technologies have largely replaced the older nickel metal-hydride batteries. Battery life is highly variable by model and workload and can range from one hour to nearly a day. A battery's performance gradually decreases over time; substantial reduction in capacity is typically evident after one to three years of regular use, depending on the charging and discharging pattern and the design of the battery. Innovations in laptops and batteries have seen situations in which the battery can provide up to 24 hours of continued operation, assuming average power consumption levels. An example is the HP EliteBook 6930p when used with its ultra-capacity battery.A laptop's battery is charged using an external power supply, which is plugged into a wall outlet. The power supply outputs a DC voltage typically in the range of 7.2—24 volts. The power supply is usually external and connected to the laptop through a DC connector cable. In most cases, it can charge the battery and power the laptop simultaneously. When the battery is fully charged, the laptop continues to run on power supplied by the external power supply, avoiding battery use. The battery charges in a shorter period of time if laptop is turned off or sleeping. The charger typically adds about 400 grams (0.88 lb) to the overall transporting weight of a laptop, although some models are substantially heavier or lighter. Most 2016-era laptops use a smart battery, a rechargeable battery pack with a built-in battery management system (BMS). The smart battery can internally measure voltage and current, and deduce charge level and State of Health (SoH) parameters, indicating the state of the cells.


=== Cooling ===
Waste heat from operation is difficult to remove in the compact internal space of a laptop. Early laptops used heat sinks placed directly on the components to be cooled, but when these hot components are deep inside the device, a large space-wasting air duct is needed to exhaust the heat. Modern laptops instead rely on heat pipes to rapidly move waste heat towards the edges of the device, to allow for a much smaller and compact fan and heat sink cooling system. Waste heat is usually exhausted away from the device operator towards the rear or sides of the device. Multiple air intake paths are used since some intakes can be blocked, such as when the device is placed on a soft conforming surface like a chair cushion. It is believed that some designs with metal cases, like Apple's aluminum MacBook Pro and MacBook Air, also employ the case of the machine as a heat sink, allowing it to supplement cooling by dissipating heat out of the device core. Secondary device temperature monitoring may reduce performance or trigger an emergency shutdown if it is unable to dissipate heat, such as if the laptop were to be left running and placed inside a carrying case. Aftermarket cooling pads with external fans can be used with laptops to reduce operating temperatures.


=== Docking station ===

A docking station (sometimes referred to simply as a dock) is a laptop accessory that contains multiple ports, and in some cases expansion slots or bays for fixed or removable drives. A laptop connects and disconnects to a docking station, typically through a single large proprietary connector. A docking station is an especially popular laptop accessory in a corporate computing environment, due to a possibility of a docking station to transform a laptop into a full-featured desktop replacement, yet allowing for its easy release. This ability can be advantageous to ""road warrior"" employees who have to travel frequently for work, and yet who also come into the office. If more ports are needed, or their position on a laptop is inconvenient, one can use a cheaper passive device known as a port replicator. These devices mate to the connectors on the laptop, such as through USB or FireWire.


=== Charging trolleys ===
Laptop charging trolleys, also known as laptop trolleys or laptop carts, are mobile storage containers to charge multiple laptops, netbooks, and tablet computers at the same time. The trolleys are used in schools that have replaced their traditional static computer labs suites of desktop equipped with ""tower"" computers, but do not have enough plug sockets in an individual classroom to charge all of the devices. The trolleys can be wheeled between rooms and classrooms so that all students and teachers in a particular building can access fully charged IT equipment.Laptop charging trolleys are also used to deter and protect against opportunistic and organized theft. Schools, especially those with open plan designs, are often prime targets for thieves who steal high-value items. Laptops, netbooks, and tablets are among the highest–value portable items in a school. Moreover, laptops can easily be concealed under clothing and stolen from buildings. Many types of laptop–charging trolleys are designed and constructed to protect against theft. They are generally made out of steel, and the laptops remain locked up while not in use. Although the trolleys can be moved between areas from one classroom to another, they can often be mounted or locked to the floor or walls to prevent thieves from stealing the laptops, especially overnight.


=== Solar panels ===

In some laptops, solar panels are able to generate enough solar power for the laptop to operate. The One Laptop Per Child Initiative released the OLPC XO-1 laptop which was tested and successfully operated by use of solar panels. Presently, they are designing an OLPC XO-3 laptop with these features. The OLPC XO-3 can operate with 2 watts of electricity because its renewable energy resources generate a total of 4 watts. Samsung has also designed the NC215S solar–powered notebook that will be sold commercially in the U.S. market.


=== Accessories ===
A common accessory for laptops is a laptop sleeve, laptop skin, or laptop case, which provides a degree of protection from scratches. Sleeves, which are distinguished by being relatively thin and flexible, are most commonly made of neoprene, with sturdier ones made of low-resilience polyurethane. Some laptop sleeves are wrapped in ballistic nylon to provide some measure of waterproofing. Bulkier and sturdier cases can be made of metal with polyurethane padding inside and may have locks for added security. Metal, padded cases also offer protection against impacts and drops. Another common accessory is a laptop cooler, a device which helps lower the internal temperature of the laptop either actively or passively. A common active method involves using electric fans to draw heat away from the laptop, while a passive method might involve propping the laptop up on some type of pad so it can receive more air flow. Some stores sell laptop pads which enable a reclining person on a bed to use a laptop.


=== Changes in certain features ===
Some of the components of earlier models of laptops can easily be replaced without opening completely its bottom part, such as keyboard, battery, hard disk, memory modules, CPU cooling fan, etc.
Some of the components of recent models of laptop reside inside. Replacing most of its components, such as keyboard, battery, hard disk, memory modules, CPU cooling fan, etc., requires removal of its either top or bottom part, removal of motherboard, and returning them back.


=== Obsolete features ===

Features that certain early models of laptops used to have that are not available in most current laptops include:

Reset (""cold restart"") button in a hole (needed a thin metal tool to press)
Instant power off button in a hole (needed a thin metal tool to press)
Integrated charger or power adapter inside the laptop
Floppy disk drive
Serial port
Parallel port
Modem
Shared PS/2 input device port
VHS or 8mm VCR
IrDA
S-video port
PC Card / PCMCIA slot
ExpressCard slot
CD/DVD Drives (starting with 2013 models)
VGA port (starting with 2013 models)


== Comparison with desktops ==


=== Advantages ===

Portability is usually the first feature mentioned in any comparison of laptops versus desktop PCs. Physical portability allows a laptop to be used in many places—not only at home and at the office, but also during commuting and flights, in coffee shops, in lecture halls and libraries, at clients' locations or at a meeting room, etc. Within a home, portability enables laptop users to move their device from the living room to the dining room to the family room. Portability offers several distinct advantages:

Productivity: Using a laptop in places where a desktop PC cannot be used can help employees and students to increase their productivity on work or school tasks. For example, an office worker reading their work e-mails during an hour-long commute by train, or a student doing their homework at the university coffee shop during a break between lectures.
Immediacy: Carrying a laptop means having instant access to information, including personal and work files. This allows better collaboration between coworkers or students, as a laptop can be flipped open to look at a report, document, spreadsheet, or presentation anytime and anywhere.
Up-to-date information: If a person has more than one desktop PC, a problem of synchronization arises: changes made on one computer are not automatically propagated to the others. There are ways to resolve this problem, including physical transfer of updated files (using a USB flash memory stick or CD-ROMs) or using synchronization software over the Internet, such as cloud computing. However, transporting a single laptop to both locations avoids the problem entirely, as the files exist in a single location and are always up-to-date.
Connectivity: In the 2010s, a proliferation of Wi-Fi wireless networks and cellular broadband data services (HSDPA, EVDO and others) in many urban centers, combined with near-ubiquitous Wi-Fi support by modern laptops meant that a laptop could now have easy Internet and local network connectivity while remaining mobile. Wi-Fi networks and laptop programs are especially widespread at university campuses.Other advantages of laptops:

Size: Laptops are smaller than desktop PCs. This is beneficial when space is at a premium, for example in small apartments and student dorms. When not in use, a laptop can be closed and put away in a desk drawer.
Low power consumption: Laptops are several times more power-efficient than desktops. A typical laptop uses 20–120 W, compared to 100–800 W for desktops. This could be particularly beneficial for large businesses, which run hundreds of personal computers thus multiplying the potential savings, and homes where there is a computer running 24/7 (such as a home media server, print server, etc.).
Quiet: Laptops are typically much quieter than desktops, due both to the components (quieter, slower 2.5-inch hard drives) and to less heat production leading to use of fewer and slower cooling fans.
Battery: a charged laptop can continue to be used in case of a power outage and is not affected by short power interruptions and blackouts. A desktop PC needs an Uninterruptible power supply (UPS) to handle short interruptions, blackouts, and spikes; achieving on-battery time of more than 20–30 minutes for a desktop PC requires a large and expensive UPS.
All-in-One: designed to be portable, most 2010-era laptops have all components integrated into the chassis (however, some small laptops may not have an internal CD/CDR/DVD drive, so an external drive needs to be used). For desktops (excluding all-in-ones) this is divided into the desktop ""tower"" (the unit with the CPU, hard drive, power supply, etc.), keyboard, mouse, display screen, and optional peripherals such as speakers.


=== Disadvantages ===
Compared to desktop PCs, laptops have disadvantages in the following areas:


==== Performance ====
While the performance of mainstream desktops and laptop is comparable, and the cost of laptops has fallen less rapidly than desktops, laptops remain more expensive than desktop PCs at the same performance level. The upper limits of performance of laptops remain much lower than the highest-end desktops (especially ""workstation class"" machines with two processor sockets), and ""bleeding-edge"" features usually appear first in desktops and only then, as the underlying technology matures, are adapted to laptops.
For Internet browsing and typical office applications, where the computer spends the majority of its time waiting for the next user input, even relatively low-end laptops (such as Netbooks) can be fast enough for some users. Most higher-end laptops are sufficiently powerful for high-resolution movie playback, some 3D gaming and video editing and encoding. However, laptop processors can be disadvantaged when dealing with a higher-end database, maths, engineering, financial software, virtualization, etc. This is because laptops use the mobile versions of processors to conserve power, and these lag behind desktop chips when it comes to performance. Some manufacturers work around this performance problem by using desktop CPUs for laptops.


==== Upgradeability ====
Upgradeability of laptops is very limited compared to desktops, which are thoroughly standardized. In general, hard drives and memory can be upgraded easily. Optical drives and internal expansion cards may be upgraded if they follow an industry standard, but all other internal components, including the motherboard, CPU and graphics, are not always intended to be upgradeable. Intel, Asus, Compal, Quanta and some other laptop manufacturers have created the Common Building Block standard for laptop parts to address some of the inefficiencies caused by the lack of standards. The reasons for limited upgradeability are both technical and economic. There is no industry-wide standard form factor for laptops; each major laptop manufacturer pursues its own proprietary design and construction, with the result that laptops are difficult to upgrade and have high repair costs. Moreover, starting with 2013 models, laptops have become increasingly integrated (soldered) with the motherboard for most of its components (CPU, SDD, RAM, Keyboard...) in order to reduce size and upgradeability prospects. Devices such as sound cards, network adapters, hard and optical drives, and numerous other peripherals are available, but these upgrades usually impair the laptop's portability, because they add cables and boxes to the setup and often have to be disconnected and reconnected when the laptop is on the move.


==== Ergonomics and health effects ====


===== Wrists =====

Prolonged use of laptops can cause repetitive strain injury because of their small, flat keyboard and trackpad pointing devices. Usage of separate, external ergonomic keyboards and pointing devices is recommended to prevent injury when working for long periods of time; they can be connected to a laptop easily by USB or via a docking station. Some health standards require ergonomic keyboards at workplaces.


===== Neck and spine =====
A laptop's integrated screen often requires users to lean over for a better view, which can cause neck or spinal injuries. A larger and higher-quality external screen can be connected to almost any laptop to alleviate this and to provide additional screen space for more productive work. Another solution is to use a computer stand.


===== Possible effect on fertility =====
A study by State University of New York researchers found that heat generated from laptops can increase the temperature of the lap of male users when balancing the computer on their lap, potentially putting sperm count at risk. The study, which included roughly two dozen men between the ages of 21 and 35, found that the sitting position required to balance a laptop can increase scrotum temperature by as much as 2.1 °C (4 °F). However, further research is needed to determine whether this directly affects male sterility. A later 2010 study of 29 males published in Fertility and Sterility found that men who kept their laptops on their laps experienced scrotal hyperthermia (overheating) in which their scrotal temperatures increased by up to 2.0 °C (4 °F). The resulting heat increase, which could not be offset by a laptop cushion, may increase male infertility.A common practical solution to this problem is to place the laptop on a table or desk, or to use a book or pillow between the body and the laptop. Another solution is to obtain a cooling unit for the laptop. These are usually USB powered and consist of a hard thin plastic case housing one, two, or three cooling fans – with the entire assembly designed to sit under the laptop in question – which results in the laptop remaining cool to the touch, and greatly reduces laptop heat buildup.


==== Thighs ====
Heat generated from using a laptop on the lap can also cause skin discoloration on the thighs known as ""toasted skin syndrome"".


==== Durability ====

Laptops are less durable than the desktops/PCs. However, the durability of the laptop depends on the user if proper maintenance is done then the laptop can work longer.


===== Equipment wear =====
Because of their portability, laptops are subject to more wear and physical damage than desktops. Components such as screen hinges, latches, power jacks, and power cords deteriorate gradually from ordinary use, and may have to be replaced. A liquid spill onto the keyboard, a rather minor mishap with a desktop system (given that a basic keyboard costs about US$20), can damage the internals of a laptop and destroy the computer, result in a costly repair or entire replacement of laptops. One study found that a laptop is three times more likely to break during the first year of use than a desktop. To maintain a laptop, it is recommended to clean it every three months for dirt, debris, dust, and food particles. Most cleaning kits consist of a lint-free or microfiber cloth for the LCD screen and keyboard, compressed air for getting dust out of the cooling fan, and cleaning solution. Harsh chemicals such as bleach should not be used to clean a laptop, as they can damage it.


===== Parts replacement =====
Original external components are expensive and usually proprietary and non-interchangeable; other parts are inexpensive—a power jack can cost a few dollars—but their replacement may require extensive disassembly and reassembly of the laptop by a technician. Other inexpensive but fragile parts often cannot be purchased separately from larger more expensive components. For example, the video display cable and the backlight power cable that pass through the lid hinges to connect the motherboard to the screen may eventually break from repeated opening and closing of the lid. These tiny cables usually cannot be purchased from the original manufacturer separate from the entire LCD panel, with the price of hundreds of dollars, although for popular models an aftermarket in pulled parts generally exists. The repair costs of a failed motherboard or LCD panel often exceeds the value of a used laptop. Parts can also be ordered from third party vendors.


===== Heating and cooling =====
Laptops rely on extremely compact cooling systems involving a fan and heat sink that can fail from blockage caused by accumulated airborne dust and debris. Most laptops do not have any type of removable dust collection filter over the air intake for these cooling systems, resulting in a system that gradually conducts more heat and noise as the years pass. In some cases the laptop starts to overheat even at idle load levels. This dust is usually stuck inside where the fan and heat sink meet, where it can not be removed by a casual cleaning and vacuuming. Most of the time, compressed air can dislodge the dust and debris but may not entirely remove it. After the device is turned on, the loose debris is reaccumulated into the cooling system by the fans. A complete disassembly is usually required to clean the laptop entirely. However, preventative maintenance such as regular cleaning of the heat sink via compressed air can prevent dust build up on the heat sink. Many laptops are difficult to disassemble by the average user and contain components that are sensitive to electrostatic discharge (ESD).


===== Battery life =====
Battery life is limited because the capacity drops with time, eventually requiring replacement after as little as a year. A new battery typically stores enough energy to run the laptop for three to five hours, depending on usage, configuration, and power management settings. Yet, as it ages, the battery's energy storage will dissipate progressively until it lasts only a few minutes. The battery is often easily replaceable and a higher capacity model may be obtained for longer charging and discharging time. Some laptops (specifically ultrabooks) do not have the usual removable battery and have to be brought to the service center of its manufacturer or a third-party laptop service center to have its battery replaced. Replacement batteries can also be expensive.


==== Security and privacy ====

Because they are valuable, commonly used, portable, and easy to hide in a backpack or other type of travel bag, laptops are often stolen. Every day, over 1,600 laptops go missing from U.S. airports. The cost of stolen business or personal data, and of the resulting problems (identity theft, credit card fraud, breach of privacy), can be many times the value of the stolen laptop itself. Consequently, physical protection of laptops and the safeguarding of data contained on them are both of great importance. Most laptops have a Kensington security slot, which can be used to tether them to a desk or other immovable object with a security cable and lock. In addition, modern operating systems and third-party software offer disk encryption functionality, which renders the data on the laptop's hard drive unreadable without a key or a passphrase. As of 2015, some laptops also have additional security elements added, including eye recognition software and fingerprint scanning components.Software such as LoJack for Laptops, Laptop Cop, and GadgetTrack have been engineered to help people locate and recover their stolen laptop in the event of theft. Setting one's laptop with a password on its firmware (protection against going to firmware setup or booting), internal HDD/SSD (protection against accessing it and loading an operating system on it afterwards), and every user account of the operating system are additional security measures that a user should do. Fewer than 5% of lost or stolen laptops are recovered by the companies that own them, however, that number may decrease due to a variety of companies and software solutions specializing in laptop recovery. In the 2010s, the common availability of webcams on laptops raised privacy concerns. In Robbins v. Lower Merion School District (Eastern District of Pennsylvania 2010), school-issued laptops loaded with special software enabled staff from two high schools to take secret webcam shots of students at home, via their students' laptops.


== Sales ==


=== Manufacturers ===

There are many laptop brands and manufacturers. Several major brands that offer notebooks in various classes are listed in the adjacent box.
The major brands usually offer good service and support, including well-executed documentation and driver downloads that remain available for many years after a particular laptop model is no longer produced. Capitalizing on service, support, and brand image, laptops from major brands are more expensive than laptops by smaller brands and ODMs. Some brands specialize in a particular class of laptops, such as gaming laptops (Alienware), high-performance laptops (HP Envy), netbooks (EeePC) and laptops for children (OLPC).
Many brands, including the major ones, do not design and do not manufacture their laptops. Instead, a small number of Original Design Manufacturers (ODMs) design new models of laptops, and the brands choose the models to be included in their lineup. In 2006, 7 major ODMs manufactured 7 of every 10 laptops in the world, with the largest one (Quanta Computer) having 30% of world market share. Therefore, identical models are available both from a major label and from a low-profile ODM in-house brand.


=== Market share ===
Battery-powered portable computers had just 2% worldwide market share in 1986. However, laptops have become increasingly popular, both for business and personal use. Around 109 million notebook PCs shipped worldwide in 2007, a growth of 33% compared to 2006. In 2008 it was estimated that 145.9 million notebooks were sold, and that the number would grow in 2009 to 177.7 million. The third quarter of 2008 was the first time when worldwide notebook PC shipments exceeded desktops, with 38.6 million units versus 38.5 million units.May 2005 was the first time notebooks outsold desktops in the US over the course of a full month; at the time notebooks sold for an average of $1,131 while desktops sold for an average of $696. When looking at operating systems, for Microsoft Windows laptops the average selling price (ASP) showed a decline in 2008/2009, possibly due to low-cost netbooks, drawing an average US$689 at U.S. retail stores in August 2008. In 2009, ASP had further fallen to $602 by January and to $560 in February. While Windows machines ASP fell $129 in these seven months, Apple macOS laptop ASP declined just $12 from $1,524 to $1,512.


== Laptop disposal ==
The list of materials that go into a laptop computer is long, and many of the substances used, such as beryllium, lead, chromium, and mercury compounds, are toxic or carcinogenic to humans.  Although these toxins are relatively harmless when the laptop is in use, concerns that discarded laptops cause a serious health risk and toxic environment damage, were so strong, that the Waste Electrical and Electronic Equipment Directive (WEEE Directive) in Europe specified that all laptop computers must be recycled by law. Similarly, the U.S. Environmental Protection Agency (EPA) has outlawed landfill dumping or the incinerating of discarded laptop computers.
Most laptop computers begin the recycling process with a method known as Demanufacturing (Demanufacture), this involves the physical separation of the components of the laptop.  These components are then either grouped into materials (e.g. plastic, metal and glass) for recycling or more complex items that require more advanced materials separation (e.g.) circuit boards, hard drives and batteries.
Corporate laptop recycling can require an additional process known as data destruction.  The data destruction process ensures that all information or data that has been stored on a laptops hard drive can never be retrieved again.   Below is an overview of some of the data protection and environmental laws and regulations applicable for laptop recycling data destruction:

Data Protection Act 1998 (DPA)
EU Privacy Directive (Due 2016)
Financial Conduct Authority
Sarbanes-Oxley Act
PCI-DSS Data Security Standard
Waste, Electronic & Electrical Equipment Directive (WEEE)
Basel Convention
Bank Secrecy Act (BSA)
FACTA Sarbanes-Oxley Act
FDA Security Regulations (21 C.F.R. part 11)
Gramm-Leach-Bliley Act (GLBA)
HIPAA (Health Insurance Portability and Accountability Act)
NIST SP 800-53
Add NIST SP 800-171
Identity Theft and Assumption Deterrence Act
Patriot Act of 2002
PCI Data Security Standard
US Safe Harbor Provisions
Various state laws
JFAN 6/3
Gramm-leach-Bliley Act
DCID


== Extreme use ==

The ruggedized Grid Compass computer was used since the early days of the Space Shuttle program. The first commercial laptop used in space was a Macintosh portable in 1991 aboard Space Shuttle mission STS-43. Apple and other laptop computers continue to be flown aboard manned spaceflights, though the only long duration flight certified computer for the International Space Station is the ThinkPad. As of 2011, over 100 ThinkPads were aboard the ISS. Laptops used aboard the International Space Station and other spaceflights are generally the same ones that can be purchased by the general public but needed modifications are made to allow them to be used safely and effectively in a weightless environment such as updating the cooling systems to function without relying on hot air rising and accommodation for the lower cabin air pressure. Laptops operating in harsh usage environments and conditions, such as strong vibrations, extreme temperatures, and wet or dusty conditions differ from those used in space in that they are custom designed for the task and do not use commercial off-the-shelf hardware.


== See also ==


== Notes ==


== References ==


== External links ==
 Media related to Laptops at Wikimedia Commons"
"A desktop computer is a personal computer designed for regular use at a single location on or near a desk or table due to its size and power requirements. The most common configuration has a case that houses the power supply, motherboard (a printed circuit board with a microprocessor as the central processing unit (CPU), memory, bus, and other electronic components, disk storage (usually one or more hard disk drives, solid state drives, optical disc drives, and in early models a floppy disk drive); a keyboard and mouse for input; and a computer monitor, speakers, and, often, a printer for output. The case may be oriented horizontally or vertically and placed either underneath, beside, or on top of a desk.


== History ==


=== Origins ===

Prior to the widespread use of microprocessors, a computer that could fit on a desk was considered remarkably small; the type of computers most commonly used were minicomputers, which were themselves desk-sized. Early computers took up the space of a whole room. Minicomputers generally fit into one or a few refrigerator-sized racks.
It was not until the 1970s when fully programmable computers appeared that could fit entirely on top of a desk. 1970 saw the introduction of the Datapoint 2200, a ""smart"" computer terminal complete with keyboard and monitor, was designed to connect with a mainframe computer but that didn't stop owners from using its built-in computational abilities as a stand-alone desktop computer. The HP 9800 series, which started out as programmable calculators in 1971 but was programmable in BASIC by 1972, used a smaller version of a minicomputer design based on ROM memory and had small one-line LED alphanumeric displays and displayed graphics with a plotter. The Wang 2200 of 1973 had a full-size cathode ray tube (CRT) and cassette tape storage. The IBM 5100 in 1975 had a small CRT display and could be programmed in BASIC and APL. These were generally expensive specialized computers sold for business or scientific uses.


=== Growth and development ===
Apple II, TRS-80 and Commodore PET were first generation personal home computers launched in 1977, which were aimed at the consumer market – rather than businessmen or computer hobbyists. Byte magazine referred to these three as the ""1977 Trinity"" of personal computing. Throughout the 1980s and 1990s, desktop computers became the predominant type, the most popular being the IBM PC and its clones, followed by the Apple Macintosh, with the third-placed Commodore Amiga having some success in the mid-1980s but declining by the early 1990s.

Early personal computers, like the original IBM Personal Computer, were enclosed in a ""desktop case"", horizontally oriented to have the display screen placed on top, thus saving space on the user's actual desk, although these cases had to be sturdy enough to support the weight of CRT displays that were widespread at the time. Over the course of the 1990s, desktop cases gradually became less common than the more-accessible tower cases (Tower was a trademark of NCR created by ad agency Reiser Williams deYong) that may be located on the floor under or beside a desk rather than on a desk. Not only do these tower cases have more room for expansion, they have also freed up desk space for monitors which were becoming larger every year. Desktop cases, particularly the compact form factors, remain popular for corporate computing environments and kiosks. Some computer cases can be interchangeably positioned either horizontally (desktop) or upright (mini-tower).
Influential games such as Doom and Quake during the 1990s had pushed gamers and enthusiasts to frequently upgrade to the latest CPUs and graphics cards (3dfx, ATI, and Nvidia) for their desktops (usually a tower case) in order to run these applications, though this has slowed since the late 2000s as the growing popularity of Intel integrated graphics forced game developers to scale back. Creative Technology's Sound Blaster series were a de facto standard for sound cards in desktop PCs during the 1990s until the early 2000s, when they were reduced to a niche product, as OEM desktop PCs came with sound boards integrated directly onto the motherboard.


=== Decline ===
While desktops have long been the most common configuration for PCs, by the mid-2000s the growth shifted from desktops to laptops. Notably, while desktops were mainly produced in the United States, laptops had long been produced by contract manufacturers based in Asia, such as Foxconn. This shift led to the closure of the many desktop assembly plants in the United States by 2010. Another trend around this time was the increasing proportion of inexpensive base-configuration desktops being sold, hurting PC manufacturers such as Dell whose build-to-order customization of desktops relied on upselling added features to buyers.Battery-powered portable computers had just a 2% worldwide market share in 1986. However, laptops have become increasingly popular, both for business and personal use.
Around 109 million notebook PCs shipped worldwide in 2007, a growth of 33% compared to 2006.
In 2008, it was estimated that 145.9 million notebooks were sold and that the number would grow in 2009 to 177.7 million. The third quarter of 2008 was the first time when worldwide notebook PC shipments exceeded desktops, with 38.6 million units versus 38.5 million units.The sales breakdown of the Apple Macintosh has seen sales of desktop Macs staying mostly constant while being surpassed by that of Mac notebooks whose sales rate has grown considerably; seven out of ten Macs sold were laptops in 2009, a ratio projected to rise to three out of four by 2010. The change in sales of form factors is due to the desktop iMac moving from affordable (iMac G3) to upscale (iMac G4) and subsequent releases are considered premium all-in-ones. By contrast, the MSRP of the MacBook laptop lines have dropped through successive generations such that the MacBook Air and MacBook Pro constitute the lowest price of entry to a Mac, with the exception of the even more inexpensive Mac Mini (albeit without a monitor and keyboard), not surprisingly the MacBooks are the top-selling form factors of the Macintosh platform today.The decades of development mean that most people already own desktop computers that meet their needs and have no need of buying a new one merely to keep pace with advancing technology. Notably, the successive release of new versions of Windows (Windows 95, 98, XP, Vista, 7, 8, 10 and so on) had been drivers for the replacement of PCs in the 1990s, but this slowed in the 2000s due to the poor reception of Windows Vista over Windows XP. Recently, some analysts have suggested that Windows 8 has actually hurt sales of PCs in 2012, as businesses have decided to stick with Windows 7 rather than upgrade. Some suggested that Microsoft has acknowledged ""implicitly ringing the desktop PC death knell"" as Windows 8 offers little upgrade in desktop PC functionality over Windows 7; instead, Windows 8's innovations are mostly on the mobile side.The post-PC trend has seen a decline in the sales of desktop and laptop PCs. The decline has been attributed to increased power and applications of alternative computing devices, namely smartphones and tablet computers. Although most people exclusively use their smartphones and tablets for more basic tasks such as social media and casual gaming, these devices have in many instances replaced a second or third PC in the household that would have performed these tasks, though most families still retain a powerful PC for serious work.Among PC form factors, desktops remain a staple in the enterprise market but have lost popularity among home buyers. PC makers and electronics retailers have responded by investing their engineering and marketing resources towards laptops (initially netbooks in the late 2000s, and then the higher-performance Ultrabooks from 2011 onwards), which manufacturers believe have more potential to revive the PC market than desktops.
In April 2017, StatCounter declared a ""Milestone in technology history and end of an era"" with the Android operating system more popular than Windows (the operating system that made desktops dominant over mainframe computers). Windows is still most popular on desktops (and laptops), while smartphones (and tablets) use Android, iOS (Apple products) or Windows 10 Mobile.


=== Resurgence ===
Although for casual use traditional desktops and laptops have seen a decline in sales, in 2018, global PC sales experienced a resurgence, driven by the business market. Desktops remain a solid fixture in the commercial and educational sectors. In addition, gaming desktops have seen a global revenue increase of 54% annually. For gaming, the global market of gaming desktops, laptops, and monitors is expected to grow to 61.1 million shipments by the end of 2023, up from 42.1 million, with desktops growing from 15.1 million shipments to 19 million. PC gaming as a whole now accounts for 28% of the total gaming market as of 2017. This is partially due to the increasing affordability of desktop PCs.


== Types ==


=== Full-sized ===
Full-sized desktops are characterized by separate display and processing components. These components are connected to each other by cables or wireless connections. They often come in a tower form factor. These computers are easy to customize and upgrade per user requirements, e.g. by expansion card.


=== All-in-one ===

An all-in-one desktop computer integrates the system's internal components into the same case as the display, thus occupying a smaller footprint (with fewer cables) than desktops that incorporate a tower.The all-in-one form factor was popular during the early 1980s for personal computers intended for professional use such as the Kaypro II, Osborne 1, TRS-80 Model II and Compaq Portable. Many manufacturers of home computers like Commodore and Atari included the computer's motherboard into the same enclosure as the keyboard; these systems were most often connected to a television set for display. Apple has manufactured several popular examples of all-in-one computers, such as the original Macintosh of the mid-1980s and the iMac of the late 1990s and 2000s. Some all-in-one desktops, such as the iMac G4, have used laptop components in order to reduce the size of the system case.  By the mid 2000s, many all-in-one designs have used flat panel displays, and later models have incorporated touchscreen displays, allowing them to be used similarly to a mobile tablet.Like most laptops, some all-in-one desktop computers are characterized by an inability to customize or upgrade internal components, as the systems' cases do not provide convenient access to upgradable components, and faults in certain aspects of the hardware may require the entire computer to be replaced, regardless of the health of its remaining components. There have been exceptions to this; the monitor portion of HP's Z1 workstation can be angled flat, and opened like a vehicle hood for access to internal hardware.


=== Compact ===
Compact desktops are reduced in physical proportions compared to full-sized desktops. They are typically small-sized, inexpensive, low-power computers designed for basic tasks such as web browsing, accessing web-based applications, document processing, and audio/video playback. Hardware specifications and processing power are usually reduced and hence make them less appropriate for running complex or resource-intensive applications. A nettop is an example of a compact desktop.


=== Home theater ===
These desktops are connected to home entertainment systems and typically used for amusement purpose. They come with high definition display, video graphics, surround sound and TV tuner systems to complement typical PC features.


=== Thin clients ===
Over time some traditional desktop computers have been replaced with thin clients utilizing off-site computing solutions like the cloud. As more services and applications are served over the internet from off-site servers, local computing needs decrease, this drives desktop computers to be smaller, cheaper, and need less powerful hardware. More applications and in some cases entire virtual desktops are moved off-site and the desktop computer only runs an operating system or a shell application while the actual content is served from a server.  Thin client computers may do almost all of their computing on a virtual machine in another site. Internal, hosted virtual desktops can offer users a completely consistent experience from anywhere.


== Comparison with laptops ==

Desktops have an advantage over laptops in that the spare parts and extensions tend to be standardized, resulting in lower prices and greater availability. For example, the size and mounting of the motherboard are standardized into ATX, microATX, BTX or other form factors. Desktops have several standardized expansion slots, like conventional PCI or PCI Express, while laptops only tend to have one mini-PCI slot and one PC Card slot (or ExpressCard slot). Procedures for assembly and disassembly of desktops tend to be simple and standardized as well. This tends not to be the case for laptops, though adding or replacing some parts, like the optical drive, hard disk, or adding an extra memory module is often quite simple. This means that a desktop computer configuration, usually a tower case, can be customized and upgraded to a greater extent than laptops. This customization has kept tower cases popular among gamers and enthusiasts.
Another advantage of the desktop is that (apart from environmental concerns) power consumption is not as critical as in laptop computers because the desktop is exclusively powered from the wall socket. Desktop computers also provide more space for cooling fans and vents to dissipate heat, allowing enthusiasts to overclock with less risk. The two large microprocessor manufacturers, Intel and AMD, have developed special CPUs for mobile computers (i.e. laptops) that consume less power and lower heat, but with lower performance levels.
Laptop computers, conversely, offer portability that desktop systems (including small form factor and all-in-one desktops) can not due to their compact size and clamshell design. The laptop's all-in-one design provides a built-in keyboard and a pointing device (such as a trackpad) for its user and can draw on power supplied by a rechargeable battery. Laptops also commonly integrate wireless technologies like WiFi, Bluetooth, and 3G, giving them a broader range of options for connecting to the internet, though this trend is changing as newer desktop computers come integrated with one or more of these technologies.
A desktop computer needs a UPS to handle electrical disturbances like short interruptions, blackouts, and spikes; achieving an on-battery time of more than 20–30 minutes for a desktop PC requires a large and expensive UPS. A laptop with a sufficiently charged battery can continue to be used for hours in case of a power outage and is not affected by short power interruptions and blackouts.
A desktop computer often has the advantage over a comparable laptop in computational capacity. Overclocking is often more feasible on a desktop than on a laptop; similarly, hardware add-ons such as discrete graphics co-processors may only be possible to install in a desktop.


== See also ==


== References ==


== External links ==
Computer Tour –  of major components of a desktop computers at HowStuffWorks
Desktop Vs Laptops"
"Application software (app for short) is a program or group of programs designed for end users. Examples of an application include a word processor, a spreadsheet, an accounting application, a web browser, an email client, a media player, a file viewer, simulators, a console game or a photo editor. The collective noun application software refers to all applications collectively. This contrasts with system software, which is mainly involved with running the computer.
Applications may be bundled with the computer and its system software or published separately, and may be coded as proprietary, open-source or university projects. Apps built for mobile platforms are called mobile apps.


== Terminology ==
In information technology, an application (app), application program or application software is a computer program designed to help people perform an activity. Depending on the activity for which it was designed, an application can manipulate text, numbers, audio, graphics and a combination of these elements. Some application packages focus on a single task, such as word processing; others, called integrated software include several applications.User-written software tailors systems to meet the user's specific needs. User-written software includes spreadsheet templates, word processor macros, scientific simulations, audio, graphics, and animation scripts. Even email filters are a kind of user software. Users create this software themselves and often overlook how important it is.
The delineation between system software such as operating systems and application software is not exact, however, and is occasionally the object of controversy.  For example, one of the key questions in the United States v. Microsoft Corp. antitrust trial was whether Microsoft's Internet Explorer web browser was part of its Windows operating system or a separable piece of application software.  As another example, the GNU/Linux naming controversy is, in part, due to disagreement about the relationship between the Linux kernel and the operating systems built over this kernel. In some types of embedded systems, the application software and the operating system software may be indistinguishable to the user, as in the case of software used to control a VCR, DVD player or microwave oven. The above definitions may exclude some applications that may exist on some computers in large organizations. For an alternative definition of an app:  see Application Portfolio Management.


=== Metonymy ===
The word ""application"" used as an adjective is not restricted to the ""of or pertaining to application software"" meaning. For example, concepts such as application programming interface (API), application server, application virtualization, application lifecycle management and portable application apply to all computer programs alike, not just application software.


=== Apps and killer apps ===

Some applications are available in versions for several different platforms; others only work on one and are thus called, for example, a geography application for Microsoft Windows, or an Android application for education, or a Linux game.  Sometimes a new and popular application arises which only runs on one platform, increasing the desirability of that platform.  This is called a killer application or killer app. For example, VisiCalc was the first modern spreadsheet software for the Apple II and helped selling the then-new personal computers into offices. For Blackberry it was their email software.
In recent years, the shortened term ""app"" (coined in 1981 or earlier) has become popular to refer to applications for mobile devices such as smartphones and tablets, the shortened form matching their typically smaller scope compared to applications on PCs. Even more recently, the shortened version is used for desktop application software as well.


== Classification ==
There are many different and alternative ways in order to classify  application software.
By the legal point of view, application software is mainly classified with a black box approach, in relation to the rights of its final end-users or subscribers (with eventual intermediate and tiered subscription levels).
Software applications are also classified in respect of the programming language in which the source code is written or executed, and respect of their purpose and outputs.


=== By property and use rights ===
Application software is usually distinguished among two main classes: closed source vs open source software applications, and among free or proprietary software applications.
Proprietary software is placed under the exclusive copyright, and a software license grants limited usage rights. The open-closed principle states that software may be ""open only for extension, but not for modification"". Such applications can only get add-on by third-parties.
Free and open-source software shall be run, distributed, sold or extended for any purpose, and -being open- shall be modified or reversed in the same way.
FOSS software applications released under a free license may be perpetual and also royalty-free. Perhaps, the owner, the holder or third-party enforcer of any right (copyright, trademark, patent, or ius in re aliena) are entitled to add exceptions, limitations, time decays or expiring dates to the license terms of use.
Public-domain software is a type of FOSS, which is royalty-free and - openly or reservedly- can be run, distributed, modified, reversed, republished or created in derivative works without any copyright attribution and therefore revocation. It can even be sold, but without transferring the public domain property to other single subjects. Public-domain SW can be released under an (un)licens
ing legal statement, which enforces those terms and conditions for an indefinite duration (for a lifetime, or forever).


=== By coding language ===
Since the development and near-universal adoption of the web, an important distinction that has emerged, has been between web applications — written with HTML, JavaScript and other web-native technologies and typically requiring one to be online and running a web browser, and the more traditional native applications written in whatever languages are available for one's particular type of computer. There has been a contentious debate in the computing community regarding web applications replacing native applications for many purposes, especially on mobile devices such as smartphones and tablets. Web apps have indeed greatly increased in popularity for some uses, but the advantages of applications make them unlikely to disappear soon, if ever. Furthermore, the two can be complementary, and even integrated.


=== By purpose and output ===
Application software can also be seen as being either horizontal or vertical.  Horizontal applications are more popular and widespread, because they are general purpose, for example word processors or databases. Vertical applications are niche products, designed for a particular type of industry or business, or department within an organization. Integrated suites of software will try to handle every specific aspect possible of, for example, manufacturing or banking worker, or accounting, or customer service.
There are many types of application software:

An application suite consists of multiple applications bundled together. They usually have related functions, features and user interfaces, and may be able to interact with each other, e.g. open each other's files. Business applications often come in suites, e.g. Microsoft Office, LibreOffice and iWork, which bundle together a word processor, a spreadsheet, etc.; but suites exist for other purposes, e.g. graphics or music.
Enterprise software addresses the needs of an entire organization's processes and data flows, across several departments, often in a large distributed environment.  Examples include enterprise resource planning systems, customer relationship management (CRM) systems and supply chain management software. Departmental Software is a sub-type of enterprise software with a focus on smaller organizations or groups within a large organization. (Examples include travel expense management and IT Helpdesk.)
Enterprise infrastructure software provides common capabilities needed to support enterprise software systems.  (Examples include databases, email servers, and systems for managing networks and security.)
Application platform as a service (aPaaS) is a cloud computing service that offers development and deployment environments for application services.
Information worker software lets users create and manage information, often for individual projects within a department, in contrast to enterprise management. Examples include time management, resource management, analytical, collaborative and documentation tools. Word processors, spreadsheets, email and blog clients, personal information system, and individual media editors may aid in multiple information worker tasks.
Content access software is used primarily to access content without editing, but may include software that allows for content editing. Such software addresses the needs of individuals and groups to consume digital entertainment and published digital content. (Examples include media players, web browsers, and help browsers.)
Educational software is related to content access software, but has the content or features adapted for use in by educators or students. For example, it may deliver evaluations (tests), track progress through material, or include collaborative capabilities.
Simulation software simulates physical or abstract systems for either research, training or entertainment purposes.
Media development software generates print and electronic media for others to consume, most often in a commercial or educational setting. This includes graphic-art software, desktop publishing software, multimedia development software, HTML editors, digital-animation editors, digital audio and video composition, and many others.
Product engineering software is used in developing hardware and software products. This includes computer-aided design (CAD), computer-aided engineering (CAE), computer language editing and compiling tools, integrated development environments, and application programmer interfaces.
Entertainment Software can refer to video games, screen savers, programs to display motion pictures or play recorded music, and other forms of entertainment which can be experienced through use of a computing device.Applications can also be classified by computing platform such as a particular operating system, delivery network such as in cloud computing and Web 2.0 applications, or delivery devices such as mobile apps for mobile devices.
The operating system itself can be considered application software when performing simple calculating, measuring, rendering, and word processing tasks not used to control hardware via command-line interface or graphical user interface. This does not include application software bundled within operating systems such as a software calculator or text editor.


=== Information worker software ===
Accounting software
Data management
Contact manager
Spreadsheet
Database software
Documentation
Document automation
Word processor
Desktop publishing software
Diagramming software
Presentation software
Email
Blog software
Enterprise resource planning
Financial software
Day trading software
Banking software
Clearing systems
Arithmetic software
Field service management
Workforce management software
Project management software
Calendaring software
Employee scheduling software
Workflow software
Reservation systems


=== Entertainment software ===
Screen savers
Video games
Arcade games
Console games
Mobile games
Personal computer games
Software art
Demo
64K intro


=== Educational software ===

Classroom management
Reference software
Sales readiness software
Survey management
Encyclopedia software


=== Enterprise infrastructure software ===
Business workflow software
Database management system (DBMS)
Digital asset management (DAM) software
Document management software
Geographic information system (GIS)


=== Simulation software ===
Computer simulators
Scientific simulators
Social simulators
Battlefield simulators
Emergency simulators
Vehicle simulators
Flight simulators
Driving simulators
Simulation games
Vehicle simulation games


=== Media development software ===
3D computer graphics software
Animation software
Graphic art software
Raster graphics editor
Vector graphics editor
Image organizer
Video editing software
Audio editing software
Digital audio workstation
Music sequencer
Scorewriter
HTML editor
Game development tool


=== Product engineering software ===
Hardware engineering
Computer-aided engineering
Computer-aided design (CAD)
Computer-aided manufacturing (CAM)
Finite element analysis


=== Software engineering ===
Compiler software
Integrated development environment
Compiler
Linker
Debugger
Version control
Game development tool
License manager


== See also ==
Software development
Mobile app
Web application


== References ==


== External links ==
 Learning materials related to Application software at Wikiversity"
